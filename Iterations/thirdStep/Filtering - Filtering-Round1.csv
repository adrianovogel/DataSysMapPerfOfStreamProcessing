Bib Key,Title,Abstract,Not in English,Not a scientific paper,Not peer-reviewed,No scalable stream processing,No real-world scenario performance benchmarking and insights,Optimizations,R1,R2,Final decision,Authors,Year,Publisher,Doi,Source
Mullen20152553,Real-time neuroimaging and cognitive monitoring using wearable dry EEG,"Goal: We present and evaluate a wearable high-density dry-electrode EEG system and an open-source software framework for online neuroimaging and state classification. Methods: The system integrates a 64-channel dry EEG form factor with wireless data streaming for online analysis. A real-time software framework is applied, including adaptive artifact rejection, cortical source localization, multivariate effective connectivity inference, data visualization, and cognitive state classification from connectivity features using a constrained logistic regression approach (ProxConn). We evaluate the system identification methods on simulated 64-channel EEG data. Then, we evaluate system performance, using ProxConn and a benchmark ERP method, in classifying response errors in nine subjects using the dry EEG system. Results: Simulations yielded high accuracy (AUC = 0.97 ± 0.021) for real-time cortical connectivity estimation. Response error classification using cortical effective connectivity [short-time direct-directed transfer function (sdDTF)] was significantly above chance with similar performance (AUC) for cLORETA (0.74 ± 0.09) and LCMV (0.72 ± 0.08) source localization. Cortical ERP-based classification was equivalent to ProxConn for cLORETA (0.74 ± 0.16) but significantly better for LCMV (0.82 ± 0.12). Conclusion: We demonstrated the feasibility for real-time cortical connectivity analysis and cognitive state classification from high-density wearable dry EEG. Significance: This paper is the first validated application of these methods to 64-channel dry EEG. This study addresses a need for robust real-time measurement and interpretation of complex brain activity in the dynamic environment of the wearable setting. Such advances can have broad impact in research, medicine, and brain-computer interfaces. The pipelines are made freely available in the open-source SIFT and BCILAB toolboxes. © 1964-2012 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Mullen, T.R. and Kothe, C.A.E. and Chi, Y.M. and Ojeda, A. and Kerth, T. and Makeig, S. and Jung, T.-P. and Cauwenberghs, G.",2015,IEEE Transactions on Biomedical Engineering,10.1109/TBME.2015.2481482,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Le-Phuoc2011370,A native and adaptive approach for unified processing of linked streams and linked data,"In this paper we address the problem of scalable, native and adaptive query processing over Linked Stream Data integrated with Linked Data. Linked Stream Data consists of data generated by stream sources, e.g., sensors, enriched with semantic descriptions, following the standards proposed for Linked Data. This enables the integration of stream data with Linked Data collections and facilitates a wide range of novel applications. Currently available systems use a ""black box"" approach which delegates the processing to other engines such as stream/event processing engines and SPARQL query processors by translating to their provided languages. As the experimental results described in this paper show, the need for query translation and data transformation, as well as the lack of full control over the query execution, pose major drawbacks in terms of efficiency. To remedy these drawbacks, we present CQELS (Continuous Query Evaluation over Linked Streams), a native and adaptive query processor for unified query processing over Linked Stream Data and Linked Data. In contrast to the existing systems, CQELS uses a ""white box"" approach and implements the required query operators natively to avoid the overhead and limitations of closed system regimes. CQELS provides a flexible query execution framework with the query processor dynamically adapting to the changes in the input data. During query execution, it continuously reorders operators according to some heuristics to achieve improved query execution in terms of delay and complexity. Moreover, external disk access on large Linked Data collections is reduced with the use of data encoding and caching of intermediate query results. To demonstrate the efficiency of our approach, we present extensive experimental performance evaluations in terms of query execution time, under varied query types, dataset sizes, and number of parallel queries. These results show that CQELS outperforms related approaches by orders of magnitude. © 2011 Springer-Verlag.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Le-Phuoc, D. and Dao-Tran, M. and XavierParreira, J. and Hauswirth, M.",2011,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-642-25073-6_24,scopus-search1.bib
Fernandez2013725,Integrating scale out and fault tolerance in stream processing using operator state management,"As users of ""big data"" applications expect fresh results, we witness a new breed of stream processing systems (SPS) that are designed to scale to large numbers of cloud-hosted machines. Such systems face new challenges: (i) to benefit from the ""pay-as-you-go"" model of cloud computing, they must scale out on demand, acquiring additional virtual machines (VMs) and parallelising operators when the workload increases; (ii) failures are common with deployments on hundreds of VMs - systems must be fault-tolerant with fast recovery times, yet low per-machine overheads. An open question is how to achieve these two goals when stream queries include stateful operators, which must be scaled out and recovered without affecting query results. Our key idea is to expose internal operator state explicitly to the SPS through a set of state management primitives. Based on them, we describe an integrated approach for dynamic scale out and recovery of stateful operators. Externalised operator state is checkpointed periodically by the SPS and backed up to upstream VMs. The SPS identifies individual operator bottlenecks and automatically scales them out by allocating new VMs and partitioning the check-pointed state. At any point, failed operators are recovered by restoring checkpointed state on a new VM and replaying unprocessed tuples. We evaluate this approach with the Linear Road Benchmark on the Amazon EC2 cloud platform and show that it can scale automatically to a load factor of L=350 with 50 VMs, while recovering quickly from failures. Copyright © 2013 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Fernandez, R.C. and Migliavacca, M. and Kalyvianaki, E. and Pietzuch, P.",2013,Proceedings of the ACM SIGMOD International Conference on Management of Data,10.1145/2463676.2465282,scopus-search1.bib;acm2-search1.bib
Baccarelli20179882,"Fog of Everything: Energy-Efficient Networked Computing Architectures, Research Challenges, and a Case Study","Fog computing (FC) and Internet of Everything (IoE) are two emerging technological paradigms that, to date, have been considered standing-alone. However, because of their complementary features, we expect that their integration can foster a number of computing and network-intensive pervasive applications under the incoming realm of the future Internet. Motivated by this consideration, the goal of this position paper is fivefold. First, we review the technological attributes and platforms proposed in the current literature for the standing-alone FC and IoE paradigms. Second, by leveraging some use cases as illustrative examples, we point out that the integration of the FC and IoE paradigms may give rise to opportunities for new applications in the realms of the IoE, Smart City, Industry 4.0, and Big Data Streaming, while introducing new open issues. Third, we propose a novel technological paradigm, the Fog of Everything (FoE) paradigm, that integrates FC and IoE and then we detail the main building blocks and services of the corresponding technological platform and protocol stack. Fourth, as a proof-of-concept, we present the simulated energy-delay performance of a small-scale FoE prototype, namely, the V-FoE prototype. Afterward, we compare the obtained performance with the corresponding one of a benchmark technological platform, e.g., the V-D2D one. It exploits only device-to-device links to establish inter-thing 'ad hoc' communication. Last, we point out the position of the proposed FoE paradigm over a spectrum of seemingly related recent research projects. © 2017 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Baccarelli, E. and Naranjo, P.G.V. and Scarpiniti, M. and Shojafar, M. and Abawajy, J.H.",2017,IEEE Access,10.1109/ACCESS.2017.2702013,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Chintapalli20161789,"Benchmarking streaming computation engines: Storm, flink and spark streaming","Streaming data processing has been gaining attention due to its application into a wide range of scenarios. To serve the booming demands of streaming data processing, many computation engines have been developed. However, there is still a lack of real-world benchmarks that would be helpful when choosing the most appropriate platform for serving real-time streaming needs. In order to address this problem, we developed a streaming benchmark for three representative computation engines: Flink, Storm and Spark Streaming. Instead of testing speed-of-light event processing, we construct a full data pipeline using Kafka and Redis in order to more closely mimic the real-world production scenarios. Based on our experiments, we provide a performance comparison of the three data engines in terms of 99th percentile latency and throughput for various configurations. © 2016 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Chintapalli, S. and Dagit, D. and Evans, B. and Farivar, R. and Graves, T. and Holderbaugh, M. and Liu, Z. and Nusbaum, K. and Patil, K. and Peng, B.J. and Poulosky, P.",2016,"Proceedings - 2016 IEEE 30th International Parallel and Distributed Processing Symposium, IPDPS 2016",10.1109/IPDPSW.2016.138,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Jain2006431,"Design, implementation, and evaluation of the linear road bnchmark on the stream processing core","Stream processing applications have recently gained significant attention in the networking and database community. At the core of these applications is a stream processing engine that performs resource allocation and management to support continuous tracking of queries over collections of physically- distributed and rapidly-updating data streams. While numerous stream processing systems exist, there has been little work on understanding the performance characteristics of these applications in a distributed setup. In this paper, we examine the performance bottlenecks of streaming data applications, in particular the Linear Road stream data management benchmark, in achieving good performance in large-scale distributed environments, using the Stream Processing Core (SPC), a stream processing middleware we have developed. First, we present the design and implementation of the Linear Road benchmark on the SPC middleware. SPC has been designed to scale to tens of thousands of processing nodes, while supporting concurrent applications and multiple simultaneous queries. Second, we identify the main performance bottlenecks in the Linear Road application in achieving scalability and low query response latency. Our results show that data locality, buffer capacity, physical allocation of processing elements to infrastructure nodes, and packaging for transporting streamed data are important factors in achieving good application performance. Though we evaluate our system primarily for the Linear Road application, we believe it also provides useful insights into the overall system behavior for supporting other distributed and large-scale continuous streaming data applications. Finally, we examine how SPC can be used and tuned to enable a very efficient implementation of the Linear Road application in a distributed environment. Copyright 2006 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Jain, N. and Amini, L. and Andrade, H. and King, R. and Park, Y. and Selo, P. and Venkatramani, C.",2006,Proceedings of the ACM SIGMOD International Conference on Management of Data,10.1145/1142473.1142522,scopus-search1.bib;acm1-search1.bib
Peng2015149,R-storm: Resource-aware scheduling in storm,"The era of big data has led to the emergence of new systems for real-time distributed stream processing, e.g., Apache Storm is one of the most popular stream processing systems in in- dustry today. However, Storm, like many other stream pro- cessing systems lacks an intelligent scheduling mechanism. The default round-robin scheduling currently deployed in Storm disregards resource demands and availability, and can therefore be inefficient at times. We present R-Storm (Resource-Aware Storm), a system that implements resource- aware scheduling within Storm. R-Storm is designed to in- crease overall throughput by maximizing resource utilization while minimizing network latency. When scheduling tasks, R-Storm can satisfy both soft and hard resource constraints as well as minimizing network distance between components that communicate with each other. We evaluate R-Storm on set of micro-benchmark Storm applications as well as Storm applications used in production at Yahoo! Inc. From our experimental results we conclude that R-Storm achieves 30-47% higher throughput and 69-350% better CPU utiliza- tion than default Storm for the micro-benchmarks. For the Yahoo! Storm applications, R-Storm outperforms default Storm by around 50% based on overall throughput. We also demonstrate that R-Storm performs much better when scheduling multiple Storm applications than default Storm. © 2015 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Peng, B. and Hosseini, M. and Hong, Z. and Farivar, R. and Campbell, R.",2015,Middleware 2015 - Proceedings of the 16th Annual Middleware Conference,10.1145/2814576.2814808,scopus-search1.bib;web-of-science-search1.bib;acm1-search1.bib
Eager2001742,Minimizing bandwidth requirements for on-demand data delivery,"Two recent techniques for multicast or broadcast delivery of streaming media can provide immediate service to each client request, yet achieve considerable client stream sharing which leads to significant server and network bandwidth savings. This paper considers 1) how well these recently proposed techniques perform relative to each other and 2) whether there are new practical delivery techniques that can achieve better bandwidth savings than the previous techniques over a wide range of client request rates. The principal results are as follows: First, the recent partitioned dynamic skyscraper technique is adapted to provide immediate service to each client request more simply and directly than the original dynamic skyscraper method. Second, at moderate to high client request rates, the dynamic skyscraper method has required server bandwidth that is significantly lower than the recent optimized stream tapping/patching/controlled multicast technique. Third, the minimum required server bandwidth for any delivery technique that provides immediate real-time delivery to clients increases logarithmically (with constant factor equal to one) as a function of the client request arrival rate. Furthermore, it is (theoretically) possible to achieve very close to the minimum required server bandwidth if client receive bandwidth is equal to two times the data streaming rate and client storage capacity is sufficient for buffering data from shared streams. Finally, we propose a new practical delivery technique, called hierarchical multicast stream merging (HMSM), which has a required server bandwidth that is lower than the partitioned dynamic skyscraper and is reasonably close to the minimum achievable required server bandwidth over a wide range of client request rates.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Eager, D. and Vernon, M. and Zahorjan, J.",2001,IEEE Transactions on Knowledge and Data Engineering,10.1109/69.956098,scopus-search1.bib;web-of-science-search1.bib
Satyanarayan2016659,Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization,"We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system. © 1995-2012 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Satyanarayan, A. and Russell, R. and Hoffswell, J. and Heer, J.",2016,IEEE Transactions on Visualization and Computer Graphics,10.1109/TVCG.2015.2467091,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Amini200627,"SPC: A distributed, scalable platform for data mining","The Stream Processing Core (SPC) is distributed stream processing middleware designed to support applications that extract information from a large number of digital data streams. In this paper, we describe the SPC programming model which, to the best of our knowledge, is the first to support stream-mining applications using a subscription-like model for specifying stream connections as well as to provide support for non-relational operators. This enables stream-mining applications to tap into, analyze and track an ever-changing array of data streams which may contain information relevant to the streaming-queries placed on it. We describe the design, implementation, and experimental evaluation of the SPC distributed middleware, which deploys applications on to the running system in an incremental fashion, making stream connections as required. Using micro-benchmarks and a representative large-scale synthetic stream-mining application, we evaluate the performance of the control and data paths of the SPC middleware. Copyright 2006 ACM.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Amini, L. and Andrade, H. and Bhagwan, R. and Eskesen, F. and King, R. and Selo, P. and Park, Y. and Venkatramani, C.",2006,"4th International Workshop on Data Mining Standards, Services and Platforms",10.1145/1289612.1289615,scopus-search1.bib;acm2-search1.bib
Green2004752,Processing XML streams with deterministic automata and stream indexes,"We consider the problem of evaluating a large number of XPath expressions on a stream of XML packets. We contribute two novel techniques. The first is to use a single Deterministic Finite Automaton (DFA). The contribution here is to show that the DFA can be used effectively for this problem: in our experiments we achieve a constant throughput, independently of the number of XPath expressions. The major issue is the size of the DFA, which, in theory, can be exponential in the number of XPath expressions. We provide a series of theoretical results and experimental evaluations that show that the lazy DFA has a small number of states, for all practical purposes. These results are of general interest in XPath processing, beyond stream processing. The second technique is the Streaming IndeX (SLK), which consists of adding a small amount of binary data to each XML packet that allows the query processor to achieve significant speedups. As an application of these techniques we describe the XML Toolkit (XMLTK), a collection of command-line tools providing highly scalable XML data processing.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Green, T.J. and Gupta, A. and Miklau, G. and Onizuka, M. and Suciu, D.",2004,ACM Transactions on Database Systems,10.1145/1042046.1042051,scopus-search1.bib
He201063,Comet: Batched stream processing for data intensive distributed computing,"Batched stream processing is a new distributed data processing paradigm that models recurring batch computations on incrementally bulk-appended data streams. The model is inspired by our empirical study on a trace from a large-scale production data-processing cluster; it allows a set of effective query optimizations that are not possible in a traditional batch processing model. We have developed a query processing system called Comet that embraces batched stream processing and integrates with DryadLINQ. We used two complementary methods to evaluate the effectiveness of optimizations that Comet enables. First, a prototype system deployed on a 40-node cluster shows an I/O reduction of over 40% using our benchmark. Second, when applied to a real production trace covering over 19 million machine-hours, our simulator shows an estimated I/O saving of over 50%. Copyright 2010 ACM.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"He, B. and Yang, M. and Guo, Z. and Chen, R. and Su, B. and Lin, W. and Zhou, L.",2010,"Proceedings of the 1st ACM Symposium on Cloud Computing, SoCC '10",10.1145/1807128.1807139,scopus-search1.bib;acm1-search1.bib
Cardellini2016271,On QoS-Aware scheduling of data stream applications over fog computing infrastructures,"Fog computing is rapidly changing the distributed computing landscape by extending the Cloud computing paradigm to include wide-spread resources located at the network edges. This diffused infrastructure is well suited for the implementation of data stream processing (DSP) applications, by possibly exploiting local computing resources. Storm is an open source, scalable, and fault-Tolerant DSP system designed for locally distributed clusters. We made it suitable to operate in a geographically distributed and highly variable environment; to this end, we extended Storm with new components that allow to execute a distributed QoS-Aware scheduler and give self-Adaptation capabilities to the system. In this paper we provide a thorough experimental evaluation of the proposed solution using two sets of DSP applications: The former is characterized by a simple topology with different requirements; the latter comprises some well known applications (i.e., Word Count, Log Processing). The results show that the distributed QoS-Aware scheduler outperforms the centralized default one, improving the application performance and enhancing the system with runtime adaptation capabilities. However, complex topologies involving many operators may cause some instability that can decrease the DSP application availability. © 2015 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Cardellini, V. and Grassi, V. and Presti, F.L. and Nardelli, M.",2015,Proceedings - IEEE Symposium on Computers and Communications,10.1109/ISCC.2015.7405527,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Karimov20181519,Benchmarking distributed stream data processing systems,"The need for scalable and efficient stream analysis has led to the development of many open-source streaming data processing systems (SDPSs) with highly diverging capabilities and performance characteristics. While first initiatives try to compare the systems for simple workloads, there is a clear gap of detailed analyses of the systems' performance characteristics. In this paper, we propose a framework for benchmarking distributed stream processing engines. We use our suite to evaluate the performance of three widely used SDPSs in detail, namely Apache Storm, Apache Spark, and Apache Flink. Our evaluation focuses in particular on measuring the throughput and latency of windowed operations, which are the basic type of operations in stream analytics. For this benchmark, we design workloads based on real-life, industrial use-cases inspired by the online gaming industry. The contribution of our work is threefold. First, we give a definition of latency and throughput for stateful operators. Second, we carefully separate the system under test and driver, in order to correctly represent the open world model of typical stream processing deployments and can, therefore, measure system performance under realistic conditions. Third, we build the first benchmarking framework to define and test the sustainable performance of streaming systems. Our detailed evaluation highlights the individual characteristics and use-cases of each system. © 2018 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Karimov, J. and Rabl, T. and Katsifodimos, A. and Samarev, R. and Heiskanen, H. and Markl, V.",2018,"Proceedings - IEEE 34th International Conference on Data Engineering, ICDE 2018",10.1109/ICDE.2018.00169,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib;scholar.bib
Lohrmann2015399,Elastic Stream Processing with Latency Guarantees,"Many Big Data applications in science and industry have arisen, that require large amounts of streamed or event data to be analyzed with low latency. This paper presents a reactive strategy to enforce latency guarantees in data flows running on scalable Stream Processing Engines (SPEs), while minimizing resource consumption. We introduce a model for estimating the latency of a data flow, when the degrees of parallelism of the tasks within are changed. We describe how to continuously measure the necessary performance metrics for the model, and how it can be used to enforce latency guarantees, by determining appropriate scaling actions at runtime. Therefore, it leverages the elasticity inherent to common cloud technology and cluster resource management systems. We have implemented our strategy as part of the Nephele SPE. To showcase the effectiveness of our approach, we provide an experimental evaluation on a large commodity cluster, using both a synthetic workload as well as an application performing real-time sentiment analysis on real-world social media data. © 2015 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,EXCLUDED,EXCLUDED,,"Lohrmann, B. and Janacik, P. and Kao, O.",2015,Proceedings - International Conference on Distributed Computing Systems,10.1109/ICDCS.2015.48,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Venkataraman2017374,Drizzle: Fast and Adaptable Stream Processing at Scale,"Large scale streaming systems aim to provide high throughput and low latency. They are often used to run mission-critical applications, and must be available 24x7. Thus such systems need to adapt to failures and inherent changes in workloads, with minimal impact on latency and throughput. Unfortunately, existing solutions require operators to choose between achieving low latency during normal operation and incurring minimal impact during adaptation. Continuous operator streaming systems, such as Naiad and Flink, provide low latency during normal execution but incur high overheads during adaptation (e.g., recovery), while micro-batch systems, such as Spark Streaming and FlumeJava, adapt rapidly at the cost of high latency during normal operations. Our key observation is that while streaming workloads require millisecond-level processing, workload and cluster properties change less frequently. Based on this, we develop Drizzle, a system that decouples the processing interval from the coordination interval used for fault tolerance and adaptability. Our experiments on a 128 node EC2 cluster show that on the Yahoo Streaming Benchmark, Drizzle can achieve end-to-end record processing latencies of less than 100ms and can get 2–3x lower latency than Spark. Drizzle also exhibits better adaptability, and can recover from failures 4x faster than Flink while having up to 13x lower latency during recovery. © 2017 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Venkataraman, S. and Armbrust, M. and Panda, A. and Ghodsi, A. and Ousterhout, K. and Franklin, M.J. and Recht, B. and Stoica, I.",2017,SOSP 2017 - Proceedings of the 26th ACM Symposium on Operating Systems Principles,10.1145/3132747.3132750,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Mokbel2005343,Continuous query processing of spatio-temporal data streams in PLACE,"The tremendous increase in the use of cellular phones, GPS-like devices, and RFIDs results in highly dynamic environments where objects as well as queries are continuously moving. In this paper, we present a continuous query processor designed specifically for highly dynamic environments (e.g., location-aware environments). We implemented the proposed continuous query processor inside the PLACE server (Pervasive Location-Aware Computing Environments); a scalable location-aware database server developed at Purdue University. The PLACE server extends data streaming management systems to support location-aware environments. These environments are characterized by the wide variety of continuous spatio-temporal queries and the unbounded spatio-temporal streams. The proposed continuous query processor includes: (1) New incremental spatio-temporal operators to support a wide variety of continuous spatio-temporal queries, (2) Extended semantics of sliding window queries to deal with spatial sliding windows as well as temporal sliding windows, and (3) A shared-execution framework for scalable execution of a set of concurrent continuous spatio-temporal queries. Experimental evaluation shows promising performance of the continuous query processor of the PLACE server. © 2005 Springer Science + Business Media, Inc.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Mokbel, M.F. and Xiong, X. and Aref, W.G. and Hammad, M.A.",2005,GeoInformatica,10.1007/s10707-005-4576-7,scopus-search1.bib;web-of-science-search1.bib
Kolajo2019,Big data stream analysis: a systematic literature review,"Recently, big data streams have become ubiquitous due to the fact that a number of applications generate a huge amount of data at a great velocity. This made it difficult for existing data mining tools, technologies, methods, and techniques to be applied directly on big data streams due to the inherent dynamic characteristics of big data. In this paper, a systematic review of big data streams analysis which employed a rigorous and methodical approach to look at the trends of big data stream tools and technologies as well as methods and techniques employed in analysing big data streams. It provides a global view of big data stream tools and technologies and its comparisons. Three major databases, Scopus, ScienceDirect and EBSCO, which indexes journals and conferences that are promoted by entities such as IEEE, ACM, SpringerLink, and Elsevier were explored as data sources. Out of the initial 2295 papers that resulted from the first search string, 47 papers were found to be relevant to our research questions after implementing the inclusion and exclusion criteria. The study found that scalability, privacy and load balancing issues as well as empirical analysis of big data streams and technologies are still open for further research efforts. We also found that although, significant research efforts have been directed to real-time analysis of big data stream not much attention has been given to the preprocessing stage of big data streams. Only a few big data streaming tools and technologies can do all of the batch, streaming, and iterative jobs; there seems to be no big data tool and technology that offers all the key features required for now and standard benchmark dataset for big data streaming analytics has not been widely adopted. In conclusion, it was recommended that research efforts should be geared towards developing scalable frameworks and algorithms that will accommodate data stream computing mode, effective resource allocation strategy and parallelization issues to cope with the ever-growing size and complexity of data. © 2019, The Author(s).",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,UNCERTAIN,UNCERTAIN,,"Kolajo, T. and Daramola, O. and Adebiyi, A.",2019,Journal of Big Data,10.1186/s40537-019-0210-7,scopus-search1.bib;web-of-science-search1.bib
Feng2008269,On large-scale peer-to-peer streaming Systems with Network Coding,"Live peer-to-peer (P2P) streaming has recently received much research attention, with successful commercial systems showing its viability in the Internet. Nevertheless, existing analytical studies of P2P streaming systems have failed to mathematically investigate and understand their critical properties, especially with a large scale and under extreme dynamics such as a flash crowd scenario. Even more importantly, there exists no prior analytical work that focuses on an entirely new way of designing streaming protocols, with the help of network coding. In this paper, we seek to show an in-depth analytical understanding of fundamental properties of P2P streaming systems, with a particular spotlight on the benefits of network coding. We show that, if network coding is used according to certain design principles, provably good performance can be guaranteed, with respect to high playback qualities, short initial buffering delays, resilience to peer dynamics, as well as minimal bandwidth costs on dedicated streaming servers. Our results are obtained with mathematical rigor, but without sacrificing realistic assumptions of system scale, peer dynamics, and upload capacities. For further insights, streaming systems using network coding are compared with traditional pull-based streaming in large-scale simulations, with a focus on fundamentals, rather than protocol details. The scale of our simulations throughout this paper exceeds 200, 000 peers at times, which is in sharp contrast with existing empirical studies, typically with a few hundred peers involved. Copyright 2008 ACM.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Feng, C. and Li, B.",2008,"MM'08 - Proceedings of the 2008 ACM International Conference on Multimedia, with co-located Symposium and Workshops",10.1145/1459359.1459396,scopus-search1.bib
Shukla2017,RIoTBench: An IoT benchmark for distributed stream processing systems,"The Internet of Things (IoT) is an emerging technology paradigm where millions of sensors and actuators help monitor and manage physical, environmental, and human systems in real time. The inherent closed-loop responsiveness and decision making of IoT applications make them ideal candidates for using low latency and scalable stream processing platforms. Distributed stream processing systems (DSPS) hosted in cloud data centers are becoming the vital engine for real-time data processing and analytics in any IoT software architecture. But the efficacy and performance of contemporary DSPS have not been rigorously studied for IoT applications and data streams. Here, we propose RIoTBench, a real-time IoT benchmark suite, along with performance metrics, to evaluate DSPS for streaming IoT applications. The benchmark includes 27 common IoT tasks classified across various functional categories and implemented as modular microbenchmarks. Further, we define four IoT application benchmarks composed from these tasks based on common patterns of data preprocessing, statistical summarization, and predictive analytics that are intrinsic to the closed-loop IoT decision-making life cycle. These are coupled with four stream workloads sourced from real IoT observations on smart cities and smart health, with peak streams rates that range from 500 to 10 000 messages/second from up to 3 million sensors. We validate the RIoTBench suite for the popular Apache Storm DSPS on the Microsoft Azure public cloud and present empirical observations. This suite can be used by DSPS researchers for performance analysis and resource scheduling, by IoT practitioners to evaluate DSPS platforms, and even reused within IoT solutions. Copyright © 2017 John Wiley & Sons, Ltd.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Shukla, A. and Chaturvedi, S. and Simmhan, Y.",2017,Concurrency and Computation: Practice and Experience,10.1002/cpe.4257,scopus-search1.bib;web-of-science-search1.bib;scholar.bib
Lu201469,Stream bench: Towards benchmarking modern distributed stream computing frameworks,"While big data is becoming ubiquitous, interest in handling data stream at scale is also gaining popularity, which leads to the sprout of many distributed stream computing systems. However, complexity of stream computing and diversity of workloads expose great challenges to benchmark these systems. Due to lack of standard criteria, evaluations and comparisons of these systems tend to be difficult. This paper takes an early step towards benchmarking modern distributed stream computing frameworks. After identifying the challenges and requirements in the field, we raise our benchmark definition Stream Bench regarding the requirements. Stream Bench proposes a message system functioning as a mediator between stream data generation and consumption. It also covers 7 benchmark programs that intend to address typical stream computing scenarios and core operations. Not only does it care about performance of systems under different data scales, but also takes fault tolerance ability and durability into account, which drives to incorporate four workload suites targeting at these various aspects of systems. Finally, we illustrate the feasibility of Stream Bench by applying it to two popular frameworks, Apache Storm and Apache Spark Streaming. We draw comparisons from various perspectives between the two platforms with workload suites of Stream Bench. In addition, we also demonstrate performance improvement of Storm's latest version with the benchmark. © 2014 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Lu, R. and Wu, G. and Xie, B. and Hu, J.",2014,"Proceedings - 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing, UCC 2014",10.1109/UCC.2014.15,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib;acm1-search1.bib
Zhang20162114,Parallel Processing Systems for Big Data: A Survey,"The volume, variety, and velocity properties of big data and the valuable information it contains have motivated the investigation of many new parallel data processing systems in addition to the approaches using traditional database management systems (DBMSs). MapReduce pioneered this paradigm change and rapidly became the primary big data processing system for its simplicity, scalability, and fine-grain fault tolerance. However, compared with DBMSs, MapReduce also arouses controversy in processing efficiency, low-level abstraction, and rigid dataflow. Inspired by MapReduce, nowadays the big data systems are blooming. Some of them follow MapReduce's idea, but with more flexible models for general-purpose usage. Some absorb the advantages of DBMSs with higher abstraction. There are also specific systems for certain applications, such as machine learning and stream data processing. To explore new research opportunities and assist users in selecting suitable processing systems for specific applications, this survey paper will give a high-level overview of the existing parallel data processing systems categorized by the data input as batch processing, stream processing, graph processing, and machine learning processing and introduce representative projects in each category. As the pioneer, the original MapReduce system, as well as its active variants and extensions on dataflow, data access, parameter tuning, communication, and energy optimizations will be discussed at first. System benchmarks and open issues for big data processing will also be studied in this survey. © 1963-2012 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,UNCERTAIN,UNCERTAIN,,"Zhang, Y. and Cao, T. and Li, S. and Tian, X. and Yuan, L. and Jia, H. and Vasilakos, A.V.",2016,Proceedings of the IEEE,10.1109/JPROC.2016.2591592,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Dayarathna2018,Recent advancements in event processing,"Event processing (EP) is a data processing technology that conducts online processing of event information. In this survey, we summarize the latest cutting-edge work done on EP from both industrial and academic research community viewpoints. We divide the entire field of EP into three subareas: EP system architectures, EP use cases, and EP open research topics. Then we deep dive into the details of each subsection. We investigate the system architecture characteristics of novel EP platforms, such as Apache Storm, Apache Spark, and Apache Flink. We found significant advancements made on novel application areas, such as the Internet of Things; streaming machine learning (ML); and processing of complex data types such as text, video data streams, and graphs. Furthermore, there has been significant body of contributions made on event ordering, system scalability, development of EP languages and exploration of use of heterogeneous devices for EP, which we investigate in the latter half of this article. Through our study, we found key areas that require significant attention from the EP community, such as Streaming ML, EP system benchmarking, and graph stream processing. © 2018 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,UNCERTAIN,UNCERTAIN,,"Dayarathna, M. and Perera, S.",2018,ACM Computing Surveys,10.1145/3170432,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Chen2013,Measurement and modeling of video watching time in a large-scale internet video-on-demand system,"Video watching time is a crucial measure for studying user watching behavior in online Internet video-on-demand (VoD) systems. It is important for system planning, user engagement understanding, and system quality evaluation. However, due to the limited access of user data in large-scale streaming systems, a systematic measurement, analysis, and modeling of video watching time is still missing. In this paper, we measure PPLive, one of the most popular commercial Internet VoD systems in China, over a three week period. We collect accurate user watching data of more than 100 million streaming sessions of more than 100 thousand distinct videos. Based on the measurement data, we characterize the distribution of watching time of different types of videos and reveal a number of interesting characteristics regarding the relation between video watching time and various video-related features (including video type, duration, and popularity). We further build a suite of mathematical models for characterizing these relationships. Extensive performance evaluation shows the high accuracy of these models as compared with commonly used data-mining based models. Our measurement and modeling results bring forth important insights for simulation, design, deployment, and evaluation of Internet VoD systems. © 2013 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Chen, Y. and Zhang, B. and Liu, Y. and Zhu, W.",2013,IEEE Transactions on Multimedia,10.1109/TMM.2013.2280123,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Schlinker2007,Supersonic jet noise source characteristics & propagation: Engine and model scale,"This study benchmarks the source characteristics and propagation of noise on a full scale supersonic exhaust stream engine. The intent is to provide a better understanding of supersonic jet noise generation mechanisms and high intensity propagation for both commercial and military engines. Although high exhaust stream Mach number studies are available to researchers, these are usually limited in temperature and velocity capability by today's model scale test facilities. A series of full scale engine noise measurements were, therefore, conducted using ground plane microphones in the geometric near field below the engine, far field microphones extending to over 300 engine diameters, and, a 30 microphone phased array. This diagnostic configuration provided: a) engine noise directivity and OASPL dependence on exhaust conditions, b) acoustic spectra and propagation decay in the peak directivity angle, c) acoustic source distribution characteristics in the jet axial direction, and d) impulsive acoustic signature dependence on exhaust conditions and variation with propagation distance. The data was acquired over a supersonic Mach number range that varied by factor of 2 and also included variations in nozzle temperature ratio beyond existing laboratory studies. © 2007 by Robert Hans Schlinker.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Schlinker, R.H. and Liljenberg, S.A. and Polak, D.R. and Post, K.A. and Chipman, C.T. and Stern, A.M.",2007,13th AIAA/CEAS Aeroacoustics Conference (28th AIAA Aeroacoustics Conference),,scopus-search1.bib
Luckow20151201,"Automotive big data: Applications, workloads and infrastructures","Data is increasingly affecting the automotive industry, from vehicle development, to manufacturing and service processes, to online services centered around the connected vehicle. Connected, mobile and Internet of Things devices and machines generate immense amounts of sensor data. The ability to process and analyze this data to extract insights and knowledge that enable intelligent services, new ways to understand business problems, improvements of processes and decisions, is a critical capability. Hadoop is a scalable platform for compute and storage and emerged as de-facto standard for Big Data processing at Internet companies and in the scientific community. However, there is a lack of understanding of how and for what use cases these new Hadoop capabilities can be efficiently used to augment automotive applications and systems. This paper surveys use cases and applications for deploying Hadoop in the automotive industry. Over the years a rich ecosystem emerged around Hadoop comprising tools for parallel, in-memory and stream processing (most notable MapReduce and Spark), SQL and NOSQL engines (Hive, HBase), and machine learning (Mahout, MLlib). It is critical to develop an understanding of automotive applications and their characteristics and requirements for data discovery, integration, exploration and analytics. We then map these requirements to a confined technical architecture consisting of core Hadoop services and libraries for data ingest, processing and analytics. The objective of this paper is to address questions, such as: What applications and datasets are suitable for Hadoop? How can a diverse set of frameworks and tools be managed on multi-tenant Hadoop cluster? How do these tools integrate with existing relational data management systems? How can enterprise security requirements be addressed? What are the performance characteristics of these tools for real-world automotive applications? To address the last question, we utilize a standard benchmark (TPCx-HS), and two application benchmarks (SQL and machine learning) that operate on a dataset of multiple Terabytes and billions of rows. © 2015 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Luckow, A. and Kennedy, K. and Manhardt, F. and Djerekarov, E. and Vorster, B. and Apon, A.",2015,"Proceedings - 2015 IEEE International Conference on Big Data, IEEE Big Data 2015",10.1109/BigData.2015.7363874,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Lin2015811,Scalable distributed stream join processing,"Efficient and scalable stream joins play an important role in performing real-time analytics for many cloud applications. However, like in conventional database processing, online theta-joins over data streams are computationally expensive and moreover, being memory-based processing, they impose high memory requirement on the system. In this paper, we propose a novel stream join model, called join-biclique, which organizes a large cluster as a complete bipartite graph. Join-biclique has several strengths over state-of-the-art techniques, including memory-efficiency, elasticity and scalability. These features are essential for building efficient and scalable streaming systems. Based on join-biclique, we develop a scalable distributed stream join system, BiStream, over a large-scale commodity cluster. Specifically, BiStream is designed to support efficient full-history joins, windowbased joins and online data aggregation. BiStream also supports adaptive resource management to dynamically scale out and down the system according to its application workloads. We provide both theoretical cost analysis and extensive experimental evaluations to evaluate the efficiency, elasticity and scalability of BiStream. Copyright © 2015 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Lin, Q. and Ooi, B.C. and Wang, Z. and Yu, C.",2015,Proceedings of the ACM SIGMOD International Conference on Management of Data,10.1145/2723372.2746485,scopus-search1.bib
Picconi2008289,Is there a future for mesh-based live video streaming?,"Peer-to-peer live streaming systems allow a bandwidth-constrained source to broadcast a video feed to a large number of users. In addition, a design with high link utilization can achieve high stream rates, supporting high-quality video. Until now, only tree-based designs have been shown to achieve close-to-optimal rates in real-life conditions, leaving the question open as to the attainable efficiency of completely unstructured mesh-based approaches. In this paper we answer that question by showing that a carefully-designed mesh-based system can achieve close-to-optimal stream rates. Specifically, we implement and evaluate a design based on a mesh-based algorithm called DP/LU. Contrary to tree-based designs, DP/LU uses an unstructured overlay, which is easier to construct and is highly resistant to churn. In addition, we introduce mechanisms for overlay rewiring and source scheduling that lead to significant performance improvements. Our experimental evaluation shows that our design achieves 95% of the maximum achievable stream rate in a static environment, and 90% under high churn. This demonstrates that mesh-based designs are an excellent choice for scalable and robust high-quality peer-to-peer live streaming. © 2008 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Picconi, F. and Massoulié, L.",2008,"Proceedings - P2P'08, 8th International Conference on Peer-to-Peer Computing",10.1109/P2P.2008.18,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Lopez2016,A performance comparison of open-source stream processing platforms,"Distributed stream processing platforms is a new class of real-time monitoring systems that analyze and extracts knowledge from large continuous streams of data. This type of systems is crucial for providing high throughput and low latency required by Big Data or Internet of Things monitoring applications. This paper describes and analyzes three main open-source distributed stream- processing platforms: Storm Flink, and Spark Streaming. We analyze the system architectures and we compare their main features. We carry out two experiments concerning anomaly detection on network traffic to evaluate the throughput efficiency and the resilience to node failures. Results show that the performance of native stream processing systems, Storm and Flink, is up to 15 times higher than the micro-batch processing system, Spark Streaming. On the other hand, Spark Streaming is more robust to node failures and provides recovery without losses. © 2016 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Lopez, M.A. and Lobato, A.G.P. and Duarte, O.C.M.B.",2016,"2016 IEEE Global Communications Conference, GLOBECOM 2016 - Proceedings",10.1109/GLOCOM.2016.7841533,scopus-search1.bib;ieee3-search1.bib
Cetintemel20141633,S-Store: A streaming NewSQL system for big velocity applications,"First-generation streaming systems did not pay much attention to state management via ACID transactions (e.g., [3, 4]). S-Store is a data management system that combines OLTP transactions with stream processing. To create S-Store, we begin with H-Store, a main-memory transaction processing engine, and add primitives to support streaming. This includes triggers and transaction workflows to implement push-based processing, windows to provide a way to bound the computation, and tables with hidden state to implement scoping for proper isolation. This demo explores the benefits of this approach by showing how a naïve implementation of our benchmarks using only H-Store can yield incorrect results. We also show that by exploiting push-based semantics and our implementation of triggers, we can achieve significant improvement in transaction throughput. We demo two modern applications: (i) leaderboard maintenance for a version of ""American Idol"", and (ii) a city-scale bicycle rental scenario. © 2014 VLDB Endowment 2150-8097/14/08.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Cetintemel, U. and Du, J. and Kraska, T. and Madden, S. and Maier, D. and Meehan, J. and Pavlo, A. and Stonebraker, M. and Sutherland, E. and Tatbul, N. and Tufte, K. and Wang, H. and Zdonik, S.",2014,Proceedings of the VLDB Endowment,10.14778/2733004.2733048,scopus-search1.bib;acm3-search1.bib
Xu201622,Stela: Enabling stream processing systems to scale-in and scale-out on-demand,"The era of big data has led to the emergence of new real-time distributed stream processing engines like Apache Storm. We present Stela (STream processing ELAsticity), a stream processing system that supports scale-out and scale-in operations in an on-demand manner, i.e., when the user requests such a scaling operation. Stela meets two goals: 1) it optimizes post-scaling throughput, and 2) it minimizes interruption to the ongoing computation while the scaling operation is being carried out. We have integrated Stela into Apache Storm. We present experimental results using micro-benchmark Storm applications, as well as production applications from industry (Yahoo! Inc. and IBM). Our experiments show that compared to Apache Storm's default scheduler, Stela's scale-out operation achieves throughput that is 21-120% higher, and interruption time that is significantly smaller. Stela's scale-in operation chooses the right set of servers to remove and achieves 2X-5X higher throughput than Storm's default strategy. © 2016 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Xu, L. and Peng, B. and Gupta, I.",2016,"Proceedings - 2016 IEEE International Conference on Cloud Engineering, IC2E 2016: Co-located with the 1st IEEE International Conference on Internet-of-Things Design and Implementation, IoTDI 2016",10.1109/IC2E.2016.38,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Brenna2009,Distributed event stream processing with non-deterministic finite automata,"Efficient matching of incoming events to persistent queries is fundamental to event pattern matching, complex event processing, and publish/subscribe systems. Recent processing engines based on non-deterministic finite automata (NFAs) have demonstrated scalability in the number of queries that can be efficiently executed on a single machine. However, existing NFA based systems are limited to processing events on a single machine. Consequently, their event processing capacity cannot be increased by adding more machines. In this paper, we present an experimental evaluation of different methods for distributing an event processing system that is based on NFAs across multiple machines in a cluster. Our results show that careful input stream partitioning gives close to linear performance scaleup for CPU bound workloads. © 2009 ACM.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Brenna, L. and Gehrke, J. and Hong, M. and Johansen, D.",2009,"Proceedings of the 3rd ACM International Conference on Distributed Event-Based Systems, DEBS 2009",10.1145/1619258.1619263,scopus-search1.bib
Cardellini201711,Optimal operator replication and placement for distributed stream processing systems,"Exploiting on-The-fly computation, Data Stream Processing (DSP) applications are widely used to process unbounded streams of data and extract valuable information in a near real-Time fashion. As such, they enable the development of new intelligent and pervasive services that can improve our everyday life. To keep up with the high volume of daily produced data, the operators that compose a DSP application can be replicated and placed on multiple, possibly distributed, computing nodes, so to process the incoming data flow in parallel. Moreover, to better exploit the abundance of diffused computational resources (e.g., Fog computing), recent trends investigate the possibility of decentralizing the DSP application placement. In this paper, we present and evaluate a general formulation of the optimal DSP replication and placement (ODRP) as an integer linear programming problem, which takes into account the heterogeneity of application requirements and infrastructural resources. We integrate ODRP as prototype scheduler in the Apache Storm DSP framework. By leveraging on the DEBS 2015 Grand Challenge as benchmark application, we show the benefits of a joint optimization of operator replication and placement and how ODRP can optimize different QoS metrics, namely response time, internode traffic, cost, availability, and a combination thereof.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Cardellini, V. and Grassi, V. and Presti, F.L. and Nardelli, M.",2017,Performance Evaluation Review,10.1145/3092819.3092823,scopus-search1.bib;acm1-search1.bib
Zeitler20111181,Massive scale-out of expensive continuous queries,"Scalable execution of expensive continuous queries over massive data streams requires input streams to be split into parallel substreams. The query operators are continuously executed in parallel over these sub-streams. Stream splitting involves both partitioning and replication of incoming tuples, depending on how the continuous query is parallelized. We provide a stream splitting operator that enables such customized stream splitting. However, it is critical that the stream splitting itself keeps up with input streams of high volume. This is a problem when the stream splitting predicates have some costs. Therefore, to enable customized splitting of high-volume streams, we introduce a parallelized stream splitting operator, called parasplit. We investigate the performance of parasplit using a cost model and experimentally. Based on these results, a heuristic is devised to automatically parallelize the execution of parasplit. We show that the maximum stream rate of parasplit is network bound, and that the parallelization is energy efficient. Finally, the scalability of our approach is experimentally demonstrated on the Linear Road Benchmark, showing an order of magnitude higher stream processing rate over previously published results, allowing at least 512 expressways. © 2011 VLDB Endowment.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zeitler, E. and Risch, T.",2011,Proceedings of the VLDB Endowment,,scopus-search1.bib
Cardellini2018171,Decentralized self-adaptation for elastic Data Stream Processing,"Data Stream Processing (DSP) applications are widely used to develop new pervasive services, which require to seamlessly process huge amounts of data in a near real-time fashion. To keep up with the high volume of daily produced data, these applications need to dynamically scale their execution on multiple computing nodes, so to process the incoming data flow in parallel. In this paper, we present a hierarchical distributed architecture for the autonomous control of elastic DSP applications. It consists of a two-layered hierarchical solution, where a centralized per-application component coordinates the run-time adaptation of subordinated distributed components, which, in turn, locally control the adaptation of single DSP operators. Thanks to its features, the proposed solution can efficiently run in large-scale Fog computing environments. Exploiting this framework, we design several distributed self-adaptation policies, including a popular threshold-based approach and two reinforcement learning solutions. We integrate the hierarchical architecture and the devised self-adaptation policies in Apache Storm, a popular open-source DSP framework. Relying on the DEBS 2015 Grand Challenge as a benchmark application, we show the benefits of the presented self-adaptation policies, and discuss the strengths of reinforcement learning based approaches, which autonomously learn from experience how to optimize the application performance. (C) 2018 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Cardellini, V. and LoPresti, F. and Nardelli, M. and RussoRusso, G.",2018,Future Generation Computer Systems,10.1016/j.future.2018.05.025,scopus-search1.bib;web-of-science-search1.bib
Bar2015165,"Large-scale network traffic monitoring with DBStream, a system for rolling big data analysis","The complexity of the Internet has rapidly increased, making it more important and challenging to design scalable network monitoring tools. Network monitoring typically requires rolling data analysis, i.e., continuously and incrementally updating (rolling-over) various reports and statistics over highvolume data streams. In this paper, we describe DBStream, which is an SQL-based system that explicitly supports incremental queries for rolling data analysis. We also present a performance comparison of DBStream with a parallel data processing engine (Spark), showing that, in some scenarios, a single DBStream node can outperform a cluster of ten Spark nodes on rolling network monitoring workloads. Although our performance evaluation is based on network monitoring data, our results can be generalized to other big data problems with high volume and velocity. © 2014 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Bar, A. and Finamore, A. and Casas, P. and Golab, L. and Mellia, M.",2015,"Proceedings - 2014 IEEE International Conference on Big Data, IEEE Big Data 2014",10.1109/BigData.2014.7004227,scopus-search1.bib
Paniga2011165,Experimental evaluation of a video streaming system for Wireless Multimedia Sensor Networks,"Wireless Multimedia Sensor Networks (WMSNs) are recently emerging as an extension to traditional scalar wireless sensor networks, with the distinctive feature of supporting the acquisition and delivery of multimedia content such as audio, images and video. In this paper, a complete framework is proposed and developed for streaming video flows in WMSNs. Such framework is designed in a cross-layer fashion with three main building blocks: (i) a hybrid DPCM/DCT encoder; (ii) a congestion control mechanism and (iii) a selective priority automatic request mechanism at the MAC layer. The system has been implemented on the IntelMote2 platform operated by TinyOS and thoroughly evaluated through testbed experiments on multi-hop WMSNs. The source code of the whole system is publicly available to enable reproducible research. © 2011 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Paniga, S. and Borsani, L. and Redondi, A. and Tagliasacchi, M. and Cesana, M.",2011,"2011 the 10th IFIP Annual Mediterranean Ad Hoc Networking Workshop, Med-Hoc-Net'2011",10.1109/Med-Hoc-Net.2011.5970484,scopus-search1.bib;ieee3-search1.bib
Zeuch2018516,Analyzing Efficient Stream Processing on Modern Hardware,"Modern Stream Processing Engines (SPEs) process large data volumes under tight latency constraints. Many SPEs execute processing pipelines using message passing on sharednothing architectures and apply a partition-based scale-out strategy to handle high-velocity input streams. Furthermore, many state-of-the-art SPEs rely on a Java Virtual Machine to achieve platform independence and speed up system development by abstracting from the underlying hardware. In this paper, we show that taking the underlying hardware into account is essential to exploit modern hardware efficiently. To this end, we conduct an extensive experimental analysis of current SPEs and SPE design alternatives optimized for modern hardware. Our analysis highlights potential bottlenecks and reveals that state-of-the-art SPEs are not capable of fully exploiting current and emerging hardware trends, such as multi-core processors and high-speed networks. Based on our analysis, we describe a set of design changes to the common architecture of SPEs to scale-up on modern hardware. We show that the single-node throughput can be increased by up to two orders of magnitude compared to state-of-the-art SPEs by applying specialized code generation, fusing operators, batch-style parallelization strategies, and optimized windowing. This speedup allows for deploying typical streaming applications on a single or a few nodes instead of large clusters. © 2019, VLDB Endowment.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Zeuch, S. and Monte, B.D. and Karimov, J. and Lutz, C. and Renz, M. and Traub, J. and Breß, S. and Rabl, T. and Markl, V.",2018,Proceedings of the VLDB Endowment,10.14778/3303753.3303758,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Kumbhare2015105,Reactive resource provisioning heuristics for dynamic dataflows on cloud infrastructure,"The need for low latency analysis over high-velocity data streams motivates the need for distributed continuous dataflow systems. Contemporary stream processing systems use simple techniques to scale on elastic cloud resources to handle variable data rates. However, application QoS is also impacted by variability in resource performance exhibited by clouds and hence necessitates autonomic methods of provisioning elastic resources to support such applications on cloud infrastructure. We develop the concept of 'dynamic dataflows' which utilize alternate tasks as additional control over the dataflow's cost and QoS. Further, we formalize an optimization problem to represent deployment and runtime resource provisioning that allows us to balance the application's QoS, value, and the resource cost. We propose two greedy heuristics, centralized and sharded, based on the variable-sized bin packing algorithm and compare against a Genetic Algorithm (GA) based heuristic that gives a near-optimal solution. A large-scale simulation study, using the linear road benchmark and VM performance traces from the AWS public cloud, shows that while GA-based heuristic provides a better quality schedule, the greedy heuristics are more practical, and can intelligently utilize cloud elasticity to mitigate the effect of variability, both in input data rates and cloud resource performance, to meet the QoS of fast data applications. © 2013 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kumbhare, A.G. and Simmhan, Y. and Frincu, M. and Prasanna, V.K.",2015,IEEE Transactions on Cloud Computing,10.1109/TCC.2015.2394316,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Zhao2006298,Finding global icebergs over distributed data sets,"Finding icebergs-items whose frequency of occurrence is above a certain threshold-is an important problem with a wide range of applications. Most of the existing work focuses on iceberg queries at a single node. However, in many real-life applications, data sets are distributed across a large number of nodes. Two naïve approaches might be considered. In the first, each node ships its entire data set to a central server, and the central server uses single-node algorithms to find icebergs. But it may incur prohibitive communication overhead. In the second, each node submits local icebergs, and the central server combines local icebergs to find global icebergs. But it may fail because in many important applications, globally frequent items may not be frequent at any node. In this work, we propose two novel schemes that provide accurate and efficient solutions to this problem: a sampling-based scheme and a counting-sketch-based scheme. In particular, the latter scheme incurs a communication cost at least an order of magnitude smaller than the naïve scheme of shipping all data, yet is able to achieve very high accuracy. Through rigorous theoretical and experimental analysis we establish the statistical properties of our proposed algorithms, including their accuracy bounds. Copyright 2006 ACM.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Zhao, Q. and Ogihara, M. and Wang, H. and Xu, J.",2006,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,10.1145/1142351.1142394,scopus-search1.bib;acm2-search1.bib
Plale2003422,Dynamic querying of streaming data with the dQUOB system,"Data streaming has established itself as a viable communication abstraction in data-intensive parallel and distributed computations, occurring in applications such as scientific visualization performance monitoring, and large-scale data transfer. A known problem in large-scale event communication is tailoring the data received at the consumer. It is the general problem of extracting data of interest from a data source, a problem that the database community,has successfully addressed with SOL queries, a time tested, user-friendly way for, noncomputer scientists to access data. By leveraging the efficiency of query processing provided by relational queries, the dQUOB system provides a conceptual relational data model and SOL query access over streaming data. Queries can be used to extract data, combine streams, and create hew streams. The. language augments queries with an action to enable more complex data. transformations such as Fourier transforms. The dQUOB system has been applied to two large-scale distributed applications: a safety critical autonomous robotics simulation and scientific software visualization for global atmospheric transport modeling. In this paper, we present the dQUOB system and the results of-performance evaluation undertaken to assess its applicability in data-intensive wide-area computations, where the benefit of portable data transformation must be evaluated against the cost of continuous query evaluation.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Plale, B. and Schwan, K.",2003,IEEE Transactions on Parallel and Distributed Systems,10.1109/TPDS.2003.1195413,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Nardelli20191753,Efficient Operator Placement for Distributed Data Stream Processing Applications,"In the last few years, a large number of real-time analytics applications rely on the Data Stream Processing (DSP) so to extract, in a timely manner, valuable information from distributed sources. Moreover, to efficiently handle the increasing amount of data, recent trends exploit the emerging presence of edge/Fog computing resources so to decentralize the execution of DSP applications. Since determining the Optimal DSP Placement (for short, ODP) is an NP-hard problem, we need efficient heuristics that can identify a good application placement on the computing infrastructure in a feasible amount of time, even for large problem instances. In this paper, we present several DSP placement heuristics that consider the heterogeneity of computing and network resources; we divide them in two main groups: model-based and model-free. The former employ different strategies for efficiently solving the ODP model. The latter implement, for the problem at hand, some of the well-known meta-heuristics, namely greedy first-fit, local search, and tabu search. By leveraging on ODP, we conduct a thorough experimental evaluation, aimed to assess the heuristics' efficiency and efficacy under different configurations of infrastructure size, application topology, and optimization objectives. © 2019 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Nardelli, M. and Cardellini, V. and Grassi, V. and LoPresti, F.",2019,IEEE Transactions on Parallel and Distributed Systems,10.1109/TPDS.2019.2896115,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Zacheilas2015213,Elastic complex event processing exploiting prediction,"Supporting real-time, cost-effective execution of Complex Event processing applications in the cloud has been an important goal for many scientists in recent years. Distributed Stream Processing Systems (DSPS) have been widely adopted by major computing companies as a powerful approach for large-scale Complex Event processing (CEP). However, determining the appropriate degree of parallelism of the DSPS' components can be particularly challenging as the volume of data streams is becoming increasingly large, the rule set is becoming continuously complex, and the system must be able to handle such large data stream volumes in real-time, taking into consideration changes in the burstiness levels and data characteristics. In this paper we describe our solution to building elastic complex event processing systems on top of our distributed CEP system which combines two commonly used frameworks, Storm and Esper, in order to provide both ease of usage and scalability. Our approach makes the following contributions: (i) we provide a mechanism for predicting the load and latency of the Esper engines in upcoming time windows, and (ii) we propose a novel algorithm for automatically adjusting the number of engines to use in the upcoming windows, taking into account the cost and the performance gains of possible changes. Our detailed experimental evaluation with a real traffic monitoring application that analyzes bus traces from the city of Dublin indicates the benefits in the working of our approach. Our proposal outperforms the current state of the art technique in regards to the amount of tuples that it can process by four orders of magnitude. © 2015 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zacheilas, N. and Kalogeraki, V. and Zygouras, N. and Panagiotou, N. and Gunopulos, D.",2015,"Proceedings - 2015 IEEE International Conference on Big Data, IEEE Big Data 2015",10.1109/BigData.2015.7363758,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Mueller2013,Dynamic adaptive streaming over HTTP/2.0,"MPEG Dynamic Adaptive Streaming over HTTP (DASH) is a new streaming standard that has been recently ratified as an international standard (IS). In comparison to other streaming systems, e.g., HTTP progressive download, DASH is able to handle varying bandwidth conditions providing smooth streaming. Furthermore, it enables NAT and Firewall traversal, flexible and scalable deployment as well as reduced infrastructure costs due to the reuse of existing Internet infrastructure components, e.g., proxies, caches, and Content Distribution Networks (CDN). Recently, the Hypertext Transfer Protocol Bis (httpbis) working group of the IETF has officially started the development of HTTP 2.0. Initially three major proposals have been submitted to the IETF i.e., Googles' SPDY, Microsofts' HTTP Speed+Mobility and Network-Friendly HTTP Upgrade, but SPDY has been chosen as working draft for HTTP 2.0. In this paper we implemented MPEG-DASH over HTTP 2.0 (i.e., SPDY), demonstrating its potential benefits and drawbacks. Moreover, several experimental evaluations have been performed that compare HTTP 2.0 with HTTP 1.1 and HTTP 1.0 in the context of DASH. In particular, the protocol overhead, the performance for different round trip times, and DASH with HTTP 2.0 in a lab test scenario has been evaluated in detail. © 2013 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Mueller, C. and Lederer, S. and Timmerer, C. and Hellwagner, H.",2013,Proceedings - IEEE International Conference on Multimedia and Expo,10.1109/ICME.2013.6607498,scopus-search1.bib;ieee3-search1.bib
Ericson20131024,On the performance of high dimensional data clustering and classification algorithms,"There is often a need to perform machine learning tasks on voluminous amounts of data. These tasks have application in fields such as pattern recognition, data mining, bioinformatics, and recommendation systems. Here we evaluate the performance of 4 clustering algorithms and 2 classification algorithms supported by Mahout within two different cloud runtimes, Hadoop and Granules. Our benchmarks use the same Mahout backend code, ensuring a fair comparison. The differences between these implementations stem from how the Hadoop and Granules runtimes (1) support and manage the lifecycle of individual computations, and (2) how they orchestrate exchange of data between different stages of the computational pipeline during successive iterations of the clustering algorithm. We include an analysis of our results for each of these algorithms in a distributed setting, as well as a discussion on measures for failure recovery. (c) 2012 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ericson, K. and Pallickara, S.",2013,Future Generation Computer Systems,10.1016/j.future.2012.05.026,scopus-search1.bib;web-of-science-search1.bib
Kalyvianaki2011840,SQPR: Stream query planning with reuse,"When users submit new queries to a distributed stream processing system (DSPS), a query planner must allocate physical resources, such as CPU cores, memory and network bandwidth, from a set of hosts to queries. Allocation decisions must provide the correct mix of resources required by queries, while achieving an efficient overall allocation to scale in the number of admitted queries. By exploiting overlap between queries and reusing partial results, a query planner can conserve resources but has to carry out more complex planning decisions. In this paper, we describe SQPR, a query planner that targets DSPSs in data centre environments with heterogeneous resources. SQPR models query admission, allocation and reuse as a single constrained optimisation problem and solves an approximate version to achieve scalability. It prevents individual resources from becoming bottlenecks by re-planning past allocation decisions and supports different allocation objectives. As our experimental evaluation in comparison with a state-of-the-art planner shows SQPR makes efficient resource allocation decisions, even with a high utilisation of resources, with acceptable overheads. © 2011 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,EXCLUDED,EXCLUDED,,"Kalyvianaki, E. and Wiesemann, W. and Vu, Q.H. and Kuhn, D. and Pietzuch, P.",2011,Proceedings - International Conference on Data Engineering,10.1109/ICDE.2011.5767851,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Gu2006824,On composing stream applications in peer-to-peer environments,"Stream processing has become increasingly important as many emerging applications call for continuous real-time processing over data streams, such as voice-over-IP telephony, security surveillance, and sensor data analysis. In this paper, we propose a composable stream processing system for cooperative peer-to-peer environments. The system can dynamically select and compose stream processing elements located on different peers into user desired applications. We investigate multiple alternative approaches to composing stream applications: 1) global-state-based centralized versus local-state-based distributed algorithms for initially composing stream applications at setup phase. The centralized algorithm performs periodical global state maintenance while the distributed algorithm performs on-demand state collection. 2) Reactive versus proactive failure recovery schemes for maintaining composed stream applications during runtime. The reactive failure recovery algorithm dynamically recomposes a new stream application upon failures while the proactive approach maintains a number of backup compositions for failure recovery. We conduct both theoretical analysis and experimental evaluations to study the properties of different approaches. Our study illustrates the performance and overhead trade-offs among different design alternatives, which can provide important guidance for selecting proper algorithms to compose stream applications in cooperative peer-to-peer environments. © 2006 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Gu, X. and Nahrstedt, K.",2006,IEEE Transactions on Parallel and Distributed Systems,10.1109/TPDS.2006.107,scopus-search1.bib
Cardellini2018,Optimal operator deployment and replication for elastic distributed data stream processing,"Processing data in a timely manner, data stream processing (DSP) applications are receiving an increasing interest for building new pervasive services. Due to the unpredictability of data sources, these applications often operate in dynamic environments; therefore, they require the ability to elastically scale in response to workload variations. In this paper, we deal with a key problem for the effective runtime management of a DSP application in geo-distributed environments: We investigate the placement and replication decisions while considering the application and resource heterogeneity and the migration overhead, so to select the optimal adaptation strategy that can minimize migration costs while satisfying the application quality of service (QoS) requirements. We present elastic DSP replication and placement (EDRP), a unified framework for the QoS-aware initial deployment and runtime elasticity management of DSP applications. In EDRP, the deployment and runtime decisions are driven by the solution of a suitable integer linear programming problem, whose objective function captures the relative importance between QoS goals and reconfiguration costs. We also present the implementation of EDRP and the related mechanisms on Apache Storm. We conduct a thorough experimental evaluation, both numerical and prototype-based, that shows the benefits achieved by EDRP on the application performance. Copyright © 2017 John Wiley & Sons, Ltd.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Cardellini, V. and LoPresti, F. and Nardelli, M. and RussoRusso, G.",2018,Concurrency Computation,10.1002/cpe.4334,scopus-search1.bib;web-of-science-search1.bib
Tournavitis2010377,Semi-automatic extraction and exploitation of hierarchical pipeline parallelism using profiling information,"In recent years multi-core computer systems have left the realm of high-performance computing and virtually all of today's desktop computers and embedded computing systems are equipped with several processing cores. Still, no single parallel programming model has found widespread support and parallel programming remains an art for the majority of application programmers. In addition, there exists a plethora of sequential legacy applications for which automatic parallelization is the only hope to benefit from the increased processing power of modern multi-core systems. In the past automatic parallelization largely focused on data parallelism. In this paper we present a novel approach to extracting and exploiting pipeline parallelism from sequential applications. We use profiling to overcome the limitations of static data and control flow analysis enabling more aggressive parallelization. Our approach is orthogonal to existing automatic parallelization approaches and additional data parallelism may be exploited in the individual pipeline stages. The key contribution of this paper is a whole-program representation that supports profiling, parallelism extraction and exploitation. We demonstrate how this enhances conventional pipeline parallelization by incorporating support for multi-level loops and pipeline stage replication in a uniform and automatic way. We have evaluated our methodology on a set of multimedia and stream processing benchmarks and demonstrate speedups of up to 4.7 on a eight-core Intel Xeon machine. © 2010 ACM.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Tournavitis, G. and Franke, B.",2010,"Parallel Architectures and Compilation Techniques - Conference Proceedings, PACT",10.1145/1854273.1854321,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib;acm2-search1.bib
Shukla201898,Model-driven scheduling for distributed stream processing systems,"Distributed Stream Processing Systems (DSPS) are ``Fast Data{''} platforms that allow streaming applications to be composed and executed with low latency on commodity clusters and Clouds. Such applications are composed as a Directed Acyclic Graph (DAG) of tasks, with data parallel execution using concurrent task threads on distributed resource slots. Scheduling such DAGs for DSPS has two parts-allocation of threads and resources for a DAG, and mapping threads to resources. Existing schedulers often address just one of these, make the assumption that performance linearly scales, or use ad hoc empirical tuning at runtime. Instead, we propose model-driven techniques for both mapping and allocation that rely on low-overhead a priori performance modeling of tasks. Our scheduling algorithms are able to offer predictable and low resource needs that is suitable for elastic pay-as-you-go Cloud resources, support a high input rate through high VM utilization, and can be combined with other mapping approaches as well. These are validated for micro and application benchmarks, and compared with contemporary schedulers, for the Apache Storm DSPS. (C) 2018 Elsevier Inc. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Shukla, A. and Simmhan, Y.",2018,Journal of Parallel and Distributed Computing,10.1016/j.jpdc.2018.02.003,scopus-search1.bib;web-of-science-search1.bib
Khoshkbarforoushha2017120,Distribution Based Workload Modelling of Continuous Queries in Clouds,"Resource usage estimation for managing streaming workload in emerging applications domains such as enterprise computing, smart cities, remote healthcare, and astronomy, has emerged as a challenging research problem. Such resource estimation for processing continuous queries over streaming data is challenging due to: (i) uncertain stream arrival patterns, (ii) need to process different mixes of queries, and (iii) varying resource consumption. Existing techniques approximate resource usage for a query as a single point value which may not be sufficient because it is neither expressive enough nor does it capture the aforementioned nature of streaming workload. In this paper, we present a novel approach of using mixture density networks to estimate the whole spectrum of resource usage as probability density functions. We have evaluated our technique using the linear road benchmark and TPC-H in both private and public clouds. The efficiency and applicability of the proposed approach is demonstrated via two novel applications: i) predictable auto-scaling policy setting which highlights the potential of distribution prediction in consistent definition of cloud elasticity rules; and ii) a distribution based admission controller which is able to efficiently admit or reject incoming queries based on probabilistic service level agreements compliance goals. © 2013 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Khoshkbarforoushha, A. and Ranjan, R. and Gaire, R. and Abbasnejad, E. and Wang, L. and Zomaya, A.Y.",2017,IEEE Transactions on Emerging Topics in Computing,10.1109/TETC.2016.2597546,scopus-search1.bib;web-of-science-search1.bib
Ed-daoudy2019,A new Internet of Things architecture for real-time prediction of various diseases using machine learning on big data environment,"A number of technologies enabled by Internet of Thing (IoT) have been used for the prevention of various chronic diseases, continuous and real-time tracking system is a particularly important one. Wearable medical devices with sensor, health cloud and mobile applications have continuously generating a huge amount of data which is often called as streaming big data. Due to the higher speed of the data generation, it is difficult to collect, process and analyze such massive data in real-time in order to perform real-time actions in case of emergencies and extracting hidden value. using traditional methods which are limited and time-consuming. Therefore, there is a significant need to real-time big data stream processing to ensure an effective and scalable solution. In order to overcome this issue, this work proposes a new architecture for real-time health status prediction and analytics system using big data technologies. The system focus on applying distributed machine learning model on streaming health data events ingested to Spark streaming through Kafka topics. Firstly, we transform the standard decision tree (DT) (C4.5) algorithm into a parallel, distributed, scalable and fast DT using Spark instead of Hadoop MapReduce which becomes limited for real-time computing. Secondly, this model is applied to streaming data coming from distributed sources of various diseases to predict health status. Based on several input attributes, the system predicts health status, send an alert message to care providers and store the details in a distributed database to perform health data analytics and stream reporting. We measure the performance of Spark DT against traditional machine learning tools including Weka. Finally, performance evaluation parameters such as throughput and execution time are calculated to show the effectiveness of the proposed architecture. The experimental results show that the proposed system is able to effectively process and predict real-time and massive amount of medical data enabled by IoT from distributed and various diseases. © 2019, The Author(s).",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ed-daoudy, A. and Maalmi, K.",2019,Journal of Big Data,10.1186/s40537-019-0271-7,scopus-search1.bib;web-of-science-search1.bib
Fortuna2010,QoE in pull based P2P-TV systems: Overlay topology design tradeoffs,"This paper presents a systematic performance analysis of pull P2P video streaming systems for live applications, providing guidelines for the design of the overlay topology and the chunk scheduling algorithm. The contribution of the paper is threefold: 1) we propose a realistic simulative model of the system that represents the effects of access bandwidth heterogeneity, latencies, peculiar characteristics of the video, while still guaranteeing good scalability properties; 2) we propose a new latency/bandwidth-aware overlay topology design strategy that improves application layer performance while reducing the underlying transport network stress; 3) we investigate the impact of chunk scheduling algorithms that explicitly exploit properties of encoded video. Results show that our proposal jointly improves the actual Quality of Experience of users and reduces the cost the transport network has to support. ©2010 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Fortuna, R. and Leonardi, E. and Mellia, M. and Meo, M. and Traverso, S.",2010,"2010 IEEE 10th International Conference on Peer-to-Peer Computing, P2P 2010 - Proceedings",10.1109/P2P.2010.5569966,scopus-search1.bib;ieee2-search1.bib
Luo2007497,Resource-adaptive real-time new event detection,"In a document streaming environment, online detection of the first documents that mention previously unseen events is an open challenge. For this online new event detection (ONED) task, existing studies usually assume that enough resources are always available and focus entirely on detection accuracy without considering efficiency. Moreover, none of the existing work addresses the issue of providing an effective and friendly user interface. As a result, there is a significant gap between the existing systems and a system that can be used in practice. In this paper, we propose an ONED framework with the following prominent features. First, a combination of indexing and compression methods is used to improve the document processing rate by orders of magnitude without sacrificing much detection accuracy. Second, when resources are tight, a resource-adaptive computation method is used to maximize the benefit that can be gained from the limited resources. Third, when the new event arrival rate is beyond the processing capability of the consumer of the ONED system, new events are further filtered and prioritized before they are presented to the consumer. Fourth, implicit citation relationships are created among all the documents and used to compute the importance of document sources. This importance information can guide the selection of document sources. We implemented a prototype of our framework on top of IBM's Stream Processing Core middleware. We also evaluated the effectiveness of our techniques on the standard TDT5 benchmark. To the best of our knowledge, this is the first implementation of a real application in a large-scale stream processing system. Copyright 2007 ACM.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Luo, G. and Tang, C. and Yu, P.S.",2007,Proceedings of the ACM SIGMOD International Conference on Management of Data,10.1145/1247480.1247536,scopus-search1.bib;acm2-search1.bib
Pechanek2000348,The ManArray™ embedded processor architecture,"The BOPS(R) ManArray™ architecture is presented as a scalable DAP platform for the embedded processor domain. In this domain, ManArray-based processors use a single architecture definition, that supports multiple configurations of processing elements (PEs) from low end single PE to large arrays of PEs, and single tool set. The ManArray (selectable) parallelism architecture mixes control oriented operations, VLIWs, packed data operations, and distributed array processing in a cohesive, independently selectable manner. In addition, scalable conditional execution and single-cycle communications across a high connectivity, low cost network are integrated in the architecture. This allows another level of selectivity that enhances the application of the parallel resources that enhances the application of the parallel resources to high performance algorithms. Coupled with the array DSP is a scalable DMA engine that runs in the background and provides programmer-selectable data-distribution patterns and a high-bandwidth data-streaming interface to system peripherals and global memory. This paper introduces the embedded scalable ManArray architecture and a number of benchmarks. For example, a standard ASIC flow DSP/coprocessor core, the BOPS2040, can process a distributed 256-point complex FFT in 425 cycles and an 8 times; 8 2D IDCT that meets IEEE standards in 34 cycles. © 2000 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Pechanek, G.G. and Vassiliadis, S.",2000,Conference Proceedings of the EUROMICRO,10.1109/EURMIC.2000.874652,scopus-search1.bib;ieee2-search1.bib
Eskandari2016,P-scheduler: Adaptive hierarchical scheduling in Apache Storm,"With ever-accelerating data creation rates in Big Data applications, there is a need for efficient stream processing engines. Apache Storm has been of interest in both academia and industry because of its real-time, distributed, scalable and reliable framework for stream processing. In this paper, we propose an adaptive hierarchical scheduler for the Storm framework, to allocate the resources more efficiently and improve performance. In our method, we consider the data transfer rate and traffic pattern between Storm's tasks and assign highly-communicating task pairs to the same computing node by dynamically employing two phases of graph partitioning. We also calculate the number of required computing nodes in the cluster based on the overall load of the application and use this information to reduce inter-node traffic. Our performance evaluation shows a significant improvement compared to the default scheduler provided by Storm, which evenly distributes the tasks across the cluster, ignoring the communication patterns between them. © 2016 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Eskandari, L. and Huang, Z. and Eyers, D.",2016,ACM International Conference Proceeding Series,10.1145/2843043.2843056,scopus-search1.bib;acm1-search1.bib
Cerviño2012295,Adaptive provisioning of stream processing systems in the cloud,"With the advent of data-intensive applications that generate large volumes of real-time data, distributed stream processing systems (DSPS) become increasingly important in domains such as social networking and web analytics. In practice, DSPSs must handle highly variable workloads caused by unpredictable changes in stream rates. Cloud computing offers an elastic infrastructure that DSPSs can use to obtain resources on-demand, but an open problem is to decide on the correct resource allocation when deploying DSPSs in the cloud. This paper proposes an adaptive approach for provisioning virtual machines (VMs) for the use of a DSPS in the cloud. We initially perform a set of benchmarks across performance metrics such as network latency and jitter to explore the feasibility of cloud-based DSPS deployments. Based on these results, we propose an algorithm for VM provisioning for DSPSs that reacts to changes in the stream workload. Through a prototype implementation on Amazon EC2, we show that our approach can achieve low-latency stream processing when VMs are not overloaded, while adjusting resources dynamically with workload changes. © 2012 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Cerviño, J. and Kalyvianaki, E. and Salvachúa, J. and Pietzuch, P.",2012,"Proceedings - 2012 IEEE 28th International Conference on Data Engineering Workshops, ICDEW 2012",10.1109/ICDEW.2012.40,scopus-search1.bib;ieee2-search1.bib
Cheng2013291,TESLA-based homomorphic MAC for Authentication in p2p system for live streaming with network coding,"Recently, the peer-to-peer (P2P) live streaming system has benefited from the advent of network coding. However, it was demonstrated that malicious nodes could significantly reduce the network throughput by launching pollution attacks or entropy attacks. In this paper, we propose an efficient symmetric-key based authentication scheme for P2P live streaming system with network coding, to provide in-network detection against pollution attacks and entropy attacks simultaneously. Since the nature of P2P live streaming requires that the detection scheme has high computation efficiency and small communication overheads, we firstly propose a homomorphic message authentication code (MAC), called as PMAC, which has small key size and low computation overhead. Then, the proposed PMAC and the delayed key disclosure technique are employed to make sure that the peers could not only detect the corrupted blocks, but also upload blocks in accordance with random linear network coding. Furthermore, the performance evaluation demonstrates that the proposed scheme has both low communication and computation overheads. © 1983-2012 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Cheng, C. and Jiang, T. and Zhang, Q.",2013,IEEE Journal on Selected Areas in Communications,10.1109/JSAC.2013.SUP.0513026,scopus-search1.bib
Chen2011509,Experience in Continuous analytics as a Service (CaaaS),"Mobile applications, such as those on WebOS, increasingly depend on continuous analytics results of real-time events, for monitoring oil & gas production, watching traffic status and detecting accident, etc, which has given rise to the need of providing Continuous analytics as a Service (CaaaS). While representing a paradigm shift in cloud computing, CaaaS poses several challenges in scalability, latency, time-window semantics, transaction control and result-set staging.A data stream is infinite thus can only be analyzed in granules. We propose a continuous query model over both static relations and dynamic streaming data, which allows a long-standing SQL query instance to run cycle by cycle, each cycle for a chunk of data from the data stream, using a cut-and-rewind mechanism. We further support the cycle-based transaction model with cycle-based isolation and visibility, for delivering analytics results to the clients continuously while the query is running. To have the continuously generated analytics results staged efficiently, we developed the table-ring and label switching mechanism characterized by staging data through metadata manipulation without physical data moving and copying. To scale-out analytics computation, we support both parallel database based and network distributed Map-Reduce based infrastructure with multiple cooperating engines.We have built the proposed infrastructure by extending the PostgreSQL engine. We tested the throughput and latency of this service based on a well-known stream processing benchmark; the results show that the proposed approach is highly competitive. Our experiments indicate that the database technology can be extended and applied to real-time continuous analytics service provisioning.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Chen, Q. and Hsu, M. and Zeller, H.",2011,ACM International Conference Proceeding Series,10.1145/1951365.1951426,scopus-search1.bib;acm3-search1.bib
Thomos2015893,Adaptive prioritized random linear coding and scheduling for layered data delivery from multiple servers,"In this paper, we deal with the problem of jointly determining the optimal coding strategy and the scheduling decisions when receivers obtain layered data from multiple servers. The layered data is encoded by means of prioritized random linear coding (PRLC) in order to be resilient to channel loss while respecting the unequal levels of importance in the data, and data blocks are transmitted simultaneously in order to reduce decoding delays and improve the delivery performance. We formulate the optimal coding and scheduling decisions problem in our novel framework with the help of Markov decision processes (MDP), which are effective tools for modeling adapting streaming systems. Reinforcement learning approaches are then proposed to derive reduced computational complexity solutions to the adaptive coding and scheduling problems. The novel reinforcement learning approaches and the MDP solution are examined in an illustrative example for scalable video transmission. Our methods offer large performance gains over competing methods that deliver the data blocks sequentially. The experimental evaluation also shows that our novel algorithms offer continuous playback and guarantee small quality variations which is not the case for baseline solutions. Finally, our work highlights the advantages of reinforcement learning algorithms to forecast the temporal evolution of data demands and to decide the optimal coding and scheduling decisions. © 2015 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Thomos, N. and Kurdoglu, E. and Frossard, P. and VanDerSchaar, M.",2015,IEEE Transactions on Multimedia,10.1109/TMM.2015.2425228,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Hazra2012,Power grid transient stability prediction using wide area synchrophasor measurements,"Electric power systems are prone to various kinds of transient disturbances which exist only for a fraction of second and often trigger cascading failures. Hence it is important to detect and prevent them from spreading in time. Conventionally these events are prevented by deploying costly special protection systems (SPS). Unfortunately, in many cases SPSs mis-operate as they could not predict the stability well ahead and are designed to operate based on past experiences and extensive off-line simulations. This paper proposes an online transient stability prediction scheme based on live synchrophasor data. The novelty of the proposed method is that it accurately predicts the transient stability based on only few (10 to 12) sample fault data without solving computationally extensive electromechanical dynamics. Synchrophasor data from geographically distributed Phasor Measurement Units (PMUs) are collected, synchronized, aggregated (if required) and analyzed on a stream computing platform to predict the trajectories of the generators which are then used to predict the transient stability of the grid. Performance of the proposed scheme is evaluated on the benchmark systems and evaluation results are presented in this paper. © 2012 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Hazra, J. and Reddi, R.K. and Das, K. and Seetharam, D.P. and Sinha, A.K.",2012,IEEE PES Innovative Smart Grid Technologies Conference Europe,10.1109/ISGTEurope.2012.6465752,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Bourennane2012147,Comparison of shape descriptors for hand posture recognition in video,"Hand posture recognition remains a challenging task for in-line systems working directly in the video stream. In this work, we compare several shape descriptors, with the objective of finding a good compromise between accuracy of recognition and computation load for a real-time application. Experiments are run on two families of contour-based Fourier descriptors and two sets of region-based moments, all of them are invariant to translation, rotation and scale changes of hands. These methods are independent of the camera view point. Systematic tests are performed on the Triesch benchmark database and on our own large database, which includes more realistic conditions. Temporal filtering and a method for unknown posture detection are considered to improve posture recognition results in case of video stream processing. © 2010 Springer-Verlag London Limited.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Bourennane, S. and Fossati, C.",2012,"Signal, Image and Video Processing",10.1007/s11760-010-0176-6,scopus-search1.bib;web-of-science-search1.bib
Carra20071667,Graph based analysis of mesh overlay streaming systems,"This paper studies fundamental properties of stream-based content distribution services. We assume the presence of an overlay network (such as those built by P2P systems) with limited degree of connectivity, and we develop a mathematical model that captures the essential features of overlay-based streaming protocols and systems. The methodology is based on stochastic graph theory, and models the streaming system as a stochastic process, whose characteristics are related to the streaming protocol. The model captures the elementary properties of the streaming system such as the number of active connections, the different play-out delay of nodes, and the probability of not receiving the stream due to node failures/misbehavior. Besides the static properties, the model is able to capture the transient behavior of the distribution graphs, i.e., the evolution of the structure over time, for instance in the initial phase of the distribution process. Contributions of this paper include a detailed definition of the methodology, its comparison with other analytical approaches and with simulative results, and a discussion of the additional insights enabled by this methodology. Results show that mesh based architectures are able to provide bounds on the receiving delay and maintain rate fluctuations due to system dynamics very low. Additionally, given the tight relationship between the stochastic process and the properties of the distribution protocol, this methodology gives basic guidelines for the design of such protocols and systems. © 2007 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Carra, D. and LoCigno, R. and Biersack, E.W.",2007,IEEE Journal on Selected Areas in Communications,10.1109/JSAC.2007.071206,scopus-search1.bib
Riabov200631,Scalable planning for distributed stream processing systems,"Recently the problem of automatic composition of workflows has been receiving increasing interest. Initial investigation has shown that designing a practical and scalable composition algorithm for this problem is hard. A very general computational model of a workflow (e.g., BPEL) can be Turing-complete, which precludes fully automatic analysis of compositions. However, in many applications, workflow model can be simplified. We consider a model known as the Stream Processing Planning Language (SPPL), applicable in stream processing and other related domains. SPPL replaces the notion of concurrency by timeless functional computation. In addition, SPPL defines workflow metrics of resource consumption and quality of service. Experiments have shown earlier that even a naïve SPPL planning algorithm significantly outperforms existing metric PDDL planners on stream processing workflow composition problems. In this paper we describe an efficient and scalable algorithm for finding high-quality approximate solutions for large instances of SPPL problems. We demonstrate the scalability of the algorithm on synthetic benchmarks that are derived from practical problems. We also give an example of SPPL model for practical problems. Copyright © 2006, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Riabov, A. and Liu, Z.",2006,"ICAPS 2006 - Proceedings, Sixteenth International Conference on Automated Planning and Scheduling",,scopus-search1.bib
VanDongen20201845,Evaluation of Stream Processing Frameworks,"The increasing need for real-time insights in data sparked the development of multiple stream processing frameworks. Several benchmarking studies were conducted in an effort to form guidelines for identifying the most appropriate framework for a use case. In this article, we extend this research and present the results gathered. In addition to Spark Streaming and Flink, we also include the emerging frameworks Structured Streaming and Kafka Streams. We define four workloads with custom parameter tuning. Each of these is optimized for a certain metric or for measuring performance under specific scenarios such as bursty workloads. We analyze the relationship between latency, throughput, and resource consumption and we measure the performance impact of adding different common operations to the pipeline. To ensure correct latency measurements, we use a single Kafka broker. Our results show that the latency disadvantages of using a micro-batch system are most apparent for stateless operations. With more complex pipelines, customized implementations can give event-driven frameworks a large latency advantage. Due to its micro-batch architecture, Structured Streaming can handle very high throughput at the cost of high latency. Under tight latency SLAs, Flink sustains the highest throughput. Additionally, Flink shows the least performance degradation when confronted with periodic bursts of data. When a burst of data needs to be processed right after startup, however, micro-batch systems catch up faster while event-driven systems output the first events sooner. © 1990-2012 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"VanDongen, G. and VanDenPoel, D.",2020,IEEE Transactions on Parallel and Distributed Systems,10.1109/TPDS.2020.2978480,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Gupta2018148,FogStore: A geo-distributed key-value store guaranteeing low latency for strongly consistent access,"We design Fogstore, a key-value store for event-based systems, that exploits the concept of relevance to guarantee low-latency access to relevant data with strong consistency guarantees, while providing tolerance from geographically correlated failures. Distributed event-based processing pipelines are envisioned to utilize the resources of densely geo-distributed infrastructures for low-latency responses - enabling real-time applications. Increasing complexity of such applications results in higher dependence on state, which has driven the incorporation of state-management as a core functionality of contemporary stream processing engines a la Apache Flink and Samza. Processing components executing under the same context (like location) often produce information that may be relevant to others, thereby necessitating shared state and an out-of-band globally-accessible data-store. Efficient access to application state is critical for overall performance, thus centralized data-stores are not a viable option due to the high-latency of network traversals. On the other hand, a highly geo-distributed datastore with low-latency implemented with current key-value stores would necessitate degrading client expectation of consistency as per the PACELC theorem. In this paper we exploit the notion of contextual relevance of events (data) in situation-awareness applications - and offer differential consistency guarantees for clients based on their context. We highlight important systems concerns that may arise with a highly geo-distributed system and show how Fogstore's design tackles them. We present, in detail, a prototype implementation of Fogstore's mechanisms on Apache Cassandra and a performance evaluation. Our evaluations show that Fogstore is able to achieve the throughput of eventually consistent configurations while serving data with strong consistency to the contextually relevant clients. © 2018 Copyright held by the owner/author(s).",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Gupta, H. and Ramachandran, U.",2018,DEBS 2018 - Proceedings of the 12th ACM International Conference on Distributed and Event-Based Systems,10.1145/3210284.3210297,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Zhang2017659,Revisiting the design of data stream processing systems on multi-core processors,"Driven by the rapidly increasing demand for handling real-Time data streams, many data stream processing (DSP) systems have been proposed. Regardless of the different architectures of those DSP systems, they are mostly aiming at scaling out using a cluster of commodity machines and built around a number of key design aspects: A) pipelined processing with message passing, b) on-demand data parallelism, and c) JVM based implementation. However, there lacks a study on those key design aspects on modern scale-up architectures, where more CPU cores are being put on the same die, and the onchip cache hierarchies are getting larger, deeper, and complex. Multiple sockets bring non-uniform memory access (NUMA) effort. In this paper, we revisit the aforementioned design aspects on a modern scale-up server. Specifically, we use a series of applications as micro benchmark to conduct detailed profiling studies on Apache Storm and Flink. From the profiling results, we observe two major performance issues: A) the massively parallel execution model causes serious front-end stalls, which are a major performance bottleneck issue on a single CPU socket, b) the lack of NUMA-Aware mechanism causes major drawback on the scalability of DSP systems on multi-socket architectures. Addressing these issues should allow DSP systems to exploit modern scale-up architectures, which also benefits scaling out environments. We present our initial efforts on resolving the above-mentioned performance issues, which have shown up to 3.2x and 3.1x improvement on the performance of Storm and Flink, respectively. © 2017 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Zhang, S. and He, B. and Dahlmeier, D. and Zhou, A.C. and Heinze, T.",2017,Proceedings - International Conference on Data Engineering,10.1109/ICDE.2017.119,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib;scholar.bib
Tang20132344,Autopipelining for data stream processing,"Stream processing applications use online analytics to ingest high-rate data sources, process them on-the-fly, and generate live results in a timely manner. The data flow graph representation of these applications facilitates the specification of stream computing tasks with ease, and also lends itself to possible runtime exploitation of parallelization on multicore processors. While the data flow graphs naturally contain a rich set of parallelization opportunities, exploiting them is challenging due to the combinatorial number of possible configurations. Furthermore, the best configuration is dynamic in nature; it can differ across multiple runs of the application, and even during different phases of the same run. In this paper, we propose an autopipelining solution that can take advantage of multicore processors to improve throughput of streaming applications, in an effective and transparent way. The solution is effective in the sense that it provides good utilization of resources by dynamically finding and exploiting sources of pipeline parallelism in streaming applications. It is transparent in the sense that it does not require any hints from the application developers. As a part of our solution, we describe a light-weight runtime profiling scheme to learn resource usage of operators comprising the application, an optimization algorithm to locate best places in the data flow graph to explore additional parallelism, and an adaptive control scheme to find the right level of parallelism. We have implemented our solution in an industrial-strength stream processing system. Our experimental evaluation based on microbenchmarks, synthetic workloads, as well as real-world applications confirms that our design is effective in optimizing the throughput of stream processing applications without requiring any changes to the application code. © 1990-2012 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Tang, Y. and Gedik, B.",2013,IEEE Transactions on Parallel and Distributed Systems,10.1109/TPDS.2012.333,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Kofler200863,An H.264/SVC-based adaptation proxy on a WiFi router,"Recent advances in video coding technology like the scalable extension of the MPEG-4 AVC/H.264 video coding standard pave the way for computationally cheap adaptation of video content. In this paper we present our work on a lightweight RTSP/RTP proxy that enables in-network stream processing. Based on an off-the-shelf wireless router that runs a Linux-based firmware we demonstrate that the video adaptation can be performed on-the-fly directly on a network device. The paper covers design and implementation details of the proxy as well as a discussion about the actual adaptation of the SVC stream. Based on experimental evaluations we show that our approach can handle a reasonable number of concurrent sessions for a typical home deployment scenario. Furthermore, the paper covers possible applications in which adaptation on the network device can be beneficial. © 2008 ACM.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Kofler, I. and Prangl, M. and Kuschnig, R. and Hellwagner, H.",2008,Proceedings of the International Workshop on Network and Operating System Support for Digital Audio and Video,10.1145/1496046.1496061,scopus-search1.bib
Jonathan2018412,Multi-query optimization in wide-area streaming analytics,"Wide-area data analytics has gained much attention in recent years due to the increasing need for analyzing data that are geographically distributed. Many of such queries often require real-time analysis on data streams that are continuously being generated across multiple locations. Yet, analyzing these geo-distributed data streams in a timely manner is very challenging due to the highly heterogeneous and limited bandwidth availability of the wide-area network (WAN). This paper examines the opportunity of applying multi-query optimization in the context of wide-area streaming analytics, with the goal of utilizing WAN bandwidth efficiently while achieving high throughput and low latency execution. Our approach is based on the insight that many streaming analytics queries often exhibit common executions, whether in consuming a common set of input data or performing the same data processing. In this work, we study different types of sharing opportunities and propose a practical online algorithm that allows streaming analytics queries to share their common executions incrementally. We further address the importance of WAN awareness in applying multi-query optimization. Without WAN awareness, sharing executions in a wide-area environment may lead to performance degradation. We have implemented our WAN-aware multi-query optimization in a prototype implementation based on Apache Flink. Experimental evaluation using Twitter traces on a real wide-area system deployment across geo-distributed EC2 data centers shows that our technique is able to achieve 21% higher throughput while saving WAN bandwidth consumption by 33% compared to a WAN-aware, sharing-agnostic system. © 2018 Association for Computing Machinery.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Jonathan, A. and Chandra, A. and Weissman, J.",2018,SoCC 2018 - Proceedings of the 2018 ACM Symposium on Cloud Computing,10.1145/3267809.3267842,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Zacheilas2017112,Maximizing determinism in stream processing under latency constraints,"The problem of coping with the demands of determinism and meeting latency constraints is challenging in distributed data stream processing systems that have to process high volume data streams that arrive from different unsynchronized input sources. In order to deterministically process the streaming data, they need mechanisms that synchronize the order in which tuples are processed by the operators. On the other hand, achieving real-time response in such a system requires careful tradeoff between determinism and low latency performance. We build on a recently proposed approach to handle data exchange and synchronization in stream processing, namely ScaleGate, which comes with guarantees for determinism and an efficient lock-free implementation, enabling high scalability. Considering the challenge and trade-offs implied by real-time constraints, we propose a system which comprises (a) a novel data structure called Slack-ScaleGate (SSG), along with its algorithmic implementation; SSG enables us to guarantee the deterministic processing of tuples as long as they are able to meet their latency constraints, and (b) a method to dynamically tune the maximum amount of time that a tuple can wait in the SSG data-structure, relaxing the determinism guarantees when needed, in order to satisfy the latency constraints. Our detailed experimental evaluation using a traffic monitoring application deployed in the city of Dublin, illustrates the working and benefits of our approach. © 2017 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zacheilas, N. and Kalogeraki, V. and Nikolakopoulos, Y. and Gulisano, V. and Papatriantafilou, M. and Tsigas, P.",2017,DEBS 2017 - Proceedings of the 11th ACM International Conference on Distributed Event-Based Systems,10.1145/3093742.3093921,scopus-search1.bib;acm1-search1.bib
Liu2013351,Peer-assisted on-demand streaming: Characterizing demands and optimizing supplies,"Nowadays, there has been significant deployment of peer-assisted on-demand streaming services over the Internet. Two of the most unique and salient features in a peer-assisted on-demand streaming system are the differentiation in the demand (or request) and the prefetching capability with caching. In this paper, we develop a theoretical framework based on queuing models, in order to 1) justify the superiority of service prioritization based on a taxonomy of requests, and 2) understand the fundamental principles behind optimal prefetching and caching designs in peer-assisted on-demand streaming systems. The focus is to instruct how limited uploading bandwidth resources and peer caching capacities can be utilized most efficiently to achieve better system performance. To achieve these objectives, we first use priority queuing analysis to prove how service quality and user experience can be statistically guaranteed, by prioritizing requests in the order of significance, including urgent playback (e.g., random seeks or initial startup), normal playback, and prefetching. We then proceed to construct a fine-grained stochastic supply-demand model to investigate peer caching and prefetching as a global optimization problem. This not only provides insights in understanding the fundamental characterization of demand, but also offers guidelines toward optimal prefetching and caching strategies in peer-assisted on-demand streaming systems. © 1968-2012 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Liu, F. and Li, B. and Li, B. and Jin, H.",2013,IEEE Transactions on Computers,10.1109/TC.2011.222,scopus-search1.bib
Nguyen2011,PAL: Propagation-aware Anomaly Localization for cloud hosted distributed applications,"Distributed applications running inside cloud are prone to performance anomalies due to various reasons such as insufficient resource allocations, unexpected workload increases, or software bugs. However, those applications often consist of multiple interacting components where one component anomaly may cause its dependent components to exhibit anomalous behavior as well. It is challenging to identify the faulty components among numerous distributed application components. In this paper, we present a Propagation-aware Anomaly Localization (PAL) system that can pinpoint the source faulty components in distributed applications by extracting anomaly propagation patterns. PAL provides a robust critical change point discovery algorithm to accurately capture the onset of anomaly symptoms at different application components. We then derive the propagation pattern by sorting all critical change points in chronological order. PAL is completely application-agnostic and non-intrusive, which only relies on system-level metrics. We have implemented PAL on top of the Xen platform and tested it on a production cloud computing infrastructure using the RUBiS online auction benchmark application and the IBM System S data streaming processing application with a range of common software bugs. Our experimental results show that PAL can pinpoint faulty components in distributed applications with high accuracy and low overhead. © 2011 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Nguyen, H. and Tan, Y. and Gu, X.",2011,"Managing Large-Scale Systems via the Analysis of System Logs and the Application of Machine Learning Techniques, SLAML'11",10.1145/2038633.2038634,scopus-search1.bib;acm3-search1.bib
Qian2016592,Benchmarking modern distributed streaming platforms,"The prevalence of big data technology has generated increasing demands in large-scale streaming data processing. However, for certain tasks it is still challenging to appropriately select a platform due to the diversity of choices and the complexity of configurations. This paper focuses on benchmarking some principal streaming platforms. We achieve our goals on StreamBench, a streaming benchmark tool based on which we introduce proper modifications and extensions. We then accomplish performance comparisons among different big data platforms, including Apache Spark, Apache Storm and Apache Samza. In terms of performance criteria, we consider both computational capability and fault-tolerance ability. Finally, we give a summary on some key knobs for performance tuning as well as on hardware utilization. © 2016 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Qian, S. and Wu, G. and Huang, J. and Das, T.",2016,Proceedings of the IEEE International Conference on Industrial Technology,10.1109/ICIT.2016.7474816,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Tudoran201423,JetStream: Enabling high performance event streaming across cloud data-centers,"The easily-accessible computation power offered by cloud infrastructures coupled with the revolution of Big Data are expanding the scale and speed at which data analysis is performed. In their quest for finding the Value in the 3 Vs of Big Data, applications process larger data sets, within and across clouds. Enabling fast data transfers across geographically distributed sites becomes particularly important for applications which manage continuous streams of events in real time. Scientific applications (e.g. the Ocean Observatory Initiative or the ATLAS experiment) as well as commercial ones (e.g. Microsoft's Bing and Office 365 large-scale services) operate on tens of data-centers around the globe and follow similar patterns: they aggregate monitoring data, assess the QoS or run global data mining queries based on inter site event stream processing. In this paper, we propose a set of strategies for efficient transfers of events between cloud data-centers and we introduce JetStream: a prototype implementing these strategies as a high performance batch-based streaming middleware. JetStream is able to self-adapt to the streaming conditions by modeling and monitoring a set of context parameters. It further aggregates the available bandwidth by enabling multi-route streaming across cloud sites. The prototype was validated on tens of nodes from US and Europe data-centers of the Windows Azure cloud using synthetic benchmarks and with application code from the context of the Alice experiment at CERN. The results show an increase in transfer rate of 250 times over individual event streaming. Besides, introducing an adaptive transfer strategy brings an additional 25% gain. Finally, the transfer rate can further be tripled thanks to the use of multi-route streaming. © 2014 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Tudoran, R. and Nano, O. and Santos, I. and Costan, A. and Soncu, H. and Bougé, L. and Antoniu, G.",2014,DEBS 2014 - Proceedings of the 8th ACM International Conference on Distributed Event-Based Systems,10.1145/2611286.2611298,scopus-search1.bib;acm2-search1.bib
Zinn2010447,Parallelizing XML data-streaming workflows via MapReduce,"In prior work it has been shown that the design of scientific workflows can benefit from a collection-oriented modeling paradigm which views scientific workflows as pipelines of XML stream processors. In this paper, we present approaches for exploiting data parallelism in XML processing pipelines through novel compilation strategies to the MapReduce framework Pipelines in our approach consist of sequences of processing steps that receive XML-structured data and produce, often through calls to ``black-box{''} (scientific) functions, modified (i.e.. updated) XML structures. Our main contributions are (i) the development of a set of strategies for compiling scientific workflows, modeled as XML processing pipelines, into parallel MapReduce networks, and (ii) a discussion of their advantages and trade-offs, based on a thorough experimental evaluation of the various translation strategies. Our evaluation uses the Hadoop MapReduce system as an implementation platform. Our results show that execution times of XML workflow pipelines can be significantly reduced using our compilation strategies. These efficiency gains, together with the benefits of MapReduce (e.g., fault tolerance) make our approach ideal for executing large-scale, compute-intensive XML-based Scientific workflows (C) 2009 Elsevier Inc. All rights reserved",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zinn, D. and Bowers, S. and Köhler, S. and Ludäscher, B.",2010,Journal of Computer and System Sciences,10.1016/j.jcss.2009.11.006,scopus-search1.bib;web-of-science-search1.bib
Fang2007232,Active memory operations,"The performance of modern microprocessors is increasingly limited by their inability to hide main memory latency. The problem is worse in large-scale shared memory systems, where remote memory latencies are hundreds, and soon thousands, of processor cycles. To mitigate this problem, we propose the use of Active Memory Operations (AMOs), in which select operations can be sent to and executed on the home memory controller of data. AMOs can eliminate significant number of coherence messages, minimize intranode and internode memory traffic, and create opportunities for parallelism. Our implementation of AMOs is cache-coherent and requires no changes to the processor core or DRAM chips. In this paper we present architectural and programming models for AMOs, and compare its performance to that of several other memory architectures on a variety of scientific and commercial benchmarks. Through simulation we show that AMOs offer dramatic performance improvements for an important set of data-intensive operations, e.g., up to 50X faster barriers, 12X faster spinlocks, 8.5X-15X faster stream/array operations, and 3X faster database queries. Based on a standard cell implementation, we predict that the circuitry required to support AMOs is less than 1% of the typical chip area of a high performance microprocessor. Copyright 2007 ACM.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Fang, Z. and Zhang, L. and Carter, J.B. and Ibrahim, A. and Parker, M.A.",2007,Proceedings of the International Conference on Supercomputing,10.1145/1274971.1275004,scopus-search1.bib;acm2-search1.bib
Zhang2011245,GStream: A general-purpose data streaming framework on GPU clusters,"Emerging accelerating architectures, such as GPUs, have proved successful in providing significant performance gains to various application domains. However, their viability to operate on general streaming data is still ambiguous. In this paper, we propose GStream, a general-purpose, scalable data streaming framework on GPUs. The contributions of GStream are as follows: (1) We provide powerful, yet concise language abstractions suitable to describe conventional algorithms as streaming problems. (2)We project these abstractions onto GPUs to fully exploit their inherent massive dataparallelism. (3) We demonstrate the viability of streaming on accelerators. Experiments show that the proposed framework provides flexibility, programmability and performance gains for various benchmarks from a collection of domains, including but not limited to data streaming, data parallel problems and numerical codes. © 2011 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Zhang, Y. and Mueller, F.",2011,Proceedings of the International Conference on Parallel Processing,10.1109/ICPP.2011.22,scopus-search1.bib;ieee3-search1.bib
Mansour20081366,Channel aware multiuser scalable video streaming over lossy under-provisioned channels: Modeling and analysis,"In this paper, we analyze the performance of media-aware multiuser video streaming strategies in capacity limited wireless channels suffering from latency problems and packet losses. Wireless video streaming applications are characterized by their bandwidth-intensity, delay-sensitivity, and loss-tolerance. Our main contributions include i) a rate-minimized unequal erasure protection (UXP) scheme, ii) an analytical expression for packet delay and play-out deadline of UXP protected scalable video, iii) a loss-distortion model for hierarchical predictive video coders with picture copy concealment, iv) an analysis of the performance and complexity of delay-aware, capacity-aware, and optimized UXP streaming scenarios, and v) we show that the use of unequal error protection causes a rate-constrained optimization problem to be nonconvex. Performance evaluations using a 3GPP network simulator show that, for different channel capacities and packet loss rates, delay-aware nonstationary rate-allocation streaming policies deliver significant gains which range between 1.65 dB to 2 dB in average Y-PSNR of the received video streams over delay-unaware strategies. These gains come at a cost of increased offline computation which is performed prior to the start of the streaming session or in batches during transmission and therefore, do not affect the run-time performance of the streaming system. © 2008 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Mansour, H. and Krishnamurthy, V. and Nasiopoulos, P.",2008,IEEE Transactions on Multimedia,10.1109/TMM.2008.2004915,scopus-search1.bib;ieee3-search1.bib
Ferdman2007105,Last-touch correlated data streaming,"Recent research advocates address-correlating predictors to identify cache block addresses for prefetch. Unfortunately, address-correlating predictors require correlation data storage proportional in size to a program's active memory footprint. As a result, current proposals for this class of predictor are either limited in coverage due to constrained on-chip storage requirements or limited in prediction lookaheaddue to long off-chip correlation data lookup. In this paper, we propose Last-Touch Correlated Data Streaming (LT-cords), a practical address-correlating predictor. The key idea of LT-cords is to record correlation data off chip in the order they will be used and stream them into a practicallysized on-chip table shortly before they are needed, thereby obviating the need for scalable on-chip tables and enabling low-latency lookup. We use cycle-accurate simulation of an 8-way out-of-order superscalar processor to show that: (1) LT-cords with 214KB of on-chip storage can achieve the same coverage as a last-touch predictor with unlimited storage, without sacrificing predictor lookahead, and (2) LT-cords improves performance by 60% on average and 385% at best in the benchmarks studied. © 2007 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Ferdman, M. and Falsafi, B.",2007,ISPASS 2007: IEEE International Symposium on Performance Analysis of Systems and Software,10.1109/ISPASS.2007.363741,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Kazanskiy2017806,Performance analysis of real-time face detection system based on stream data mining frameworks,"This work describes performance analysis results of two face detection systems based on Apache Storm and IBM InfoSphere Streams frameworks. Profiling was evaluated on image sequences of four different sizes: 100 x 100, 640 x 640, 1920 x 1080, and 4096 x 3112. Face detection was performed by OpenCV cascade classifier. Experiment was held under five CentOS nodes cluster. It was investigated that system based on Apache Storm was able to operate in real-time at 24 frames per second on used hardware configuration. Apache Storm was more scalable and demonstrated advantage in throughput over its counterpart. Experiment helped to reveal configuration parameters of frameworks that played a major role in face detection task on image sequences. (C) 2017 The Authors. Published by Elsevier Ltd.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Kazanskiy, N. and Protsenko, V. and Serafimovich, P.",2017,Procedia Engineering,10.1016/j.proeng.2017.09.602,scopus-search1.bib;web-of-science-search1.bib
Weiler2014282,Event identification and tracking in social media streaming data,"In recent years, the growing popularity and active use of social media services on the web have resulted in massive amounts of user-generated data. With these data available, there is also an increasing interest in analyzing it and to extract information from it. Since social media analysis is concerned with investigating current events around the world, there is a strong emphasis on identifying these evens as quickly as possible, ideally in real-time. In order to scale with the rapidly increasing volume of social media data, we propose to explore very simple event identification mechanisms, rather than applying the more complex approaches that have been proposed in the literature. In this paper, we present a first investigation along this motivation. We discuss a simple sliding window model, which uses shifts in the inverse document frequency (IDF) to capture trending terms as well as to track the evolution and the context around events. Further, we present an initial experimental evaluation of the results that we obtained by analyzing real-world data streams from Twitter.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Weiler, A. and Grossniklaus, M. and Scholl, M.H.",2014,CEUR Workshop Proceedings,,scopus-search1.bib
Botan2009934,Flexible and scalable storage management for data-intensive Stream processing,"Data Stream Management Systems (DSMS) operate under strict performance requirements. Key to meeting such requirements is to efficiently handle time-critical tasks such as managing internal states of continuous query operators, traffic on the queues between operators, as well as providing storage support for shared computation and archived data. In this paper, we introduce a general purpose storage management framework for DSMSs that performs these tasks based on a clean, loosely-coupled, and flexible system design that also facilitates performance optimization. An important contribution of the framework is that, in analogy to buffer management techniques in relational database systems, it uses information about the access patterns of streaming applications to tune and customize the performance of the storage manager. In the paper, we first analyze typical application requirements at different granularities in order to identify important tunable parameters and their corresponding values. Based on these parameters, we define a general-purpose storage management interface. Using the interface, a developer can use our SMS (Storage Manager for Streams) to generate a customized storage manager for streaming applications. We explore the performance and potential of SMS through a set of experiments using the Linear Road benchmark. Copyright 2009 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Botan, I. and Alonso, G. and Fischer, P.M. and Kossmann, D. and Tatbul, N.",2009,"Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology, EDBT'09",10.1145/1516360.1516467,scopus-search1.bib
Liang2008257,Smartcell: A power-efficient reconfigurable architecture for data streaming applications,"This paper presents SmartCell as a novel power efficient reconfigurable architecture targeted for data streaming applications. We describe the design details of the SmartCell architecture, including processing element, reconfigurable interconnection fabrics, instruction and control process and dynamic configuration scheme. The performance in terms of power efficiency and system throughput is evaluated through a set of benchmark applications, and is compared with ASIC, FPGA and RaPiD reconfigurable architecture. The results show that the SmartCell consumes about 52% and 75% less power than RaPiD and FPGA, respectively. It is demonstrated that SmartCell is a promising reconfigurable, power efficient and scalable computing architecture that can potentially bridge the gap between logic specific ASIC and configurable FPGA for data streaming applications. © 2008 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Liang, C. and Huang, X.",2008,"IEEE Workshop on Signal Processing Systems, SiPS: Design and Implementation",10.1109/SIPS.2008.4671772,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Suh2003410,"A performance analysis of PIM, stream processing, and tiled processing on memory-intensive signal processing kernels","Trends in microprocessors of increasing die size and clock speed and decreasing feature sizes have fueled rapidly increasing performance. However, the limited improvements in DRAM latency and bandwidth and diminishing returns of increasing superscalar ILP and cache sizes have led to the proposal of new microprocessor architectures that implement processor-in-memory, stream processing, and tiled processing. Each architecture is typically evaluated separately and compared to a baseline architecture. In this paper, we evaluate the performance of processors that implement these architectures on a common set of signal processing kernels. The implementation results are compared with the measured performance of a conventional system based on the PowerPC with Altivec. The results show that these new processors show significant improvements over conventional systems and that each architecture has its own strengths and weaknesses.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Suh, J. and Kim, E.-G. and Crago, S.P. and Srinivasan, L. and French, M.C.",2003,"Conference Proceedings - Annual International Symposium on Computer Architecture, ISCA",10.1145/859618.859665,scopus-search1.bib;ieee3-search1.bib;scholar.bib
Fernández-Rodríguez201762,Benchmarking real-time vehicle data streaming models for a smart city,"The information systems of smart cities offer project developers, institutions, industry and experts the possibility to handle massive incoming data from diverse information sources in order to produce new information services for citizens. Much of this information has to be processed as it arrives because a real-time response is often needed. Stream processing architectures solve this kind of problems, but sometimes it is not easy to benchmark the load capacity or the efficiency of a proposed architecture. This work presents a real case project in which an infrastructure was needed for gathering information from drivers in a big city, analyzing that information and sending real-time recommendations to improve driving efficiency and safety on roads. The challenge was to support the real-time recommendation service in a city with thousands of simultaneous drivers at the lowest possible cost. In addition, in order to estimate the ability of an infrastructure to handle load, a simulator that emulates the data produced by a given amount of simultaneous drivers was also developed. Experiments with the simulator show how recent stream processing platforms like Apache Kafka could replace custom-made streaming servers in a smart city to achieve a higher scalability and faster responses, together with cost reduction. (C) 2017 Elsevier Ltd. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Fernández-Rodríguez, J.Y. and Álvarez-García, J.A. and AriasFisteus, J. and Luaces, M.R. and CorcobaMagaña, V.",2017,Information Systems,10.1016/j.is.2017.09.002,scopus-search1.bib;web-of-science-search1.bib
Bumgardner2014219,Scalable hybrid stream and hadoop network analysis system,"Collections of network traces have long been used in network traffic analysis. Flow analysis can be used in network anomaly discovery, intrusion detection and more generally, discovery of actionable events on the network. The data collected during processing may be also used for prediction and avoidance of traffic congestion, network capacity planning, and the development of software-defined networking rules. As network flow rates increase and new network technologies are introduced on existing hardware platforms, many organizations find themselves either technically or financially unable to generate, collect, and/or analyze network flow data. The continued rapid growth of network trace data, requires new methods of scalable data collection and analysis. We report on our deployment of a system designed and implemented at the University of Kentucky that supports analysis of network traffic across the enterprise. Our system addresses problems of scale in existing systems, by using distributed computing methodologies, and is based on a combination of stream and batch processing techniques. In addition to collection, stream processing using Storm is utilized to enrich the data stream with ephemeral environment data. Enriched stream-data is then used for event detection and near real-time flow analysis by an in-line complex event processor. Batch processing is performed by the Hadoop MapReduce framework, from data stored in HBase BigTable storage. In benchmarks on our 10 node cluster, using actual network data, we were able to stream process over 315k flows/sec. In batch analysis were we able to process over 2.6M flows/sec with a storage compression ratio of 6.7:1.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Bumgardner, V.K.C. and Marek, V.W.",2014,ICPE 2014 - Proceedings of the 5th ACM/SPEC International Conference on Performance Engineering,10.1145/2568088.2568103,scopus-search1.bib;acm3-search1.bib
Bo2008577,A high performance enterprise service bus platform for complex event processing,"Enterprise Service Bus (ESB) technology combines the Service-Oriented Architecture, which is based on the request/ response model, and the Event-Driven Architecture, which is based on the publish/subscribe model. It can satisfy the demand of loose couple communication and cooperation in the enterprise applications. However, existing ESB based systems can't process the complex events in the real-world applications very well. In this paper, we firstly give a complex event processing model based on the relational algebra, and then propose a complex event processing oriented enterprise service bus platform and a complex event stream processing engine, and give the main algorithms of complex event processing and their performance analysis. Experiments show that our platform performs much better than the existing ESB based systems in complex event processing. © 2008 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Bo, D. and Kun, D. and Xiaoyi, Z.",2008,"Proceedings - 7th International Conference on Grid and Cooperative Computing, GCC 2008",10.1109/GCC.2008.66,scopus-search1.bib
Stephen2016348,STYX: Stream processing with trustworthy cloud-based execution,"With the advent of the Internet of Things (IoT), billions of devices are expected to continuously collect and process sensitive data (e.g., location, personal health). Due to limited computational capacity available on IoT devices, the current de facto model for building IoT applications is to send the gathered data to the cloud for computation. While private cloud infrastructures for handling large amounts of data streams are expensive to build, using low cost public (untrusted) cloud infrastructures for processing continuous queries including on sensitive data leads to concerns over data confidentiality. This paper presents STYX, a novel programming abstraction and managed runtime system, that ensures confidentiality of IoT applications whilst leveraging the public cloud for continuous query processing. The key idea is to intelligently utilize partially homomorphic encryption to perform as many computationally intensive operations as possible in the untrusted cloud. STYX provides a simple abstraction to the IoT developer to hide the complexities of (1) applying complex cryptographic primitives, (2) reasoning about performance of such primitives, (3) deciding which computations can be executed in an untrusted tier, and (4) optimizing cloud resource usage. An empirical evaluation with benchmarks and case studies shows the feasibility of our approach.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Stephen, J.J. and Savvides, S. and Sundaram, V. and Ardekani, M.S. and Eugster, P.",2016,"Proceedings of the 7th ACM Symposium on Cloud Computing, SoCC 2016",10.1145/2987550.2987574,scopus-search1.bib
Casas20161,Big-DAMA: Big data analytics for network traffic monitoring and analysis,"The complexity of the Internet has dramatically increased in the last few years, making it more important and challenging to design scalable Network Traffic Monitoring and Analysis (NTMA) applications and tools. Critical NTMA applications such as the detection of anomalies, network attacks and intrusions, require fast mechanisms for online analysis of thousands of events per second, as well as efficient techniques for offline analysis of massive historical data. We are witnessing a major development in Big Data Analysis Frameworks (BDAFs), but the application of BDAFs and scalable analysis techniques to the NTMA domain remains poorly understood and only in-house and difficult to benchmark solutions are conceived. In this position paper we describe the basis of the Big-DAMA research project, which aims at tackling this growing need by benchmarking and developing novel scalable techniques and frameworks capable to analyze both online network traffic data streams and offline massive traffic datasets. © 2016 ACM.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Casas, P. and D'Alconzo, A. and Zseby, T. and Mellia, M.",2016,"LANCOMM 2016 - Proceedings of the 2016 ACM SIGCOMM Workshop on Fostering Latin-American Research in Data Communication Networks, Part of SIGCOMM 2016",10.1145/2940116.2940117,scopus-search1.bib;acm3-search1.bib
DePauw201018,Visual debugging for stream processing applications,"Stream processing is a new computing paradigm that enables continuous and fast analysis of massive volumes of streaming data. Debugging streaming applications is not trivial, since they are typically distributed across multiple nodes and handle large amounts of data. Traditional debugging techniques like breakpoints often rely on a stop-the-world approach, which may be useful for debugging single node applications, but insufficient for streaming applications. We propose a new visual and analytic environment to support debugging, performance analysis, and troubleshooting for stream processing applications. Our environment provides several visualization methods to study, characterize, and summarize the flow of tuples between stream processing operators. The user can interactively indicate points in the streaming application from where tuples will be traced and visualized as they flow through different operators, without stopping the application. To substantiate our discussion, we also discuss several of these features in the context of a financial engineering application. © 2010 Springer-Verlag.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"DePauw, W. and Leţia, M. and Gedik, B. and Andrade, H. and Frenkiel, A. and Pfeifer, M. and Sow, D.",2010,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-642-16612-9_3,scopus-search1.bib;web-of-science-search1.bib;scholar.bib
Buddhika20161143,NEPTUNE: Real Time Stream Processing for Internet of Things and Sensing Environments,"Improvements in miniaturization and networking capabilities of sensors have contributed to the proliferation of Internet of Things (IoT) and continuous sensing environments. Data streams generated in such settings must keep pace with generation rates and be processed in real time. Challenges in accomplishing this include: high data arrival rates, buffer overflows, context-switches, and object creation overheads. We propose a holistic framework that addresses the CPU, memory, network, and kernel issues involved in stream processing. Our prototype, Neptune, builds on our Granules cloud runtime. The framework maximizes bandwidth utilization in the presence of small messages via the use of buffering and dynamic compactions of packets based on payload entropy. Our use of thread-pools and batched processing reduces context switches and improves effective CPU utilizations. NEPTUNE alleviates memory pressure that can lead to swapping, page faults, and thrashing through efficient reuse of objects. To cope with buffer overflows we rely on flow control and throttling the preceding stages of a processing pipeline. Our benchmarks demonstrate the suitability of the Neptune and we contrast our performance with Apache Storm, the dominant stream-processing framework developed by Twitter. At a single node, we are able to achieve a processing rate of similar to 2 million stream packets per-second. In a distributed setup, we achieved a rate of similar to 100 million packets per-second.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Buddhika, T. and Pallickara, S.",2016,"Proceedings - 2016 IEEE 30th International Parallel and Distributed Processing Symposium, IPDPS 2016",10.1109/IPDPS.2016.43,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Guo20151161,Fast distributed correlation discovery over streaming time-series data,"The dramatic rise of time-series data in a variety of contexts, such as social networks, mobile sensing, data centre monitoring, etc., has fuelled interest in obtaining real-time insights from such data using distributed stream processing systems. One such extremely valuable insight is the discovery of correlations in real-time from large-scale time-series data. A key challenge in discovering correlations is that the number of time-series pairs that have to be analyzed grows quadratically in the number of time-series, giving rise to a quadratic increase in both computation cost and communication cost between the cluster nodes in a distributed environment. To tackle the challenge, we propose a framework called AEGIS. AEGIS exploits well-established statistical properties to dramatically prune the number of time-series pairs that have to be evaluated for detecting interesting correlations. Our extensive experimental evaluations on real and synthetic datasets establish the efficacy of AEGIS over baselines.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Guo, T. and Sathe, S. and Aberer, K.",2015,"International Conference on Information and Knowledge Management, Proceedings",10.1145/2806416.2806440,scopus-search1.bib
Bellavista2014363,Priority-based resource scheduling in distributed stream processing systems for big data applications,"Distributed Stream Processing Systems (DSPSs) are attracting increasing industrial and academic interest as flexible tools to implement scalable and cost-effective on-line analytics applications over Big Data streams. Often hosted in private/public cloud deployment environments, DSPSs offer data stream processing services that transparently exploit the distributed computing resources made available to them at runtime. Given the volume of data of interest, possible (hard/soft) real-time processing requirements, and the time-variable characteristics of input data streams, it is very important for DSPSs to use smart and innovative scheduling techniques that allocate computing resources properly and avoid static over-provisioning. In this paper, we originally investigate the suitability of exploiting application-level indications about differentiated priorities of different stream processing tasks to enable application-specific DSPS resource scheduling, e.g., Capable of re-shaping processing resources in order to dynamically follow input data peaks of prioritized tasks, with no static over-provisioning. We originally propose a general and simple technique to design and implement priority-based resource scheduling in flow-graph-based DSPSs, by allowing application developers to augment DSPS graphs with priority metadata and by introducing an extensible set of priority schemas to be automatically handled by the extended DSPS. In addition, we show the effectiveness of our approach via its implementation and integration in our Quasit DSPS and through experimental evaluation of this prototype on a real-world stream processing application of Big Data vehicular traffic analysis. © 2014 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Bellavista, P. and Corradi, A. and Reale, A. and Ticca, N.",2014,"Proceedings - 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing, UCC 2014",10.1109/UCC.2014.46,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib;acm1-search1.bib
Mahmood2018219,Adaptive processing of spatial-keyword data over a distributed streaming cluster,"The widespread use of GPS-enabled smartphones along with the popularity of micro-blogging and social networking applications, e.g., Twitter and Facebook, has resulted in the generation of huge streams of geo-tagged textual data. Many applications require real-time processing of these streams. For example, location-based ad-targeting systems enable advertisers to register millions of ads to millions of users based on the users’ location and textual proile. Existing streaming systems are either centralized or are not spatial-keyword aware, and hence these systems cannot eiciently support the processing of rapidly arriving spatial-keyword data streams. In this paper, we introduce a two-layered indexing scheme for the distributed processing of spatial-keyword data streams. We realize this indexing scheme in Tornado, a distributed spatial-keyword streaming system. The irst layer, termed the routing layer, is used to fairly distribute the workload, and furthermore, co-locate the data objects and the corresponding queries at the same processing units. The routing layer uses the Augmented-Grid, a novel structure that is equipped with an eicient search algorithm for distributing the data objects and queries. The second layer, termed the evaluation layer, resides within each processing unit to reduce the processing overhead. The two-layered index adapts to changes in the workload by applying a cost formula that continuously represents the processing overhead at each processing unit. Extensive experimental evaluation using real Twitter data indicates that Tornado achieves high scalability and more than 2x improvement over the baseline approach in terms of the overall system throughput. © 2018 held by the owner/author(s). Publication rights licensed to ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Mahmood, A.R. and Daghistani, A. and Aly, A.M. and Tang, M. and Basalamah, S. and Prabhakar, S. and Aref, W.G.",2018,GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems,10.1145/3274895.3274932,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Hoffmann20181002,Megaphone: Latencyconscious state migration for distributed streaming dataflows,"We design and implement Megaphone, a data migration mechanism for stateful distributed dataflow engines with latency objectives. When compared to existing migration mechanisms, Megaphone has the following differentiating characteristics: (i) migrations can be subdivided to a configurable granularity to avoid latency spikes, and (ii) migrations can be prepared ahead of time to avoid runtime coordination. Megaphone is implemented as a library on an unmodified timely dataflow implementation, and provides an operator interface compatible with its existing APIs. We evaluate Megaphone on established benchmarks with varying amounts of state and observe that compared to naïve approaches Megaphone reduces service latencies during reconfiguration by orders of magnitude without significantly increasing steady-state overhead. © 2018, VLDB Endowment.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Hoffmann, M. and Lattuada, A. and McSherry, F. and Kalavri, V. and Liagouris, J. and Roscoe, T.",2018,Proceedings of the VLDB Endowment,10.14778/3329772.3329777,scopus-search1.bib;web-of-science-search1.bib
Imai2017504,Maximum Sustainable throughput Prediction for Data Stream Processing over Public Clouds,"In cloud-based stream processing services, the maximum sustainable throughput (MST) is defined as the maximum throughput that a system composed of a fixed number of virtual machines (VMs) can ingest indefinitely. If the incoming data rate exceeds the system's MST, unprocessed data accumulates, eventually making the system inoperable. Thus, it is important for the service provider to keep the MST always larger than the incoming data rate by dynamically changing the number of VMs used by the system. In this paper, we identify a common data processing environment used by modern data stream processing systems, and we propose MST prediction models for this environment. We train the models using linear regression with samples obtained from a few VMs and predict MST for a larger number of VMs. To minimize the time and cost for model training, we statistically determine a set of training samples using Intel's Storm benchmarks with representative resource usage patterns. Using typical use-case benchmarks on Amazon's EC2 public cloud, our experiments show that, training with up to 8 VMs, we can predict MST for streaming applications with less than 4% average prediction error for 12 VMs, 9% for 16 VMs, and 32% for 24 VMs. Further, we evaluate our prediction models with simulation based elastic VM scheduling on a realistic workload. These simulation results show that with 10% over provisioning, our proposed models' cost efficiency is on par with the cost of an optimal scaling policy without incurring any service level agreement violations. © 2017 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Imai, S. and Patterson, S. and Varela, C.A.",2017,"Proceedings - 2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGRID 2017",10.1109/CCGRID.2017.105,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib;acm2-search1.bib
Čermák2016919,A performance benchmark for NetFlow data analysis on distributed stream processing systems,"Modern distributed stream processing systems can potentially be applied to real time network flow processing. However, differences in performance make some systems more suitable than others for being applied to this domain. We propose a novel performance benchmark, which is based on common security analysis algorithms of NetFlow data to determine the suitability of distributed stream processing systems. Three of the most used distributed stream processing systems are bench-marked and the results are compared with NetFlow data processing challenges and requirements. The benchmark results show that each system reached a sufficient data processing speed using a basic deployment scenario with little to no configuration tuning. Our benchmark, unlike any other, enables the performance of small structured messages to be processed on any stream processing system. © 2016 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Čermák, M. and Tovarňák, D. and Laśtovička, M. and Čeleda, P.",2016,Proceedings of the NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium,10.1109/NOMS.2016.7502926,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Najafi2016493,"SplitJoin: A scalable, low-latency stream join architecture with adjustable ordering precision","There is a rising interest in accelerating stream processing through modern parallel hardware, yet it remains a challenge as how to exploit the available resources to achieve higher throughput without sacrificing latency due to the increased length of processing pipeline and communication path and the need for central coordination. To achieve these objectives, we introduce a novel top-down data flow model for stream join processing (arguably, one of the most resource-intensive operators in stream processing), called SplitJoin, that operates by splitting the join operation into independent storing and processing steps that gracefully scale with respect to the number of cores. Furthermore, SplitJoin eliminates the need for global coordination while preserving the order of input streams by re-thinking how streams are channeled into distributed join computation cores and maintaining the order of output streams by proposing a novel distributed punctuation technique. Throughout our experimental analysis, SplitJoin offered up to 60% improvement in throughput while reducing latency by up to 3.3X compared to state-of-the-art solutions. © 2016 by The USENIX Association. All Rights Reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Najafi, M. and Sadoghi, M. and Jacobsen, H.-A.",2016,"Proceedings of the 2016 USENIX Annual Technical Conference, USENIX ATC 2016",,scopus-search1.bib;web-of-science-search1.bib
Dehghanzadeh2015307,Approximate continuous query answering over streams and dynamic linked data sets,"To perform complex tasks, RDF Stream Processing Web applications evaluate continuous queries over streams and quasi-static (background) data. While the former are pushed in the application, the latter are continuously retrieved from the sources. As soon as the background data increase the volume and become distributed over the Web, the cost to retrieve them increases and applications become unresponsive. In this paper, we address the problem of optimizing the evaluation of these queries by leveraging local views on background data. Local views enhance performance, but require maintenance processes, because changes in the background data sources are not automatically reflected in the application. We propose a two-step query-driven maintenance process to maintain the local view: it exploits information from the query (e.g., the sliding window definition and the current window content) to maintain the local view based on user-defined Quality of Service constraints. Experimental evaluation show the effectiveness of the approach. © Springer International Publishing Switzerland 2015.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Dehghanzadeh, S. and Dell’Aglio, D. and Gao, S. and DellaValle, E. and Mileo, A. and Bernstein, A.",2015,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-19890-3_20,scopus-search1.bib;web-of-science-search1.bib
Mokhtari2014819,BigKernel - High performance CPU-GPU communication pipelining for big data-style applications,"GPUs offer an order of magnitude higher compute power and memory bandwidth than CPUs. GPUs therefore might appear to be well suited to accelerate computations that operate on voluminous data sets in independent ways, e.g., for transformations, filtering, aggregation, partitioning or other 'Big Data' style processing. Yet experience indicates that it is difficult, and often error-prone, to write GPGPU programs which efficiently process data that does not fit in GPU memory, partly because of the intricacies of GPU hardware architecture and programming models, and partly because of the limited bandwidth available between GPUs and CPUs. In this paper, we propose Big Kernel, a scheme that provides pseudo-virtual memory to GPU applications and is implemented using a 4-stage pipeline with automated prefetching to (i) optimize CPU-GPU communication and (ii) optimize GPU memory accesses. Big Kernel simplifies the programming model by allowing programmers to write kernels using arbitrarily large data structures that can be partitioned into segments where each segment is operated on independently, these kernels are transformed into Big Kernel using straight-forward compiler transformations. Our evaluation on six data-intensive benchmarks shows that Big Kernel achieves an average speedup of 1.7 over state-of-the-art double-buffering techniques and an average speedup of 3.0 over corresponding multi-threaded CPU implementations. © 2014 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Mokhtari, R. and Stumm, M.",2014,"Proceedings of the International Parallel and Distributed Processing Symposium, IPDPS",10.1109/IPDPS.2014.89,scopus-search1.bib;web-of-science-search1.bib
Hsu2010169,Quality-aware segment transmission scheduling in peer-to-peer streaming systems,"In peer-to-peer (P2P) mesh-based streaming systems, each video sequence is typically divided into segments, which are then streamed from multiple senders to a receiver. The receiver needs to coordinate the senders by specifying a transmission schedule for each of them. We consider the scheduling problem in both live and on-demand P2P streaming systems. We formulate the problem of scheduling segment transmission in order to maximize the perceived video quality of the receiver. We prove that this problem is NP-Complete. We present an integer linear programming (ILP) formulation for this problem, and we optimally solve it using an ILP solver. This optimal solution, however, is computationally expensive and is not suitable for real-time streaming systems. Thus, we propose a polynomial-time approximation algorithm, which yields transmission schedules with analytical guarantees on the worst-case performance. More precisely, we show that the approximation factor is at most 3, compared to the absolutely optimal solution as a benchmark. We implement the proposed approximation and optimal algorithms in a packet-level simulator for P2P streaming systems. We also implement two other scheduling algorithms proposed in the literature and used in popular P2P streaming systems. By simulating large P2P systems and streaming nine real video sequences with diverse visual and motion characteristics, we demonstrate that our proposed approximation algorithm: (i) produces near-optimal perceived video quality, (ii) can run in real time, and (iii) outperforms other algorithms in terms of perceived video quality, smoothness of the rendered videos, and balancing the load across sending peers. For example, our simulation results indicate that the proposed algorithm outperforms heuristic algorithms used in current systems by up to 8 dB in perceived video quality and up to 20% in continuity index. Copyright 2010 ACM.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Hsu, C.-H. and Hefeeda, M.",2010,MMSys'10 - Proceedings of the 2010 ACM SIGMM Conference on Multimedia Systems,10.1145/1730836.1730857,scopus-search1.bib
Kontaki2008251,Continuous trend-based clustering in data streams,"Trend analysis of time series is an important problem since trend identification enables the prediction of the near future. In streaming time series the problem is more challenging due to the dynamic nature of the data. In this paper, we propose a method to continuously clustering a number of streaming time series based on their trend characteristics. Each streaming time series is transformed to a vector by means of the Piecewise Linear Approximation (PLA) technique. The PLA vector comprises pairs of values (timestamp, trend) denoting the starting time of the trend and the type of the trend (either UP or DOWN) respectively. A distance metric for PLA vectors is introduced. We propose split and merge criteria to continuously update the clustering information. Moreover, the proposed method handles outliers. Performance evaluation results, based on real-life and synthetic data sets, show the efficiency and scalability of the proposed scheme. © 2008 Springer-Verlag Berlin Heidelberg.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kontaki, M. and Papadopoulos, A.N. and Manolopoulos, Y.",2008,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-540-85836-2_24,scopus-search1.bib
Liu2008568,Performance analysis and industrial practice of peer-assisted content distribution network for large-scale live video streaming,"Recently efficient and scalable live video streaming system over the Internet has become a hot topic. In order to improve the system performance metrics, such as startup delay, source-to-end delay, playback continuity and scalability, many previous works developed two successful cases of Content Distribution Network (CDN) and Peer-to-Peer (P2P) Network for the design of large-scale live video streaming systems, but no single one has yet delivered both the scale and service quality. To combine the advantages of CDN and P2P network has been considered as a feasible orientation for large-scale video stream delivering. In this paper, we propose a peer-assisted content distribution network, i.e. PACDN, which borrows the mesh-based P2P ideas into the traditional CDN to enhance the performance and scalability. The basic features of PACDN include: 1) To meet the real time requirement of live video stream service, i.e. to ensure that the video stream could be continuously and stably delivered from the source to each edge server for offering good QoS to different regions clients, the placement edge servers and source streaming server(s) build a hierarchical multi-tree based and in-hierarchy peer-assisted overlay, which is optimized according to the knowledge of underlying physical topology. This scheme in the design is called ""server side peer-assisted"". 2) To enhance the system scalability and reduce the deployment cost, clients and edge servers construct a Client/Server based and P2P network assisted overlay with the increasing of viewers, which is called ""client side peer-assisted"" in this design. We compare the inner performance of PACDN with existing approaches based on comprehensive simulations and analysis. The results show that our proposed design outperforms previous systems in the service quality and scalability. PACDN has been implemented as an Internet live video streaming service and it was successfully deployed for broadcasting many important live programs in China in 2007. The industrial experiences prove that this design is scalable and reliable. We believe that the wide deployment of PACDN and its further development will soon benefit many more Internet users. © 2008 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Liu, X. and Yin, H. and Lin, C. and Liu, Y. and Chen, Z. and Xiao, X.",2008,"Proceedings - International Conference on Advanced Information Networking and Applications, AINA",10.1109/AINA.2008.132,scopus-search1.bib;ieee3-search1.bib;scholar.bib
Liang2007472,Self-configuring information management for large-scale service overlays,"Service overlay networks (SON) provide important infrastructure support for many emerging distributed applications such as web service composition, distributed stream processing, and workflow management. Quality-sensitive distributed applications such as multimedia services and on-line data analysis often desire the SON to provide up-to-date dynamic information about different overlay nodes and overlay links. However, it is a challenging task to provide scalable and efficient information management for large-scale SONs, where both system conditions and application requirements can change over time. In this paper, we present InfoEye, a model-based self-configuring distributed information management system that consists of a set of monitoring sensors deployed on different overlay nodes. InfoEye can dynamically configure the operations of different sensors based on current statistical application query patterns and system attribute distributions. Thus, InfoEye can greatly improve the scalability of SON by answering information queries with minimum monitoring overhead. We have implemented a prototype of InfoEye and evaluated its performance using both extensive simulations and micro-benchmark experiments on PlanetLab. The experimental results show that InfoEye can significantly reduce the information management overhead compared with existing approaches. In addition, InfoEye can quickly reconfigure itself in response to application requirement and system information pattern changes. © 2007 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Liang, J. and Gut, X. and Nahrstedt, K.",2007,Proceedings - IEEE INFOCOM,10.1109/INFCOM.2007.62,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Zhang2019705,BriskStream: Scaling data stream processing on shared-memory multicore architectures,"We introduce BriskStream, an in-memory data stream processing system (DSPSs) specifically designed for modern shared-memory multicore architectures. BriskStream's key contribution is an execution plan optimization paradigm, namely RLAS, which takes relative-location (i.e., NUMA distance) of each pair of producer-consumer operators into consideration. We propose a branch and bound based approach with three heuristics to resolve the resulting nontrivial optimization problem. The experimental evaluations demonstrate that BriskStream yields much higher throughput and better scalability than existing DSPSs on multi-core architectures when processing different types of workloads. © 2019 Association for Computing Machinery.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Zhang, S. and Zhou, A.C. and He, J. and He, B.",2019,Proceedings of the ACM SIGMOD International Conference on Management of Data,10.1145/3299869.3300067,scopus-search1.bib
Mossel201743,Streaming and Exploration of Dynamically Changing Dense 3D Reconstructions in Immersive Virtual Reality,"We introduce a novel framework that enables large-scale dense 3D scene reconstruction, data streaming over the network and immersive exploration of the reconstructed environment using virtual reality. The system is operated by two remote entities, where one entity - for instance an autonomous aerial vehicle - captures and reconstructs the environment as well as transmits the data to another entity - such as human observer - that can immersivly explore the 3D scene, decoupled from the view of the capturing entity. The performance evaluation revealed the framework's capabilities to perform RGB-D data capturing, dense 3D reconstruction, streaming and dynamic scene updating in real time for indoor environments up to a size of 100m2, using either a state-of-the-art mobile computer or a workstation. Thereby, our work provides a foundation for enabling immersive exploration of remotely captured and incrementally reconstructed dense 3D scenes, which has not shown before and opens up new research aspects in future. © 2016 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Mossel, A. and Kroeter, M.",2016,"Adjunct Proceedings of the 2016 IEEE International Symposium on Mixed and Augmented Reality, ISMAR-Adjunct 2016",10.1109/ISMAR-Adjunct.2016.0035,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
HoseinyFarahabady2016334,A QoS-aware controller for Apache Storm,"Apache Storm has recently emerged as an attractive fault-tolerant open-source distributed data processing platform that has been chosen by many industry leaders to develop real-time applications for processing a huge amount of data in a scalable manner. A key aspect to achieve the best performance in this system lies on the design of an efficient scheduler for component execution, called topology, on the available computing resources. In response to workload fluctuations, we propose an advanced scheduler for Apache Storm that provides improved performance with highly dynamic behavior. While enforcing the required Quality-of-Service (QoS) of individual data streams, the controller allocates computing resources based on decisions that consider the future states of non-controllable disturbance parameters, e.g. arriving rate of tuples or resource utilization in each worker node. The performance evaluation is carried out by comparing the proposed solution with two well-known alternatives, namely the Storm's default scheduler and the best-effort approach (i.e. the heuristic that is based on the first-fit decreasing approximation algorithm). Experimental results clearly show that the proposed controller increases the overall resource utilization by 31% on average compared to the two others solutions, without significant negative impact on the QoS enforcement level. © 2016 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"HoseinyFarahabady, M.R. and DehghaniSamani, H.R. and Wang, Y. and Zomaya, A.Y. and Tari, Z.",2016,"Proceedings - 2016 IEEE 15th International Symposium on Network Computing and Applications, NCA 2016",10.1109/NCA.2016.7778638,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Suzumura20141321,Towards large-scale graph stream processing platform,"In recent years, real-time data mining for large-scale timeevolving graphs is becoming a hot research topic. Most of the prior arts target relatively static graphs and also process them in store-and-process batch processing model. In this paper we propose a method of applying on-the-fly and incremental graph stream computing model to such dynamic graph analysis. To process large-scale graph streams on a cluster of nodes dynamically in a scalable fashion, we propose an incremental large-scale graph processing model called ""Incremental GIM-V (Generalized Iterative Matrix-Vector Multiplication)"". We also design and implement UNICORN, a system that adopts the proposed incremental processing model on top of IBM InfoSphere Streams. Our performance evaluation demonstrates that our method achieves up to 48% speedup on PageRank with Scale 16 Log-normal Graph (vertexes=65,536, edges=8,364,525) with 4 nodes, 3023% speedup on Random walk with Restart with Kronecker Graph with Scale 18 (vertexes=262,144, edges=8,388,608) with 4 nodes against original GIM-V. © Copyright 2014 by the International World Wide Web Conferences Steering Committee.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Suzumura, T. and Nishii, S. and Ganse, M.",2014,WWW 2014 Companion - Proceedings of the 23rd International Conference on World Wide Web,10.1145/2567948.2580051,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib;scholar.bib
Simoncelli201330,Stream-monitoring with blockmon: Convergence of network measurements and data analytics platforms?,"Recent work in network measurements focuses on scaling the performance of monitoring platforms to 10Gb/s and beyond. Concurrently, IT community focuses on scaling the analysis of big-data over a cluster of nodes. So far, combinations of these approaches have targeted flexibility and usability over real-timeliness of results and efficient allocation of resources. In this paper we show how to meet both objectives with BlockMon, a network monitoring platform originally designed to work on a single node, which we extended to run distributed stream-data analytics tasks. We compare its performance against Storm and Apache S4, the state-ofthe-art open-source stream-processing platforms, by implementing a phone call anomaly detection system and a Twitter trending algorithm: our enhanced BlockMon has a gain in performance of over 2.5x and 23x, respectively. Given the different nature of those applications and the performance of BlockMon as single-node network monitor [1], we expect our results to hold for a broad range of applications, making distributed BlockMon a good candidate for the convergence of network-measurement and IT-analysis platforms.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Simoncelli, D. and Gringoli, F. and Dusi, M. and Niccolini, S.",2013,Computer Communication Review,,scopus-search1.bib
Chen2011,Modeling and performance analysis of P2P live streaming systems under flash crowds,"A fundamental problem that a peer-to-peer (P2P) live streaming system faces is how to support flash crowds effectively. A flash crowd occurs when a burst of join requests arrive at a system. When a flash crowd occurs, the sudden arrival of numerous peers may starve the upload capacity of a P2P system, and degrade the quality of service. By theoretical analysis and simulations, we find that a system has limited capacity to handle a flash crowd: It can recover to a new stable state when the size of flash crowd is small or moderate, but collapse when the flash crowd is excessively large. The capacity of a system is independent of initial state of the system while relevant to stable peers' departure rate, which suggests this capacity is an essential property of a P2P live streaming system. In addition, we prove that a P2P live streaming system with admission control has excellent capacity to handle flash crowds: It can recover from flash crowds of excessively large size and a startup peer's waiting time scales logarithmically with the size of flash crowds. Our theoretical model and simulation results provide a promising framework to understand the capacity of a P2P live streaming system for handling flash crowds. © 2011 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Chen, Y. and Zhang, B. and Chen, C.",2011,IEEE International Conference on Communications,10.1109/icc.2011.5962881,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Brito200922,Multithreading-enabled active replication for event stream processing operators,"Event Stream Processing (ESP) systems are very popular in monitoring applications. Algorithmic trading, network monitoring and sensor networks are good examples of applications that rely upon ESP systems. As these systems become larger and more widely deployed, they have to answer increasingly stronger requirements that are often difficult to satisfy. Fault-tolerance is a good example of such a nontrivial requirement. Making ESP operators fault-tolerant can add considerable performance overhead to the application. In this paper, we focus on active replication as an approach to provide fault-tolerance to ESP operators. More precisely, we address the performance costs of active replication for operators in distributed ESP applications. We use a speculation mechanism based on Software Transactional Memory (STM) to achieve the following goals: (i) enable replicas to make progress using optimistic delivery; (ii) enable early forwarding of speculative computation results; (iii) enable active replication of multi-threaded operators using transactional executions. Experimental evaluation shows that, using this combination of mechanisms, one can implement highly efficient fault-tolerant ESP operators. © 2009 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Brito, A. and Fetzer, C. and Felber, P.",2009,Proceedings of the IEEE Symposium on Reliable Distributed Systems,10.1109/SRDS.2009.37,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Bracciale20081,A push-based scheduling algorithm for large scale P2P live streaming,"In this paper, we present a chunk scheduling algorithm for a mesh-based peer-to-peer live streaming system and we evaluate it by simulations over large-scale networks. Literature papers typically design chunk scheduling algorithms by considering the chunk delivery ratio as performance metric. We propose a push-based algorithm, which not only tries to maximize the chunk delivery ratio but it also takes into account and tries to minimize the delivery delay of chunks at the peer nodes. This is an important requirement, when dealing with real-time multimedia flows. Another important contribution of this paper is the design and implementation of a simulator able to evaluate the performance of large scale P2P networks (tens of thousands peers). The importance of this contribution lies in the fact that existing simulators and performance studies handle at most hundreds or few thousands of peers, while real-life P2P streaming systems aim at distributing contents to several hundreds of thousands, if not millions, of users. The performance evaluation study aims at providing a comprehensive view of what performance can be expected for mesh-based peer-to-peer streaming systems, both in terms of chunk delivery ratio and delay, for a large range of the number of users. The individual effect of a variety of system parameters, and especially number of partner nodes in the mesh, constrained link bandwidth, node heterogeneity, and network size, has been analyzed. Our results show that performances of the proposed push-based solution are already quite effective even with severely bandwidth constrained large scale networks. © 2008 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Bracciale, L. and LoPiccolo, F. and Luzzi, D. and Salsano, S. and Bianchi, G. and Blefari-Melazzi, N.",2008,"Proceedings of the 2008 4th International Telecommunication Networking Workshop on QoS in Multiservice IP Networks, IT-NEWS",10.1109/ITNEWS.2008.4488121,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Walulya2018297,Viper: A module for communication-layer determinism and scaling in low-latency stream processing,"Stream Processing Engines (SPEs) process continuous streams of data and produce results in a real-time fashion, typically through one-at-a-time tuple analysis. In Fog architectures, the limited resources of the edge devices, enabling close-to-the-source scalable analysis, demand for computationally- and energy-efficient SPEs. When looking into the vital SPE processing properties required from applications, determinism, which ensures consistent results independently of the way the analysis is parallelized, has a strong position besides scalability in throughput and low processing latency. SPEs scale in throughput and latency by relying on shared-nothing parallelism, deploying multiple copies of each operator to which tuples are distributed based on its semantics. The coordination of the asynchronous analysis of parallel operators required to enforce determinism is then carried out by additional dedicated sorting operators. To prevent this costly coordination from becoming a bottleneck, we introduce the Viper communication module, which can be integrated in the SPE communication layer and boost the coordination of the parallel threads analyzing the data. Using Apache Storm and data extracted from the Linear Road benchmark and a real-world smart grid system, we show benefits in the throughput, latency and energy efficiency coming from the utilization of the Viper module. (C) 2018 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Walulya, I. and Palyvos-Giannas, D. and Nikolakopoulos, Y. and Gulisano, V. and Papatriantafilou, M. and Tsigas, P.",2018,Future Generation Computer Systems,10.1016/j.future.2018.05.067,scopus-search1.bib;web-of-science-search1.bib
Nagasu2017153,"FPGA-based tsunami simulation: Performance comparison with GPUs, and roofline model for scalability analysis","MOST (Method Of Splitting Tsunami) is widely used to solve shallow water equations (SWEs) for simulation of tsunami. This paper presents high-performance and power-efficient computation of MOST for practical tsunami simulation with FPGA. The custom hardware for simulation is based on a stream computing architecture for deeply pipelining to increase performance with a limited bandwidth. We design a stream processing element (SPE) of computing kernels combined with stencil buffers. We also introduce an SPE array architecture with spatial and temporal parallelism to further exploit available hardware resources by implementing multiple SPEs with parallel internal pipelines. Our prototype implementation with Arria 10 FPGA demonstrates that the FPGA-based design performs numerically stable tsunami simulation with real ocean-depth data in single precision by introducing non-dimensionalization. We explore the design space of SPE arrays, and find that the design of six cascaded SPEs with a single pipeline achieves the sustained performance of 383 GFlops and the performance per power of 8.41 GFlops/W with a stream bandwidth of only 7.2 GB/s. These numbers are 8.6 and 17.2 times higher than those of NVidia Tesla K20c GPU, and 1.7 and 7.1 times higher than those of AMD Radeon R9 280X GPU, respectively, for the same tsunami simulation in single precision. Moreover, we proposed a roofline model for stream computing with the SPE array in order to investigate factors of performance degradation and possible performance improvement for given FPGAs. With the model, we estimate that an upcoming Stratix 10 GX2800 FPGA can achieve the sustained performance of 8.7.TFlops at most with our SPE array architecture for tsunami simulation. (C) 2016 Elsevier Inc. All rights reserved.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Nagasu, K. and Sano, K. and Kono, F. and Nakasato, N.",2017,Journal of Parallel and Distributed Computing,10.1016/j.jpdc.2016.12.015,scopus-search1.bib;web-of-science-search1.bib
Korkhov2007173,VLAM-G: Interactive data driven workflow engine for Grid-enabled resources,"Grid brings the power of many computers to scientists. However, the development of Grid-enabled applications requires knowledge about Grid infrastructure and low-level API to Grid services. In turn, workflow management systems provide a high-level environment for rapid prototyping of experimental computing systems. Coupling Grid and workflow paradigms is important for the scientific community: it makes the power of the Grid easily available to the end user. The paradigm of data driven workflow execution is one of the ways to enable distributed workflow on the Grid. The work presented in this paper is carried out in the context of the Virtual Laboratory for e-Science project. We present the VLAM-G workflow management system and its core component: the Run-Time System (RTS). The RTS is a dataflow driven workflow engine which utilizes Grid resources, hiding the complexity of the Grid from a scientist. Special attention is paid to the concept of dataflow and direct data streaming between distributed workflow components. We present the architecture and components of the RTS, describe the features of VLAM-G workflow execution, and evaluate the system by performance measurements and a real life use case. © 2007 - IOS Press and the authors. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Korkhov, V. and Vasyunin, D. and Wibisono, A. and Belloum, A.S.Z. and Inda, M.A. and Roos, M. and Breit, T.M. and Hertzberger, L.O.",2007,Scientific Programming,10.1155/2007/812036,scopus-search1.bib
Zhang2006,Enabling efficient and flexible coupling of parallel scientific applications,"Emerging scientific and engineering simulations are presenting challenging requirements for coupling between multiple physics models and associated parallel codes that execute independently and in a distributed manner. Realizing coupled simulations requires an efficient, flexible and scalable coupling framework and simple programming abstractions. This paper presents a coupling framework that addresses these requirements. The framework is based on the Seine geometry-based interaction model. It enables efficient computation of communication schedules, supports low-overheads processor-to-processor data streaming, and provides high-level abstraction for application developers. The design, CCA-based implementation, and experimental evaluation of the Seine based coupling framework are presented. © 2006 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zhang, L. and Parashar, M.",2006,"20th International Parallel and Distributed Processing Symposium, IPDPS 2006",10.1109/IPDPS.2006.1639354,scopus-search1.bib;ieee2-search1.bib;acm2-search1.bib
Kreutzer2015417,Performance Engineering of the Kernel Polynomal Method on Large-Scale CPU-GPU Systems,"The Kernel Polynomial Method (KPM) is a well-established scheme in quantum physics and quantum chemistry to determine the Eigen value density and spectral properties of large sparse matrices. In this work we demonstrate the high optimization potential and feasibility of peta-scale heterogeneous CPU-GPU implementations of the KPM. At the node level we show that it is possible to decouple the sparse matrix problem posed by KPM from main memory bandwidth both on CPU and GPU. To alleviate the effects of scattered data access we combine loosely coupled outer iterations with tightly coupled block sparse matrix multiple vector operations, which enables pure data streaming. All optimizations are guided by a performance analysis and modelling process that indicates how the computational bottlenecks change with each optimization step. Finally we use the optimized node-level KPM with a hybrid-parallel framework to perform large-scale heterogeneous electronic structure calculations for novel topological materials on a pet scale-class Cray XC30 system. © 2015 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kreutzer, M. and Pieper, A. and Hager, G. and Wellein, G. and Alvermann, A. and Fehske, H.",2015,"Proceedings - 2015 IEEE 29th International Parallel and Distributed Processing Symposium, IPDPS 2015",10.1109/IPDPS.2015.76,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Dayarathna2013225,"A performance analysis of system S, S4, and Esper via two level benchmarking","Data stream processing systems have become popular due to their effectiveness in applications in large scale data stream processing scenarios. This paper compares and contrasts performance characteristics of three stream processing softwares System S, S4, and Esper. We study about which software aspects shape the characteristics of the workloads handled by these software. We use a micro benchmark and different real world stream applications on System S, S4, and Esper to construct 70 different application scenarios. We use job throughput, CPU, Memory consumption, and network utilization of each application scenario as performance metrics. We observed that S4's architectural aspect which instantiates a Processing Element (PE) for each keyed attribute is less efficient compared to the fixed number of PEs used by System S and Esper. Furthermore, all the Esper benchmarks produced more than 150% increased performance in single node compared to S4 benchmarks. S4 and Esper are more portable compared to System S and could be fine tuned for different application scenarios easily. In future we hope to widen our understanding of performance characteristics of these systems by investigating in to the code level profiling. © 2013 Springer-Verlag.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Dayarathna, M. and Suzumura, T.",2013,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-642-40196-1_19,scopus-search1.bib;scholar.bib
Purandare20071633,An alliance based peering scheme for P2P live media streaming,"While recent measurement studies have shown the effectiveness of P2P network in media streaming, there have been questions raised about the Quality of Service (QoS), reliability of streaming services and sub optimal uplink utilization in particular. P2P streaming systems are inherently less reliable because of churn, internet dynamics, node heterogeneity and randomness in the swarm. We present a new model for P2P media streaming based on clustering of peers, called alliances. We show that alliance formation is a loosely coupled and an effective way to organize the peers. We show that our model maps to a ""small-world"" network, which form efficient overlay structures and are robust to network perturbations such as churn. We present a comparative simulation based study of our model with CoolStreaming/DONet and present a quantitative performance evaluation. Simulation results are promising and show that our model scales well under varying workloads and conditions, delivers near optimal levels of QoS, and for most cases, performs at par or even better than Cool-Streaming/DONet. © 2007 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Purandare, D. and Guha, R.",2007,IEEE Transactions on Multimedia,10.1109/TMM.2007.907453,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Vikash2020207,Performance evaluation of real-time stream processing systems for Internet of Things applications,"In the current scenario, IoT is an ideal and novel technology, which fulfills the needs of most of the commercial, non-commercial, government, and private organizations by its real-time supportive nature and characteristics. However, real-time processing itself a very critical research topic. But, most of the IoT applications are empowered by real-time data processing. Thus, it become a vital part of IoT. In this work, we proposed a four-layer infrastructure for IoT along with stream processing. Further, we use stream processing techniques along with IoT infrastructure for applications and analyze the performance of stream processing techniques for IoT applications. Also, we compare and find the five most suitable distributed stream processing systems for IoT, based on its performance and characteristics. We use two benchmark applications to evaluate the performance of distributed stream processing systems against response time, throughput, jitter, and scalability. Based on that, we suggest the adapted solution for IoT applications. We evaluate the performance with peak stream rates from 100k to 1M along with the various frequencies of benchmark applications. Further, on the basis of results, we conclude that Apache NiFi is the most suitable solution for IoT applications. (C) 2020 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Vikash, and Mishra, L. and Varma, S.",2020,Future Generation Computer Systems,10.1016/j.future.2020.07.012,scopus-search1.bib;web-of-science-search1.bib
Mortazavi-Dehkordi2020241,Efficient deadline-aware scheduling for the analysis of Big Data streams in public Cloud,"The emergence of Big Data has had a profound impact on how data are analyzed. Open source distributed stream processing platforms have gained popularity for analyzing streaming Big Data as they provide low latency required for streaming Big Data applications using Cloud resources. However, existing resource schedulers are still lacking the efficiency and deadline meeting that Big Data analytical applications require. Recent works have already considered streaming Big Data characteristics to improve the efficiency and the likelihood of deadline meeting for scheduling in the platforms. Nevertheless, they have not taken into account the specific attributes of analytical application, public Cloud utilization cost and delays caused by performance degradation of leasing public Cloud resources. This study, therefore, presents BCframework, an efficient deadline-aware scheduling framework used by streaming Big Data analysis applications based on public Cloud resources. BCframework proposes a scheduling model which considers public Cloud utilization cost, performance variation, deadline meeting and latency reduction requirements of streaming Big Data analytical applications. Furthermore, it introduces two operator scheduling algorithms based on both a novel partitioning algorithm and an operator replication method. BCframework is highly adaptable to the fluctuation of streaming Big Data and the performance degradation of public Cloud resources. Experiments with the benchmark and real-world queries show that BCframework can significantly reduce the latency and utilization cost and also minimize deadline violations and provisioned virtual machine instances. © 2019, The Author(s).",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Mortazavi-Dehkordi, M. and Zamanifar, K.",2020,Cluster Computing,10.1007/s10586-019-02908-2,scopus-search1.bib;web-of-science-search1.bib
Gao2019376,Multi-User Cooperative Mobile Video Streaming: Performance Analysis and Online Mechanism Design,"Adaptive bitrate streaming enables video users to adapt their playing bitrates to the real-time network conditions, hence achieving the desirable quality-of-experience (QoE). In a multi-user wireless scenario, however, existing single-user based bitrate adaptation methods may fail to provide the desirable QoE, due to lack of consideration of multi-user interactions (such as the multi-user interferences and network congestion). In this work, we propose a novel user cooperation framework based on user-provided networking for multi-user mobile video streaming over wireless cellular networks. The framework enables nearby mobile video users to crowdsource their cellular links and resources for cooperative video streaming. We first analyze the social welfare performance bound of the proposed cooperative streaming system by introducing a virtual time-slotted system. Then, we design a low complexity Lyapunov-based online algorithm, which can be implemented in an online and distributed manner without the complete future and global network information. Numerical results show that the proposed online algorithm achieves an average 97 percent of the theoretical maximum social welfare. We further conduct experiments with real data traces, to compare our proposed online algorithm with the existing online algorithms in the literature. Experiment results show that our algorithm outperforms the existing algorithms in terms of both the achievable bitrate (with an average gain of 20 \sim 30 percent) and social welfare (with an average gain of 10 \sim 50 percent). © 2002-2012 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Gao, L. and Tang, M. and Pang, H. and Huang, J. and Sun, L.",2019,IEEE Transactions on Mobile Computing,10.1109/TMC.2018.2834358,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
GhaffariSheshjavani20177535,An adaptive buffer-map exchange mechanism for pull-based peer-to-peer video-on-demand streaming systems,"Unlike P2P live video streaming in which all the peers in a channel watch a video with tiny differences in viewing points, in P2P video on demand (VoD) streaming systems, neighbor peers may watch the same video with more different viewing points; therefore, using push-based approach is not efficient for such systems, and the overhead of the pull-based approaches is challenging due to the periodical exchange of buffer-maps among the peers. In pull-based P2P VoD systems, to achieve better quality of experience it is necessary to use large buffers at the peers that results in more buffer-maps exchange overhead. In this paper, we study buffer-map exchange challenging in pull-based P2P VoD streaming systems and propose an adaptive mechanism for decreasing overhead by sending the buffer-maps with regard to the viewing points of the peers. Bandwidth overhead of the proposed mechanism is independent of the used buffer sizes and is less dependent to the buffer-map exchange period. By using this effective mechanism, better quality of service can be achieved through using large buffers at the peers, without increasing in the overhead. Our simulation based performance evaluation shows the efficiency of the proposed mechanism in decreasing the bandwidth overhead of buffer-map exchange in P2P VoD streaming systems. © 2016, Springer Science+Business Media New York.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"GhaffariSheshjavani, A. and Akbari, B.",2017,Multimedia Tools and Applications,10.1007/s11042-016-3425-z,scopus-search1.bib
Hazra201143,Stream computing based synchrophasor application for power grids,"This paper proposes an application of stream computing analytics framework to high speed synchrophasor data for real time monitoring and control of electric grid. High volume streaming synchrophasor data from geographically distributed grid sensors (namely, Phasor Measurement Units) are collected, synchronized, aggregated when required and analyzed using a stream computing platform to estimate the grid stability in real time. This real time stability monitoring scheme will help the grid operators to take preventive or corrective measures ahead of time to mitigate any disturbance before they develop into wide-spread. A protptype of the scheme is demonstrated on a benchmark 3 machines 9 bus system and the IEEE 14 bus test system. © 2011 ACM.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Hazra, J. and Das, K. and Seetharam, D.P. and Singhee, A.",2011,"HiPCNA-PG'11 - Proceedings of the 1st International Workshop on High Performance Computing, Networking and Analytics for the Power Grid, Co-located with SC'11",10.1145/2096123.2096134,scopus-search1.bib;acm1-search1.bib
Repantis2008346,Hot-spot prediction and alleviation in distributed stream processing applications,"Many emerging distributed applications require the real-time processing of large amounts of data that are being updated continuously. Distributed stream processing systems offer a scalable and efficient means of in-network processing of such data streams. However, the large scale and the distributed nature of such systems, as well as the fluctuation of their load render it difficult to ensure that distributed stream processing applications meet their Quality of Service demands. We describe a decentralized framework for proactively predicting and alleviating hot-spots in distributed stream processing applications in real-time. We base our hot-spot prediction techniques on statistical forecasting methods, while for hot-spot alleviation we employ a non-disruptive component migration protocol. The experimental evaluation of our techniques, implemented in our Synergy distributed stream processing middleware over PlanetLab, using a real stream processing application operating on real streaming data, demonstrates high prediction accuracy and substantial performance benefits. © 2008 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Repantis, T. and Kalogeraki, V.",2008,Proceedings of the International Conference on Dependable Systems and Networks,10.1109/DSN.2008.4630103,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Gill2006289,Loop pipelining for high-throughput stream computation using self-timed rings,We present a technique for increasing the throughput of stream processing architectures by removing the bottlenecks caused by loop structures. We implement loops as self-timed pipelined rings that can operate on multiple data sets concurrently. Our contribution includes a transformation algorithm which takes as input a high-level program and gives as output the structure of an optimized pipeline ring. Our technique handles nested loops and is further enhanced by loop unrolling. Simulations run on benchmark examples show a 1.3 to 4.9x speedup without unrolling and a 2.6 to 9.7x speedup with twofold loop unrolling. Copyright 2006 ACM.,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Gill, G. and Hansen, J. and Singh, M.",2006,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",10.1109/ICCAD.2006.320135,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib;acm2-search1.bib
Enzler200563,System-level performance evaluation of reconfigurable processors,"Reconfigurable architectures that tightly integrate a standard CPU core with a field-programmable hardware structure have recently been receiving increased attention. The design of such a hybrid reconfigurable processor involves a multitude of design decisions regarding the field-programmable structure as well as its system integration with the CPU core. Determining the impact of these design decisions on the overall system performance is a challenging task. In this paper, we first present a framework for the cycle-accurate performance evaluation of hybrid reconfigurable processors on the system level. Then, we discuss a reconfigurable processor for data-streaming applications, which attaches a coarse-grained reconfigurable unit to the coprocessor interface of a standard embedded CPU core. By means of a case study we evaluate the system-level impact of certain design features for the reconfigurable unit, such as multiple contexts, register replication, and hardware context scheduling. The results illustrate that a system-level evaluation framework is of paramount importance for studying the architectural trade-offs and optimizing design parameters for reconfigurable processors. © 2004 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Enzler, R. and Plessl, C. and Platzner, M.",2005,Microprocessors and Microsystems,10.1016/j.micpro.2004.06.004,scopus-search1.bib
Chaudhari2019237,SCSI: Real-Time Data Analysis with Cassandra and Spark,"The open-source framework for stream processing and enormous informationIn-memory handling model executed with the machine learning algorithmsThe data used in subset of non-distributed mode is better than using all data in distributed modeThe Apache Spark platform handles big data sets with immaculate parallel speedup. Abstract The dynamic progress in the nature of pervasive computing datasets has been main motivation for development of the NoSQL model. The devices having capability of executing “Internet of Things” (IoT) concepts are producing massive amount of data in various forms (structured and unstructured). To handle this IoT data with traditional database schemes is impracticable and expensive. The large-scale unstructured data required as the prerequisites for a preparing pipeline, which flawlessly consolidating the NoSQL storage model such as Apache Cassandra and a Big Data processing platform such as Apache Spark. The Apache Spark is the data-intensive computing paradigm, which allows users to write the applications in various high-level programming languages including Java, Scala, R, Python, etc. The Spark Streaming module receives live input data streams and divides that data into batches by using the Map and Reduce operations. This research presents a novel and scalable approaches called ""Smart Cassandra Spark Integration (SCSI)” for solving the challenge of integrating NoSQL data stores like Apache Cassandra with Apache Spark to manage distributed systems based on varied platter of amalgamation of current technologies, IT enabled devices, etc., while eliminating complexity and risk. In this chapter, for performance evaluations, SCSI Streaming framework is compared with the file system-based data stores such as Hadoop Streaming framework. SCSI framework proved scalable, efficient, and accurate while computing big streams of IoT data. © 2019, Springer Nature Singapore Pte Ltd.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Chaudhari, A.A. and Mulay, P.",2019,Studies in Big Data,10.1007/978-981-13-0550-4_11,scopus-search1.bib
Hoffmann201895,Snailtrail: Generalizing critical paths for online analysis of distributed dataflows,"We rigorously generalize critical path analysis (CPA) to long-running and streaming computations and present SnailTrail, a system built on Timely Dataflow, which applies our analysis to a range of popular distributed dataflow engines. Our technique uses the novel metric of critical participation, computed on time-based snapshots of execution traces, that provides immediate insights into specific parts of the computation. This allows SnailTrail to work online in real-time, rather than requiring complete offline traces as with traditional CPA. It is thus applicable to scenarios like model training in machine learning, and sensor stream processing. SnailTrail assumes only a highly general model of dataflow computation (which we define) and we show it can be applied to systems as diverse as Spark, Flink, TensorFlow, and Timely Dataflow itself. We further show with examples from all four of these systems that SnailTrail is fast and scalable, and that critical participation can deliver performance analysis and insights not available using prior techniques. © Proceedings of NSDI 2010: 7th USENIX Symposium on Networked Systems Design and Implementation. All rights reserved.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Hoffmann, M. and Lattuada, A. and Liagouris, J. and Kalavri, V. and Dimitrova, D. and Wicki, S. and Chothia, Z. and Roscoe, T.",2018,"Proceedings of the 15th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2018",,scopus-search1.bib;web-of-science-search1.bib
Runsewe2017848,Cloud Resource Scaling for Big Data Streaming Applications Using a Layered Multi-dimensional Hidden Markov Model,"Recent advancements in technology have led to a deluge of data that require real-Time analysis with strict latency constraints. A major challenge, however, is determining the amount of resources required by big data stream processing applications in response to heterogeneous data sources, streaming events, unpredictable data volume and velocity changes. Over-provisioning of resources for peak loads can be wasteful while under-provisioning can have a huge impact on the performance of the streaming applications. The majority of research efforts on resource scaling in the cloud are investigated from the cloud provider's perspective, they focus on web applications and do not consider multiple resource bottlenecks. We aim at analyzing the resource scaling problem from a big data streaming application provider's point of view such that efficient scaling decisions can be made for future resource utilization. This paper proposes a Layered Multi-dimensional Hidden Markov Model (LMD-HMM) for facilitating the management of resource auto-scaling for big data streaming applications in the cloud. Our detailed experimental evaluation shows that LMD-HMM performs best with an accuracy of 98%, outperforming the single-layer hidden markov model. © 2017 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Runsewe, O. and Samaan, N.",2017,"Proceedings - 2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGRID 2017",10.1109/CCGRID.2017.147,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib;acm1-search1.bib
Kolchin2016280,YAbench: A comprehensive framework for RDF stream processor correctness and performance assessment,"RDF stream processing (RSP) has become a vibrant area of research in the semantic web community. Recent advances have resulted in the development of several RSP engines that leverage semantics to facilitate reasoning over flows of incoming data. These engines vary greatly in terms of implemented query syntax, their evaluation and operational semantics, and in various performance dimensions. Existing benchmarks tackle particular aspects such as functional coverage, result correctness, or performance. None of them, however, assess RSP engine behavior comprehensively with respect to all these dimensions. In this paper, we introduce YABench, a novel benchmarking framework for RSP engines. YABench extends the concept of correctness checking and provides a flexible and comprehensive tool set to analyze and evaluate RSP engine behavior. It is highly configurable and provides quantifiable and reproducible results on correctness and performance characteristics. To validate our approach, we replicate results of the existing CSRBench benchmark with YABench. We then assess two well-established RSP engines, CQELS and C-SPARQL, through more comprehensive experiments. In particular, we measure precision, recall, performance, and scalability characteristics while varying throughput and query complexity. Finally, we discuss implications on the development of future stream processing engines and benchmarks. © Springer International Publishing Switzerland 2016.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Kolchin, M. and Wetz, P. and Kiesling, E. and Tjoa, A.M.",2016,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-38791-8_16,scopus-search1.bib;web-of-science-search1.bib
Zacheilas2016174,Dynamic load balancing techniques for distributed complex event processing systems,"Applying real-time, cost-effective Complex Event processing (CEP) in the cloud has been an important goal in recent years. Distributed Stream Processing Systems (DSPS) have been widely adopted by major computing companies such as Facebook and Twitter for performing scalable event processing in streaming data. However, dynamically balancing the load of the DSPS’ components can be particularly challenging due to the high volume of data, the components’ state management needs, and the low latency processing requirements. Systems should be able to cope with these challenges and adapt to dynamic and unpredictable load changes in real-time. Our approach makes the following contributions: (i) we formulate the load balancing problem in distributed CEP systems as an instance of the job-shop scheduling problem, and (ii) we present a novel framework that dynamically balances the load of CEP engines in real-time and adapts to sudden changes in the volume of streaming data by exploiting two balancing policies. Our detailed experimental evaluation using data from the Twitter social network indicates the benefits of our approach in the system’s throughput. © IFIP International Federation for Information Processing 2016.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zacheilas, N. and Zygouras, N. and Panagiotou, N. and Kalogeraki, V. and Gunopulos, D.",2016,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-39577-7_14,scopus-search1.bib;web-of-science-search1.bib
Tudoran2016274,JetStream: Enabling high throughput live event streaming on multi-site clouds,"Scientific and commercial applications operate nowadays on tens of cloud datacenters around the globe, following similar patterns: they aggregate monitoring or sensor data, assess the QoS or run global data mining queries based on inter-site event stream processing. Enabling fast data transfers across geographically distributed sites allows such applications to manage the continuous streams of events in real time and quickly react to changes. However, traditional event processing engines often consider data resources as second-class citizens and support access to data only as a side-effect of computation (i.e. they are not concerned by the transfer of events from their source to the processing site): This is an efficient approach as long as the processing is executed in a single cluster where nodes are interconnected by low latency networks. In a distributed environment, consisting of multiple datacenters, with orders of magnitude differences in capabilities and connected by a WAN, this will undoubtedly lead to significant latency and performance variations. This is namely the challenge we address in this paper, by proposing JetStream, a high performance batch-based streaming middleware for efficient transfers of events between cloud datacenters. JetStream is able to self-adapt to the streaming conditions by modeling and monitoring a set of context parameters. It further aggregates the available bandwidth by enabling multi-route streaming across cloud sites, while at the same time optimizing resource utilization and increasing cost efficiency. The prototype was validated on tens of nodes from US and Europe datacenters of the Windows Azure cloud with synthetic benchmarks and a real-life application monitoring the ALICE experiment at CERN. The results show a 3 x increase of the transfer rate using the adaptive multi-route streaming, compared to state of the art solutions. (c) 2015 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Tudoran, R. and Costan, A. and Nano, O. and Santos, I. and Soncu, H. and Antoniu, G.",2016,Future Generation Computer Systems,10.1016/j.future.2015.01.016,scopus-search1.bib;web-of-science-search1.bib
Kofler2009355,Using MPEG-21 for cross-layer multimedia content adaptation,"This paper presents a cross-layer model- formulated using interoperable description formats-for the adaptation of scalable H.264/MPEG-4 AVC (i.e., SVC) content in a video streaming system operating on a Wireless LAN access network without QoS mechanisms. SVC content adaptation on the server takes place on the application layer using an adaptation process compliant with the MPEG-21 Digital Item Adaptation (DIA) standard, based on input comprised of MPEG-21 DIA descriptions of content and usage environment parameters. The latter descriptions integrate information from different layers, e.g., device characteristics and packet loss rate, in an attempt to increase the interoperability of this cross-layer model, thus making it applicable to other models. For the sake of deriving model parameters, performance measurements from two wireless access point models were taken in account. Throughout the investigation it emerged that the behavior of the system strongly depends on the access point. Therefore, we investigated the use of end-to-end-based rate control algorithms for steering the content adaptation. Simulations of rate adaptation algorithms were subsequently performed, leading to the conclusion that a TFRC-based adaptation technique (TCP-Friendly Rate Control) performs quite well in adapting to limited bandwidth and varying network conditions. In the paper we demonstrate how TFRC-based content adaptation can be realized using MPEG-21 tools. © 2008 Springer-Verlag London Limited.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kofler, I. and Seidl, J. and Timmerer, C. and Hellwagner, H. and Djama, I. and Ahmed, T.",2009,"Signal, Image and Video Processing",10.1007/s11760-008-0088-x,scopus-search1.bib
Marino2007234,Description and performance analysis of a distributed rendering architecture for virtual environments,"Complex Virtual Environments applications may require computational resources exceeding the capabilities of a single machine. Our system, called ""XVR Network Renderer"", allows rendering load to be distributed throughout a cluster of machines operating concurrently. The proposed solution consists in a set of software modules structured as a single-master multiple-slaves architecture. XVR is a development environment that allows rapid development of Virtual Environments applications. The master software intercepts all the OpenGL API calls performed by any XVR application, without requiring any code to be added or modified. The graphical commands are then reexecuted individually by the slave clients. Each slave is typically configured to manage only a subset of the whole virtual context. Our system exploits the tight integration with the underlying XVR. scene-graph manager at its own advantage, providing additional features other than the mere visualization of a high resolution OpenGL context, such as head tracking, GLSL shaders, and the ability to insert (and intercept) ""placemarkers"" inside the broadcast OpenGL data stream. Finally, the system can be configured to work with a wide range of complex visualization setups, automatically handling stereoscopy, correct perspective correction, overlapping images and other common problems, without ever changing the code of the original application. In this work we describe the proposed architecture and wo discuss the results of our performance analysis. © 2007 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Marino, G. and Vercelli, D. and Tecchia, F. and Gasparello, P.S. and Bergamasco, M.",2007,"Proceedings 17th International Conference on Artificial Reality and Telexistence, ICAT 2007",10.1109/ICAT.2007.25,scopus-search1.bib
Chao2018273,F-MStorm: Feedback-based online distributed mobile stream processing,"A distributed mobile stream processing system allows mobile devices to process stream data that exceeds any single device’s computation capability without the help of infrastructure. It is paramount to have such a system in many critical application scenarios, such as military operations and disaster response, yet an efficient online mobile stream processing system is still missing. In this paper, we make the key observation that the unique characteristics of mobile stream processing call for a feedback-based system design, which is in sharp contrast with the static configuration and scheduling of the current mobile stream processing system, “MStorm” [1]. At first, we demonstrate the inefficiencies of MStorm through several real-world experiments. Then, we propose F-MStorm, a feedback-based online distributed mobile stream processing system, which adopts the feedback-based approach in the configuration, scheduling and execution levels of system design. We implement F-MStorm on Android phones and evaluate its performance through benchmark applications. We show that it achieves up to 3x lower response time, 10% higher throughput and consumes 23% less communication energy than the state-of-the-art systems. © 2018 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Chao, M. and Yang, C. and Zeng, Y. and Stoleru, R.",2018,"Proceedings - 2018 3rd ACM/IEEE Symposium on Edge Computing, SEC 2018",10.1109/SEC.2018.00027,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Hoseinyfarahabady2017332,A Dynamic Resource Controller for a Lambda Architecture,"Lambda architecture is a novel event-driven serverless paradigm that allows companies to build scalable and reliable enterprise applications. As an attractive alternative to traditional service oriented architecture (SOA), Lambda architecture can be used in many use cases including BI tools, in-memory graph databases, OLAP, and streaming data processing. In practice, an important aim of Lambda's service providers is devising an efficient way to co-locate multiple Lambda functions with different attributes into a set of available computing resources. However, previous studies showed that consolidated workloads can compete fiercely for shared resources, resulting in severe performance variability/degradation. This paper proposes a resource allocation mechanism for a Lambda platform based on the model predictive control framework. Performance evaluation is carried out by comparing the proposed solution with multiple resource allocation heuristics, namely enhanced versions of spread and binpack, and best-effort approaches. Results confirm that the proposed controller increases the overall resource utilization by 37% on average and achieves a significant improvement in preventing QoS violation incidents compared to others. © 2017 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Hoseinyfarahabady, M. and Taheri, J. and Tari, Z. and Zomaya, A.Y.",2017,Proceedings of the International Conference on Parallel Processing,10.1109/ICPP.2017.42,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Zhou2017,Efficient streaming mass spatio-temporal vehicle data access in urban sensor networks based on apache storm,"The efficient data access of streaming vehicle data is the foundation of analyzing, using and mining vehicle data in smart cities, which is an approach to understand traffic environments. However, the number of vehicles in urban cities has grown rapidly, reaching hundreds of thousands in number. Accessing the mass streaming data of vehicles is hard and takes a long time due to limited computation capability and backward modes. We propose an efficient streaming spatio-temporal data access based on Apache Storm (ESDAS) to achieve real-time streaming data access and data cleaning. As a popular streaming data processing tool, Apache Storm can be applied to streaming mass data access and real time data cleaning. By designing the Spout/bolt workflow of topology in ESDAS and by developing the speeding bolt and other bolts, Apache Storm can achieve the prospective aim. In our experiments, Taiyuan BeiDou bus location data is selected as the mass spatio-temporal data source. In the experiments, the data access results with different bolts are shown in map form, and the filtered buses’ aggregation forms are different. In terms of performance evaluation, the consumption time in ESDAS for ten thousand records per second for a speeding bolt is approximately 300 milliseconds, and that for MongoDB is approximately 1300 milliseconds. The efficiency of ESDAS is approximately three times higher than that of MongoDB. © 2017 by the authors.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zhou, L. and Chen, N. and Chen, Z.",2017,Sensors (Switzerland),10.3390/s17040815,scopus-search1.bib
Nikolakopoulos20162,Highly concurrent stream synchronization in many-core embedded systems,"Embedded many-core architectures are expected to serve as significant components in the infrastructure of upcoming technologies like networks for the Internet of Things (IoT), facing real-time and stream processing challenges. In this work we explore the applicability of ScaleGate, a synchronization object from the massive data stream processing domain, on many-core embedded systems. We propose a new implementation of ScaleGate on the Epiphany architecture, a scalable embedded many-core co-processor, and study communication patterns that appear in the context of a baseband signal processing application. Our experimental evaluation shows significant improvements over standard barrier-based approaches, due to the asynchrony exploited by the use of ScaleGate. © 2016 Copyright held by the owner/author(s).",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Nikolakopoulos, Y. and Papatriantafilou, M. and Brauer, P. and Lundqvist, M. and Gulisano, V. and Tsigas, P.",2016,ACM International Conference Proceeding Series,10.1145/2934495.2934496,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Ploennigs20151231,"E2-diagnoser: A system for monitoring, forecasting and diagnosing energy usage","We propose e2-Diagnoser, a real-time data mining system for the energy management of smart, sensor-equipped buildings. The main features of e2-Diagnoser are: (i) fast extraction of a large portfolio of buildings' benchmarks at multiple places, and (ii) accurate prediction of buildings' energy usage down to sub meter level to detect and diagnose abnormal energy consumptions. Fundamentally, the e2-Diagnoser system is built on a novel statistical learning algorithm using the Generalized Additive Model (GAM) to simultaneously monitor the mean and variation of the energy usage as well as identify the influencing factors such as weather conditions. Its implementation is based on stream processing platform that integrates data from various sources using semantic web technologies and provides an interactive user interface to visualize results. The platform is scalable and can be easily adapted to other applications such as smart-grid networks. Here we describe the architecture, methodology, and show the web-interface to demonstrate the main functions in the e2-Diagnoser. © 2014 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Ploennigs, J. and Chen, B. and Palmes, P. and Lloyd, R.",2014,"IEEE International Conference on Data Mining Workshops, ICDMW",10.1109/ICDMW.2014.56,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Thomos2008497,Collaborative video streaming with Raptor network coding,"We investigate the problem of collaborative video streaming with Raptor network coding over overlay networks. We exploit path and source diversity, as well as basic processing capabilities of network nodes to increase the overall throughput and improve the video quality at the clients. We consider an architecture where several streaming servers simultaneously deliver video information to a set of clients. The servers apply Raptor coding on the video packets for error resiliency, and the forwarding peer nodes further combine the Raptor coded video packets in order to increase the packet diversity in the network. We find the optimal source and channel rate allocation in such a collaborative streaming system. The resulting scheme efficiently exploits the available network resources for improved video quality. The experimental evaluation demonstrates that it typically outperforms Raptor video streaming systems that do not use network coding. © 2008 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Thomos, N. and Frossard, P.",2008,"2008 IEEE International Conference on Multimedia and Expo, ICME 2008 - Proceedings",10.1109/ICME.2008.4607480,scopus-search1.bib
Mamouras2019670,Data-trace types for distributed stream processing systems,"Distributed architectures for efficient processing of streaming data are increasingly critical to modern information processing systems. The goal of this paper is to develop type-based programming abstractions that facilitate correct and efficient deployment of a logical specification of the desired computation on such architectures. In the proposed model, each communication link has an associated type specifying tagged data items along with a dependency relation over tags that captures the logical partial ordering constraints over data items. The semantics of a (distributed) stream processing system is then a function from input data traces to output data traces, where a data trace is an equivalence class of sequences of data items induced by the dependency relation. This data-trace transduction model generalizes both acyclic synchronous data-flow and relational query processors, and can specify computations over data streams with a rich variety of partial ordering and synchronization characteristics. We then describe a set of programming templates for data-trace transductions: abstractions corresponding to common stream processing tasks. Our system automatically maps these high-level programs to a given topology on the distributed implementation platform Apache Storm while preserving the semantics. Our experimental evaluation shows that (1) while automatic parallelization deployed by existing systems may not preserve semantics, particularly when the computation is sensitive to the ordering of data items, our programming abstractions allow a natural specification of the query that contains a mix of ordering constraints while guaranteeing correct deployment, and (2) the throughput of the automatically compiled distributed code is comparable to that of hand-crafted distributed implementations. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Mamouras, K. and Stanford, C. and Alur, R. and Ives, Z.G. and Tannen, V.",2019,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),10.1145/3314221.3314580,scopus-search1.bib;web-of-science-search1.bib;acm1-search1.bib
Laska2018,A scalable architecture for real-time stream processing of spatiotemporal IoT stream data — Performance analysis on the example of map matching,"Scalable real-time processing of large amounts of data has become a research topic of particular importance due to the continuously rising amount of data that is generated by devices equipped with sensing components. While existing approaches allow for fault-tolerant and scalable stream processing, we present a pipeline architecture that consists of well-known open source tools to specifically integrate spatiotemporal internet of things (IoT) data streams. In a case study, we utilize the architecture to tackle the online map matching problem, a pre-processing step for trajectory mining algorithms. Given the rising amount of vehicle location data that is generated on a daily basis, existing map matching algorithms have to be implemented in a distributed manner to be executable in a stream processing framework that provides scalability. We demonstrate how to implement state-of-the-art map matching algorithms in our distributed stream processing pipeline and analyze measured latencies. © 2018 by the authors.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Laska, M. and Herle, S. and Klamma, R. and Blankenbach, J.",2018,ISPRS International Journal of Geo-Information,10.3390/ijgi7070238,scopus-search1.bib;web-of-science-search1.bib
Maroulis201727,ExpREsS: EneRgy Efficient Scheduling of Mixed Stream and Batch Processing Workloads,"Nowadays we see the wide adoption of novel distributed processing frameworks such as Apache Spark for handling batch and stream processing big data applications. An important aspect that has not been examined in these systems is their energy consumption during the application execution. Reducing the power consumption of modern datacenters is a necessity as datacenters contribute over 2% of the total US electric usage. One way of addressing this energy issue is by scheduling the applications in an energy-efficient way. However, efficiently scheduling applications can be challenging as we need to consider the trade-off between the datacenter's energy usage and per application performance requirements. In this work we propose, ExpREsS, a scheduler for orchestrating the execution of Spark applications so that it both minimizes the energy consumption and satisfies the applications' performance requirements. Our approach exploits time-series prediction models for capturing the applications' energy usage and execution times, and then applies a novel DVFS technique to minimize the energy consumption. Our detailed experimental evaluation using realistic workloads on our local cluster illustrates the working and benefits of our approach. © 2017 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Maroulis, S. and Zacheilas, N. and Kalogeraki, V.",2017,"Proceedings - 2017 IEEE International Conference on Autonomic Computing, ICAC 2017",10.1109/ICAC.2017.43,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Fan2016309,Adaptive task scheduling in storm,"Processing of stream data attracts more and more attention of many big companies and organizations. Storm is a well-known distributed stream processing system that is often used for real-Time analysis, online machine learning, continuous computing, distributed remote process call (RPC), etc. In this paper, we study the default scheduler of Storm and other implementations of customized scheduler to discover the primary factors affecting the performance of the cluster. Then, we design and implement an adaptive task scheduler by adding load tracker to monitor the runtime status of the cluster and applying static and dynamic scheduling strategies. At last, we conduct experiments to assess our work by measuring average processing time, overall throughput and stability of the cluster through network bounded and CPU bounded benchmarks. As for average processing time of topologies, the adaptive scheduler achieves about 67% and 30% improvement on cluster of heavy and light load respectively. © 2015 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Fan, J. and Chen, H. and Hu, F.",2015,"Proceedings of 2015 4th International Conference on Computer Science and Network Technology, ICCSNT 2015",10.1109/ICCSNT.2015.7490758,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Bouillet2010249,"Scalable, real-time map-matching using IBM's System S","Vehicle GPS data is an essential ""raw"" material for a broad range of applications such as traffic management and control, routing, and navigation. To become useful, the data has to be related to the underlying road network by means of map matching algorithms, which are often computationally expensive. In addition, GPS data is not accurate and often needs to be cleaned to remove erroneous observations. In this paper, we describe how map matching can be run on IBM's System S, which provides a platform to run stream processing applications in a scalable manner. We show how various features of System S, including a component based programming model, data pipelining and parallelization of computation, help us to scale the map-matching and data cleaning processes, both as the rate of incoming GPS data increases and as the size of the underlying road network increases. We provide results of performance evaluations, where we show our system can match GPS data arriving at a rate of 1 million points per second onto a map with 1 billion links. © 2010 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Bouillet, E. and Ranganathan, A.",2010,Proceedings - IEEE International Conference on Mobile Data Management,10.1109/MDM.2010.36,scopus-search1.bib
Shahverdi201953,Big stream processing systems: An experimental evaluation,"As the world gets more instrumented and connected, we are witnessing a flood of digital data generated from various hardware (e.g., sensors) or software in the format of flowing streams of data. Real-time processing for such massive amounts of streaming data is a crucial requirement in several application domains including financial markets, surveillance systems, manufacturing, smart cities, and scalable monitoring infrastructure. In the last few years, several big stream processing engines have been introduced to tackle this challenge. In this article, we present an extensive experimental study of five popular systems in this domain, namely, Apache Storm, Apache Flink, Apache Spark, Kafka Streams and Hazelcast Jet. We report and analyze the performance characteristics of these systems. In addition, we report a set of insights and important lessons that we have learned from conducting our experiments. © 2019 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Shahverdi, E. and Awad, A. and Sakr, S.",2019,"Proceedings - 2019 IEEE 35th International Conference on Data Engineering Workshops, ICDEW 2019",10.1109/ICDEW.2019.00-35,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Marcu20181480,KerA: Scalable data ingestion for stream processing,"Big Data applications are increasingly moving from batch-oriented execution models to stream-based models that enable them to extract valuable insights close to real-time. To support this model, an essential part of the streaming processing pipeline is data ingestion, i.e., the collection of data from various sources (sensors, NoSQL stores, filesystems, etc.) and their delivery for processing. Data ingestion needs to support high throughput, low latency and must scale to a large number of both data producers and consumers. Since the overall performance of the whole stream processing pipeline is limited by that of the ingestion phase, it is critical to satisfy these performance goals. However, state-of-art data ingestion systems such as Apache Kafka build on static stream partitioning and offset-based record access, trading performance for design simplicity. In this paper we propose KerA, a data ingestion framework that alleviate the limitations of state-of-art thanks to a dynamic partitioning scheme and to lightweight indexing, thereby improving throughput, latency and scalability. Experimental evaluations show that KerA outperforms Kafka up to 4x for ingestion throughput and up to 5x for the overall stream processing throughput. Furthermore, they show that KerA is capable of delivering data fast enough to saturate the big data engine acting as the consumer. © 2018 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Marcu, O.-C. and Costan, A. and Antoniu, G. and Pérez-Hernández, M. and Nicolae, B. and Tudoran, R. and Bortoli, S.",2018,Proceedings - International Conference on Distributed Computing Systems,10.1109/ICDCS.2018.00152,scopus-search1.bib
Dünner2018252,SNaP ML: A hierarchical framework for machine learning,"We describe a new software framework for fast training of generalized linear models. The framework, named Snap Machine Learning (Snap ML), combines recent advances in machine learning systems and algorithms in a nested manner to reflect the hierarchical architecture of modern computing systems. We prove theoretically that such a hierarchical system can accelerate training in distributed environments where intra-node communication is cheaper than inter-node communication. Additionally, we provide a review of the implementation of Snap ML in terms of GPU acceleration, pipelining, communication patterns and software architecture, highlighting aspects that were critical for achieving high performance. We evaluate the performance of Snap ML in both single-node and multi-node environments, quantifying the benefit of the hierarchical scheme and the data streaming functionality, and comparing with other widely-used machine learning software frameworks. Finally, we present a logistic regression benchmark on the Criteo Terabyte Click Logs dataset and show that Snap ML achieves the same test loss an order of magnitude faster than any of the previously reported results, including those obtained using TensorFlow and scikit-learn. © 2018 Curran Associates Inc..All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Dünner, C. and Parnell, T. and Sarigiannis, D. and Ioannou, N. and Anghel, A. and Ravi, G. and Kandasamy, M. and Pozidis, H.",2018,Advances in Neural Information Processing Systems,,scopus-search1.bib;web-of-science-search1.bib
Al-Zubaidy20172238,Reliable Video Streaming with Strict Playout Deadline in Multihop Wireless Networks,"Motivated by emerging vision-based intelligent services, we consider the problem of rate adaptation for high-quality and low-delay visual information delivery over wireless networks using scalable video coding. Rate adaptation in this setting is inherently challenging due to the interplay between the variability of the wireless channels, the queuing at the network nodes, and the frame-based decoding and playback of the video content at the receiver at very short time scales. To address the problem, we propose a low-complexity model-based rate adaptation algorithm for scalable video streaming systems, building on a novel performance model based on stochastic network calculus. We validate the analytic model using extensive simulations. We show that it allows fast near-optimal rate adaptation for fixed transmission paths, as well as cross-layer optimized routing and video rate adaptation in mesh networks, with less than 10% quality degradation compared to the best achievable performance. © 1999-2012 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Al-Zubaidy, H. and Fodor, V. and Dan, G. and Flierl, M.",2017,IEEE Transactions on Multimedia,10.1109/TMM.2017.2742399,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Shukla201790,Benchmarking distributed stream processing platforms for IoT applications,"Internet of Things (IoT) is a technology paradigm where millions of sensors monitor, and help inform or manage, physical, environmental and human systems in real-time. The inherent closed-loop responsiveness and decision making of IoT applications makes them ideal candidates for using low latency and scalable stream processing platforms. Distributed Stream Processing Systems (DSPS) are becoming essential components of any IoT stack, but the efficacy and performance of contemporary DSPS have not been rigorously studied for IoT data streams and applications. Here, we develop a benchmark suite and performance metrics to evaluate DSPS for streaming IoT applications. The benchmark includes 13 common IoT tasks classified across functional categories and forming micro-benchmarks, and two IoT applications for statistical summarization and predictive analytics that leverage various dataflow patterns of DSPS. These are coupled with stream workloads from real IoT observations on smart cities. We validate the benchmark for the popular Apache Storm DSPS, and present the results. © Springer International Publishing AG 2017.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Shukla, A. and Simmhan, Y.",2016,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-54334-5_7,scopus-search1.bib;web-of-science-search1.bib;scholar.bib
Du2014275,A real-time anomalies detection system based on streaming technology,"With the wide deployment of flow monitoring in IP networks, flow data has been more and more applied on abnormal traffic detection. In practice, anomalies should be detected as fast as possible from giant quantity of flow data, while, at present, some classical anomalies detecting methods can not achieve this goal. In this paper, we propose and implement a distributed streaming computing system which aims to perform real-time anomalies detection by leveraging Apache Storm, a stream-computing platform. Based on this efficient system, we can uninterruptedly monitor the mutation of flow data and locate the source of anomalies or attacks in real-time by finding the specific abnormal IP addresses. A typical application example proved the capability and benefits of our system and we also have a detailed discussion in performance measurements and scalability. © 2014 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Du, Y. and Liu, J. and Liu, F. and Chen, L.",2014,"Proceedings - 2014 6th International Conference on Intelligent Human-Machine Systems and Cybernetics, IHMSC 2014",10.1109/IHMSC.2014.168,scopus-search1.bib
Qi2013111,MapReduce intermediate result cache for concurrent data stream processing,"With the development of Internet of Things applications, real-time processing of sensor data stream over large scale history data brings a new challenge. The traditional MapReduce programming model is designed for batch-based large-scale data processing and cannot satisfy the real-time requirement. To extend the real-time data processing capability of MapReduce by preprocessing, pipelining and localizing, an immediate result cache for key/value data type, which can avoid repeated remote I/O overhead and computation cost by taking full use of local memory and storage, localize stream processing by distributing data across the clusters and support frequent reads and writes of data stream processing, needs to be designed. This paper proposes a scalable, extensible and efficient key/value intermediate result cache, which consists of Hash B-tree structures and SSTable files. Furthermore, to optimize the high concurrency performance, this paper also devises a probability-based B-tree structure as well as its multiplexing search algorithm through the B-tree balance property, and improves the file read/write strategy and replacement algorithm by utilization of the overhead estimation and buffered information. The theoretical analysis and benchmark experiments show that the proposed structures and algorithms further optimize the concurrency performance of MapReduce immediate results, and the immediate result cache is effective to support data stream processing over large-scale data.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Qi, K. and Han, Y. and Zhao, Z. and Fang, J.",2013,Jisuanji Yanjiu yu Fazhan/Computer Research and Development,,scopus-search1.bib
Hsu2008,On the accuracy and complexity of rate-distortion models for fine-grained scalable video sequences,"Rate-distortion (R-D) models are functions that describe the relationship between the bitrate and expected level of distortion in the reconstructed video stream. R-D models enable optimization of the received video quality in different network conditions. Several R-D models have been proposed for the increasingly popular fine-grained scalable video sequences. However, the models' relative performance has not been thoroughly analyzed. Moreover, the time complexity of each model is not known, nor is the range of bitrates in which the model produces valid results. This lack of quantitative performance analysis makes it difficult to select the model that best suits a target streaming system. In this article, we classify, analyze, and rigorously evaluate all R-D models proposed for FGS coders in the literature. We classify R-D models into three categories: analytic, empirical, and semi-analytic. We describe the characteristics of each category. We analyze the R-D models by following their mathematical derivations, scrutinizing the assumptions made, and explaining when the assumptions fail and why. In addition, we implement all R-D models, a total of eight, and evaluate them using a diverse set of video sequences. In our evaluation, we consider various source characteristics, diverse channel conditions, different encoding/decoding parameters, different frame types, and several performance metrics including accuracy, range of applicability, and time complexity of each model. We also present clear systematic ways (pseudo codes) for constructing various R-D models from a given video sequence. Based on our experimental results, we present a justified list of recommendations on selecting the best R-D models for video-on-demand, video conferencing, real-time, and peer-to-peer streaming systems. © 2008 ACM.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Hsu, C.-H. and Hefeeda, M.",2008,"ACM Transactions on Multimedia Computing, Communications and Applications",10.1145/1352012.1352019,scopus-search1.bib;web-of-science-search1.bib;acm3-search1.bib
Bracciale200725,OPSS: An Overlay Peer-to-peer Streaming Simulator for large-scale networks,"In this paper we present OPSS, an Overlay Peer-to-peer Streaming Simulator designed to simulate large scale (i.e. in the order of 100K nodes) peer-to-peer streaming systems. OPSS is able to simulate a fair (i.e. ""TCP-like"") sharing of the uplink and downlink bandwidth among different connections, and it guarantees extensibility by allowing the implementation of different peer-to-peer streaming algorithms as separate modules. Source code of OPSS is available under the GPL license. © 2018 International Conference on Learning Representations, ICLR. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Bracciale, L. and Piccolo, F.L. and Luzzi, D. and Salsano, S.",2007,Performance Evaluation Review,10.1145/1328690.1328700,scopus-search1.bib
Vijayakumar2006539,Calder query grid service: Insights and experimental evaluation,"We have architected and evaluated a new kind of data resource, one that is composed of a logical collection of ephemeral data streams that could be viewed as a collection of publish-subscribe ""channels"" over which rich data-access and semantic operations can be performed. This paper contributes new insight to stream processing under the highly asynchronous stream workloads often found in data-driven scientific applications, and presents insights gained through porting a distributed stream processing system to a Grid services framework. Experimental results reveal limits on stream processing rates that are directly tied to differences in stream rates. © 2006 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Vijayakumar, N.N. and Liu, Y. and Plale, B.",2006,"Sixth IEEE International Symposium on Cluster Computing and the Grid, 2006. CCGRID 06",10.1109/CCGRID.2006.25,scopus-search1.bib;ieee3-search1.bib
Henning2021,Theodolite: Scalability Benchmarking of Distributed Stream Processing Engines in Microservice Architectures,"Distributed stream processing engines are designed with a focus on scalability to process big data volumes in a continuous manner. We present the Theodolite method for benchmarking the scalability of distributed stream processing engines. Core of this method is the definition of use cases that microservices implementing stream processing have to fulfill. For each use case, our method identifies relevant workload dimensions that might affect the scalability of a use case. We propose to design one benchmark per use case and relevant workload dimension. We present a general benchmarking framework, which can be applied to execute the individual benchmarks for a given use case and workload dimension. Our framework executes an implementation of the use case's dataflow architecture for different workloads of the given dimension and various numbers of processing instances. This way, it identifies how resources demand evolves with increasing workloads. Within the scope of this paper, we present 4 identified use cases, derived from processing Industrial Internet of Things data, and 7 corresponding workload dimensions. We provide implementations of 4 benchmarks with Kafka Streams and Apache Flink as well as an implementation of our benchmarking framework to execute scalability benchmarks in cloud environments. We use both for evaluating the Theodolite method and for benchmarking Kafka Streams' and Flink's scalability for different deployment options. (C) 2021 Elsevier Inc. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Henning, S. and Hasselbring, W.",2021,Big Data Research,10.1016/j.bdr.2021.100209,scopus-search1.bib;web-of-science-search1.bib
Silvestre20211637,Clonos: Consistent Causal Recovery for Highly-Available Streaming Dataflows,"Stream processing lies in the backbone of modern businesses, being employed for mission critical applications such as real-time fraud detection, car-trip fare calculations, traffic management, and stock trading. Large-scale applications are executed by scale-out stream processing systems on thousands of long-lived operators, which are subject to failures. Recovering from failures fast and consistently are both top priorities, yet they are only partly satisfied by existing fault tolerance methods due to the strong assumptions these make. In particular, prior solutions fail to address consistency in the presence of nondeterminism, such as calls to external services, asynchronous timers and processing-time windows. This paper describes Clonos, a fault tolerance approach that achieves fast, local operator recovery with exactly-once guarantees and high availability by instantly switching to passive standby operators. Clonos enforces causally consistent recovery, including output deduplication, by tracking nondeterminism within the system through causal logging. To implement Clonos we re-engineered many of the internal subsystems of a state of the art stream processor. We evaluate Clonos' overhead and recovery on the Nexmark benchmark against Apache Flink. Clonos achieves instant recovery with negligible overhead and, unlike previous work, does not make assumptions on the deterministic nature of operators. © 2021 Owner/Author.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Silvestre, P.F. and Fragkoulis, M. and Spinellis, D. and Katsifodimos, A.",2021,Proceedings of the ACM SIGMOD International Conference on Management of Data,10.1145/3448016.3457320,scopus-search1.bib;web-of-science-search1.bib;acm1-search1.bib
Kallas2020,DiffStream: Differential output testing for stream processing programs,"High performance architectures for processing distributed data streams, such as Flink, Spark Streaming, and Storm, are increasingly deployed in emerging data-driven computing systems. Exploiting the parallelism afforded by such platforms, while preserving the semantics of the desired computation, is prone to errors, and motivates the development of tools for specification, testing, and verification. We focus on the problem of differential output testing for distributed stream processing systems, that is, checking whether two implementations produce equivalent output streams in response to a given input stream. The notion of equivalence allows reordering of logically independent data items, and the main technical contribution of the paper is an optimal online algorithm for checking this equivalence. Our testing framework is implemented as a library called DiffStream in Flink. We present four case studies to illustrate how our framework can be used to (1) correctly identify bugs in a set of benchmark MapReduce programs, (2) facilitate the development of difficult-to-parallelize high performance applications, and (3) monitor an application for a long period of time with minimal performance overhead. © 2020 Owner/Author.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kallas, K. and Niksic, F. and Stanford, C. and Alur, R.",2020,Proceedings of the ACM on Programming Languages,10.1145/3428221,scopus-search1.bib;acm1-search1.bib
Akanbi20201,A distributed stream processing middleware framework for real-time analysis of heterogeneous data on big data platform: Case of environmental monitoring,"In recent years, the application and wide adoption of Internet of Things (IoT)-based technologies have increased the proliferation of monitoring systems, which has consequently exponentially increased the amounts of heterogeneous data generated. Processing and analysing the massive amount of data produced is cumbersome and gradually moving from classical ‘batch’ processing—extract, transform, load (ETL) technique to real-time processing. For instance, in environmental monitoring and management domain, time-series data and historical dataset are crucial for prediction models. However, the environmental monitoring domain still utilises legacy systems, which complicates the real-time analysis of the essential data, integration with big data platforms and reliance on batch processing. Herein, as a solution, a distributed stream processing middleware framework for real-time analysis of heterogeneous environmental monitoring and management data is presented and tested on a cluster using open source technologies in a big data environment. The system ingests datasets from legacy systems and sensor data from heterogeneous automated weather systems irrespective of the data types to Apache Kafka topics using Kafka Connect APIs for processing by the Kafka streaming processing engine. The stream processing engine executes the predictive numerical models and algorithms represented in event processing (EP) languages for real-time analysis of the data streams. To prove the feasibility of the proposed framework, we implemented the system using a case study scenario of drought prediction and forecasting based on the Effective Drought Index (EDI) model. Firstly, we transform the predictive model into a form that could be executed by the streaming engine for real-time computing. Secondly, the model is applied to the ingested data streams and datasets to predict drought through persistent querying of the infinite streams to detect anomalies. As a conclusion of this study, a performance evaluation of the distributed stream processing middleware infrastructure is calculated to determine the real-time effectiveness of the framework. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Akanbi, A. and Masinde, M.",2020,Sensors (Switzerland),10.3390/s20113166,scopus-search1.bib;web-of-science-search1.bib;scholar.bib
Bordin2020222900,DSPBench: A Suite of Benchmark Applications for Distributed Data Stream Processing Systems,"Systems enabling the continuous processing of large data streams have recently attracted the attention of the scientific community and industrial stakeholders. Data Stream Processing Systems (DSPSs) are complex and powerful frameworks able to ease the development of streaming applications in distributed computing environments like clusters and clouds. Several systems of this kind have been released and currently maintained as open source projects, like Apache Storm and Spark Streaming. Some benchmark applications have often been used by the scientific community to test and evaluate new techniques to improve the performance and usability of DSPSs. However, the existing benchmark suites lack of representative workloads coming from the wide set of application domains that can leverage the benefits offered by the stream processing paradigm in terms of near real-time performance. The goal of this article is to present a new benchmark suite composed of 15 applications coming from areas like Finance, Telecommunications, Sensor Networks, Social Networks and others. This article describes in detail the nature of these applications, their full workload characterization in terms of selectivity, processing cost, input size and overall memory occupation. In addition, it exemplifies the usefulness of our benchmark suite to compare real DSPSs by selecting Apache Storm and Spark Streaming for this analysis. © 2013 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Bordin, M.V. and Griebler, D. and Mencagli, G. and Geyer, C.F.R. and Fernandes, L.G.L.",2020,IEEE Access,10.1109/ACCESS.2020.3043948,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Gautam2019,Performance prediction of data streams on high-performance architecture,"Worldwide sensor streams are expanding continuously with unbounded velocity in volume, and for this acceleration, there is an adaptation of large stream data processing system from the homogeneous to rack-scale architecture which makes serious concern in the domain of workload optimization, scheduling, and resource management algorithms. Our proposed framework is based on providing architecture independent performance prediction model to enable resource adaptive distributed stream data processing platform. It is comprised of seven pre-defined domain for dynamic data stream metrics including a self-driven model which tries to fit these metrics using ridge regularization regression algorithm. Another significant contribution lies in fully-automated performance prediction model inherited from the state-of-the-art distributed data management system for distributed stream processing systems using Gaussian processes regression that cluster metrics with the help of dimensionality reduction algorithm. We implemented its base on Apache Heron and evaluated with proposed Benchmark Suite comprising of five domain-specific topologies. To assess the proposed methodologies, we forcefully ingest tuple skewness among the benchmarking topologies to set up the ground truth for predictions and found that accuracy of predicting the performance of data streams increased up to 80.62% from 66.36% along with the reduction of error from 37.14 to 16.06%. © 2019, The Author(s).",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Gautam, B. and Basava, A.",2019,Human-centric Computing and Information Sciences,10.1186/s13673-018-0163-4,scopus-search1.bib;web-of-science-search1.bib
Lombardi2019342,PASCAL: An architecture for proactive auto-scaling of distributed services,"One of the main characteristics that today makes cloud services so popular is their ability to be elastic, i.e., they can adapt their provisioning to variable workloads, thus increasing resource utilization and reducing operating costs. At the core of any elastic service lies an automatic scaling mechanism that drives provisioning on the basis of a given strategy. In this paper we propose PASCAL, an architecture for Proactive Auto-SCALing of generic distributed services. PASCAL combines a proactive approach, to forecast incoming workloads, with a profiling system, to estimate required provision. Scale-in/out operations are decided according to an application-specific strategy, which aims at provisioning the minimum number of resources needed to sustain the foreseen workload. The main novelties introduced with PASCAL architecture are: (i) a strategy to proactively auto-scale a distributed stream processing system (namely, Apache Storm) with the aim of load balancing operators through an accurate system performance estimation model, and (ii) a strategy to proactively auto-scale a distributed datastore (namely, Apache Cassandra), focused on how to choose when executing scaling actions on the basis of the time needed for the activation/deactivation of storage nodes so as to have the configuration ready when needed. We provide a prototype implementation of PASCAL for both use cases and, through an experimental evaluation conducted on a private cloud, we validate our approach and demonstrate the effectiveness of the proposed strategies in terms of saved resources and response time. (C) 2019 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Lombardi, F. and Muti, A. and Aniello, L. and Baldoni, R. and Bonomi, S. and Querzoni, L.",2019,Future Generation Computer Systems,10.1016/j.future.2019.03.003,scopus-search1.bib;web-of-science-search1.bib
Javed2018223,Cutting the Tail: Designing High Performance Message Brokers to Reduce Tail Latencies in Stream Processing,"Over the last decade, organizations have become heavily reliant on providing near-instantaneous insights to the end user based on vast amounts of data collected from various sources in real-time. In order to accomplish this task, a stream processing pipeline is constructed, which in its most basic form, consists of a Stream Processing Engine (SPE) and a Message Broker (MB). The SPE is responsible for performing actual computations on the data and providing insights from it. MB, on the other hand, acts as an intermediate queue to which data is written by ephemeral sources and then fetched by the SPE to perform computations on. Due to the inherent real-time nature of such a pipeline, low latency is a highly desirable feature for them. Thus, several existing research works in the community focus on improving latency and throughput of the streaming pipeline. However, there is a dearth of studies optimizing the tail latencies of such pipelines. Moreover, the root cause of this high tail latency is still vague. In this paper, we propose a model-based approach to analyze in-depth the reasons behind high tail latency in streaming systems such as Apache Kafka. Having found the MB to be a major contributor of messages with high tail latencies in a streaming pipeline, we design and implement an RDMA-enhanced high-performance MB, called Frieda, with the higher goal of accelerating any arbitrary stream processing pipeline regardless of the SPE used. Our experiments show a reduction of up to 98% in 99.9th percentile latency for microbenchmarks and up to 31% for full-fledged stream processing pipeline constructed using Yahoo! Streaming Benchmark. © 2018 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Javed, M.H. and Lu, X. and Panda, D.K.",2018,"Proceedings - IEEE International Conference on Cluster Computing, ICCC",10.1109/CLUSTER.2018.00040,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Kauffman201854,Inferring event stream abstractions,"We propose a formalism for specifying event stream abstractions for use in spacecraft telemetry processing. Our work is motivated by the need to quickly process streams with millions of events generated e.g. by the Curiosity rover on Mars. The approach builds a hierarchy of event abstractions for telemetry visualization and querying to aid human comprehension. Such abstractions can also be used as input to other runtime verification tools. Our notation is inspired by Allen’s Temporal Logic, and provides a rule-based declarative way to express event abstractions. We present an algorithm for applying specifications to an event stream and explore modifications to improve the algorithm’s asymptotic complexity. The system is implemented in both Scala and C, with the specification language implemented as internal as well as external DSLs. We illustrate the solution with several examples, a performance evaluation, and a real telemetry analysis scenario. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Kauffman, S. and Havelund, K. and Joshi, R. and Fischmeister, S.",2018,Formal Methods in System Design,10.1007/s10703-018-0317-z,scopus-search1.bib;web-of-science-search1.bib
Steffl2017137,LACore: A supercomputing-like linear algebra accelerator for SoC-based designs,"Linear algebra operations are at the heart of scientific computing solvers, machine learning and artificial intelligence. In this paper, LACore, a novel, programmable accelerator architecture for general-purpose linear algebra applications, is presented. LACore enables many of the architectural features typically available in custom supercomputing machines in an accelerator form factor that can be deployed in System-On-a-Chip (SoC) based designs. LACore has several architectural features including heterogeneous data-streaming LAMemUnits, a configurable systolic datapath that supports scalar, vector and multi-stream output modes, and a decoupled architecture that overlap memory transfer and execution. To evaluate LACore, we implemented its architecture as an extension to the RISC-V ISA in the gem5 cycle-accurate simulator. The LACore ISA was implemented in gcc, and a C-programming software framework, the LACoreAPI, has been developed for high-level programming of the LACore. Using the HPCC benchmark suite, we compare our LACore architecture against three other platforms: an in-order RISC-V CPU, a superscalar x86 CPU with SSE2, and a scaled NVIDIA Fermi GPU. The LACore outperforms the superscalar x86 processor in the benchmark suite by an average of 3.43x, and outperforms the scaled Fermi GPU by an average of 12.04x, within the same or less design area. © 2017 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Steffl, S. and Reda, S.",2017,"Proceedings - 35th IEEE International Conference on Computer Design, ICCD 2017",10.1109/ICCD.2017.29,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Ravindra201791,Latency aware elastic switching-based stream processing over compressed data streams,Elastic scaling of event stream processing systems has gained significant attention recently due to the prevalence of cloud computing technologies. We investigate on the complexities associated with elastic scaling of an event processing system in a private/public cloud scenario. We develop an Elastic Switching Mechanism (ESM) which reduces the overall average latency of event processing jobs by significant amount considering the cost of operating the system. ESM is augmented with adaptive compressing of upstream data. The ESM conducts one of the two types of switching where either part of the data is sent to the public cloud (data switching) or a selected query is sent to the public cloud (query switching) based on the characteristics of the query. We model the operation of the ESM as the function of two binary switching functions. We show that our elastic switching mechanism with compression is capable of handling out-of-order events more efficiently compared to techniques which does not involve compression. We used two application benchmarks called EmailProcessor and a Social Networking Benchmark (SNB2016) to conduct multiple experiments to evaluate the effectiveness of our approach. In a single query deployment with EmailProcessor benchmark we observed that our elastic switching mechanism provides 1.24 seconds average latency improvement per processed event which is 16.70% improvement compared to private cloud only deployment. When presented the option of scaling EmailProcessor with four public cloud VMs ESM further reduced the average latency by 37.55% compared to the single public cloud VM. In a multi-query deployment with both EmailProcessor and SNB2016 we obtained a reduction of average latency of both the queries by 39.61 seconds which is a decrease of 7% of overall latency. These performance figures indicate that our elastic switching mechanism with compressed data streams can effectively reduce the average elapsed time of stream processing happening in private/public clouds. © 2017 ACM.,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Ravindra, S. and Dayarathna, M. and Jayasena, S.",2017,ICPE 2017 - Proceedings of the 2017 ACM/SPEC International Conference on Performance Engineering,10.1145/3030207.3030227,scopus-search1.bib;acm2-search1.bib
Kritikakis2016,An FPGA-based high-throughput stream join architecture,"Stream join is a fundamental operation that combines information from different high-speed and high-volume data streams. This paper presents an FPGA-based architecture that maps the most performance-efficient stream join algorithm, i.e. ScaleJoin, to reconfigurable logic. The system was fully implemented on a Convey HC-2ex hybrid computer and the experimental performance evaluation shows that the proposed system outperforms by up to one order of magnitude the corresponding fully optimized parallel software-based solution running on a high-end 48-core multiprocessor platform. The proposed architecture can be used as a generic template for mapping stream processing algorithms to reconfigurable logic, taking into consideration real-world challenges. © 2016 EPFL.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Kritikakis, C. and Chrysos, G. and Dollas, A. and Pnevmatikatos, D.N.",2016,FPL 2016 - 26th International Conference on Field-Programmable Logic and Applications,10.1109/FPL.2016.7577354,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Martin2014270,Predicting energy consumption with StreamMine3G,"In this paper, we present our approach on solving the DEBS Grand Challenge using StreamMine3G, a distributed, highly scalable, elastic and fault tolerant ESP system. We will provide an overview about the system architecture of Stream-Mine3G and implementation details of an application aimed at consumption prediction and outlier detection. Using our elastic approach, we can provide an accurate prediction as we can keep a practically unbounded history able to deal with high volume, highly fluctuating workloads. Our system also provides techniques for dealing with incomplete data in the source stream, which is a common problem when processing data from a large number of sources. Finally, we provide performance measurements showing that we are able to process the dataset given as part of the 2014 DEBS Challenge (135 GB) at a throughput of up to 40 kEvents/s. © 2014 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Martin, A. and Marinho, R. and Brito, A. and Fetzer, C.",2014,DEBS 2014 - Proceedings of the 8th ACM International Conference on Distributed Event-Based Systems,10.1145/2611286.2611325,scopus-search1.bib
Whittier20132,Towards window stream queries over continuous phenomena,"Technological advances have created an unprecedented availability of inexpensive sensors capable of streaming environmental data in real-time. Data stream engines (DSE) with tuple processing rates of around 500k tuples/s have demonstrated their ability to both keep up with large numbers of spatio-temporal data streams, and execute stream window queries over them efficiently. Typically, geographically distributed sensors take samples asynchronously; however, when approximating the reality of a continuous phenomenon - - such as the radiation field over an urban region- the objective is to integrate their values correctly over space as well as over time. This paper presents an approach to extend DSEs with support enabling sliding window queries over dynamic continuous phenomena, which return both spatio-temporal snapshot and movies as window query results. We introduce a novel grid-pane index as a main memory index structure shared between multi-queries over a phenomenon and an adaptive, data driven kNN algorithm for efficiently approximating cells based on available stream data samples. AkNN implements a spatio-temporal inverse distance weighting interpolation (IDW) method that integrates time with space via an anisotropic ratio. Further, we introduce the shell list template that allows quick calculation of NN cells by distance in a space-time (ST) cuboid. We performed extensive performance evaluations using the Fukushima nuclear event in March 2011 as a test data set. © 2013 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Whittier, J.C. and Nittel, S. and Plummer, M.A. and Liang, Q.",2013,"Proceedings of the 4th ACM SIGSPATIAL International Workshop on GeoStreaming, IWGS 2013",10.1145/2534303.2534305,scopus-search1.bib
Mazur20111102,Towards scalable one-pass analytics using MapReduce,"An integral part of many data-intensive applications is the need to collect and analyze enormous datasets efficiently. Concurrent with such application needs is the increasing adoption of MapReduce as a programming model for processing large datasets using a cluster of machines. Current MapReduce systems, however, require the data set to be loaded into the cluster before running analytical queries, and thereby incur high delays to start query processing. Furthermore, existing systems are geared towards batch processing. In this paper, we seek to answer a fundamental question: what architectural changes are necessary to bring the benefits of the MapReduce computation model to incremental, one-pass analytics, i.e., to support stream processing and online aggregation? To answer this question, we first conduct a detailed empirical performance study of current MapReduce implementations including Hadoop and MapReduce Online using a variety of workloads. By doing so, we identify several drawbacks of existing systems for one-pass analytics. Based on the insights from our study, we list key design requirements for incremental one-pass analytics and argue for architectural changes of MapReduce systems to overcome their current limitations. We conclude by sketching an initial design of our new MapReduce-based platform for incremental one-pass analytics and showing promising preliminary results. © 2011 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Mazur, E. and Li, B. and Diao, Y. and Shenoy, P.",2011,IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum,10.1109/IPDPS.2011.251,scopus-search1.bib;ieee2-search1.bib
Pianese2007317,Resource and locality awareness in an incentive-based P2P live streaming system,"One of the main challenges in P2P live streaming is the efficient allocation of the available resources. This paper presents an experimental evaluation of the effects of a local pairwise incentive mechanism applied to an unstructured mesh-based architecture. We focus on the relationship between resource availability in the system and the average quality of its data distribution paths, both in terms of bandwidth efficiency and awareness to network locality. We show via large scale testbed experiments based on the PULSE live streaming system that the introduction of appropriate incentive-based policies as the main peer selection mechanism can lead to a global content distribution mesh which has properties similar to tree-based structured systems. © 2007 ACM.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Pianese, F. and Perino, D.",2007,"Proceedings of the 2007 Workshop on Peer-to-Peer Streaming and IP-TV, P2P-TV'07",10.1145/1326320.1326323,scopus-search1.bib;acm2-search1.bib
Tu200469,Performance analysis of a hybrid media streaming system,"Recent research efforts have demonstrated the promising potential of building cost-effective media streaming systems on top of peer-to-peer (P2P) networks. A P2P media streaming architecture can reach large size and streaming capacity that are difficult to achieve in conventional server-based streaming services. Hybrid streaming systems that combine the use of dedicated streaming servers and P2P networks were proposed to build on the advantages of both paradigms. However, the dynamics of such systems and the impact of various factors on system behaviors are not totally clear. In this paper, we present an analytical framework to quantitatively study the features of a hybrid media streaming model. Based on this framework, we derive an equation to describe the capacity growth of a single-file streaming system. We then extend the analysis to multi-file scenarios by solving an optimization problem. We also show that the system model achieves optimal allocation of server bandwidth among different media objects. The unpredictable departure/failure of peers is a critical factor that affects performance of P2P systems. To model peer failures in our system, we propose the concept of peer lifespan. The original equation is enhanced with coefficients generated from the distribution of peer lifespan. Results from large-scale simulations support our analysis.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Tu, Y.-C. and Sun, J. and Prabhakar, S.",2004,Proceedings of SPIE - The International Society for Optical Engineering,10.1117/12.538806,scopus-search1.bib;web-of-science-search1.bib
Jonathan2020221,WASP: Wide-area Adaptive Stream Processing,"Adaptability is critical for stream processing systems to ensure stable, low-latency, and high-throughput processing of long-running queries. Such adaptability is particularly challenging for wide-area stream processing due to the highly dynamic nature of the wide-area environment, which includes unpredictable workload patterns, variable network bandwidth, occurrence of stragglers, and failures. Unfortunately, existing adaptation techniques typically achieve these performance goals by compromising the quality/accuracy of the results, and they are often application-dependent. In this work, we rethink the adaptability property of wide-area stream processing systems and propose a resource-aware adaptation framework, called WASP. WASP adapts queries through a combination of multiple techniques: task re-assignment, operator scaling, and query re-planning, and applies them in a WAN-aware manner. It is able to automatically determine which adaptation action to take depending on the type of queries, dynamics, and optimization goals. We have implemented a WASP prototype on Apache Flink. Experimental evaluation with the YSB benchmark and a real Twitter trace shows that WASP can handle various dynamics without compromising the quality of the results. © 2020 Association for Computing Machinery.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Jonathan, A. and Chandra, A. and Weissman, J.",2020,Middleware 2020 - Proceedings of the 2020 21st International Middleware Conference,10.1145/3423211.3425668,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Rodrigo2019223,Latency-Aware Secure Elastic Stream Processing with Homomorphic Encryption,"Increasingly organizations are elastically scaling their stream processing applications into the infrastructure as a service clouds. However, state-of-the-art approaches for elastic stream processing do not consider the potential threats of exposing their data to third parties in cloud environments. We present the design and implementation of an Elastic Switching Mechanism for data stream processing which is based on homomorphic encryption (HomoESM). The HomoESM not only elastically scales data stream processing applications into public clouds but also preserves the privacy of such applications. Using a real-world test setup, which includes an E-mail Filter benchmark and a Web server access log processor benchmark (EDGAR), we demonstrate the effectiveness of our approach. Experiments on Amazon EC2 indicate that the proposed approach for homomorphic encryption provides a significant result which is 10–17% improvement in average latency in the case of E-mail Filter benchmark and EDGAR benchmark, respectively. Furthermore, EDGAR add/subtract operations, multiplication, and comparison operations showed up to 6.13%, 7.81%, and 26.17% average latency improvements, respectively. Finally, we evaluate the potential of scaling the homomorphic stream processor in the public cloud. These results indicate the potential for real-world deployments of secure elastic data stream processing applications. © 2019, The Author(s).",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Rodrigo, A. and Dayarathna, M. and Jayasena, S.",2019,Data Science and Engineering,10.1007/s41019-019-00100-5,scopus-search1.bib
Trotter2019136,Forecasting a Storm: Divining Optimal Configurations using Genetic Algorithms and Supervised Learning,"With the advent of Big Data platforms like Apache Storm, computations once deemed infeasible locally become possible at scale. However, doing so entails orchestrating powerful yet expensive clusters. With its focus on stream processing, Storm optimizes for low-latency and high throughput. However, to realize this goal and thereby maximize the utility of these clusters' resources, operators must execute these tasks under their optimal configurations. Yet, the search space for finding such configurations is so vast and time-consuming to explore so as to be effectively intractable due to issues like the temporal overhead of testing new candidate configurations, the sheer number of permutations of parameters within each configuration and their interdependence among each other. In order to efficiently cover the search space, we automate the process with genetic algorithms. Moreover, we fuse this technique not only with additional cluster information gleaned from JMX profiling and Storm performance data but also with classifiers constructed from training data from past executions of a plethora of Storm topologies. Utilizing a diverse set of Storm benchmark topologies as evaluation data, we show that the fully enhanced genetic algorithms can efficiently find configurations that perform on average 4.67x better than 'rules of thumb'-derived manual baselines. Moreover, we demonstrate that our fully refined classifiers enhance the GA throughput on average across the topologies by 22% while reducing search time by a factor of 6.47x. © 2019 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Trotter, M. and Wood, T. and Hwang, J.",2019,"Proceedings - 2019 IEEE International Conference on Autonomic Computing, ICAC 2019",10.1109/ICAC.2019.00025,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Zvara2019578,Optimizing distributed data stream processing by tracing,"Heterogeneous mobile, sensor, IoT, smart environment, and social networking applications have recently started to produce unbounded, fast, and massive-scale streams of data that have to be processed “on the fly”. Systems that process such data have to be enhanced with detection for operational exceptions and with triggers for both automated and manual operator actions. In this paper, we illustrate how tracing in distributed data processing systems can be applied to detecting changes in data and operational environment to maintain the efficiency of heterogeneous data stream processing systems under potentially changing data quality and distribution. By the tracing of individual input records, we can (1) identify outliers in a web crawling and document processing system and use the insights to define URL filtering rules; (2) identify heavy keys, such as NULL, that should be filtered before processing; (3) give hints to improve the key-based partitioning mechanisms; and (4) measure the limits of overpartitioning if heavy thread-unsafe libraries are imported. By using Apache Spark as illustration, we show how various data stream processing efficiency issues can be mitigated or optimized by our distributed tracing engine. We describe and qualitatively compare two different designs, one based on reporting to a distributed database and another based on trace piggybacking. Our prototype implementation consists of wrappers suitable for JVM environments in general, with minimal impact on the source code of the core system. Our tracing framework is the first to solve tracing in multiple systems across boundaries and to provide detailed performance measurements suitable for automated optimization, not just debugging. © 2018 Elsevier B.V.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zvara, Z. and Szabó, P.G.N. and Balázs, B. and Benczúr, A.",2019,Future Generation Computer Systems,10.1016/j.future.2018.06.047,scopus-search1.bib
Ma201526,Live Data Replication Approach from Relational Tables to Schema-Free Collections Using Stream Processing Framework,"Recent researches focus on the data replication issue from relational tables to schema-free collections in a batch processing way. However, there are few publications on live data replication in real time. In this paper, we attempt to address this legacy issue with new stream processing framework. The process of replication consists of log-based change data capture and stream-based data replication. Data replication mappings are present, and the proposed architecture of stream processing framework including column grouping, column merging and column versioning, is introduced to avoid data lost in case of failure. Finally, our experimental evaluation of live data replication approach with stream processing framework shows the higher effectiveness and efficiency than current methods. © 2015 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Ma, K. and Yang, B.",2015,"Proceedings - 2015 10th International Conference on P2P, Parallel, Grid, Cloud and Internet Computing, 3PGCIC 2015",10.1109/3PGCIC.2015.64,scopus-search1.bib
Ravishankar2012617,Analysis and evaluation of greedy thread swapping based dynamic power management for MPSoC platforms,"Thread migration (TM) is a recently proposed dynamic power management technique for heterogeneous multi-processor system-on-chip (MPSoC) platforms that eliminates the area and power overheads incurred by fine-grained dynamic voltage and frequency scaling (DVFS) based power management. In this paper, we take the first step towards formally analyzing and experimentally evaluating the use of power-aware TM for parallel data streaming applications on MPSoC platforms. From an analysis perspective, we characterize the optimal mapping of threads to cores and prove the convergence properties of a complexity effective greedy thread swapping based TM algorithm to the globally optimal solution. The proposed techniques are evaluated on a 9-core FPGA based MPSoC prototype equipped with fully-functional TM and DVFS support, and running a parallelized video encoding benchmark based on the Motion Picture Experts Group (MPEG-2) standard. Our experimental results validate the proposed theoretical analysis, and show that the proposed TM algorithm provides within 8% of the DVFS performance under the same power budget, and assuming no overheads for DVFS. Assuming voltage regulator inefficiency of 80%, the proposed TM algorithm has 9% higher performance than DVFS, again under the same total power budget. © 2012 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ravishankar, C. and Ananthanarayanan, S. and Garg, S. and Kennings, A.",2012,"Proceedings - International Symposium on Quality Electronic Design, ISQED",10.1109/ISQED.2012.6187557,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Ericson201133,On the performance of distributed clustering algorithms in file and streaming processing systems,"There is often a need to cluster voluminous amounts of data. Such clustering has application in fields such as pattern recognition, data mining, bioinformatics, and recommendation systems. Here we evaluate the performance of 4 clustering algorithms viz. K-means, Fuzzy k-means, Dirichlet, and Latent Dirichlet Allocation within two different cloud runtimes: Hadoop and Granules. Our benchmarks use identical clustering code with both Hadoop and Granules. The difference between these implementations stem from how the Hadoop and Granules runtimes (1) support and manage the lifecycle of individual computations, and (2) how they orchestrate exchange of data between different stages of the computational pipeline during successive iterations of the clustering algorithm. We also include an analysis of our results for each of these clustering algorithms in a distributed setting. © 2011 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ericson, K. and Pallickara, S.",2011,"Proceedings - 2011 4th IEEE International Conference on Utility and Cloud Computing, UCC 2011",10.1109/UCC.2011.15,scopus-search1.bib;ieee2-search1.bib
Kuntschke2006769,Data stream sharing,"Recent research efforts in the fields of data stream processing and data stream management systems (DSMSs) show the increasing importance of processing data streams, e. g., in the e-science domain. Together with the advent of peer-to-peer (P2P) networks and grid computing, this leads to the necessity of developing new techniques for distributing and processing continuous queries over data streams in such networks. In this paper, we present a novel approach for optimizing the integration, distribution, and execution of newly registered continuous queries over data streams in grid-based P2P networks. We introduce Windowed XQuery (WXQuery), our XQuery-based subscription language for continuous queries over XML data streams supporting window-based operators. Concentrating on filtering and window-based aggregation, we present our stream sharing algorithms as well as experimental evaluation results from the astrophysics application domain to assess our approach. © Springer-Verlag Berlin Heidelberg 2006.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kuntschke, R. and Kemper, A.",2006,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/11896548_58,scopus-search1.bib;web-of-science-search1.bib
Henning202185,How to measure scalability of distributed stream processing engines?,"Scalability is promoted as a key quality feature of modern big data stream processing engines. However, even though research made huge efforts to provide precise definitions and corresponding metrics for the term scalability, experimental scalability evaluations or benchmarks of stream processing engines apply different and inconsistent metrics. With this paper, we aim to establish general metrics for scalability of stream processing engines. Derived from common definitions of scalability in cloud computing, we propose two metrics: a load capacity function and a resource demand function. Both metrics relate provisioned resources and load intensities, while requiring specific service level objectives to be fulfilled. We show how these metrics can be employed for scalability benchmarking and discuss their advantages in comparison to other metrics, used for stream processing engines and other software systems. © 2021 Association for Computing Machinery.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Henning, S. and Hasselbring, W.",2021,ICPE 2021 - Companion of the ACM/SPEC International Conference on Performance Engineering,10.1145/3447545.3451190,scopus-search1.bib;acm1-search1.bib;scholar.bib
Koo2020,IoT-enabled directed acyclic graph in spark cluster,"Real-time data streaming fetches live sensory segments of the dataset in the heterogeneous distributed computing environment. This process assembles data chunks at a rapid encapsulation rate through a streaming technique that bundles sensor segments into multiple micro-batches and extracts into a repository, respectively. Recently, the acquisition process is enhanced with an additional feature of exchanging IoT devices’ dataset comprised of two components: (i) sensory data and (ii) metadata. The body of sensory data includes record information, and the metadata part consists of logs, heterogeneous events, and routing path tables to transmit micro-batch streams into the repository. Real-time acquisition procedure uses the Directed Acyclic Graph (DAG) to extract live query outcomes from in-place micro-batches through MapReduce stages and returns a result set. However, few bottlenecks affect the performance during the execution process, such as (i) homogeneous micro-batches formation only, (ii) complexity of dataset diversification, (iii) heterogeneous data tuples processing, and (iv) linear DAG workflow only. As a result, it produces huge processing latency and the additional cost of extracting event-enabled IoT datasets. Thus, the Spark cluster that processes Resilient Distributed Dataset (RDD) in a fast-pace using Random access memory (RAM) defies expected robustness in processing IoT streams in the distributed computing environment. This paper presents an IoT-enabled Directed Acyclic Graph (I-DAG) technique that labels micro-batches at the stage of building a stream event and arranges stream elements with event labels. In the next step, heterogeneous stream events are processed through the I-DAG workflow, which has non-linear DAG operation for extracting queries’ results in a Spark cluster. The performance evaluation shows that I-DAG resolves homogeneous IoT-enabled stream event issues and provides an effective stream event heterogeneous solution for IoT-enabled datasets in spark clusters. © 2020, The Author(s).",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Koo, J. and FaseehQureshi, N.M. and Siddiqui, I.F. and Abbas, A. and Bashir, A.K.",2020,Journal of Cloud Computing,10.1186/s13677-020-00195-6,scopus-search1.bib;web-of-science-search1.bib
Tantalaki2020117182,Pipeline-Based Linear Scheduling of Big Data Streams in the Cloud,"Nowadays, there is an accelerating need to efficiently and timely handle large amounts of data that arrives continuously. Streams of big data led to the emergence of several Distributed Stream Processing Systems (DSPS) that assign processing tasks to the available resources (dynamically or not) and route streaming data between them. Efficient scheduling of processing tasks can reduce application latencies and eliminate network congestions. However, the available DSPSs' in-built scheduling techniques are far from optimal. In this work, we extend our previous work, where we proposed a linear scheme for the task allocation and scheduling problem. Our scheme takes advantage of pipelines to handle efficiently applications, where there is need for heavy communication (all-to-all) between tasks assigned to pairs of components. In this work, we prove that our scheme is periodic, we provide a communication refinement algorithm and a mechanism to handle many-to-one assignments efficiently. For concreteness, our work is illustrated based on Apache Storm semantics. The performance evaluation depicts that our algorithm achieves load balance and constraints the required buffer space. For throughput testing, we compared our work to the default Storm scheduler, as well as to R-Storm. Our scheme was found to outperform both the other strategies and achieved an average of 25%-40% improvement compared to Storm's default scheduler under different scenarios, mainly as a result of reduced buffering (approximate to 45% less memory). Compared to R-storm, the results indicate an average of 35%-45% improvement.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Tantalaki, N. and Souravlas, S. and Roumeliotis, M. and Katsavounis, S.",2020,IEEE Access,10.1109/ACCESS.2020.3004612,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Stehle2020616,ParPaRaw: Massively parallel parsing of delimiter-separated raw data,"Parsing is essential for a wide range of use cases, such as stream processing, bulk loading, and in-situ querying of raw data. Yet, the compute-intense step often constitutes a major bottleneck in the data ingestion pipeline, since parsing of inputs that require more involved parsing rules is challenging to parallelise. This work proposes a massively parallel algorithm for parsing delimiter-separated data formats on GPUs. Other than the state-of-the-art, the proposed approach does not require an initial sequential pass over the input to determine a thread's parsing context. That is, how a thread, beginning somewhere in the middle of the input, should interpret a certain symbol (e.g., whether to interpret a comma as a delimiter or as part of a larger string enclosed in double-quotes). Instead of tailoring the approach to a single format, we are able to perform a massively parallel finite state machine (FSM) simulation, which is more flexible and powerful, supporting more expressive parsing rules with general applicability. Achieving a parsing rate of as much as 14.2 GB/s, our experimental evaluation on a GPU with 3 584 cores shows that the presented approach is able to scale to thousands of cores and beyond. With an end-to-end streaming approach, we are able to exploit the full-duplex capabilities of the PCIe bus and hide latency from data transfers. Considering the end-to-end performance, the algorithm parses 4:8 GB in as little as 0:44 seconds, including data transfers.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Stehle, E. and Jacobsen, H.-A.",2020,Proceedings of the VLDB Endowment,10.14778/3377369.3377372,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Hesse20191381,Quantitative impact evaluation of an abstraction layer for data stream processing systems,"With the demand to process ever-growing data volumes, a variety of new data stream processing frameworks have been developed. Moving an implementation from one such system to another, e.g., for performance reasons, requires adapting existing applications to new interfaces. Apache Beam addresses these high substitution costs by providing an abstraction layer that enables executing programs on any of the supported streaming frameworks. In this paper, we present a novel benchmark architecture for comparing the performance impact of using Apache Beam on three streaming frameworks: Apache Spark Streaming, Apache Flink, and Apache Apex. We find significant performance penalties when using Apache Beam for application development in the surveyed systems. Overall, usage of Apache Beam for the examined streaming applications caused a high variance of query execution times with a slowdown of up to a factor of 58 compared to queries developed without the abstraction layer. All developed benchmark artifacts are publicly available to ensure reproducible results. © 2019 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Hesse, G. and Matthies, C. and Glass, K. and Huegle, J. and Uflacker, M.",2019,Proceedings - International Conference on Distributed Computing Systems,10.1109/ICDCS.2019.00138,scopus-search1.bib;web-of-science-search1.bib
Renart2019885,An edge-based framework for enabling data-driven pipelines for IoT systems,"Due to the proliferation of the Internet of Things (IoT) paradigm, the number of devices connected to the Internet is growing. These devices are generating unprecedented amounts of data at the edges of the infrastructure. Although the generated data provides great potential, identifying and processing relevant data points hidden in streams of unimportant data, and doing this in near real time, remains a significant challenge. Existing stream processing platforms require the data to be transported to the cloud for processing, resulting in latencies that can prevent timely decision making or may reduce the amount of data processed. To tackle this problem, we designed an IoT Edge Framework, called R-Pulsar, that extends cloud capabilities to local devices and provides a programming model for deciding what, when, and where data get collected and processed. In this paper, we discuss motivating use cases and the architectural design of R-Pulsar. We have deployed and tested R-Pulsar on embedded devices (Raspberry Pi and Android phone) and present an experimental evaluation that demonstrates that R-Pulsar can enable timely data analytics by effectively leveraging edge and cloud resources. © 2019 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Renart, E.G. and Balouek-Thomert, D. and Parashar, M.",2019,"Proceedings - 2019 IEEE 33rd International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2019",10.1109/IPDPSW.2019.00146,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Prosperi201942,Planner: Cost-Efficient Execution Plans Placement for Uniform Stream Analytics on Edge and Cloud,"Stream processing applications handle unbounded and continuous flows of data items which are generated from multiple geographically distributed sources. Two approaches are commonly used for processing: Cloud-based analytics and Edge analytics. The first one routes the whole data set to the Cloud, incurring significant costs and late results from the high latency networks that are traversed. The latter can give timely results but forces users to manually define which part of the computation should be executed on Edge and to interconnect it with the remaining part executed in the Cloud, leading to sub-optimal placements. In this paper, we introduce Planner, a middleware for uniform and transparent stream processing across Edge and Cloud. Planner automatically selects which parts of the execution graph will be executed at the Edge in order to minimize the network cost. Real-world micro-benchmarks show that Planner reduces the network usage by 40% and the makespan (end-to-end processing time) by 15% compared to state-of-the-art. © 2018 IEEE.",FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Prosperi, L. and Costan, A. and Silva, P. and Antoniu, G.",2018,"Proceedings of WORKS 2018: 13th Workshop on Workflows in Support of Large-Scale Science, Held in conjunction with SC 2018: The International Conference for High Performance Computing, Networking, Storage and Analysis",10.1109/WORKS.2018.00010,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Truong2018754,Performance Analysis of Large-Scale Distributed Stream Processing Systems on the Cloud,"Real-time data processing is often a necessity as it can provide insights that have less value if discovered off-line or after the fact. However, large-scale stream processing systems are non-trivial to build and deploy. While there are many frameworks that allow users to create large-scale distributed systems, there remains many challenges in understanding the performance, cost of deployment and considerations and impact of potential (partial) outages on real-time systems performance. Our work considers the performance of Cloud-based stream processing systems in terms of back-pressure and expected utilization. The performance of an exemplar stream application is explored using different Cloud-based virtual machine resources and where the scale of deployment and cost benefits are taken into consideration in relation to the overall performance. To achieve this, we develop an algorithm based on queueing theory to predict the throughput and latency of stream data processing while supporting system stability. Our methodology for making fundamental measurements is applicable to mainstream stream processing frameworks such as Apache Storm and Heron. The method is especially suitable for large-scale distributed stream processing where jobs can run for extended time periods. We benchmark the performance of the system on the national research cloud of Australia (Nectar), and present a performance analysis based on estimating the overall effective utilization. © 2018 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Truong, T.M. and Harwood, A. and Sinnott, R.O. and Chen, S.",2018,"IEEE International Conference on Cloud Computing, CLOUD",10.1109/CLOUD.2018.00103,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib;scholar.bib
Ivanov2018141,Exploratory analysis of spark structured streaming,"In the Big Data era, stream processing has become a common requirement for many data-intensive applications. This has lead to many advances in the development and adaption of large scale streaming systems. Spark and Flink have become a popular choice for many developers as they combine both batch and streaming capabilities in a single system. However, introducing the Spark Structured Streaming in version 2.0 opened up completely new features for SparkSQL, which are alternatively only available in Apache Calcite. This work focuses on the new Spark Structured Streaming and analyses it by diving into its internal functionalities. With the help of a micro-benchmark consisting of streaming queries, we perform initial experiments evaluating the technology. Our results show that Spark Structured Streaming is able to run multiple queries successfully in parallel on data with changing velocity and volume sizes. © 2018 Association for Computing Machinery.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Ivanov, T. and Taaffe, J.",2018,ICPE 2018 - Companion of the 2018 ACM/SPEC International Conference on Performance Engineering,10.1145/3185768.3186360,scopus-search1.bib;web-of-science-search1.bib;acm3-search1.bib
Dayarathna20171443,Energy consumption analysis of data stream processing: a benchmarking approach,"Energy efficiency of data analysis systems has become a very important issue in recent times because of the increasing costs of data center operations. Although distributed streaming workloads have increasingly been present in modern data centers, energy-efficient scheduling of such applications remains as a significant challenge. In this paper, we conduct an energy consumption analysis of data stream processing systems in order to identify their energy consumption patterns. We follow stream system benchmarking approach to solve this issue. Specifically, we implement Linear Road benchmark on six stream processing environments (S4, Storm, ActiveMQ, Esper, Kafka, and Spark Streaming) and characterize these systems' performance on a real-world data center. We study the energy consumption characteristics of each system with varying number of roads as well as with different types of component layouts. We also use a microbenchmark to capture raw energy consumption characteristics. We observed that S4, Esper, and Spark Streaming environments had highest average energy consumption efficiencies compared with the other systems. Using a neural networkbased technique with the power/performance information gathered from our experiments, we developed a model for the power consumption behavior of a streaming environment. We observed that energy-efficient execution of streaming application cannot be specifically attributed to the system CPU usage. We observed that communication between compute nodes with moderate tuple sizes and scheduling plans with balanced system overhead produces better power consumption behaviors in the context of data stream processing systems. Copyright © 2016 John Wiley & Sons, Ltd. Copyright © 2016 John Wiley & Sons, Ltd.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Dayarathna, M. and Li, Y. and Wen, Y. and Fan, R.",2017,Software - Practice and Experience,10.1002/spe.2458,scopus-search1.bib;web-of-science-search1.bib
HoseinyFarahabady2017137,QoS-and Contention-Aware Resource Provisioning in a Stream Processing Engine,"This paper addresses the shared resource contention problem associated with the auto-parallelization of running queries in distributed stream processing engines. In such platforms, analyzing a large amount of data often requires to execute user-defined queries over continues raw-inputs in a parallel fashion at each single host. However, previous studies showed that the collocated applications can fiercely compete for shared resources, resulting in a severe performance degradation among applications. This paper presents an advanced resource allocation strategy for handling scenarios in which the target applications have different quality of service (QoS) requirements while shared-resource interference is considered as a key performance-limiting parameter.To properly allocate the best possible resource to each query, the proposed controller predicts the performance degradation of the running pane-level as well as the window-level queries when co-running with other queries. This is addressed as an optimization problem where a set of cost functions is defined to achieve the following goals: A) reduce the sum of QoS violation incidents over all machines; b) keep the CPU utilization level within an accepted range; and c) avoid fierce shared resource interference among collocated applications. Particle swarm optimization is used to find an acceptable solution at each round of the controlling period. The performance of the proposed solution is benchmarked with Round-Robin and best-effort strategies, and the experimental results clearly demonstrate that the proposed controller has the following advantages over its opponents: it increases the overall resource utilization by 15% on average while can reduce the average tuple latencies by 14%. It also achieves an average 123% improvement in preventing QoS violation incidents. © 2017 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"HoseinyFarahabady, M. and Zomaya, A.Y. and Tari, Z.",2017,"Proceedings - IEEE International Conference on Cluster Computing, ICCC",10.1109/CLUSTER.2017.21,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Wang2017107,Cloud-based integration and service of streaming data,"Big data management and processing are a good place where a Cloud infrastructure shows power. Service offers an important way to implement the delivery and usage model for various Cloud-based resources and abilities. With the prevalence of large-scale sensor data, the scale of system has expanded dramatically, the complexity of the multivariate and heterogeneous data has escalated, and the concurrency and frequency of streaming data has increased a lot. These bring great challenges to the traditional streaming data system in addressing issues in areas such as processing efficiency, scalability and fault tolerance. The Cloud computing techniques can be the foundation to manage and process large scale streaming data because of their high scalability, parallel processing capabilities, support of service delivery model and fault tolerance. The issue of streaming data integration and services based on Cloud computing is the focus of this paper. The paper starts with the application requirements of large-scale streaming data processing and integration, presents a framework for streaming integration, discusses the state-of-the-art key technologies including streaming data query, service customizations, mechanisms for scalability and reliability, evaluation metrics and benchmark etc. The uses of Cloud computing for large-scale streaming data integration and service provision are scrutinized, and challenges and future trends are summarized. © 2017, Science Press. All right reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Wang, G.-L. and Han, Y.-B. and Zhang, Z.-M. and Zhu, M.-L.",2017,Jisuanji Xuebao/Chinese Journal of Computers,10.11897/SP.J.1016.2017.00107,scopus-search1.bib
Saleh20162140,Performance Analysis of Network-Coding-Based P2P Live Streaming Systems,"Peer-to-peer (P2P) video streaming is a scalable and cost-effective technology to stream video content to a large population of users and has attracted a lot of research for over a decade now. Recently, network coding has been introduced to improve the efficiency of these systems and to simplify the protocol design. There are already some successful commercial applications that utilize network coding. However, previous analytical studies of network-coding-based P2P streaming systems mainly focused on fundamental properties of the system and ignored the influence of the protocol details. In this study, a unique stochastic model is developed to reveal how segments of the video stream evolve over their lifetime in the buffer before they go into playback. Different strategies for segment selection have been studied with the model, and their performance has been compared. A new approximation of the probability of linear independence of coded blocks has been proposed to study the redundancy of network coding. Finally, extensive numerical results and simulations have been provided to validate our model. From these results, in-depth insights into how system parameters and segment selection strategies affect the performance of the system have been obtained. © 2015 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Saleh, B. and Qiu, D.",2016,IEEE/ACM Transactions on Networking,10.1109/TNET.2015.2448597,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Zahmatkesh2016299,When a FILTER makes the difference in continuously answering SPARQL queries on streaming and quasi-static linked data,"We are witnessing a growing interest for Web applications that (i) require to continuously combine highly dynamic data stream with background data and (ii) have reactivity as key performance indicator. The Semantic Web community showed that RDF Stream Processing (RSP) is an adequate framework to develop this type of applications. However, when the background data is distributed over theWeb, even RSP engines risk losing reactiveness due to the time necessary to access the background data. State-of-the-art RSP engines remain reactive using a local replica of the background data, but such a replica progressively become stale if not updated to reflect the changes in the remote background data. For this reason, recently, the RSP community investigated maintenance policies (collectively named Acqua) that guarantee reactiveness while maximizing the freshness of the replica. Acqua’s policies apply to queries that join a basic graph pattern in a window clause with another basic graph pattern in a service clause. In this paper, we extend the class of queries considered in Acqua adding a FILTER clause that selects mapping in the background data. We propose a new maintenance policy (namely, the Filter Update Policy) and we show how to combine it with Acqua policies. A set of experimental evaluations empirically proves the ability of the proposed policies to guarantee reactiveness while keeping the replica fresher than with the Acqua policies. © Springer International Publishing Switzerland 2016.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zahmatkesh, S. and DellaValle, E. and Dell’Aglio, D.",2016,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-38791-8_17,scopus-search1.bib
Gu2011347,Improving throughput and reliability of distributed scientific workflows for streaming data processing,"With the advent of next-generation scientific applications, the workflow-based computing technology has become an indispensable research method for managing and streamlining large-scale distributed data processing. This paper investigates a problem of mapping distributed workflows for streaming data processing in faulty networks where nodes and links are subject to probabilistic failures. We formulate this problem as a bi-objective optimization problem in terms of both throughput and reliability, and propose a decentralized layer-oriented method to achieve high throughput for smooth data flow while satisfying a prespecified overall failure rate bound for a guaranteed level of reliability. The superiority of the proposed mapping solution is illustrated by both extensive simulation-based performance comparisons with existing algorithms and experimental results from a real-life scientific workflow deployed in wide-area networks. © 2011 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Gu, Y. and Wu, Q. and Liu, X. and Yu, D.",2011,Proc.- 2011 IEEE International Conference on HPCC 2011 - 2011 IEEE International Workshop on FTDCS 2011 -Workshops of the 2011 Int. Conf. on UIC 2011- Workshops of the 2011 Int. Conf. ATC 2011,10.1109/HPCC.2011.52,scopus-search1.bib;ieee3-search1.bib
Karki2010111,Performance analysis of home streaming video using Orb,"A new paradigm in video streaming is emerging, that of personal video servers in the home streaming video to remote clients on the Internet. The potential impact of such technologies demands careful study to assess performance and impact. This project studies one such personal video streaming system called Orb in a closed network environment, allowing us to control network bandwidths. Our performance evaluation focuses on Orb's method of bandwidth estimation, video performance and bitrates, and resource usage during transcoding. Analysis shows Orb uses simplistic, but effective, methods of determining available bandwidth, dynamic temporal and spatial scaling, and significant CPU cycles when transcoding. The results should be useful for subsequent comparison with other home streaming technologies and capacity planning for network providers. © 2010 ACM.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Karki, R. and Seenivasan, T. and Claypool, M. and Kinicki, R.",2010,Proceedings of the International Workshop on Network and Operating System Support for Digital Audio and Video,10.1145/1806565.1806593,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib;scholar.bib
Bouillet20081003,Distributed multi-layered workload synthesis for testing stream processing systems,"Testing and benchmarking of stream processing systems requires workload representative of real world scenarios with myriad of users, interacting through different applications over different modalities with different underlying protocols. The workload should have realistic volumetric and contextual statistics at different levels: user level, application level, packet level etc. Further realistic workload is inherently distributed in nature. We present a scalable framework for synthesis of distributed workload based on identifying different layers of workload corresponding to different time-scales. The architecture is extensible and modular, promotes reuse of libraries at different layers and offers the flexibility to add additional plug-ins at different layers without sacrificing the efficiency. © 2008 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Bouillet, E. and Dube, P. and George, D. and Liu, Z. and Pendarakis, D. and Zhang, Li.",2008,Proceedings - Winter Simulation Conference,10.1109/WSC.2008.4736167,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib;acm2-search1.bib
Jacob20212613,Exathlon: A benchmark for explainable anomaly detection over time series,"Access to high-quality data repositories and benchmarks have been instrumental in advancing the state of the art in many experimental research domains. While advanced analytics tasks over time series data have been gaining lots of attention, lack of such community resources severely limits scientific progress. In this paper, we present Exathlon, the first comprehensive public benchmark for explainable anomaly detection over high-dimensional time series data. Exathlon has been systematically constructed based on real data traces from repeated executions of large-scale stream processing jobs on an Apache Spark cluster. Some of these executions were intentionally disturbed by introducing instances of six different types of anomalous events (e.g., misbehaving inputs, resource contention, process failures). For each of the anomaly instances, ground truth labels for the root cause interval as well as those for the extended effect interval are provided, supporting the development and evaluation of a wide range of anomaly detection (AD) and explanation discovery (ED) tasks. We demonstrate the practical utility of Exathlon’s dataset, evaluation methodology, and end-to-end data science pipeline design through an experimental study with three state-of-the-art AD and ED techniques. © 2021, VLDB Endowment. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Jacob, V. and Song, F. and Stiegler, A. and Rad, B. and Diao, Y. and Tatbul, N.",2021,Proceedings of the VLDB Endowment,10.14778/3476249.3476307,scopus-search1.bib;web-of-science-search1.bib
Wang20201628,Online Computation Performance Analysis for Distributed Machine Learning Pipelines in Fog Manufacturing,"Smart manufacturing enables real-time data streaming from interconnected manufacturing processes to improve manufacturing quality, throughput, flexibility, and cost reduction via computation services. In these computation services, machine learning pipelines integrate various types of computation method options to match the contextualized, on-demand computation needs for the maximum prediction accuracy or the best model structure interpretation. On the other hand, there is a pressing need to integrate Fog computing in manufacturing, which will reduce communication time latency and dependency on connections, improve responsiveness and reliability of the computation services, and maintain data privacy. However, there is a knowledge gap in using machine learning pipelines in Fog manufacturing. Existing offloading strategies are not effective, due to the lack of accurate prediction model for the performance of computation services before the execution of those heterogeneous computation tasks. In this paper, machine learning pipelines are implemented in Fog manufacturing. The computation performance of each sub-step of pipelines is predicted and analyzed via linear regression models and random forest regression models. A Fog manufacturing testbed is adopted to validate the performance of the employed models. The results show that the models can adequately predict the performance of computation services, which can be further integrated into Fog manufacturing to better support offloading strategies for machine learning pipelines. © 2020 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Wang, L. and Zhang, Y. and Chen, X. and Jin, R.",2020,IEEE International Conference on Automation Science and Engineering,10.1109/CASE48305.2020.9216979,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
RezaHoseinyfarahabady2020629,Q-Flink: A QoS-Aware Controller for Apache Flink,"Modern stream-data processing platforms are required to execute processing pipelines over high-volume, yet high-velocity, datasets under tight latency constraints. Apache Flink has emerged as an important new technology of large-scale platform that can distribute processing over a large number of computing nodes in a cluster (i.e., scale-out processing). Flink allows application developers to design and execute queries over continuous raw-inputs to analyze a large amount of streaming data in a parallel and distributed fashion. To increase the throughput of computing resources in stream processing platforms, a service provider might be tempted to use a consolidation strategy to pack as many processing applications as possible on the working nodes, with the hope of increasing the total revenue by improving the overall resource utilization. However, there is a hidden trap for achieving such a higher throughput solely by relying on an interference-oblivious consolidation strategy. In practice, collocated applications in a shared platform can fiercely compete with each others for obtaining the capacity of shared resources (e.g., cache and memory bandwidth) which in turn can lead to a severe performance degradation for all consolidated workloads.This paper addresses the shared resource contention problem associated with the auto-resource controlling mechanism of Apache Flink engine running across a distributed cluster. A controlling strategy is proposed to handle scenarios in which stream processing applications may have different quality of service (QoS) requirements while the resource interference is considered as the key performance-limiting parameter. The performance evaluation is carried out by comparing the proposed controller with the default Flink resource allocation strategy in a testbed cluster with total 32 Intel Xeon cores under different workload traffic with up to 4000 streaming applications chosen from various benchmarking tools. Experimental results demonstrate that the proposed controller can successfully decrease the average latency of high priority applications by 223% during the burst traffic while maintaining the requested QoS enforcement levels. © 2020 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"RezaHoseinyfarahabady, M. and Jannesari, A. and Taheri, J. and Bao, W. and Zomaya, A.Y. and Tari, Z.",2020,"Proceedings - 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing, CCGRID 2020",10.1109/CCGrid49817.2020.00-30,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Ordonez-Ante2020,Explora: Interactive querying of multidimensional data in the context of smart cities,"Citizen engagement is one of the key factors for smart city initiatives to remain sustainable over time. This in turn entails providing citizens and other relevant stakeholders with the latest data and tools that enable them to derive insights that add value to their day-to-day life. The massive volume of data being constantly produced in these smart city environments makes satisfying this requirement particularly challenging. This paper introduces EXPLORA, a generic framework for serving interactive low-latency requests, typical of visual exploratory applications on spatiotemporal data, which leverages the stream processing for deriving—on ingestion time—synopsis data structures that concisely capture the spatial and temporal trends and dynamics of the sensed variables and serve as compacted data sets to provide fast (approximate) answers to visual queries on smart city data. The experimental evaluation conducted on proof-of-concept implementations of EXPLORA, based on traditional database and distributed data processing setups, accounts for a decrease of up to 2 orders of magnitude in query latency compared to queries running on the base raw data at the expense of less than 10% query accuracy and 30% data footprint. The implementation of the framework on real smart city data along with the obtained experimental results prove the feasibility of the proposed approach. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ordonez-Ante, L. and VanSeghbroeck, G. and Wauters, T. and Volckaert, B. and DeTurck, F.",2020,Sensors (Switzerland),10.3390/s20092737,scopus-search1.bib;web-of-science-search1.bib
Henning20193512,Scalable and Reliable Multi-Dimensional Aggregation of Sensor Data Streams,"Ever-increasing amounts of data and requirements to process them in real time lead to more and more analytics platforms and software systems being designed according to the concept of stream processing. A common area of application is the processing of continuous data streams from sensors, for example, IoT devices or performance monitoring tools. In addition to analyzing pure sensor data, analyses of data for groups of sensors often need to be performed as well. Therefore, data streams of the individual sensors have to be continuously aggregated to a data stream for a group. Motivated by a real-world application scenario, we propose that such a stream aggregation approach has to allow for aggregating sensors in hierarchical groups, support multiple such hierarchies in parallel, provide reconfiguration at runtime, and preserve the scalability and reliability qualities induced by applying stream processing techniques. We propose a stream processing architecture fulfilling these requirements, which can be integrated into existing big data architectures. We present a pilot implementation of such an extended architecture and show how it is used in industry. Furthermore, in experimental evaluations we show that our solution scales linearly with the amount of sensors and provides adequate reliability in the case of faults. © 2019 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Henning, S. and Hasselbring, W.",2019,"Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019",10.1109/BigData47090.2019.9006452,scopus-search1.bib
Bartnik2019127,On-the-fly reconfiguration of query plans for stateful stream processing engines,"Stream Processing Engines (SPEs) must tolerate the dynamic nature of unbounded data streams and provide means to quickly adapt to fluctuations in the data rate. Many major SPEs however provide very little functionality to adjust the execution of a potentially infinite streaming query at runtime. Each modification requires a complete query restart, which involves an expensive redistribution of the state of a query and may require external systems in order to guarantee correct processing semantics. This results in significant downtime, which increase the operational cost of those SPEs. We present a modification protocol that enables modifying specific operators as well as the data flow of a running query while ensuring exactly-once processing semantics. We provide an implementation for Apache Flink, which enables stateful operator migration across machines, the introduction of new operators into a running query, and changes to a specific operator based on external triggers. Our results on two benchmarks show that migrating operators for queries with small state is as fast as using the savepoint mechanism of Flink. Migrating operators in the presence of large state even outperforms the savepoint mechanism by a factor of more than 2.3. Introducing and replacing operators at runtime is performed in less than 10 s. Our modification protocol demonstrates the general feasibility of runtime modifications and opens the door for many other modification use cases, such as online algorithm tweaking and up- or downscaling operator instances. © 2019 Gesellschaft fur Informatik (GI). All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Bartnik, A. and Monte, B.D. and Rabl, T. and Markl, V.",2019,"Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)",10.18420/btw2019-09,scopus-search1.bib
Mortazavi-Dehkordi201977,Efficient resource scheduling for the analysis of Big Data streams,"The emergence of Big Data has had a profound impact on how data are analyzed. Open source distributed stream processing platforms have gained popularity for analyzing streaming Big Data as they provide low latency required for streaming Big Data applications using cluster resources. However, existing resource schedulers are still lacking the efficiency that Big Data analytical applications require. Recent works have already considered streaming Big Data characteristics to improve the efficiency of scheduling in the platforms. Nevertheless, they have not taken into account the specific attributes of analytical applications. This study, therefore, presents Bframework, an efficient resource scheduling framework used by streaming Big Data analysis applications based on cluster resources. Bframework proposes a query model using Directed Graphs (DGs) and introduces operator assignment and operator scheduling algorithms based on a novel partitioning algorithm. Bframework is highly adaptable to the fluctuation of streaming Big Data and the availability of cluster resources. Experiments with the benchmark and well-known real-world queries show that Bframework can significantly reduce the latency of streaming Big Data analysis queries up to about 65%. © 2019 - IOS Press and the authors. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Mortazavi-Dehkordi, M. and Zamanifar, K.",2019,Intelligent Data Analysis,10.3233/IDA-173691,scopus-search1.bib;web-of-science-search1.bib
Nardelli201953,A multi-level elasticity framework for distributed data stream processing,"Data Stream Processing (DSP) applications should be capable to efficiently process high-velocity continuous data streams by elastically scaling the parallelism degree of their operators so to deal with high variability in the workload. Moreover, to efficiently use computing resources, modern DSP frameworks should seamlessly support infrastructure elasticity, which allows to exploit resources available on-demand in geo-distributed Cloud and Fog systems. In this paper we propose E2DF, a framework to autonomously control the multi-level elasticity of DSP applications and the underlying computing infrastructure. E2DF revolves around a hierarchical approach, with two control layers that work at different granularity and time scale. At the lower level, fully decentralized Operator and Region managers control the reconfiguration of distributed DSP operators and resources. At the higher level, centralized managers oversee the overall application and infrastructure adaptation. We have integrated the proposed solution into Apache Storm, relying on a previous extension we developed, and conducted an experimental evaluation. It shows that, even with simple control policies, E2DF can improve resource utilization without application performance degradation. © Springer Nature Switzerland AG 2019.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Nardelli, M. and RussoRusso, G. and Cardellini, V. and LoPresti, F.",2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-030-10549-5_5,scopus-search1.bib;web-of-science-search1.bib
Chen2018169,A cloud/edge computing streaming system for network traffic monitoring and threat detection,"Abstract: The unyielding trend of increasing cyber threats has made cyber security paramount in protecting personal and private intellectual property. To provide a highly secured network environment, network threat detection systems must handle real-time big data from varied places in enterprise networks. In this paper, we introduce a streaming-based threat detection system that can rapidly analyse highly intensive network traffic data in real-time, utilising streaming-based clustering algorithms to detect abnormal network activities. The developed system integrates the high-performance data analysis capabilities of Flume, Spark and Hadoop into a cloud-computing environment to provide network monitoring and intrusion detection. Our performance evaluation validates that the developed system can cope with a significant volume of streaming data in a high detection accuracy and good system performance. We further extend our system for edge computing and discuss some key challenges, as well as some potential solutions, aiming to improve the scalability of our system. Copyright © 2018 Inderscience Enterprises Ltd.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Chen, Z. and Wei, S. and Yu, W. and Nguyen, J.H. and Hatcher, W.G.",2018,International Journal of Security and Networks,10.1504/IJSN.2018.093556,scopus-search1.bib
Schaffner2018265,Towards Edge-Aware Spatio-Temporal Filtering in Real-Time,"Spatio-temporal edge-aware (STEA) filtering methods have recently received increased attention due to their ability to efficiently solve or approximate important image-domain problems in a temporally consistent manner - which is a crucial property for video-processing applications. However, existing STEA methods are currently unsuited for real-time, embedded stream-processing settings due to their high processing latency, large memory, and bandwidth requirements, and the need for accurate optical flow to enable filtering along motion paths. To this end, we propose an efficient STEA filtering pipeline based on the recently proposed permeability filter (PF), which offers high quality and halo reduction capabilities. Using mathematical properties of the PF, we reformulate its temporal extension as a causal, non-linear infinite impulse response filter, which can be efficiently evaluated due to its incremental nature. We bootstrap our own accurate flow using the PF and its temporal extension by interpolating a quasi-dense nearest neighbour field obtained with an improved PatchMatch algorithm, which employs binarized octal orientation maps (BOOM) descriptors to find correspondences among subsequent frames. Our method is able to create temporally consistent results for a variety of applications such as optical flow estimation, sparse data upsampling, visual saliency computation and disparity estimation. We benchmark our optical flow estimation on the MPI Sintel dataset, where we currently achieve a Pareto optimal quality-efficiency tradeoff with an average endpoint error of 7.68 at 0.59 s single-core execution time on a recent desktop machine. © 2017 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Schaffner, M. and Scheidegger, F. and Cavigelli, L. and Kaeslin, H. and Benini, L. and Smolic, A.",2018,IEEE Transactions on Image Processing,10.1109/TIP.2017.2757259,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Wang20171,QoS-aware resource allocation for stream processing engines using priority channels,"Nowadays, a lot of data is produced every second and it needs to be processed immediately. Processing such unbounded streams of data is often applied in a distributed environment in order to achieve high throughput. There is a challenge to predict the performance-related characteristics of such applications. Knowledge of these properties is essential for decisions about the amount of needed computational resources, how the computations should be spread in the distributed environment, etc. In this paper, we propose a model to represent such streaming applications with the respect to their performance related properties.We present a conversion of the model to Colored Petri Nets (CPNs) which is used for performance analysis of the original application. The behavior of the proposed model and its conversion to the CPNs is validated through experiments. Our prediction was able to achieve nearly 100% precise maximum delays of real stream processing applications. © Springer International Publishing Switzerland 2015.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Wang, Y. and Tari, Z. and RezaHoseinyfarahabady, M. and Zomaya, A.Y.",2017,"2017 IEEE 16th International Symposium on Network Computing and Applications, NCA 2017",10.1109/NCA.2017.8171365,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Suárez-Cetrulo201767,An online classification algorithm for large scale data streams: iGNGSVM,"Stream Processing has recently become one of the current commercial trends to face huge amounts of data. However, normally these techniques need specific infrastructures and high resources in terms of memory and computing nodes. This paper shows how mini-batch techniques and topology extraction methods can help making gigabytes of data to be manageable for just one server using computationally costly Machine Learning techniques as Support Vector Machines. The algorithm iGNGSVM is proposed to improve the performance of Support Vector Machines in datasets where the data is continuously arriving. It is benchmarked against a mini-batch version of LibSVM, achieving good accuracy rates and performing faster than this. (C) 2017 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Suárez-Cetrulo, A.L. and Cervantes, A.",2017,Neurocomputing,10.1016/j.neucom.2016.12.093,scopus-search1.bib;web-of-science-search1.bib
LeVan2017238,Optimizing the performance of concurrent RDF stream processing queries,"With the growing popularity of Internet of Things (IoT) and sensing technologies, a large number of data streams are being generated at a very rapid pace. To explore the potentials of the integration of IoT and semantic technologies, a few RDF Stream Processing (RSP) query engines are made available which are capable of processing, analyzing and reasoning over semantic data streams in real-time. This way, RSP mitigates data interoperability issues and promotes knowledge discovery and smart decision making for time-sensitive applications. However, a major hurdle in the wide adoption of RSP systems is their query performance. Particularly, the ability of RSP engines to handle a large number of concurrent queries is very limited which refrains large scale stream processing applications (e.g. smart city applications) to adopt RSP. In this paper, we propose a shared-join based approach to improve the performance of an RSP engine for concurrent queries. We also leverage query federation mechanisms to allow distributed query processing over multiple RSP engine instances in order to gain performance for concurrent and distributed queries. We apply load balancing strategies to distribute queries and further optimize the concurrent query performance. We provide a proof of concept implementation by extending CQELS RSP engine and evaluate our approach using existing benchmark datasets for RSP. We also compare the performance of our proposed approach with the state of the art implementation of CQELS RSP engine. © Springer International Publishing AG 2017.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"LeVan, C. and Gao, F. and Ali, M.I.",2017,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-58068-5_15,scopus-search1.bib;web-of-science-search1.bib
Nalepa201693,Performance analysis of distributed stream processing applications through Colored Petri Nets,"Nowadays, a lot of data are produced every second and they need to be processed immediately. Processing such unbounded streams of data is often run in a distributed environment in order to achieve high throughput. The challenge is the ability to predict the performance- related characteristics of such applications. Knowledge of these properties is essential for decisions about the amount of needed computational resources, how the computations should be spread in the distributed environment, etc. In this paper, we present performance analysis of distributed stream processing applications using Colored Petri Nets (CPNs). We extend our previously proposed model with processing strategies which are used to specify performance effects when multiple tasks are placed on the same resource. We also show a detailed conversion of the whole proposed model to the CPNs. The conversion is validated through simulations of the CPNs which are compared to real streaming applications. © Springer International Publishing Switzerland 2016.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Nalepa, F. and Batko, M. and Zezula, P.",2016,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-29817-7_9,scopus-search1.bib;web-of-science-search1.bib
Nalepa2015520,Model for performance analysis of distributed stream processing applications,"Nowadays, a lot of data is produced every second and it needs to be processed immediately. Processing such unbounded streams of data is often applied in a distributed environment in order to achieve high throughput. There is a challenge to predict the performance-related characteristics of such applications. Knowledge of these properties is essential for decisions about the amount of needed computational resources, how the computations should be spread in the distributed environment, etc. In this paper, we propose a model to represent such streaming applications with the respect to their performance related properties. We present a conversion of the model to Colored Petri Nets (CPNs) which is used for performance analysis of the original application. The behavior of the proposed model and its conversion to the CPNs is validated through experiments. Our prediction was able to achieve nearly 100 % precise maximum delays of real stream processing applications.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Nalepa, F. and Batko, M. and Zezula, P.",2015,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-22852-5_42,scopus-search1.bib
Simoncelli2013253,Scaling out the performance of service monitoring applications with BlockMon,"To cope with real-time data analysis as the amount of data being exchanged over the network increases, an idea is to re-design algorithms originally implemented on the monitoring probe to work in a distributed manner over a stream-processing platform. In this paper we show preliminary performance analysis of a Twitter trending algorithm when running over BlockMon, an open-source monitoring platform which we extended to run distributed data-analytics algorithms: we show that it performs up to 23.5x and 34.2x faster on BlockMon than on Storm and Apache S4 respectively, two emerging stream-processing platforms. © 2013 Springer-Verlag Berlin Heidelberg.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Simoncelli, D. and Dusi, M. and Gringoli, F. and Niccolini, S.",2013,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-642-36516-4_26,scopus-search1.bib
Keong2011735,Efficient hybrid push-pull based P2P media streaming system,"Peer-to-Peer (P2P) communication is a popular protocol that has significant impacted and also changed the way for files being distributed over the large networks. Variants of P2P protocols are also applied for other media distribution such as audio and video streaming. The P2P protocol is widely adapted by researchers as a method to handle larger group of users. Coolstreaming, the first large scale P2P streaming experiment till today, applied a mesh-based streaming system which has slowly evolved from a pure pull system to a hybrid push-pull system. In this paper, we present our proposed push-pull scheduling for P2P streaming that can heuristically select the most optimal frame to be pushed based on the rules that we designed. Our proposed solution incorporates the fast content distribution characteristic of both Push and Pull approaches. For performance evaluation, we compare our scheduling algorithm with the pure pull Coolstreaming scheduling and Random push-pull scheduling where both scheduling serve as a benchmark in three main criteria - end-to-end delay, frame miss-ratio and frame redundancy. Simulation results showed that our proposed heuristic push-pull overall outperformed the other scheduling schemes, where our proposed scheduling algorithm demonstrates as a better solution towards reducing mesh delay in P2P streaming. © 2011 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Keong, C.Y. and Hoong, P.K. and Ting, C.-Y.",2011,Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS,10.1109/ICPADS.2011.55,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib;scholar.bib
Zotos2011,Performance evaluation of H264/SVC streaming system featuring real-time in-network adaptation,"In the recent years one of the most active research topics in multimedia networking is the exploitation of the Scalable Video Coding (SVC) as a scalable solution for efficient network resources utilization. SVC introduces scalability by exploiting a layered encoding of the video stream, thus enabling real-time in-network adaptation by selectively allowing the transmission of appropriate layers. This paper presents an architecture that exploits SVC capabilities in order to provide end-to-end QoS assurance via in-network video adaptation. The adaptation system management is based on MPEG-21 framework while the network QoS mechanisms are based on DiffServ standard. The performance evaluation of the proposed architecture is performed over a real test-bed infrastructure. © 2011 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zotos, N. and Xilouris, G. and Kourtis, A. and Renzi, D. and Shao, B.",2011,"IEEE International Workshop on Quality of Service, IWQoS",10.1109/IWQOS.2011.5931331,scopus-search1.bib;ieee3-search1.bib
Ferreira2010306,4Sensing- Decentralized processing for participatory sensing data,"Participatory Sensing is an emerging application paradigm that leverages the growing ubiquity of sensor-capable smart phones to allow communities carry out wide-area sensing tasks, as a side-effect of people's everyday lives and movements. This paper proposes a decentralized infrastructure for supporting Participatory Sensing applications. It describes an architecture and a domain specific programming language for modeling, prototyping and developing the distributed processing of participatory sensing data with the goal of allowing faster and easier development of these applications. Moreover, a case-study application is also presented as the basis for an experimental evaluation. © 2010 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ferreira, H. and Duarte, S. and Preguiça, N.",2010,Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS,10.1109/ICPADS.2010.20,scopus-search1.bib;ieee2-search1.bib
Zhang2008199,Distributed and incremental clustering based on weighted affinity propagation,"A new clustering algorithm Affinity Propagation (AP) is hindered by its quadratic complexity. The Weighted Affinity Propagation (WAP) proposed in this paper is used to eliminate this limitation, support two scalable algorithms. Distributed AP clustering handles large datasets by merging the exemplars learned from subsets. Incremental AP extends AP to online clustering of data streams. The paper validates all proposed algorithms on benchmark and on real-world datasets. Experimental results show that the proposed approaches offer a good trade-off between computational effort and performance. © 2008 The authors and IOS Press. All rights reserved.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Zhang, X. and Furtlehner, C. and Sebag, M.",2008,Frontiers in Artificial Intelligence and Applications,10.3233/978-1-58603-893-9-199,scopus-search1.bib;web-of-science-search1.bib
Shen2008106,Lineage-based probabilistic event stream processing,"Many sensor network applications such as monitoring video camera streams or management of RFID data streams or tiny sensor data streams from Motes or SunSPOTs require the ability to detect composite events over high-volume data streams. Sensor data inputs from physical world are usually noisy, incomplete and unreliable because sensing devices are usually unreliable. Thus they are usually expressed with probability in ubiquitous sensor network environment. To manage this kind of data, the probabilistic event stream processing system is a natural consequence. In this paper, we propose a query language to support probabilistic queries for composite event stream matching. The language allows users to express Kleene closure patterns for complex event detection in physical world. We also propose a working framework for query processing over probabilistic event streams. Our method first detects sequence patterns over probabilistic data streams by using a new data structure, AIG which handles a record sets of active states with a NFA-based approach. After detecting active states, our method then computes the probability of each detected sequence pattern on its lineage. That is, query processing and confidence computation are decoupled. By the benefit of lineage, the probability of an output event can be directly calculated without considering the query plan. We conduct a performance evaluation of our method comparing with naive one which is called possible worlds approach. The result clearly shows the effectiveness of our approach. While our approach shows scalable throughput, naive approach degrades its performance rapidly. The experiments are conducted with the window size, the number of event types and the number of alternatives.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Shen, Z. and Kawashima, H. and Kitagawa, H.",2008,"2008 9th International Conference on Mobile Data Management Workshops, MDMW 2008",10.1109/MDMW.2008.12,scopus-search1.bib
Zeitler2006,Processing High-Volume stream queries on a supercomputer,"Scientific instruments, such as radio telescopes, colliders, sensor networks, and simulators generate very high volumes of data streams that scientists analyze to detect and understand physical phenomena. The high data volume and the need for advanced computations on the streams require substantial hardware resources and scalable stream processing. We address these challenges by developing data stream management technology to support high-volume stream queries utilizing massively parallel computer hardware. We have developed a data stream management system prototype for state-of-The-Art parallel hardware. The performance evaluation uses real measurement data from LOFAR, a radio telescope antenna array being developed in the Netherlands. © 2006 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zeitler, E. and Risch, T.",2006,ICDEW 2006 - Proceedings of the 22nd International Conference on Data Engineering Workshops,10.1109/ICDEW.2006.118,scopus-search1.bib;ieee1-search1.bib
Tang200691,Distributed resource allocation for stream data processing,"Data streaming applications are becoming more and more common due to the rapid development in the areas such as sensor networks, multimedia streaming, and on-line data mining, etc. These applications are often running in a decentralized, distributed environment. The requirements for processing large volumes of streaming data at real time have posed many great design challenges. It is critical to optimize the ongoing resource consumption of multiple, distributed, cooperating, processing units. In this paper, we consider a generic model for the general stream data processing systems. We address the resource allocation problem for a collection of processing units so as to maximize the weighted sum of the throughput of different streams. Each processing unit may require multiple input data streams simultaneously and produce one or many valuable output streams. Data streams flow through such a system after processing at multiple processing units. Based on this framework, we develop distributed algorithms for finding the best resource allocation schemes in such data stream processing networks. Performance analysis on the optimality and complexity of these algorithms are also provided. © Springer-Verlag Berlin Heidelberg 2006.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Tang, A. and Liu, Z. and Xia, C. and Zhang, L.",2006,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/11847366_10,scopus-search1.bib;web-of-science-search1.bib
Nandi2022340,A federated learning method for real-time emotion state classification from multi-modal streaming,"Emotional and physical health are strongly connected and should be taken care of simultaneously to ensure completely healthy persons. A person's emotional health can be determined by detecting emotional states from various physiological measurements (EDA, RB, EEG, etc.). Affective Computing has become the field of interest, which uses software and hardware to detect emotional states. In the IoT era, wearable sensor-based real-time multi-modal emotion state classification has become one of the hottest topics. In such setting, a data stream is generated from wearable-sensor devices, data accessibility is restricted to those devices only and usually a high data generation rate should be processed to achieve real-time emotion state responses. Additionally, protecting the users’ data privacy makes the processing of such data even more challenging. Traditional classifiers have limitations to achieve high accuracy of emotional state detection under demanding requirements of decentralized data and protecting users’ privacy of sensitive information as such classifiers need to see all data. Here comes the federated learning, whose main idea is to create a global classifier without accessing the users’ local data. Therefore, we have developed a federated learning framework for real-time emotion state classification using multi-modal physiological data streams from wearable sensors, called Fed-ReMECS. The main findings of our Fed-ReMECS framework are the development of an efficient and scalable real-time emotion classification system from distributed multimodal physiological data streams, where the global classifier is built without accessing (privacy protection) the users’ data in an IoT environment. The experimental study is conducted using the popularly used multi-modal benchmark DEAP dataset for emotion classification. The results show the effectiveness of our developed approach in terms of accuracy, efficiency, scalability and users’ data privacy protection. © 2022 Elsevier Inc.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Nandi, A. and Xhafa, F.",2022,Methods,10.1016/j.ymeth.2022.03.005,scopus-search1.bib;web-of-science-search1.bib
Eskandari2021219,I-Scheduler: Iterative scheduling for distributed stream processing systems,"Task allocation in Data Stream Processing Systems (DSPSs) has a significant impact on performance metrics such as data processing latency and system throughput. An application processed by DSPSs can be represented as a Directed Acyclic Graph (DAG), where each vertex represents a task and the edges show the dataflow between the tasks. Task allocation can be defined as the assignment of the vertices in the DAG to the physical compute nodes such that the data movement between the nodes is minimised. Finding an optimal task placement for DSPSs is NP-hard. Thus, approximate scheduling approaches are required to improve the performance of DSPSs. In this paper, we propose a heuristic scheduling algorithm which reliably and efficiently finds highly communicating tasks by exploiting graph partitioning algorithms and a mathematical optimisation software package. We evaluate the communication cost of our method using three micro-benchmarks, showing that we can achieve results that are close to optimal. We further compare our scheduler with two popular existing schedulers, R-Storm and Aniello et al.'s `Online scheduler' using two real-world applications. Our experimental results show that our proposed scheduler outperforms R-Storm, increasing throughput by up to 30%, and improves on the Online scheduler by 20%-86% as a result of finding a more efficient schedule.(1) (C) 2020 Published by Elsevier B.V.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Eskandari, L. and Mair, J. and Huang, Z. and Eyers, D.",2021,Future Generation Computer Systems,10.1016/j.future.2020.11.011,scopus-search1.bib;web-of-science-search1.bib
VanDongen202193745,A Performance Analysis of Fault Recovery in Stream Processing Frameworks,"Distributed stream processing frameworks have gained widespread adoption in the last decade because they abstract away the complexity of parallel processing. One of their key features is built-in fault tolerance. In this work, we dive deeper into the implementation, performance, and efficiency of this critical feature for four state-of-the-art frameworks. We include the established Spark Streaming and Flink frameworks and the more novel Spark Structured Streaming and Kafka Streams frameworks. We test the behavior under different types of faults and settings: master failure with and without high-availability setups, driver failures for Spark frameworks, worker failure with or without exactly-once semantics, application and task failures. We highlight differences in behavior during these failures on several aspects, e.g., whether there is an outage, downtime, recovery time, data loss, duplicate processing, accuracy, and the cost and behavior of different message delivery guarantees. Our results highlight the impact of framework design on the speed of fault recovery and explain how different use cases may benefit from different approaches. Due to their task-based scheduling approach, the Spark frameworks can recover within 30 seconds and in most cases without necessitating an application restart. Kafka Streams has only a few seconds of downtime, but is slower at catching up on delays. Finally, Flink can offer end-to-end exactly-once semantics at a low cost but requires job restarts for most failures leading to high recovery times of around 50 seconds. © 2013 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"VanDongen, G. and Poel, D.V.D.",2021,IEEE Access,10.1109/ACCESS.2021.3093208,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib;scholar.bib
Carpio2020,Engineering and Experimentally Benchmarking a Container-based Edge Computing System,"While edge computing is envisioned to superbly serve latency sensitive applications, the implementation-based studies benchmarking its performance are few and far between. To address this gap, we engineer a modular edge cloud computing system architecture that is built on latest advances in containerization techniques, including Kafka, for data streaming, Docker, as application platform, and Firebase Cloud, as realtime database system. We benchmark the performance of the system in terms of scalability, resource utilization and latency by comparing three scenarios: cloud-only, edge-only and combined edge-cloud. The measurements show that edge-only solution outperforms other scenarios only when deployed with data located at one edge only, i.e., without edge computing wide data synchronization. In case of applications requiring data synchronization through the cloud, edge-cloud scales around a factor 10 times better than cloudonly, until certain number of concurrent users in the system, and above this point, cloud-only scales better. In terms of resource utilization, we observe that whereas the mean utilization increases linearly with the number of user requests, the maximum values for the memory and the network I/O heavily increase when with an increasing amount of data. © 2020 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Carpio, F. and Delgado, M. and Jukan, A.",2020,IEEE International Conference on Communications,10.1109/ICC40277.2020.9148636,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Onishi202066,Recovery-conscious adaptive watermark generation for time-order event stream processing,"Achieving low latency in time-order real-time event stream processing of data produced by a large number of IoT devices is difficult due to the buffering time required for sorting event messages arrived. Despite the existence of real-time IoT applications that highly depend on the order of event occurrences, event messages arriving from the devices to the event processing system are not time-ordered in many cases. Therefore, such an event processing system needs to buffer arriving event messages, sort, and then process them. This buffering time tends to be decided as a safe large period to guarantee correctness in terms of time-ordering, and leads to an increase of latency. Furthermore, failure recovery mechanism of a stateful stream processing deployed into distributed processing nodes makes this problem more difficult. It frequently causes large time-order reversal among event messages in the distributed stream processing system, that cannot be handled with a buffering time designed for real-time processing during normal periods. In this paper, we introduce a novel technique to adaptively determine the minimum necessary amount of buffering time to guarantee time-order sorting depending on the event-time progress in arrival event messages. To be more precise, instead of specifying the actual buffering time, the method adaptively controls the minimum time margin to determine the current 'watermark' that shows the event time upon which a processing unit in a distributed stream processing system believes to have received all the messages. Further, we developed a complete function (called 'time alignment') to sort the time-order of messages while keeping low latency in our developed distributed event stream processing platform. Through the experimental evaluations, it is shown that the developed method has the capability to determine a proper watermark to achieve both a strong guarantee on time-order correctness and low latency in real-time event stream processing. © 2020 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Onishi, T. and Michaelis, J. and Kanemasa, Y.",2020,"Proceedings - 5th ACM/IEEE Conference on Internet of Things Design and Implementation, IoTDI 2020",10.1109/IoTDI49375.2020.00014,scopus-search1.bib
Katsipoulakis20201105,SPEAr: Expediting stream processing with accuracy guarantees,"Stream Processing Engines (SPEs) are used for realtime and continuous processing with stateful operations. This type of processing poses numerous challenges due to its associated complexity, unpredictable input, and need for timely results. As a result, users tend to overprovision resources, and online scaling is required in order to overcome overloaded situations. Current attempts for expediting stateful processing are impractical, due to their inability to uphold the quality of results, maintain performance, and reduce memory requirements.In this paper, we present the SPEAr system, which can expedite processing of stateful operations automatically by trading accuracy for performance. SPEAr detects when it can accelerate processing by employing online sampling and accuracy estimation at no additional cost. We built SPEAr on top of Storm and our experiments indicate that it can reduce processing times by more than an order of magnitude, use more than an order of magnitude less memory, and offer accuracy guarantees in real-world benchmarks. © 2020 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Katsipoulakis, N.R. and Labrinidis, A. and Chrysanthis, P.K.",2020,Proceedings - International Conference on Data Engineering,10.1109/ICDE48307.2020.00100,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Prasad2020,Ensemble framework for concept-drift detection in multidimensional streaming data,"The potential objective of data mining (DM) over the data streaming is the detection of concept-drift. Concept-Drift signifies a diversity among the data tuples streamed in the sequence. The concept-drift often appears as incremental or abrupt. The incremental drift denotes the gradual increment of the drift between the tuples of streaming data. The other format of the drift is abrupt, which signifies the drift between tuples of data streaming in sequence. The proposed method is an Ensemble Framework for Concept-Drift Detection in Multidimensional Streaming Data (EFCDD). In addition, the proposed method EFCDD deals with the recurrent drift of the concept in streaming data. To state the drift, the projection diversity of the values representing the field positions or field-IDs, which are in use for framing the structure of the records streaming form the intended sources. The experimental study was carried out by mocking the streams of those transmitting records of the benchmark datasets often used in DM. The outcomes of the experimental study evince the scalability and prominence of EFCDD toward the detection of drift in concept. The proposal performance is measured by comparing simulation outcomes with the other existing model. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Prasad, K.S.N. and Rao, A.S. and Ramana, A.V.",2020,International Journal of Computers and Applications,10.1080/1206212X.2020.1711617,scopus-search1.bib
Fang20192471,Integrating workload balancing and fault tolerance in distributed stream processing system,"Distributed Stream Processing Engine (DSPE) is designed for processing continuous streams so as to achieve the real-time performance with low latency guaranteed. To satisfy such requirement, the availability and efficiency are the main concern of the DSPE system, which can be achieved by a proper design of the fault tolerance module and the workload balancing module, respectively. However, the inherent characteristics of data streams, including persistence, dynamic and unpredictability, pose great challenges in satisfying both properties. As far as we know, most of the state-of-the-art DSPE systems take either fault tolerance or workload balancing as its single optimization goal, which in turn receives a higher resource overhead or longer recovery time. In this paper, we combine the fault tolerance and workload balancing mechanisms in the DSPE to reduce the overall resource consumption while keeping the system interactive, high-throughput, scalable and highly available. Based on our data-level replication strategy, our method can handle the dynamic data skewness and node failure scenario: during the distribution fluctuation of the incoming stream, we rebalance the workload by selectively inactivate the data in high-load nodes and activate their replicas on low-load nodes to minimize the migration overhead within the stateful operator; when a fault occurs in the process, the system activates the replicas of the data affected to ensure the correctness while keeping the workload balanced. Extensive experiments on various join workloads on both benchmark data and real data show our superior performance compared with baseline systems. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Fang, J. and Chao, P. and Zhang, R. and Zhou, X.",2019,World Wide Web,10.1007/s11280-018-0656-0,scopus-search1.bib;web-of-science-search1.bib
Kang201961,Deep learning for volumetric segmentation in spatio-temporal data: Application to segmentation of prostate in DCE-MRI,"Segmentation of the prostate in MR images is an essential step that underpins the success of subsequent analysis methods, such as cancer lesion detection inside the tumour and registration between different modalities. This work focuses on leveraging deep learning for analysis of longitudinal volumetric datasets, particularly for the task of segmentation, and presents proof-of-concept for segmentation of the prostate in 3D+T DCE-MRI sequences. A two-stream processing pipeline is proposed for this task, comprising a spatial stream modelled using a volumetric fully convolutional network and a temporal stream modeled using recurrent neural networks with Long-Short-term Memory (LSTM) units. The predictions of the two streams are fused using deep neural networks. The proposed method has been validated on a public benchmark dataset of 17 patients, each with 40 temporal volumes. When averaged over three experiments, a highly competitive Dice overlap score of 0.8688 and sensitivity of 0.8694 were achieved. As a spatiotemporal segmentation method, it can easily migrate to other datasets. © 2019 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kang, J. and Samarasinghe, G. and Senanayake, U. and Conjeti, S. and Sowmya, A.",2019,Proceedings - International Symposium on Biomedical Imaging,10.1109/ISBI.2019.8759314,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Wang2019773,An on-the-fly scheduling strategy for distributed stream processing platform,"Distributed stream processing can accomplish real-time processing of continuous streaming big data to obtain valuable information with high velocity. To maintain continuously stable and efficient running of stream applications, however, continuous online scheduling operations are required in the context of highly dynamic data stream. For this reason, this paper proposes the on-the-fly scheduling strategy in a distributed stream processing environment, which dynamically predicts abnormal events through double exponential smoothing and adopts traffic-aware active migration protocol to adjust the network routing structure on-the-fly to balance the inter-worker load. Moreover, an evaluation method is proposed to quantitatively analyze the various scheduling objectives. Finally, we commendably apply the scheduling strategy to a stream processing platform, which regards docker instance as basic scheduling units. Meanwhile, based on the platform and the evaluation method, we complete performance comparison experiments of the scheduling algorithm. The experimental results indicate that our algorithm has excellent performance in throughput of topology, average processing time and balance of task load, which is suitable for deployment in a distributed environment with large-scale nodes and tasks. © 2018 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Wang, W. and Zhang, C. and Chen, X. and Li, Z. and Ding, H. and Wen, X.",2018,"Proceedings - 16th IEEE International Symposium on Parallel and Distributed Processing with Applications, 17th IEEE International Conference on Ubiquitous Computing and Communications, 8th IEEE International Conference on Big Data and Cloud Computing, 11th IEEE International Conference on Social Computing and Networking and 8th IEEE International Conference on Sustainable Computing and Communications, ISPA/IUCC/BDCloud/SocialCom/SustainCom 2018",10.1109/BDCloud.2018.00116,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Sahin2017,C-Stream: A co-routine-based elastic stream processing engine,"Stream processing is a computational paradigm for on-the-fly processing of live data. This paradigm lends itself to implementations that can provide high throughput and low latency by taking advantage of various forms of parallelism that are naturally captured by the stream processing model of computation, such as pipeline, task, and data parallelism. In this article, we describe the design and implementation of C-Stream, which is an elastic stream processing engine. C-Stream encompasses three unique properties. First, in contrast to the widely adopted event-based interface for developing streaming operators, C-Stream provides an interface wherein each operator has its own driver loop and relies on data availability application programming interfaces (APIs) to decide when to perform its computations. This self-control-based model significantly simplifies the development of operators that require multiport synchronization. Second, C-Stream contains a dynamic scheduler that manages the multithreaded execution of the operators. The scheduler, which is customizable via plug-ins, enables the execution of the operators as co-routines, using any number of threads. The base scheduler implements back-pressure, provides data availability APIs, and manages preemption and termination handling. Last, C-Stream varies the degree of parallelism to resolve bottlenecks by both dynamically changing the number of threads used to execute an application and adjusting the number of replicas of data-parallel operators.We provide an experimental evaluation of C-Stream. The results show that C-Stream is scalable, highly customizable, and can resolve bottlenecks by dynamically adjusting the level of data parallelism used. © 2017 ACM.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Sahin, S. and Gedik, B.",2017,ACM Transactions on Parallel Computing,10.1145/3184120,scopus-search1.bib;acm1-search1.bib
Ma2017351,Stream-based live entity resolution approach with adaptive duplicate count strategy,"Recently, researchers have been more concerned about large-scale news and tweet data generated by the social media. Some cloud service providers utilise the data to find public sentiments for the tenants. The challenge is how to clean the big data in the cloud before making further analysis. To address this issue, we propose a new live entity resolution approach at a time to find duplicates from the news and tweet data. We investigate possible solutions to address live entity resolution in the cloud, to make sliding window size adaptive using multistep distance and window size dependent duplicate count strategy with alterable window step, and find duplicates by overlapping boundary objects in adjacent blocks. Finally, our experimental evaluation based on the news data on large datasets shows the high effectiveness and efficiency of the proposed approaches. Copyright © 2017 Inderscience Enterprises Ltd.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Ma, K. and Yang, B.",2017,International Journal of Web and Grid Services,10.1504/IJWGS.2017.085167,scopus-search1.bib;web-of-science-search1.bib
Su2015949,Achieving self-aware parallelism in stream programs,"The age of big data open the door to a new approach in data exploration and utilization. With the increasing complexities and dynamics of modern IT systems and services, it has become a challenge to effectively exploit parallelism on multicore platforms in computing systems that are heterogeneous, dynamic and decentralised. Self-aware software is a response to these demands in dealing with distributed applications in changing environments. It is a closed-loop system with a series of optimization strategies to adjust itself dynamicly during data processing. We focus on incorporating adaptation mechanisms into the stream programs for exposing distributed parallelism. In the traditional stream programming models, changing data and status normally require human supervision to adjust the stream graph for performance. As one-time optimization strategy, the reconfiguration and maintenance lead to costly and time-consuming procedures during the operating phase. To address these problems, we propose a self-aware stream programming model called StreamAware. A key property of this model is that exposing self-aware parallelism in the message driven execution paradigm, which provides dynamic and reconfigurable stream graph in adapting to the data flow changes. The model defines the self-awareness loop based on finite state machine for stream applications to adjust their own stream graph with continuous optimization strategy. This paper presents three different self-aware systems built using StreamAware. The empirical evaluation demonstrate how these systems can exploit self-aware parallelism using the Parsec benchmark problems, optimize performance per Watt, and respond to significant changes in stream processing. © 2014, Springer Science+Business Media New York.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Su, Y. and Shi, F. and Talpur, S. and Wang, Y. and Hu, S. and Wei, J.",2015,Cluster Computing,10.1007/s10586-014-0412-x,scopus-search1.bib;web-of-science-search1.bib
Rooholamin2015237,Modular vector processor architecture targeting at data-level parallelism,"Taking advantage of DLP (Data-Level Parallelism) is indispensable in most data streaming and multimedia applications. Several architectures have been proposed to improve both the performance and energy consumption for such applications. Superscalar and VLIW (Very Long Instruction Word) processors along with SIMD (Single-Instruction Multiple-Data) and vector processor (VP) accelerators, are among the available options for designers to accomplish their desired requirements. We present an innovative architecture for a VP which separates the path for performing data shuffle and memory-indexed accesses from the data path for executing other vector instructions that access the memory. This separation speeds up the most common memory access operations by avoiding extra delays and unnecessary stalls. In our lane-based VP design, each vector lane uses its own private memory to avoid any stalls during memory access instructions. The proposed VP, which is developed in VHDL and prototyped on an FPGA, serves as a coprocessor for one or more scalar cores. Benchmarking shows that our VP can achieve very high performance. For example, it achieves a larger than 1500-fold speedup in the color space converting benchmark compared to running the code on a scalar core. The inclusion of distributed data shuffle engines across vector lanes has a spectacular impact on the execution time, primarily for applications like FFT (Fast-Fourier Transform) that require large amounts of data shuffling. Compared to running the benchmark on a VP without the shuffle engines, the speedup is 5.92 and 7.33 for the 64-point FFT without and with compiler optimization, respectively. Compared to runs on the scalar core, the achieved speed-ups for this benchmark are 52.07 and 110.45 without and with compiler optimization, respectively. (C) 2015 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Rooholamin, S.A. and Ziavras, S.G.",2015,Microprocessors and Microsystems,10.1016/j.micpro.2015.04.007,scopus-search1.bib;web-of-science-search1.bib
Seyfabad2014908,CAC-live: Centralized assisted cloud P2P live streaming,"Peer-to-Peer (P2P) live video streaming over the Internet is a developing technology that recently has gained more attention. The use of P2P network with leveraging of local resources of peers, increases scalability and reduces costs. One of the limitations of P2P live video streaming systems is the lack of adequate resources such as available upload bandwidth, both at video source and inside P2P overlay network that lead to reduce the quality of service (QoS) experienced by the users. One solution for this problem is to employ additional on-demand resources such as virtual machines (VM) that are rented from a cloud provider to increase the amount of total available bandwidth. In this paper, we propose an architecture for improving the QoS of the peers by using virtual machines (VMs) dynamically are rented from cloud providers. Estimation of required VMs is performed through a central-based method and the number of VMs is calculated periodically. Our simulation based performance evaluation shows the efficiency of the proposed method. © 2015 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Seyfabad, M.S. and Akbari, B.",2014,"22nd Iranian Conference on Electrical Engineering, ICEE 2014",10.1109/IranianCEE.2014.6999665,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Gijsbers2014988,An efficient scalable runtime system for macro data flow processing using S-net,"S-Net is a declarative coordination language and component technology aimed at radically facilitating software engineering for modern parallel compute systems by near-complete separation of concerns between application (component) engineering and concurrency orchestration. S-Net builds on the concept of stream processing to structure networks of communicating asynchronous components implemented in a conventional (sequential) language. In this paper we present the design, implementation and evaluation of a new and innovative runtime system for S-Net streaming networks. The Front runtime system outperforms the existing implementations of S-Net by orders of magnitude for stress-test benchmarks, significantly reduces runtimes of fully-fledged parallel applications with compute-intensive components and achieves good scalability on our 48-core test system. © 2013 Springer Science+Business Media New York.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Gijsbers, B. and Grelck, C.",2014,International Journal of Parallel Programming,10.1007/s10766-013-0271-8,scopus-search1.bib;web-of-science-search1.bib
Viel2014199,Data stream partitioning re-optimization based on runtime dependency mining,"In distributed data stream processing, a program made of multiple queries can be parallelized by partitioning input streams according to the values of specific attributes, or partitioning keys. Applying different partitioning keys to different queries requires re-partitioning intermediary streams, causing extra communication and reduced throughput. Re-partitionings can be avoided by detecting dependencies between the partitioning keys applicable to each query. Existing partitioning optimization methods analyze query syntax at compile-time to detect inter-key dependencies and avoid re-partitionings. This paper extends those compile-time methods by adding a runtime re-optimization step based on the mining of temporal approximate dependencies (TADs) between partitioning keys. A TAD is defined in this paper as a type of dependency that can be approximately valid over a moving time window. Our evaluation, based on a simulation of the Linear Road Benchmark, showed a 94.5% reduction of the extra communication cost. © 2014 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Viel, E. and Ueda, H.",2014,Proceedings - International Conference on Data Engineering,10.1109/ICDEW.2014.6818327,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Spanos2012178,SensorStream: A semantic real-time stream management system,"As data proliferates at increasing rates, the need for real-time stream processing applications increases as well. In the same way that Data Stream Management Systems (DSMS) have emerged from the database community, there is now a similar concern in managing dynamic knowledge among the Semantic Web community. Unfortunately, early relevant approaches are, to a large extent, theoretical and do not present convincing evidence of their efficiency in real dynamic environments. In this paper, we present a framework for the effective, real-time processing of streaming data and we define and analyse in depth its key components. Our framework serves as a basis for the implementation of the SensorStream prototype, on which we run numerous performance and scalability measurements that outline its behaviour and demonstrate its suitability and scalability for solutions that require real-time information processing from distributed and heterogeneous data sources. Copyright © 2012 Inderscience Enterprises Ltd.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Spanos, D.-E. and Stavrou, P. and Mitrou, N. and Konstantinou, N.",2012,International Journal of Ad Hoc and Ubiquitous Computing,10.1504/IJAHUC.2012.050252,scopus-search1.bib
Qi2012718,MapReduce-based data stream processing over large history data,"With the development of Internet of Things applications based on sensor data, how to process high speed data stream over large scale history data brings a new challenge. This paper proposes a new programming model RTMR, which improves the real-time capability of traditional batch processing based MapReduce by preprocessing and caching, along with pipelining and localizing. Furthermore, to adapt the topologies to application characteristics and cluster environments, a model analysis based RTMR cluster constructing method is proposed. The benchmark built on the urban vehicle monitoring system shows RTMR can provide the real-time capability and scalability for data stream processing over large scale data. © Springer-Verlag Berlin Heidelberg 2012.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Qi, K. and Zhao, Z. and Fang, J. and Han, Y.",2012,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-642-34321-6_57,scopus-search1.bib
Ajwani2011409,A flexible workload generator for simulating stream computing systems,"Stream computing is an emerging computational model for performing complex operations on and across multi-source, high volume data ?ows. Given that the deployment of the model has only started, the pool of mature applications employing this model is fairly small, and therefore the availability of workloads for various types of applications is scarce. Thus, there is a need for synthetic generation of large-scale workloads for evaluation of stream computing applications at scale. This paper presents a framework for producing synthetic workloads for stream computing systems. Our framework extends known random graph generation concepts with stream computing spe-cific features, providing researchers with realistic input stream graphs and allowing them to focus on system development, optimization and analysis. Serving the goal of covering a disparity of potential applications, the presented framework exhibits high user-controlled configurability. The produced workloads could be used to drive simulations for performance evaluation and for proof-of-concept prototyping of processing, networking and operating system hardware and software. © 2011 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Ajwani, D. and Ali, S. and Katrinis, K. and Li, C.-H. and Park, A.J. and Morrison, J.P. and Schenfeld, E.",2011,"IEEE International Workshop on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems - Proceedings",10.1109/MASCOTS.2011.54,scopus-search1.bib;ieee3-search1.bib
Leidi201136,Event-driven scheduling for parallel stream processing,"To optimize real-time stream-processing applications for chip-level multi processors, several challenges have to be met. Poor scalability and poor internal data pressure may result from serial dependencies within or between the algorithms. Load imbalances introduced by the parallel-processing hardware and execution environment may also limit performance. To maximize the throughput and minimize the latency of parallel stream-processing applications, we propose an approach that complements run-time dynamic load balancing with static pre-compile partitioning. In our solution, the dynamic features are based on event-driven scheduling, while the static features benefit from profile-guided automatic optimizations. In this paper, we present some recent enhancements of DSPE, an open-source development environment, featuring model and source code generators for prototyping, refining and customizing real-time stream-processing applications. By using our approach on micro-benchmarks and sample applications, we also show that it is possible to reduce the impact of the different speed-up constrainers. © 2011 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Leidi, T. and Heeb, T. and Colla, M. and Thiran, J.-P.",2011,"Proceedings - 6th International Symposium on Parallel Computing in Electrical Engineering, PARELEC 2011",10.1109/PARELEC.2011.14,scopus-search1.bib;ieee2-search1.bib
Takeshi2011958,QoS analysis of real-time distributed systems based on hybrid analysis of probabilistic model checking technique and simulation,"For the Internet, system developers often have to estimate the QoS by simulation techniques or mathematical analysis. Probabilistic model checking can evaluate performance, dependability and stability of information processing systems with random behaviors. We apply a hybrid analysis approach onto real-time distributed systems. In the hybrid analysis approach, we perform stepwise analysis using probabilistic models of target systems in different abstract levels. First, we create a probabilistic model with detailed behavior of the system (called detailed model), and apply simulation on the detailed model. Next, based on the simulation results, we create a probabilistic model in an abstract level (called simplified model). Then, we verify qualitative properties using the probabilistic model checking techniques. This prevents from state-explosion. We evaluate the validity of our approach by comparing to simulation results of NS-2 using a case study of a video data streaming system. The experiments show that the result of the proposed approach is very close to that of NS-2 simulation. The result encourages the approach is useful for the performance analysis on various domain. © 2011 The Institute of Electronics.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Takeshi, N. and Akihiko, I. and Kozo, O. and Shinji, K.",2011,IEICE Transactions on Information and Systems,10.1587/transinf.E94.D.958,scopus-search1.bib;web-of-science-search1.bib
Cazalas2010112,GEDS: GPU execution of continuous queries on spatio-temporal data streams,"Much research exists for the efficient processing of spatio-temporal data streams. However, all methods ultimately rely on an ill-equipped processor [22], namely a CPU, to evaluate concurrent, continuous spatio-temporal queries over these data streams. This paper presents GEDS, a scalable, Graphics Processing Unit (GPU)-based framework for the evaluation of continuous spatio-temporal queries over spatio-temporal data streams. GEDS employs the computation sharing and parallel processing paradigms to deliver scalability in the evaluation of continuous spatio-temporal queries. The GEDS framework utilizes the parallel processing capability of the GPU, a stream processor by trade, to handle the computation required in this application. Experimental evaluation shows promising performance and shows the scalability and efficacy of GEDS in spatio-temporal data streaming environments. © 2010 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Cazalas, J. and Guha, R.",2010,"Proceedings - IEEE/IFIP International Conference on Embedded and Ubiquitous Computing, EUC 2010",10.1109/EUC.2010.26,scopus-search1.bib;ieee1-search1.bib
Kowalski2009243,Empirical analysis of multi-sender segment transmission algorithms in peer-to-peer streaming,"We study and analyze segment transmission scheduling algorithms in swarm-based peer-to-peer (P2P) streaming systems. These scheduling algorithms are responsible for coordinating the streaming of video data from multiple senders to a receiver in each streaming session. Although scheduling algorithms directly impact the user-perceived visual quality in streaming sessions, they have not been rigorously analyzed in the literature. In this paper, we first conduct an extensive experimental study to evaluate various scheduling algorithms on many PlanetLab nodes distributed all over the world. We study three important performance metrics: (i) continuity index which captures the smoothness of the video playback, (ii) load balancing index which indicates how the load is spread across sending peers, and (iii) buffering delay required to ensure continuous playback. Our experimental analysis reveals the strengths and weaknesses of each scheduling algorithm, and provides insights for developing better ones in order to improve the overall performance of P2P streaming systems. Then, we propose a new scheduling algorithm called On-time Delivery of VBR streams (ODV). Our experiments show that the proposed scheduling algorithm improves the playback quality by increasing the continuity index, requires smaller buffering delays, and achieves more balanced load distribution across peers. © 2009 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kowalski, G. and Hefeeda, M.",2009,ISM 2009 - 11th IEEE International Symposium on Multimedia,10.1109/ISM.2009.55,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Shen2009355,Efficient probabilistic event stream processing with lineage and Kleene-plus,"This paper proposes a working framework and a query language to support probabilistic queries for composite event detection over probabilistic event streams. The language allows users to express Kleene closure patterns for complex event detection in the physical world. Our processing method first detects sequence patterns over probabilistic data streams using AIG, a new data structure, which handles active states with a nondeterministic finite automaton (NFA). Our method then computes the probability of each detected sequence pattern based on its lineage. Through the benefit of lineage, the probability of an output event can be directly calculated without taking into account the query plan. An optimised plan can be selected. Finally, we conducted a performance evaluation of our method and compared the results with the original and optimised query plan. The experiment clearly showed that our proposal outperforms straight-forward query plans. Copyright © 2009 Inderscience Enterprises Ltd.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Shen, Z. and Kawashima, H. and Kitagawa, H.",2009,International Journal of Communication Networks and Distributed Systems,10.1504/IJCNDS.2009.026554,scopus-search1.bib
Hoong200851,PALMS: A reliable and incentive-based P2P live media streaming system,"In recent years, the peer-to-peer (P2P) approach for media streaming has been studied extensively. In comparison with on-demand media streaming, P2P live media streaming faces a very stringent time constraint. To improve the performance metrics, such as startup delay, source-to-end delay, and playback continuity, we present PALMS - a P2P approach for live media streaming where a node employs gossip-based pull and push protocols to receive and forward media data among connected nodes.We present a simple heuristic mechanism for the pull protocol in the selection of media segments and peers. Besides the pull method, a push method is deployed to increase the streaming quality. We know that the presence of free-riders could degrade the delivered streaming quality. In PALMS, a simple score-based incentive mechanism, similar to BitTorrent's tit-for-tat incentive mechanism, is adopted to discourage the existence of free-riders. We conducted simulations and performance comparisons for PALMS. Experimental results demonstrate that PALMS can deliver better streaming quality and more resilience towards the heterogeneity of network bandwidths as compared to some of the existing protocols. © Springer 2008.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Hoong, P.K. and Matsuo, H.",2008,Lecture Notes in Electrical Engineering,10.1007/978-0-387-74938-9_5,scopus-search1.bib
Sun20071733,Optimization of B-NIDS for multicore,"With the rapid increase of network bandwidth and the growing variety of Internet applications, the backbone network intrusion detection systems (B-NIDS) meet the great requirements of delivering higher performance and enhancing effectiveness according to different features of network streams. Computing is entering a new phase in which CPU improvements are driven by the addition of multiple cores on a single chip, rather than higher frequencies. Parallel processing on these systems is in a primitive stage, and the parallelization of a sequential B-NIDS requires the explicit use and knowledge of underlying thread architecture. In this paper the bottleneck of the thread synchronization using fine-grained lock operations is discovered, and the new synchronization mechanism with no contention for shared structures is proposed based on the characteristics of data flow. Then a pipelining programming model of multithreading system with three contexts is issued, and the differential service for streams is implemented with the multiple weighed queues. In performance evaluation, the optimized system shows much better performance in three aspects of resource utilization, throughput, and response time on 8 core server. The improved system with the proposed synchronization mechanism shows good scalability. The processing capability on tested server can exceed over 1 Gbps traffic flow. Also the multiple weighed queues for service quality introduce little latency, and a kind of probe-based sampling test shows that the response times of prioritized streams are shorter than those of non-prioritized.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Sun, X. and Sun, N. and Chen, M.",2007,Jisuanji Yanjiu yu Fazhan/Computer Research and Development,10.1360/crad20071015,scopus-search1.bib
DeHeus202131,Distributed transactions on serverless stateful functions,"Serverless computing is currently the fastest-growing cloud services segment. The most prominent serverless offering is Function-as-a-Service (FaaS), where users write functions and the cloud automates deployment, maintenance, and scalability. Although FaaS is a good fit for executing stateless functions, it does not adequately support stateful constructs like microservices and scalable, low-latency cloud applications, mainly because it lacks proper state management support and the ability to perform function-to-function calls. Most importantly, executing transactions across stateful functions remains an open problem. In this paper, we introduce a programming model and implementation for transaction orchestration of stateful serverless functions. Our programming model supports serializable distributed transactions with two-phase commit, as well as relaxed transactional guarantees with Sagas. We design and implement our programming model on Apache Flink StateFun. We choose to build our solution on top of StateFun in order to leverage Flink's exactly-once processing and state management guarantees. We base our evaluation on the YCSB benchmark, which we extended with transactional operations and adapted for the SFaaS programming model. Our experiments show that our transactional orchestration adds 10% overhead to the original system and that Sagas can achieve up to 34% more transactions per second than two-phase commit transactions at a sub-200ms latency. © 2021 Owner/Author.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"DeHeus, M. and Psarakis, K. and Fragkoulis, M. and Katsifodimos, A.",2021,DEBS 2021 - Proceedings of the 15th ACM International Conference on Distributed and Event-Based Systems,10.1145/3465480.3466920,scopus-search1.bib
Gencer20213110,Hazelcast jet: Low-latency stream processing at the 99.99th percentile,"Jet is an open-source, high-performance, distributed stream processor built at Hazelcast during the last five years. Jet was engineered with millisecond latency on the 99.99th percentile as its primary design goal. Originally Jet’s purpose was to be an execution engine that performs complex business logic on top of streams generated by Hazelcast’s In-memory Data Grid (IMDG): a set of in-memory, partitioned and replicated data structures. With time, Jet evolved into a full-fledged, scale-out stream processor that can handle out-of-order streams and provide exactly-once processing guarantees. Jet’s end-to-end latency lies in the order of milliseconds, and its throughput in the order of millions of events per CPU-core. This paper presents the main design decisions we made in order to maximize the performance per CPU-core, alongside lessons learned, and an empirical performance evaluation. © The authors.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Gencer, C. and Topolnik, M. and Ďurina, V. and Demirci, E. and Kahveci, E.B. and Gürbüz, A. and Lukáš, O. and Bartók, J. and Gierlach, G. and Hartman, F. and Yılmaz, U. and Doğan, M. and Mandouh, M. and Fragkoulis, M. and Katsifodimos, A.",2021,Proceedings of the VLDB Endowment,10.14778/3476311.3476387,scopus-search1.bib;web-of-science-search1.bib;scholar.bib
Fu2020,ImRP: A Predictive Partition Method for Data Skew Alleviation in Spark Streaming Environment,"Spark Streaming is an extension of the core Spark engine that enables scalable, high-throughput, fault-tolerant stream processing of live data streams. It treats stream as a series of deterministic batches and handles them as regular jobs. However, for a stream job responsible for a batch, data skew (i.e., the imbalance in the amount of data allocated to each reduce task), can degrade the job performance significantly because of load imbalance. In this paper, we propose an improved range partitioner (ImRP) to alleviate the reduce skew for stream jobs in Spark Streaming. Unlike previous work, ImRP does not require any pre-run sampling of input data and generates the data partition scheme based on the intermediate data distribution estimated by the previous batch processing, in which a prediction model EWMA (Exponentially Weighted Moving Average) is adopted. To lighten the data skew, ImRP presents a novel method of calculating the partition borders optimally, and a mechanism of splitting the border key clusters when the semantics of shuffle operators permit. Besides, ImRP considers the integrated partition size and heterogeneity of computing environments when balancing the load among reduce tasks appropriately. We implement ImRP in Spark-3.0 and evaluate its performance on four representative benchmarks: wordCount, sort, pageRank, and LDA. The results show that by mitigating the data skew, ImRP can decrease the execution time of stream jobs substantially compared with some other partition strategies, especially when the skew degree of input batch is serious. © 2020",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Fu, Z. and Tang, Z. and Yang, L. and Li, K. and Li, K.",2020,Parallel Computing,10.1016/j.parco.2020.102699,scopus-search1.bib;web-of-science-search1.bib
Khudabukhsh20202594,Generalized Cost-Based Job Scheduling in Very Large Heterogeneous Cluster Systems,"We study job assignment in large, heterogeneous resource-sharing clusters of servers with finite buffers. This load balancing problem arises naturally in today's communication and big data systems, such as Amazon Web Services, Network Service Function Chains, and Stream Processing. Arriving jobs are dispatched to a server, following a load balancing policy that optimizes a performance criterion such as job completion time. Our contribution is a randomized Cost-Based Scheduling (CBS) policy in which the job assignment is driven by general cost functions of the server queue lengths. Beyond existing schemes, such as the Join the Shortest Queue (JSQ), the power of dd or the SQ(dd) and the capacity-weighted JSQ, the notion of CBS yields new application-specific policies such as hybrid locally uniform JSQ. As today's data center clusters have thousands of servers, exact analysis of CBS policies is tedious. In this article, we derive a scaling limit when the number of servers grows large, facilitating a comparison of various CBS policies with respect to their transient as well as steady state behavior. A byproduct of our derivations is the relationship between the queue filling proportions and the server buffer sizes, which cannot be obtained from infinite buffer models. Finally, we provide extensive numerical evaluations and discuss several applications including multi-stage systems. © 1990-2012 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Khudabukhsh, W.R. and Kar, S. and Alt, B. and Rizk, A. and Koeppl, H.",2020,IEEE Transactions on Parallel and Distributed Systems,10.1109/TPDS.2020.2997771,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Venugopal202051,AIR: A light-weight yet high-performance dataflow engine based on asynchronous iterative routing,"Distributed Stream Processing Engines (DSPEs) are currently among the most emerging topics in data management, with applications ranging from real-time event monitoring to processing complex dataflow programs and big data analytics. In this paper, we describe the architecture of our AIR engine, which is designed from scratch in C++ using the Message Passing Interface (MPI), pthreads for multithreading, and is directly deployed on top of a common HPC workload manager such as SLURM. AIR implements a light-weight, dynamic sharding protocol (referred to as 'Asynchronous Iterative Routing'), which facilitates a direct and asynchronous communication among all worker nodes and thereby completely avoids any additional communication overhead with a dedicated master node. With its unique design, AIR fills the gap between the prevalent scale-out (but Java-based) architectures like Apache Spark and Flink, on one hand, and recent scale-up (and C++ based) prototypes such as StreamBox and PiCo, on the other hand. Our experiments over various benchmark settings confirm that AIR performs as good as the best scale-up SPEs on a single-node setup, while it outperforms existing scale-out DSPEs in terms of processing latency and sustainable throughput by a factor of up to 15 in a distributed setting. © 2020 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Venugopal, V.E. and Theobald, M. and Chaychi, S. and Tawakuli, A.",2020,Proceedings - Symposium on Computer Architecture and High Performance Computing,10.1109/SBAC-PAD49847.2020.00018,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Kesavan2020206,A Visual Analytics Framework for Reviewing Streaming Performance Data,"Understanding and tuning the performance of extreme-scale parallel computing systems demands a streaming approach due to the computational cost of applying offline algorithms to vast amounts of performance log data. Analyzing large streaming data is challenging because the rate of receiving data and limited time to comprehend data make it difficult for the analysts to sufficiently examine the data without missing important changes or patterns. To support streaming data analysis, we introduce a visual analytic framework comprising of three modules: data management, analysis, and interactive visualization. The data management module collects various computing and communication performance metrics from the monitored system using streaming data processing techniques and feeds the data to the other two modules. The analysis module automatically identifies important changes and patterns at the required latency. In particular, we introduce a set of online and progressive analysis methods for not only controlling the computational costs but also helping analysts better follow the critical aspects of the analysis results. Finally, the interactive visualization module provides the analysts with a coherent view of the changes and patterns in the continuously captured performance data. Through a multi-faceted case study on performance analysis of parallel discrete-event simulation, we demonstrate the effectiveness of our framework for identifying bottlenecks and locating outliers. © 2020 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kesavan, S.P. and Fujiwara, T. and Li, J.K. and Ross, C. and Mubarak, M. and Carothers, C.D. and Ross, R.B. and Ma, K.-L.",2020,IEEE Pacific Visualization Symposium,10.1109/PacificVis48177.2020.9280,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Zhang20201537,Towards concurrent stateful stream processing on multicore processors,"Recent data stream processing systems (DSPSs) can achieve excellent performance when processing large volumes of data under tight latency constraints. However, they sacrifice support for concurrent state access that eases the burden of developing stateful stream applications. Recently, some have proposed managing concurrent state access during stream processing by modeling state accesses as transactions. However, these are realized with locks involving serious contention overhead. The coarse-grained processing paradigm adopted in these proposals magnify contention issues and does not exploit modern multicore architectures to their full potential. This paper introduces TStream, a novel DSPS supporting efficient concurrent state access on multicore processors. Transactional semantics is employed like previous work, but scalability is greatly improved due to two novel designs: 1) dual-mode scheduling, which exposes more parallelism opportunities, 2) dynamic restructuring execution, which aggressively exploits the parallelism opportunities from dual-mode scheduling without centralized lock contentions. To validate our proposal, we evaluate TStream with a benchmark of four applications on a modern multicore machine. Experimental results show that 1) TStream achieves up to 4.8 times higher throughput with similar processing latency compared to the state-of-the-art and 2) unlike prior solutions, TStream is highly tolerant of varying application workloads such as key skewness and multi-partition state accesses. © 2020 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zhang, S. and Wu, Y. and Zhang, F. and He, B.",2020,Proceedings - International Conference on Data Engineering,10.1109/ICDE48307.2020.00136,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Kahveci2020205,Joker: Elastic stream processing with organic adaptation,"This paper addresses the problem of auto-parallelization of streaming applications. We propose an online parallelization optimization algorithm that adjusts the degree of pipeline and data parallelism in a joint manner. We define an operator development API and a flexible parallel execution model to form a basis for the optimization algorithm. The operator interface unifies the development of different types of operators and makes operator properties visible in order to enable safe optimizations. The parallel execution model splits a data flow graph into regions. A region contains the longest sequence of compatible operators that are amenable to data parallelism as a whole and can be further parallelized with pipeline parallelism. We also develop a stream processing run-time, named Joker, to scale the execution of streaming applications in a safe, transparent, dynamic, and automatic manner. This ability is called organic adaptation. Joker implements the runtime machinery to execute a data flow graph with any parallelization configuration and most importantly change this configuration at run-time with low cost in the presence of partitioned stateful operators, in a way that is transparent to the application developers. Joker continuously monitors the run-time performance, and runs the optimization algorithm to resolve bottlenecks and scale the application by adjusting the degree of pipeline and data parallelism. The experimental evaluation based on micro-benchmarks and real-world applications showcase that our solution accomplishes elasticity by finding an effective parallelization configuration. (C) 2019 Elsevier Inc. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Kahveci, B. and Gedik, B.",2020,Journal of Parallel and Distributed Computing,10.1016/j.jpdc.2019.10.012,scopus-search1.bib;web-of-science-search1.bib
Blamey2020335,"Apache spark streaming, kafka and harmonicio: a performance benchmark and architecture comparison for enterprise and scientific computing","Many scientific computing applications generate streams where message sizes exceed one megabyte, in contrast with smaller message sizes in enterprise contexts (order kilobytes, often XML or JSON). Furthermore, the processing cost of messages in scientific computing applications are usually an order of magnitude higher than in typical enterprise applications. Frameworks such as Apache Spark offer high throughput processing of streams with such ‘enterprise’ characteristics, as well as scalability, with high resilience and many other desirable features. Motivated by the development of near real-time image processing pipelines for roboticized microscopy, we evaluate the suitability of Apache Spark for streams more typical of scientific computing applications, those with large message sizes (up to 10 MB), and heavy per-message CPU load, under typical stream integrations. For comparison, we benchmark a P2P stream processing framework, HarmonicIO, developed in-house. Our study reveals a complex interplay of performance trade-offs, revealing the boundaries of good performance for each framework and integration over a wide domain of application loads. Based on these results, we suggest which are likely to offer good performance for a given load. Broadly, the advantages of Spark’s rich features makes its performance sensitive to message size in particular, whereas the simplicity of HarmonicIO offers more robust performance, and better CPU utilization. © Springer Nature Switzerland AG 2020.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Blamey, B. and Hellander, A. and Toor, S.",2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-030-49556-5_30,scopus-search1.bib
Maroulis20192624,A Holistic Energy-Efficient Real-Time Scheduler for Mixed Stream and Batch Processing Workloads,"In recent years we have experienced a wide adoption of novel distributed processing frameworks such as Apache Spark for handling batch and stream processing big data applications. An important aspect that has not been examined in these systems yet, is the energy consumption during the applications' execution. Reducing the energy consumption of modern datacenters is a necessity, as datacenters contribute over 2 percent of the total US electric usage. However, efficiently scheduling applications in distributed processing systems can be challenging as there is a trade-off between minimizing the datacenter's energy usage and satisfying the application performance requirements. In this work we propose, ExpREsS, a scheduler for orchestrating the execution of Spark applications in a way that enables us to minimize the energy consumption while ensuring that the applications' performance requirements are met. Our approach exploits time-series segmentation for capturing the applications' energy usage and execution times, and then applies a novel DVFS technique to minimize the energy consumption. In order to tackle the limited number of application's profiling runs, we exploit regression techniques to predict the applications' execution times and power consumption. Our detailed experimental evaluation using realistic workloads on our local cluster illustrates the working and benefits of our approach. © 1990-2012 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Maroulis, S. and Zacheilas, N. and Kalogeraki, V.",2019,IEEE Transactions on Parallel and Distributed Systems,10.1109/TPDS.2019.2922606,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Hanif2019393,Benchmarking Tool for Modern Distributed Stream Processing Engines,"There is an upsurge in the usage and adaptation of streaming applications in the recent years by both industry and academia. At the core of these applications is streaming data processing engines that perform resource management and allocation in order to support continuous track of queries over distributed data streams. Several stream processing engines exists to handle these distributed streaming applications. In this paper, we present different challenges of the stream processing systems, in particular to stateful operators and implement Linear Road benchmark to examine the characteristic and performance metrics of the streaming system, in particular Apache Flink. Furthermore, we examine that Apache Flink can be used as a core for an efficient Linear Road application implementation for distributed environments without breaching the SLA requirements of the application. © 2019 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Hanif, M. and Yoon, H. and Lee, C.",2019,International Conference on Information Networking,10.1109/ICOIN.2019.8718106,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
López-Gómez201924,Exploring stream parallel patterns in distributed MPI environments,"In recent years, the large volumes of stream data and the near real-time requirements of data streaming applications have exacerbated the need for new scalable algorithms and programming interfaces for distributed and shared-memory platforms. To contribute in this direction, this paper presents a new distributed MPI back end for GRPPI, a C++ high-level generic interface of data-intensive and stream processing parallel patterns. This back end, as a new execution policy, supports distributed and hybrid (distributed+shared-memory) parallel executions of the Pipeline and Farm patterns, where the hybrid mode combines the MPI policy with a GRPPI shared-memory one. These patterns internally leverage distributed queues, which can be configured to use two-sided or one-sided MPI primitives to communicate items among nodes. A detailed analysis of the GOP! MPI execution policy reports considerable benefits from the programmability, flexibility and readability points of view. The experimental evaluation of two different streaming applications with different distributed and shared-memory scenarios reports considerable performance gains with respect to the sequential versions at the expense of negligible GRPPI overheads. (C) 2019 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"López-Gómez, J. and FernándezMuñoz, J. and RioAstorga, D. and Dolz, M.F. and Garcia, J.D.",2019,Parallel Computing,10.1016/j.parco.2019.03.004,scopus-search1.bib;web-of-science-search1.bib
Zacheilas2019378,Scalable Distributed Top-k Join Queries in Topic-Based Pub/Sub Systems,"In this paper, we provide a novel approach that enables the execution of top-k join queries over sliding windows in a way that reduces the amount of data that need to be analyzed by the stream processing operators. The main idea is that brokers individually invoke the query on their received messages and forward the top-k results to a stream processing operator that performs the merging of the results and provides to the end-user the final top-k results. Moreover, our system exploits the Bayesian Optimization technique to determine automatically the number of top-k results that should be provided by each broker. Our approach has been developed in the Kappa architecture that exploits topic-based scalable publish/subscribe (pub/sub) systems like Apache Kafka to efficiently forward the high volume of incoming messages to distributed processing systems (i.e., Apache Spark or Apache Flink) that perform the batch and stream analytics operations. Our detailed experimental evaluation on our local cluster illustrates that we can efficiently execute top-k join queries on our system with high accuracy and low latency. © 2018 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zacheilas, N. and Dedousis, D. and Kalogeraki, V.",2018,"Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018",10.1109/BigData.2018.8621949,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
TurrisidaCosta20193,Evaluating the Four-Way Performance Trade-Off for Stream Classification,"Machine Learning (ML) solutions need to deal efficiently with a huge amount of data available, addressing scalability concerns without sacrificing predictive performance. Moreover, this data comes in the form of a continuous and evolving stream imposing new constraints, e.g., limited memory and energy resources. In the same way, energy-aware ML algorithms are gaining relevance due to the power constraints of hardware platforms in several real-life applications, as the Internet of Things (IoT). Many algorithms have been proposed to cope with the mutable nature of data streams, with the Very Fast Decision Tree (VFDT) being one of the most widely used. An adaptation of the VFDT, called Strict VFDT (SVFDT), can significantly reduce memory usage without putting aside the predictive performance and time efficiency. However, the analysis of energy consumption regarding data stream processing of the VFDT and SVFDT is overlooked. In this work, we compare the four-way relationship between predictive performance, memory costs, time efficiency and energy consumption, tuning the hyperparameters of the algorithms to optimise the resources devoted to it. Experiments over 23 benchmark datasets revealed that the SVFDT-I is the most energy-friendly algorithm and greatly reduced memory consumption, being statistically superior to the VFDT. © 2019, Springer Nature Switzerland AG.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Costa, V.G. and Santana, E.J. and Lopes, J.F. and Barbon, Jr.",2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-030-19223-5_1,scopus-search1.bib;web-of-science-search1.bib
Chauvin2019,"Efficiency, economics and compliance: A practical planning tool for optimizing cuttings treatment","The expanding focus on total cost of ownership (TCO) in the oilfield is driving the application of global best practices in drilling and completion operations. Measurable benefits can result from a proactive approach to separating, treating, and handling disposal streams that accounts for both short- and long-term effects and is tailored to the specific needs of projects in the Middle East. This paper provides a versatile decision-making tool to help determine the optimal processes for a variety of conditions based on efficiency, economics, and sustainability. The most effective treatment solutions and services seek to address multiple factors, including logistics and expenses, drilling efficiency and performance, remote locations with infrastructure limitations, and strict environmental regulations. Interdependencies between the fluids, equipment, and services will also influence the selection of appropriate separation and treatment processes. A useful decision tree is based on the critical goals of waste volume reduction and maximum recovery of valuable components. Making the right choices in both of these areas will provide effective long-term results and economic benefits. This paper summarizes multiple case histories that demonstrate successful cuttings and waste stream processing, including both land and offshore operations. In some cases, a mobile or well-specific treatment system works best; others rely on a central treatment facility to serve an entire field or multirig operation. The results achieved in each case contribute to a step-by-step planning tool in matrix format that can be used to design the best set of equipment and services for each location. The matrix accounts for many factors, including rig equipment and capacities, proposed drilling and completion fluids, lithology, risk assessment, system maintenance, potential process rates and throughput, mobilization, environmental regulations, and infrastructure requirements. The decision tree presented facilitates the treatment selection process by incorporating useful benchmarks for volumes, process rates, expected base oil/fluid recovery, installation costs/requirements, scalability, longevity, and decommissioning (and/or relocation of the treatment system). It provides a practical starting point for planning an efficient, fit-for-purpose treatment configuration, scaled to match operational needs, reduce total cost of ownership, and meet or exceed existing and future standards. © Copyright 2018, Society of Petroleum Engineers.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Chauvin, and E.,",2019,"Society of Petroleum Engineers - Abu Dhabi International Petroleum Exhibition and Conference 2018, ADIPEC 2018",,scopus-search1.bib
VanDongen2018247,Latency Measurement of Fine-Grained Operations in Benchmarking Distributed Stream Processing Frameworks,"This paper describes a benchmark for stream processing frameworks allowing accurate latency benchmarking of fine-grained individual stages of a processing pipeline. By determining the latency of distinct common operations in the processing flow instead of the end-to-end latency, we can form guidelines for efficient processing pipeline design. Additionally, we address the issue of defining time in distributed systems by capturing time on one machine and defining the baseline latency. We validate our benchmark for Apache Flink using a processing pipeline comprising common stream processing operations. Our results show that joins are the most time consuming operation in our processing pipeline. The latency incurred by adding a join operation is 4.5 times higher than for a parsing operation, and the latency gradually becomes more dispersed after adding additional stages. © 2018 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"VanDongen, G. and Steurtewagen, B. and VanDenPoel, D.",2018,"Proceedings - 2018 IEEE International Congress on Big Data, BigData Congress 2018 - Part of the 2018 IEEE World Congress on Services",10.1109/BigDataCongress.2018.00043,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Dolz201839944,Towards Automatic Parallelization of Stream Processing Applications,"Parallelizing and optimizing codes for recent multi-/many-core processors have been recognized to be a complex task. For this reason, strategies to automatically transform sequential codes into parallel and discover optimization opportunities are crucial to relieve the burden to developers. In this paper, we present a compile-time framework to (semi) automatically find parallel patterns (Pipeline and Farm) and transform sequential streaming applications into parallel using GrPPI, a generic parallel pattern interface. This framework uses a novel pipeline stage-balancing technique which provides the code generator module with the necessary information to produce balanced pipelines. The evaluation, using a synthetic video benchmark and a real-world computer vision application, demonstrates that the presented framework is capable of producing parallel and optimized versions of the application. A comparison study under several thread-core oversubscribed conditions reveals that the framework can bring comparable performance results with respect to the Intel TBB programming framework. © 2013 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Dolz, M.F. and DelRioAstorga, D. and Fernandez, J. and DanielGarcia, J. and Carretero, J.",2018,IEEE Access,10.1109/ACCESS.2018.2855064,scopus-search1.bib;web-of-science-search1.bib
Bilal201816,Mitigating network side channel leakage for stream processing systems in trusted execution environments,"A crucial concern regarding cloud computing is the confidentiality of sensitive data being processed in the cloud. Trusted Execution Environments (TEEs), such as Intel Software Guard eXtensions (SGX), allow applications to run securely on an untrusted platform. However, using TEEs alone for stream processing is not enough to ensure privacy as network communication patterns may leak information about the data. This paper introduces two techniques - anycast and multicast - for mitigating leakage at inter-stage communications in streaming applications according to a user-selected mitigation level. These techniques aim to achieve network data obliviousness, i.e., communication patterns should not depend on the data. We implement these techniques in an SGX-based stream processing system. We evaluate the latency and throughput overheads, and the data obliviousness using three benchmark applications. The results show that anycast scales better with input load and mitigation level, and provides better data obliviousness than multicast. © 2018 Copyright held by the owner/author(s).",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Bilal, M. and Alsibyani, H. and Canini, M.",2018,DEBS 2018 - Proceedings of the 12th ACM International Conference on Distributed and Event-Based Systems,10.1145/3210284.3210286,scopus-search1.bib;web-of-science-search1.bib;acm1-search1.bib
Mahapatra201841,Designing flink pipelines in IoT mashup tools,"Internet of Things (IoT) applications are generating increasingly large amounts of data because of continuous activity and periodical sensing capabilities. Processing the data generated by IoT applications is necessary to derive important insights-for example, processing data from CO emissions can help municipal authorities apply traffic restrictions in order to improve a city's air quality. State-of-the-art stream-processing platforms, such as Apache Flink, can be used to process large amounts of data streams from different IoT devices. However, it is difficult to both set-up and write applications for these platforms; this is also manifested in the increasing need for data analysts and engineers. A promising solution is to enable domain experts, who are not necessarily programmers, to develop the necessary stream pipelines by providing them with domain-specific graphical tools. We present our proposal for a state-of-the-art mashup tool, originally developed for wiring IoT applications together, to graphically design streaming data pipelines and deploy them as a Flink application. Our prototype and experimental evaluation show that our proposal is feasible and potentially impactful. © held by the author(s). NOBIDS 2018",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Mahapatra, T. and Gerostathopoulos, I. and FernándezMoreno, F.A. and Prehofer, C.",2018,CEUR Workshop Proceedings,,scopus-search1.bib
Saroliya2018753,Performance Evaluation and Statistical Analysis of AUR-Chord Algorithm with Default Working of Structured P2P Overlay Network,"In today’s scenario, where data streaming and file sharing (audio, video, jpeg, etc) are the most performed tasks over the internet, the several characteristic functionalities of peer-to-peer network for resource distribution makes its usage much more than the initially used client–server-based network. Peer-to-peer network requires less time compared to client–server approach for distributing data over the network because at an instance of time any node can behave as client and server in accordance to the requirement, i.e., there exists no predefined behavior/state of a node. The distribution of nodes and their scalable linking increases the churn rate in P2P network which as a result affects various parameters like data availability and data security as the higher churn rate creates an overhead on the data transaction activities. In this paper, statistical analysis and simulation results depict that improved algorithm give a highly efficient response which minimize the incomplete lookup as compared to earlier one. © 2018, Springer Nature Singapore Pte Ltd.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Saroliya, A. and Mishra, U. and Rana, A.",2018,Advances in Intelligent Systems and Computing,10.1007/978-981-10-5687-1_67,scopus-search1.bib
Jambi2017131,Engineering scalable distributed services for real-time big data analytics,"There is high demand for tools that analyze large sets of streaming data in both industrial and academic settings. While existing work has examined a wide range of issues, we focus on query support. In particular, we focus on providing analysts flexibility with respect to the types of queries they can make on large data sets in real time as well as over historical data. We have designed and implemented a lightweight service-based framework-EPIC Real-Time-that manages a set of queries that can be applied to user-initiated data analysis events (such as studying tweets generated during a disaster). Our prototype combines stream processing and batch processing techniques inspired by the Lambda Architecture. We investigate a core set of query types that can answer a wide range of queries asked by analysts who study crisis events. In this paper, we present a prototype implementation of EPIC Real-Time which makes use of event-driven and reactive programming techniques. We also present a performance evaluation on how efficiently the real-time and batch-oriented queries perform, how well these queries meet the needs of our analysts, and provide insight into how EPIC Real-Time performs along a number of dimensions including performance, usability, scalability, and reliability. © 2017 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Jambi, S. and Anderson, K.M.",2017,"Proceedings - 3rd IEEE International Conference on Big Data Computing Service and Applications, BigDataService 2017",10.1109/BigDataService.2017.22,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Siow2017245,Ewya: An interoperable fog computing infrastructure with RDF stream processing,"Fog computing is an emerging technology for the Internet of Things (IoT) that aims to support processing on resource-constrained distributed nodes in between the sensors and actuators on the ground and compute clusters in the cloud. Fog Computing benefits from low latency, location awareness, mobility, wide-spread deployment and geographical distribution at the edge of the network. However, there is a need to investigate, optimise for and measure the performance, scalability and interoperability of resource-constrained Fog nodes running real-time applications and queries on streaming IoT data before we can realise these benefits. With Eywa, a novel Fog Computing infrastructure, we (1) formally define and implement a means of distribution and control of query workload with an inverse publish-subscribe and push mechanism, (2) show how data can be integrated and made interoperable through organising data as Linked Data in the Resource Description Format (RDF), (3) test if we can improve RDF Stream Processing query performance and scalability over state-of-the-art engines with our approach to query translation and distribution for a published IoT benchmark on resource-constrained nodes and (4) position Fog Computing within the Internet of the Future. © 2017, Springer International Publishing AG.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Siow, E. and Tiropanis, T. and Hall, W.",2017,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-70284-1_20,scopus-search1.bib
Chakraborty2016,A priority based resource scheduling technique for multitenant storm clusters,"In this work in progress paper, we present our ongoing effort towards devising a priority based resource scheduling technique and framework for apache storm. Apache Storm is a popular distributed real time stream processing engine which has been widely adopted by key players in the industry including YAHOO and Twitter. An application running in storm is called a topology that is characterized by a Directed Acyclic Graph (DAG). To run multiple of such topologies in a storm cluster, storm provides with default, out of the box scheduler called Isolation Scheduler. Isolation Scheduler assigns resources to topologies based on static resource configuration and does not provide any means to prioritize topologies based on their varying business priority. As a result, performance degradation, even complete starvation of topologies with high business priority is possible when available cluster resources are insufficient. A priority based resource scheduling strategy is proposed in this paper to overcome this problem. A preliminary performance evaluation is performed to demonstrate effectiveness of the proposed scheduler over the default storm Isolation Scheduler. © 2016 The Society for Modeling and Simulation International.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Chakraborty, R. and Majumdar, S.",2016,"Proceedings of the 2016 International Symposium on Performance Evaluation of Computer and Telecommunication Systems, SPECTS 2016 - Part of SummerSim 2016 Multiconference",10.1109/SPECTS.2016.7570513,scopus-search1.bib;ieee1-search1.bib
Coluccio2014,Online stream processing of machine-to-machine communications traffic: A platform comparison,"In a machine-to-machine (M2M) communications system, the deployed devices relay data from on-board sensors to a back-end application over a wireless network. Since the cellular network provides very good coverage (especially in inhabited areas) and is relatively inexpensive, commercial M2M applications often prefer it to other technologies such as WiFi or satellite links. Unfortunately, having been originally designed with human users in mind, the cellular network provides little support to monitor millions of unattended devices. For this reason, it is extremely important to monitor the underlying signalling traffic to detect misbehaving devices or network problems. In the cellular network used by M2M communications systems, the network elements communicate using the Signalling System #7 (SS7), and a real-life system can generate tens of millions of SS7 messages per hour. This paper reports the results of our practical investigation on the possibility to use distributed stream processing systems (DSPSs) to perform real-time analysis of SS7 traffic in a commercial M2M communications system consisting of hundreds of thousands of devices. Through a thorough experimental evaluation based on the analysis of real-world SS7 traces, we present and compare the implementations of a DSPS-based data analysis application on top of either the well-known Storm DSPS or the Quasit middleware. The results show that, by using DSPS services, we are able to largely meet the real-time processing requirements of our use-case scenario. © 2014 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Coluccio, R. and Ghidini, G. and Reale, A. and Levine, D. and Bellavista, P. and Emmons, S.P. and Smith, J.O.",2014,Proceedings - IEEE Symposium on Computers and Communications,10.1109/ISCC.2014.6912528,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Kotevski2014410,Hybrid fluid modeling approach for performance analysis of P2P live video streaming systems,"In this paper a hybrid modeling approach with different modeling formalisms and solution methods is employed in order to analyze the performance of peer to peer live video streaming systems. We conjointly use queuing networks and Fluid Stochastic Petri Nets, developing several performance models to analyze the behavior of rather complex systems. The models account for: network topology, peer churn, scalability, peer average group size, peer upload bandwidth heterogeneity and video buffering, while introducing several features unconsidered in previous performance models, such as: admission control for lower contributing peers, control traffic overhead and internet traffic packet loss. Our analytical and simulation results disclose the optimum number of peers in a neighborhood, the minimum required server upload bandwidth, the optimal buffer size and the influence of control traffic overhead. The analysis reveals the existence of a performance switch-point (i.e. threshold) up to which system scaling is beneficial, whereas performance steeply decreases thereafter. Several degrees of degraded service are introduced to explore performance with arbitrary percentage of lost video frames and provide support for protocols that use scalable video coding techniques. We also find that implementation of admission control does not improve performance and may discourage new peers if waiting times for joining the system increase. © 2013 Springer Science+Business Media New York.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kotevski, Z. and Mitrevski, P.",2014,Peer-to-Peer Networking and Applications,10.1007/s12083-013-0205-7,scopus-search1.bib;web-of-science-search1.bib
Lai2014119,CSense: A stream-processing toolkit for robust and high-rate mobile sensing applications,"This paper presents CSense - a stream-processing toolkit for developing robust and high-rate mobile sensing application in Java. CSense addresses the needs of these systems by providing a new programming model that supports flexible application configuration, a high-level concurrency model, memory management, and compiler analyses and optimizations. Our compiler includes a novel flow analysis that optimizes the exchange of data across components from an application-wide perspective. A mobile sensing application benchmark indicates that flow analysis may reduce CPU utilization by as much as 45%. Static analysis is used to detect a range of programming errors including application composition errors, improper use of memory management, and data races. We identify that memory management and concurrency limit the scalability of stream processing systems. We incorporate memory pools, frame conversion optimizations, and custom synchronization primitives to develop a scalable run-time. CSense is evaluated on Galaxy Nexus phones running Android. Empirical results indicate that our run-time achieves 19 times higher steam processing rate compared to a realistic baseline implementation. We demonstrate the versatility of CSense by developing three mobile sensing applications. © 2014 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Lai, F. and Hasan, S.S. and Laugesen, A. and Chipara, O.",2014,IPSN 2014 - Proceedings of the 13th International Symposium on Information Processing in Sensor Networks (Part of CPS Week),10.1109/IPSN.2014.6846746,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib;acm2-search1.bib
Maamar201281,A multihop supplying partner protocol for 3D streaming systems over thin mobile devices,"The recent advances in technology and mobile computing led to the rapid growth of networked 3D streaming applications. Due to the limited network bandwidth of the client server approach, research works are now turning toward mobile ad- hoc networks (MANET)-based streaming. MANET-based streaming is considered challenging due to the limitation of the wireless medium. Moreover, given that the 3D data is distributed among peers, finding a suitable supplying part- ner is not considered an easy task. In this paper, we pro- pose a supplying partner selection technique coupled with a content delivery technique for MANET-based 3D streaming. We refer to our protocol as MULTIPLY. The performance evaluation of MULTIPLY obtained using an extensive set of simulation experiments is then reported. Copyright 2012 ACM.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Maamar, H.R. and Boukerche, A. and Petriu, E.",2012,DIVANet'12 - Proceedings of the ACM Workshop on Design and Analysis of Intelligent Vehicular Networks and Applications,10.1145/2386958.2386961,scopus-search1.bib
Verstraaten201141,On mapping distributed S-net to the 48-core intel scc processor,"Distributed S-NET is a declarative coordination language and component technology primarily aimed at modern multi-core/many-core chip architectures. It builds on the concept of stream processing to structure dynamically evolving networks of communicating asynchronous components. These components themselves are implemented using a conventional language suitable for the application domain. Our goal is to map Distributed S-NET to the Intel SCC processor in order to provide users with a simplified programming environment, yet still allowing them to make use of the advanced features of the SCC architecture. Following a brief introduction to the design principles of S-NET, we sketch out the general ideas of our implementation approach. These mainly concern the use of SCC's message passing buffers for lightweight communication of S-NET records and control data between cores as well as remapping of large data structures through lookup table manipulation. The latter avoids costly memory copy operations that would result from more traditional message passing approaches. Last, but not least, we present prototypical performance measurements for our communication primitives.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Verstraaten, M. and Grelck, C. and VanTol, M.W. and Bakker, R. and Jesshope, C.R.",2011,"3rd Many-Core Applications Research Community Symposium, MARC 2011",,scopus-search1.bib
Kotevski2011215,A modeling framework for performance analysis of P2P live video streaming systems,"Client/server media streaming systems exhibit streaming limitations when number of clients rises and the server can no longer sustain the upload load. At first, IP Multicast was proposed as an alternative solution to this problem but its deployment brought many practical issues in scalability and deployment that prevented it from wider use. Recently, a new promising technique emerged which is cost effective, easy to deploy and can support thousands of simultaneous users. It's a peer to peer network of logically connected clients which form an application level overlay network on top of the physical network. This new paradigm brings numerous advantages, but also a lot of open issues that need to be resolved. This paper exposes the fundamental characteristics of p2p live video streaming systems, gives a survey of p2p video streaming applications and presents a novel modeling framework for performance analysis of such systems as our main goal in future research. © 2011 Springer-Verlag.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kotevski, Z. and Mitrevski, P.",2011,Communications in Computer and Information Science,10.1007/978-3-642-19325-5_22,scopus-search1.bib;web-of-science-search1.bib
Liu2009161,A decentralized control mechanism for stream processing networks,"Data streaming applications are becoming more and more common due to the rapid development in emerging areas such as sensor networks, multimedia streaming, and on-line data mining, etc. These applications are often running in a decentralized, distributed environment. The requirements for processing large volumes of streaming data at real time have posed many great design challenges. One of the critical issues is to optimize the ongoing resource consumption of multiple, distributed, cooperating processing units. In this paper, we consider a generic model for the general stream data processing systems. We address the resource allocation problem for a collection of processing units so as to maximize the weighted sum of the throughput of different streams. Each processing unit may require multiple input data streams simultaneously and produce one or many valuable output streams. We develop decentralized control mechanisms that maximize the overall system throughput in such data stream processing networks. Performance analysis on the optimality and complexity of these mechanisms are also provided. © 2008 Springer Science+Business Media, LLC.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Liu, Z. and Tang, A. and Xia, C.H. and Zhang, L.",2009,Annals of Operations Research,10.1007/s10479-008-0434-y,scopus-search1.bib;web-of-science-search1.bib
Singh20221585,A data structure perspective to the RDD-based Apriori algorithm on Spark,"During the recent years, a number of efficient and scalable frequent itemset mining algorithms for big data analytics have been proposed by many researchers. Initially, MapReduce-based frequent itemset mining algorithms on Hadoop cluster were proposed. Although, Hadoop has been developed as a cluster computing system for handling and processing big data, but the performance of Hadoop does not meet the expectation for the iterative algorithms of data mining, due to its high I/O, and writing and then reading intermediate results in the disk. Consequently, Spark has been developed as another cluster computing infrastructure which is much faster than Hadoop due to its in-memory computation. It is highly suitable for iterative algorithms and supports batch, interactive, iterative, and stream processing of data. Many frequent itemset mining algorithms have been re-designed on the Spark, and most of them are Apriori-based. All these Spark-based Apriori algorithms use Hash Tree as the underlying data structure. This paper investigates the efficiency of various data structures for the Spark-based Apriori. Although, the data structure perspective has been investigated previously, but for the MapReduce-based Apriori, and it must be re-investigated in the distributed computing environment of Spark. The considered underlying data structures are Hash Tree, Trie, and Hash Table Trie. The experimental results on the benchmark datasets show that the performance of Spark-based Apriori with Trie and Hash Table Trie are almost similar but both perform many times better than Hash Tree in the distributed computing environment of Spark. © 2019, Bharati Vidyapeeth's Institute of Computer Applications and Management.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Singh, P. and Singh, S. and Mishra, P.K. and Garg, R.",2022,International Journal of Information Technology (Singapore),10.1007/s41870-019-00337-3,scopus-search1.bib
Farrokh2022,SP-ant: An ant colony optimization based operator scheduler for high performance distributed stream processing on heterogeneous clusters,"A key feature of distributed stream processing (DSP) systems is the scheduling of operators on clustered computers. In scheduling, the assignment plan of operators to nodes of the cluster, requirements of operators, and the computational power of each worker node must be considered with the goal of finding a tradeoff between the communication latency of operators and the utilization of worker nodes to minimize the overall system response time. To reach this goal is quite challenging, especially in heterogeneous clusters, because there are no accurate estimations about the loads of worker nodes at run time. To address this challenge, we propose a novel stream processing scheduling using ant colony algorithm (SP-Ant). SP-Ant finds the best operator assignment plan considering the inter-node communication latencies of operators by initially collocating highly communicative operators on the same worker nodes using the bin-packing algorithm and iteratively (re-)scheduling only the less communicative operators using the exploration and exploitation phases of the evolutionary ant colony optimization (ACO) algorithm in order to reduce its convergence time. SP-Ant is implemented on the standard Apache Storm. Using several standard benchmark topologies of Storm, it is shown that SP-Ant outperforms the R-Storm and Storm default schedulers by at least 50% in reducing the response time. © 2021 Elsevier Ltd",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Farrokh, M. and Hadian, H. and Sharifi, M. and Jafari, A.",2022,Expert Systems with Applications,10.1016/j.eswa.2021.116322,scopus-search1.bib;web-of-science-search1.bib
Zhang2021671,RDMA-Based Apache Storm for High-Performance Stream Data Processing,"Apache Storm is a scalable fault-tolerant distributed real time stream-processing framework widely used in big data applications. For distributed data-sensitive applications, low-latency, high-throughput communication modules have a critical impact on overall system performance. Apache Storm currently uses Netty as its communication component, an asynchronous server/client framework based on TCP/IP protocol stack. The TCP/IP protocol stack has inherent performance flaws due to frequent memory copying and context switching. The Netty component not only limits the performance of the Storm but also increases the CPU load in the IPoIB (IP over InfiniBand) communication mode. In this paper, we introduce two new implementations for Apache Storm communication components with the help of RDMA technology. The performance evaluation on Mellanox QDR Cards (40 Gbps) shows that our implementations can achieve speedup up to 5× compared with IPoIB and 10× with Gigabit Ethernet. Our implementations also significantly reduce the CPU load and increase the throughput of the system. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zhang, Z. and Liu, Z. and Jiang, Q. and Chen, J. and An, H.",2021,International Journal of Parallel Programming,10.1007/s10766-021-00696-0,scopus-search1.bib;scopus-search1.bib;web-of-science-search1.bib
Marić2021148,DEBS grand challenge: Real-time detection of air quality improvement with Apache Flink,"The topic of the DEBS Grand Challenge 2021 is to develop a solution for detecting areas in which the air quality index (AQI) improved the most when compared to the previous year. The solution must run two given continuous queries in parallel on the incoming sensor data stream which must return the following: 1) a top 50 cities in terms of AQI improvement with their current AQIs and 2) a histogram of the longest streaks of good AQI. The incoming data is accessed through an API which provides streaming sensor measurements in batches. We present our solution based on Apache Flink, a distributed stream processing framework for the cluster. We opted for Flink since its applications can easily be scaled horizontally and vertically by adding computation nodes or increasing available resources, respectively. Flink allows us to divide the given queries into smaller tasks which can be run concurrently on different nodes in order to reduce the overall processing time and thus improve the performance of our solution. In more detail, the following performance intensive tasks are run in parallel on distributed nodes: 1) retrieving measurement batches, 2) assigning a city to each measurement and 3) calculating air quality index per city. We also discuss the main optimizations we have used to improve the performance and present an experimental evaluation of our solution. © 2021 ACM.",FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Marić, J. and Pripužić, K. and Antonić, M.",2021,DEBS 2021 - Proceedings of the 15th ACM International Conference on Distributed and Event-Based Systems,10.1145/3465480.3466930,scopus-search1.bib;acm2-search1.bib
Mostafaei2021820,SNR: Network-aware geo-distributed stream analytics,"Emerging applications such as those running on the Internet of Things (IoT) devices produce constant data streams that need to be processed in real-time. Distributed stream processing systems (DSPs), with geographically distributed cluster networks interconnected via wide area network (WAN) links, have recently gained interest in handling these applications. How-ever, these applications have stringent requirements such as low-latency and high bandwidth that must be guaranteed to ensure the quality of service (QoS). These application requirements raise fundamental DSPs resource management and scheduling challenge. In this paper, we formulate the problem of placement of worker nodes on a geo-distributed DSPs cluster network as a multi-criteria decision-making problem and propose an additive weighting-based approach to solve it. The proposed solution finds the trade-off among different network parameters and allows executing the tasks according to the desired performance metrics. We evaluated the proposed approach using the Yahoo! streaming benchmark on a testbed and compare it against mechanisms deployed in Apache Spark, Apache Storm, and Apache Flink. The results of the evaluation show that our approach improves the performance of Spark up to 2.2x-7.2x, Storm up to 1.2x-3.4x, and Flink up to 1.4x-3.3x compared to other approaches, which makes our approach useful for use in practical environments. © 2021 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Mostafaei, H. and Afridi, S. and Abawajy, J.H.",2021,"Proceedings - 21st IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing, CCGrid 2021",10.1109/CCGrid51090.2021.00100,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Ndubuaku2019164,Cloud-assisted adaptive stream processing from discriminative representations,"As the streaming data generated by Internet of Things (IoT) ubiquitous sensors grow in massive scale, extracting interesting information (anomalies) in real-time becomes more challenging. Traditional systems which retrospectively perform all the processing in the cloud do not capture real-time changes in the data. Similarly, real-time solutions which rely on human monitors have the tendency to miss the anomalies due to their rare nature. In recent times, several machine learning techniques have been proposed for stream processing. Approaches based on supervised or semi-supervised learning fail to adapt to changing patterns of the streaming data and the data labelling costs are huge. To address these limitations, we propose a cloud-assisted framework where an intermediary node (edge) is introduced between the end devices and the cloud to assist in stream processing. A model deployed on the edge is designed to learn in an iterative manner to discriminate between similar and dissimilar data representations, making it easier to distinguish the anomalies. In this work, we have proposed an iterative method that combines the capabilities of deep clustering and l2-normalisation to achieve better discriminative representations. Experimental results demonstrate the proposed method achieves robust performance over state-of-the-art discriminative representation algorithms and sets new benchmark accuracy on transformation invariant image dataset. © 2019 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Ndubuaku, M. and Anjum, A. and Liotta, A.",2019,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",10.1109/SMC.2019.8914227,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Wang2019,A network-aware and partition-based resource management scheme for data stream processing,"With the increasing demand for data-driven decision making, there is an urgent need for processing geographically distributed data streams in real-time. The existing scheduling and resource management schemes efficiently optimize stream processing performance with the awareness of resource, quality-of-service, and network traffic. However, the correlation between network delay and inter-operator communication pattern is not well-understood. In this study, we propose a network-aware and partition-based resource management scheme to deal with the ever-changing network condition and data communication in stream processing. The proposed approach applies operator fusion by considering the computational demand of individual operators and the inter-operator communication patterns. It maps the fused operators to the clustered hosts with the weighted shortest processing time heuristic. Meanwhile, we established a 3-dimensional coordinate system for prompt reflection of the network condition, real-time traffic, and resource availability. We evaluated the proposed approach against two benchmarks, and the results demonstrate the efficiency in throughput and resource utilization. We also conducted a case study and implemented a prototype system supported by the proposed approach that aims to utilize the stream processing paradigm for pedestrian behavior analysis. The prototype application estimates walking time for a given path according to the real crowd traffic. The promising evaluation results of processing performance further illustrate the efficiency of the proposed approach. © 2019 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Wang, Y. and Tari, Z. and Huang, X. and Zomaya, A.Y.",2019,ACM International Conference Proceeding Series,10.1145/3337821.3337870,scopus-search1.bib;web-of-science-search1.bib;acm1-search1.bib
Schelter201961,Efficient incremental cooccurrence analysis for item-based collaborative filtering,"Recommender systems are ubiquitous in the modern internet, where they help users find items they might like. A widely deployed recommendation approach is item-based collaborative filtering. This approach relies on analyzing large item cooccurrence matrices that denote how many users interacted with a pair of items. The potentially quadratic number of items to compare poses a scalability bottleneck in analyzing such item cooccurrences. Additionally, this problem intensifies in real world use cases with incrementally growing datasets, especially when the recommendation model is regularly recomputed from scratch. We highlight the connection between the growing cost of item-based recommendation and densification processes in common interaction datasets. Based on our findings, we propose an efficient incremental algorithm for item-based collaborative filtering based on cooccurrence analysis. This approach restricts the number of interactions to consider from ‘power users’ and ‘ubiquitous items’ to guarantee a provably constant amount of work per user-item interaction to process. We discuss efficient implementations of our algorithm on a single machine as well as on a distributed stream processing engine, and present an extensive experimental evaluation. Our results confirm the asymptotic benefits of the incremental approach. Furthermore, we find that our implementation is an order of magnitude faster than existing open source recommender libraries on many datasets, and at the same time scales to high dimensional datasets which these existing recommenders fail to process. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Schelter, S. and Celebi, U. and Dunning, T.",2019,ACM International Conference Proceeding Series,10.1145/3335783.3335784,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Minallah2019387,Performance Comparison of Chunk/Peer Scheduling Algorithms of Peer-to-Peer Streaming Systems,"In a P2P system, the media stream is divided into small data units known as chunks. Each peer in a P2P system has to take two important decisions at a given time i.e. how the chunks are to be shared? (chunk scheduling) and with which peer are they to be shared with (peer scheduling). Scheduling plays an important role in evaluating performance of P2P systems. This paper compares the performance of different combinations of chunk/peer schedulers in terms of chunk diffusion delay, average chunk distribution delay and max chunk distribution delay. The results obtained under the specified experimental setup show that when Deadline Based chunk scheduling(DLc) is combined with different peer scheduling algorithms, the best results are obtained by its combination with Chunk Earliest Free Peer Scheduler (CEFp). For a constant peer scheduler CEFp combined with different chunk schedulers, the best results are obtained by combining it with Lastest Blind Chunk Scheduler (LBc). Finally, with varying neighborhood size, the best results are obtained by the combination of DLC/CAFp. © 2019 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Minallah, N. and Shah, S.S.H. and Said, N. and Khan, W. and Nayab, A. and Shinwari, Z.",2019,"Proceedings - 2nd International Conference on Multimedia Information Processing and Retrieval, MIPR 2019",10.1109/MIPR.2019.00077,scopus-search1.bib
Weibbach201965,Live traffic data analysis using stream processing,"The increasing digitalization in the traffic infrastructure offers a great potential to optimize traffic flows, to save costs, and to improve the CO2 balance. Achieving this requires the use of scalable, high-performance software environments that process live traffic data with minimal latency. However, there are no standard solutions that work out of the box. Instead, technology stacks of complex components must be assembled, configured, and deployed from a large and heterogeneous set of available building blocks. Since there are no guidelines on which particular software to use in which configuration for specific use cases, it is extremely difficult to build such complex architectures from scratch. Nevertheless, many application areas, including traffic data analysis, have domain-specific requirements, which makes it possible to close these gaps on the basis of further research. Following this idea, we analyze how typical applications of traffic data analysis can be implemented using stream processing technologies in order to find reusable solutions that can be used as blueprints for the design of applications with similar requirements. Therefore, a number of typical use cases will be analyzed, implemented and benchmarked on the basis of various stream processing architectures. This way, specific levers are to be found to systematically increase the performance. Our first results show significant performance differences between different software solutions and architectures. © 2018 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,EXCLUDED,EXCLUDED,,"Weibbach, and M.,",2018,"Proceedings - 11th IEEE/ACM International Conference on Utility and Cloud Computing Companion, UCC Companion 2018",10.1109/UCC-Companion.2018.00036,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Rodrigo2019264,Privacy preserving elastic stream processing with clouds using homomorphic encryption,"Prevalence of the Infrastructure as a Service (IaaS) clouds has enabled organizations to elastically scale their stream processing applications to public clouds. However, current approaches for elastic stream processing do not consider the potential security vulnerabilities in cloud environments. In this paper we describe the design and implementation of an Elastic Switching Mechanism for data stream processing which is based on Homomorphic Encryption (HomoESM). The HomoESM not only does elastically scale data stream processing applications into public clouds but also preserves the privacy of such applications. Using a real world test setup, which includes an email filter benchmark and a web server access log processor benchmark (EDGAR) we demonstrate the effectiveness of our approach. Multiple experiments on Amazon EC2 indicate that the proposed approach for Homomorphic encryption provides significant results which is 10% to 17% improvement of average latency in the case of email filter benchmark and EDGAR benchmarks respectively. Furthermore, EDGAR add/subtract operations and comparison operations showed 6.13% and 26.17% average latency improvements respectively. These promising results pave the way for real world deployments of privacy preserving elastic stream processing in the cloud. © Springer Nature Switzerland AG 2019.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Rodrigo, A. and Dayarathna, M. and Jayasena, S.",2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-030-18579-4_16,scopus-search1.bib;web-of-science-search1.bib
Li20182193,Burstiness-Aware Elastic Resource Allocation in Stream Data Processing [流数据处理中负载突发感知的弹性资源分配],"In distributed parallel data stream processing, facing the real-time-changing and bursting stream data, fixed resource allocation will cause waste of resources or reduce the quality of service. To achieve desirable performances without resource wastes, the scalable and elastic resource allocation is a critical problem to be solved, which allows applications to change dynamically their resource configuration in response to data load fluctuations at run-time. However, most elastic resource allocation policies only adjust their resources when the performance of nodes does not match the data load. The adjustment delay caused by the immediate resource allocation, and the unpredictable data load reduce the performance of the elastic allocation policy. In some work, the data load prediction is introduced into the elastic resource allocation, but in the data prediction model, the future data is predicted based on the historical data, which is not applicable to the bursty stream data. Moreover, the unnecessary resource adjustment bump increases the system overhead. This paper focuses on the adjustment delay and the adjustment jump in the elastic resource allocation. For the above problems, the main challenge lies in the prediction of burst load and the cooperation among nodes. Therefore, this paper firstly constructs a data load correlation model to predict the data load of nodes accurately. This model considers the correlation between nodes of the stream application, that is the node will experience the sudden load change, once its upstream nodes have carried out resource adjustments, then uses the queuing theory to predict the data load of the node in the next window, according to the states of its neighborhood upstream nodes in the current window, which includes the data load, the buffer occupy, the processing ability and the consumption ratio. Furthermore, a bi-directional control mechanism is designed to support the cooperative resource allocation between the upstream and downstream nodes, in which the feed forward control transmits the information of upstream nodes to downstream nodes, and the feedback control transmits the information inversely and selects the appropriate upstream nodes to participate in the resource allocation of the downstream nodes. Based on the data load correlation model and the bi-directional control mechanism, this paper proposes an upstream-downstream cooperative and elastic resource allocation strategy, optimizing for data quality and resource utilization rate quality of service (QoS) requirements and considering the adjustment cost. In this strategy, the downstream node can timely detect the sudden load and load variation trend produced by the upstream nodes, and thus the resource adjustment will be done in advance, and the adjustment bump can also be avoided. At the same time, according to the feedback mechanism, the upstream nodes can dynamically adjust the data processing rate to suppress the load fluctuation of the downstream node, aimed at reducing the possibility of resource adjustment. Experimental results show that, the strategy is effective, compared with two benchmark strategies used in similar scenarios. When the load change is large, the strategy can reduce the average data loss by 85%, and significantly reduce the overhead of system resource adjustment, and improves the resource utilization. © 2018, Science Press. All right reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Li, L.-N. and Wei, X.-H. and Li, X. and Wang, X.-W.",2018,Jisuanji Xuebao/Chinese Journal of Computers,10.11897/SP.J.1016.2018.02193,scopus-search1.bib
Sajjad201833,Optimizing windowed aggregation over geo-distributed data streams,"Real-time data analytics is essential since more and more applications require online decision making in a timely manner. However, efficient analysis of geo-distributed data streams is challenging. This is because data needs to be collected from all edge data centers, which aggregate data from local sources, in order to process most of the analytic tasks. Thus, most of the time edge data centers need to transfer data to a central data center over a wide area network, which is expensive. In this paper, we advocate for a coordinated approach of edge data centers in order to handle these analytic tasks efficiently and hence, reducing the communication cost among data centers. We focus on the windowed aggregation of data streams, which has been widely used in stream analytics. In general, aggregation of data streams among edge data centers in the same region reduces the amount of data that needs to be sent over cross-region communication links. Based on state-of-the-art research, we leverage intra-region links and design a low-overhead coordination algorithm that optimizes communication cost for data aggregation. Our algorithm has been evaluated using synthetic and Big Data Benchmark datasets. The evaluation results show that our algorithm reduces the bandwidth cost up to ~6x, as compared to the state-of-the-art solution. © 2018 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Sajjad, H.P. and Liu, Y. and Vlassov, V.",2018,"Proceedings - 2018 IEEE International Conference on Edge Computing, EDGE 2018 - Part of the 2018 IEEE World Congress on Services",10.1109/EDGE.2018.00012,scopus-search1.bib;web-of-science-search1.bib
Muñoz2018,Supporting MPI-distributed stream parallel patterns in GrPPI,"In the recent years, the large volumes of stream data and the near real-time requirements of data streaming applications have exacerbated the need for new scalable algorithms and programming interfaces for distributed and shared-memory platforms. To contribute in this direction, this paper presents a new distributed MPI back end for GrPPI, a C++ high-level generic interface of data-intensive and stream processing parallel patterns. This back end, as a new execution policy, supports the distributed and hybrid (distributed and shared-memory) parallel execution of the Pipeline and Farm patterns, where the hybrid mode combines the MPI policy with a GrPPI shared-memory one. A detailed analysis of the GrPPI MPI execution policy reports considerable benefits from the programma-bility, flexibility and readability points of view. The experimental evaluation on a streaming application with different distributed and shared-memory scenarios reports considerable performance gains with respect to the sequential versions at the expense of negligible GrPPI overheads. © 2018 Association for Computing Machinery.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Muñoz, J.F. and Dolz, M.F. and DelRioAstorga, D. and Cepeda, J.P. and DanielGarcía, J.",2018,ACM International Conference Proceeding Series,10.1145/3236367.3236380,scopus-search1.bib;web-of-science-search1.bib;acm1-search1.bib
Tran2018278,Reducing tail latencies while improving resiliency to timing errors for stream processing workloads,"Stream processing is an increasingly popular model for online data processing that can be partitioned into streams of elements. It is commonly used in real-time data analytics services, such as processing Twitter tweets and Internet of Things (IoT) device feeds. Current stream processing frameworks boast high throughput and low average latency. However, users of these frameworks may desire lower tail latencies and better real-time performance for their applications. In practice, there are a number of errors that can affect the performance of stream processing applications, such as garbage collection and resource contention. For some applications, these errors may cause unacceptable violations of real-time constraints. In this paper we propose applying redundancy in the data processing pipeline to increase the resiliency of stream processing applications to timing errors. This results in better real-time performance and a reduction in tail latency. We present a methodology and apply this redundancy in a framework based on Twitter's Heron. Finally, we evaluate the effectiveness of this technique against a range of injected timing errors using benchmarks from Intel's Storm Benchmark. Our results show that redundant tuple processing can effectively reduce the tail latency, and that the number of missed deadlines can also be reduced by up to 94% in the best case. We also study the potential effects of duplication when applied at different stages in the topology. For the topologies in this paper, we further observe that duplication is most effective when computation is redundant at the first bolt. Finally, we evaluate the additional overhead that duplicating tuples brings to a stream processing topology. Our results also show that computation overhead scales slower than communication, and that the real-time performance is improved in spite of the overheads. Overall we conclude that redundancy through duplicated tuples is indeed a powerful tool for increasing the resiliency to intermittent runtime timing errors. ©2018 IEEE",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Tran, G.P.C. and Walters, J.P. and Crago, S.P.",2018,"Proceedings - 2018 IEEE International Conference on Services Computing, SCC 2018 - Part of the 2018 IEEE World Congress on Services",10.1109/SCC.2018.00048,scopus-search1.bib;scopus-search1.bib;web-of-science-search1.bib;web-of-science-search1.bib;ieee2-search1.bib;ieee2-search1.bib
Wang2018215,Model-Based Scheduling for Stream Processing Systems,"Stream processing is emerging to react to the changing business situations of real-time processing. The main aim of this paradigm is to deal with the huge volume of data in the format of information flows originating from distributed devices. This consequently poses challenges to the scheduling problem in cloud data centers regarding the time-varying velocity of data ingesting and processing. In response to the uncertainties and complexities of streaming data, we propose a model-based scheduling scheme for stream processing systems, capturing the system behavior and providing an optimal allocation strategy to adapt to the changing work conditions. The proposed scheduling policy is implemented in Apache Storm, and micro-benchmarks with various shapes (e.g line, star, and diamond) were used in the evaluation. A topology that tracks trending topics on Twitter is also used, where the input is feeding with tweets in real-time. Experimental results show that the proposed solution can perform estimations that are well aligned with the system performance. The proposed scheduling policy achieves an improved performance with regards throughput and latency under varying ingesting rates. © 2017 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Wang, Y. and Tari, Z. and Farahabady, M.R.H. and Zomaya, A.Y.",2017,"Proceedings - 2017 IEEE 19th Intl Conference on High Performance Computing and Communications, HPCC 2017, 2017 IEEE 15th Intl Conference on Smart City, SmartCity 2017 and 2017 IEEE 3rd Intl Conference on Data Science and Systems, DSS 2017",10.1109/HPCC-SmartCity-DSS.2017.28,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Grulich20181030,Smart stream-based car information systems that scale: an experimental evaluation,"Real-time information from embedded sources is hard to process if the number of sources is high. One typical example of this application area are car information systems where the cyber-physical system of a car connects to arbitrary sources in and outside of the car to deliver value-adding information to the driver of the car. In this paper, we propose a new architecture for such a car information system based on a smart data streaming infrastructure. This architecture has been implemented and we have run several experiments to examine the quality of our proposed solution. The current implementation is based on Spark Streaming, Couchbase and written in Scala. We have deployed our implementation on a distributed system using cloud services. This allows us to perform experiments with a high load as typical for the application scenario. First results from our experiments show that our proposed solution for a smart data based car information system is resilient to typical failures and scales for the described use-cases. © 2017 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Grulich, P.M. and Zukunft, O.",2017,"Proceedings - 2017 IEEE International Conference on Internet of Things, IEEE Green Computing and Communications, IEEE Cyber, Physical and Social Computing, IEEE Smart Data, iThings-GreenCom-CPSCom-SmartData 2017",10.1109/iThings-GreenCom-CPSCom-SmartData.2017.181,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Yan2018624,Performance Analysis of Storm in a Real-World Big Data Stream Computing Environment,"As an important distributed real-time computation system, Storm has been widely used in a number of applications such as online machine learning, continuous computation, distributed RPC, and more. Storm is designed to process massive data streams in real time. However, there have been few studies conducted to evaluate the performance characteristics clusters in Storm. In this paper, we analyze the performance of a Storm cluster mainly from two aspects, hardware configuration and parallelism setting. Key factors that affect the throughput and latency of the Storm cluster are identified, and the performance of Storm’s fault-tolerant mechanism is evaluated, which help users use the computation system more efficiently. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Yan, H. and Sun, D. and Gao, S. and Zhou, Z.",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",10.1007/978-3-030-00916-8_57,scopus-search1.bib;web-of-science-search1.bib
Tahara2018451,Power performance analysis of FPGA-based particle filtering for realtime object tracking,"Real-time image processing with a compact FPGA-based architecture plays a key role in dynamic state-space models. This paper presents an energy efficient FPGA acceleration architecture of a particle filter, which is based on stream processing structure with a parallel resampling algorithm. Particle filters solve the state estimation problems with three steps: prediction, likelihood calculation and resampling. By accomplishing the resampling in a valid pixel area of an input image frame, while executing prediction in a synchronization region, our approach achieves real-time object tracking. This paper mainly highlights implementation alternatives using different clock frequencies and resource usages of FPGA. The result shows the comparisons of power consumption for the compact architecture with an accelerated clock frequency (135 MHz) compared to the larger circuit size with clock frequency (27 MHz). Interestingly, the larger architecture with a slower clock frequency shows lower power consumption. © Springer International Publishing AG 2018.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Tahara, A. and Hayashida, Y. and Thu, T.T. and Shibata, Y. and Oguri, K.",2018,Advances in Intelligent Systems and Computing,10.1007/978-3-319-61566-0_41,scopus-search1.bib
Xie2017366,Docker based overlay network performance evaluation in large scale streaming system,"Docker, the most popular container technique today, has accepted by more and more people and companies. It achieves agility and controls for Development and IT Operations teams to build, ship, and run any app, anywhere. Taking Docker's advantages, enterprises are able to leverage big data analytics more efficiently. In this paper, we use two network modes in Docker when building one Spark based streaming application. To get better achievement we design one experimental system to investigate performance between host and overlay network mode from different aspects. Through our working, we find host mode is faster overlay mode around 8%. At the same time, the overlay mode is more stable. We introduce coefficient of variation to see the difference of transfer latency among every package and overlay mode is better than host mode more than 50%. Therefore, overlay network mode is more suitable for the business with high quality requirement of network jitter like video conference. On the other hand, when need to get higher transfer latency, host mode is better choice. © 2016 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Xie, B. and Sun, G. and Ma, G.",2016,"Proceedings of 2016 IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference, IMCEC 2016",10.1109/IMCEC.2016.7867235,scopus-search1.bib;web-of-science-search1.bib
Roodaki2017,Scalable multiview video coding for immersive video streaming systems,"Immersive video places the user inside the video scene, allowing the user to control the direction of the view. To achieve this, the view of every direction must be recorded using either a panoramic camera or multiple cameras placed at different positions with different angels. The size of the captured video can be quite large due to multiple video streams, one from each camera. Even with compression standards such as Multiview Video Coding (MVC), the transmission of the whole MVC video is still bandwidth-costly, especially for heterogeneous users whose bandwidths vary. In this paper, we present a new approach for immersive video streaming by using Scalable Multiview Video Coding (SMVC) to create multiple layers of the immersive video, supporting heterogeneous receivers more efficiently. Our method limits the number of views in its base layer, while it uses view scalability and free view-point scalability in the additional layers to synthesize more views at the receiver and provide high quality free view-point viewing to the user. Performance evaluations demonstrate that our method: 1-synthesizes missing views more accurately, as evident subjectively, and 2-achieves an average and maximum gain of 0.75 and 1.4 in Bjontegaard BD-Bitrate scale, respectively, compared to existing work which simply group adjacent views in the same layer. © 2016 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Roodaki, H. and Shirmohammadi, S.",2017,VCIP 2016 - 30th Anniversary of Visual Communication and Image Processing,10.1109/VCIP.2016.7805454,scopus-search1.bib
Ma2017397,Stream-based live probabilistic topic computing and matching,"Public opinion monitoring refers to real-time first story detection (FSD) on a particular Internet news event. It play an important part in finding news propagation tendency. Current opinion monitoring methods are related to text matching. However, it has some limitations such as latent and hidden topic discovery and incorrect relevance ranking of matching results on large-scale data. In this paper, we propose one improved solution to live public opinion monitoring: stream-based live probabilistic topic computing and matching. Our method attempts to address the disadvantages such as semantic matching and low efficiency on timely big data. Topic real-time computing with stream processing paradigm and topic matching with query-time document and field boosting are proposed to make substantial improvements. Finally, our experimental evaluation on topic computing and matching using crawled historical Netease news records shows the high effectiveness and efficiency of the proposed approach. © Springer International Publishing AG 2017.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Ma, K. and Yu, Z. and Ji, K. and Yang, B.",2017,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-65482-9_27,scopus-search1.bib;web-of-science-search1.bib
Karavadara2016,Dynamic power management for reactive stream processing on the SCC tiled architecture,"Dynamic voltage and frequency scaling (DVFS) is a means to adjust the computing capacity and power consumption of computing systems to the application demands. DVFS is generally useful to provide a compromise between computing demands and power consumption, especially in the areas of resource-constrained computing systems. Many modern processors support some form of DVFS. In this article, we focus on the development of an execution framework that provides lightweight DVFS support for reactive stream processing systems (RSPS). RSPs are a common form of embedded control systems, operating in direct response to inputs from their environment. At the execution framework, we focus on support for many-core scheduling for parallel execution of concurrent programs. We provide a DVFS strategy for RSPs that is simple and lightweight, to be used for dynamic adaptation of the power consumption at runtime. The simplicity of the DVFS strategy became possible by the sole focus on the application domain of RSPs. The presented DVFS strategy does not require specific assumptions about the message arrival rate or the underlying scheduling method. While DVFS is a very active field, in contrast to most existing research, our approach works also for platforms like many-core processors, where the power settings typically cannot be controlled individually for each computational unit. We also support dynamic scheduling with variable workload. While many research results are provided with simulators, in our approach, we present a parallel execution framework with experiments conducted on real hardware, using the single-chip cloud computer many-core processor. The results of our experimental evaluation confirm that our simple DVFS strategy provides potential for significant energy saving on RSPs. © 2016, Karavadara et al.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Karavadara, N. and Zolda, M. and NgaNguyen, V.T. and Knoop, J. and Kirner, R.",2016,Eurasip Journal on Embedded Systems,10.1186/s13639-016-0035-9,scopus-search1.bib
Algemili2016226,Investigation of Reconfigurable FPGA Design for Processing Big Data Streams,"Big Data situation has placed a tremendous pressure on the existing computational models. The challenges of Big Data call for a new approach to solve both software and hardware problems. Streaming applications is a form of on-demand software distribution. In streaming scenarios, only essential portions of an application's code need to be installed on the system, while the receiver performs the main operations. The necessary code and files are delivered over the network as, and when, they are required. The hardware architecture plays an important role in improving the efficiency of a streaming system. The variance of hardware performance on different HW architectures is quite interesting. Previous work confirms that the CPUs, GPUs, and FPGAs are performing differently on specific applications. The previous efforts of hardware benchmarking show that GPUs outperformed the other platforms in terms of execution time. CPUs outperformed in overall execution combined with transfer time. FPGAs outperformed for fixed algorithms using streaming [1]. Hence, this paper evaluates the performance of streaming applications on a pipelined FPGA design. In the context of real-time processing, it elects one of the Big Data streaming problems that gets a candidate for majority element on-the-fly, that is Moore's Voting Algorithm. The performance analysis of Moore's algorithm on FPGA highlights a noticeable improvement by using a pipelining architecture. © 2016 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Algemili, and U.,",2016,"Proceedings - 2nd IEEE International Conference on Big Data Security on Cloud, IEEE BigDataSecurity 2016, 2nd IEEE International Conference on High Performance and Smart Computing, IEEE HPSC 2016 and IEEE International Conference on Intelligent Data and Security, IEEE IDS 2016",10.1109/BigDataSecurity-HPSC-IDS.2016.75,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Martin2016322,Grand challenge: Real-time social network graph analysis using stream mine 3G,"In this paper, we present our approach for solving the DEBS Grand Challenge 2016 using StreamMine3G, a distributed, highly scalable, elastic and fault tolerant event stream processing (ESP) system. We first provide an overview about StreamMine3G with regards to its programming model and architecture, followed by thorough description of the implementation for the two queries that provide up-to-date information about (i) the top-3 active posts and (ii) the top-k comments with the largest maximum cliques. Novel aspects of our implementation include (i) highly optimized data structures that lower the amount of lookups and traversals, and a (ii) deterministic data partitioning and processing scheme that allows the system to scale without bounds in an elastic fashion while still guaranteeing semantic transparency. In order to better utilize nowadays many-core machines, we furthermore propose a pipelining scheme in addition to data partitioning. Finally, we present a brief performance evaluation of our system. © 2016 ACM.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Martin, A. and Brito, A. and Fetzer, C.",2016,DEBS 2016 - Proceedings of the 10th ACM International Conference on Distributed and Event-Based Systems,10.1145/2933267.2933514,scopus-search1.bib;acm1-search1.bib
Vaidya2016813,Symbiote coprocessor unit-A streaming coprocessor for data stream acceleration,"This paper describes the design and the architecture of symbiote coprocessor unit (SCU)-a programmable streaming coprocessor for a heterogeneous reconfigurable logic-assisted data stream management systems (DSMSs) such as symbiote. The SCU is intended for streaming applications with real-time event and data processing that have stricter deadlines, high-bandwidth, and high-accuracy requirements. To meet these requirements, the SCU exploits unique characteristics of DSMSs, such as single-pass tuple processing, windowed operators, and inherent data level parallelism, using a single-instruction multiple-data very large instruction word (SIMD-VLIW) microarchitecture and a novel inverted distributed register file. In order to better explain the instruction set, design, and functionality of the various units in the SCU, this paper also provides a brief overview of SymQL-a procedural query language that we developed to describe the queries that can be executed on the SCU. Finally, this paper presents the performance of SCU using four queries that represent common data stream processing use-cases, one of them being similar to a query found in the Linear Road Benchmark. Using these queries on SCU simulation, we show that the SCU outperforms a software-only DSMS running on an AMD Opteron 2350 quad-core processor by 1.5-42 times. © 2015 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Vaidya, P.S. and Lee, J.J. and Pai, V.S. and Lee, M. and Hur, S.",2016,IEEE Transactions on Very Large Scale Integration (VLSI) Systems,10.1109/TVLSI.2015.2432063,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Rokicki2016817,Just in time: Controlling temporal performance in crowdsourcing competitions,"Many modern data analytics applications in areas such as crisis management, stock trading, and healthcare, rely on components capable of nearly real-Time processing of stream-ing data produced at varying rates. In addition to automatic processing methods, many tasks involved in those applica-tions require further human assessment and analysis. How-ever, current crowdsourcing platforms and systems do not support stream processing with variable loads. In this pa-per, we investigate how incentive mechanisms in competi-tion based crowdsourcing can be employed in such scenar-ios. More specifically, we explore techniques for stimulating workers to dynamically adapt to both anticipated and sud-den changes in data volume and processing demand, and we analyze effects such as data processing throughput, peak-to-Average ratios, and saturation effects. To this end, we study a wide range of incentive schemes and utility func-tions inspired by real world applications. Our large-scale experimental evaluation with more than 900 participants and more than 6200 hours of work spent by crowd work-ers demonstrates that our competition based mechanisms are capable of adjusting the throughput of online workers and lead to substantial on-demand performance boosts.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Rokicki, M. and Zerr, S. and Siersdorfer, S.",2016,"25th International World Wide Web Conference, WWW 2016",10.1145/2872427.2883075,scopus-search1.bib;web-of-science-search1.bib;acm1-search1.bib
Smirnov2016323,Quality-based Workload Scaling for Real-time Streaming Systems,"In this paper we propose an idea to scale workload via elastic quality of solution provided by the particular streaming applications. The contribution of this paper consists of quality-based workload scaling model, implementation details for quality assessment mechanism implemented at the top of Apache Storm and experimental evaluation of the proposed model on a synthetic and real-world (medical) examples. © 2016 The Authors. Published by Elsevier B.V.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Smirnov, P.A. and Nasonov, D.",2016,Procedia Computer Science,10.1016/j.procs.2016.11.038,scopus-search1.bib;web-of-science-search1.bib
Chen20152371,Distinct element counting in distributed dynamic data streams,"We consider a new type of distinct element counting problem in dynamic data streams, where (1) insertions and deletions of an element can appear not only in the same data stream but also in two or more different streams, (2) a deletion of a distinct element cancels out all the previous insertions of this element, and (3) a distinct element can be re-inserted after it has been deleted. Our goal is to count the number of distinct elements that were inserted but have not been deleted in a continuous data stream. We also solve this new type of distinct element counting problem in a distributed setting. This problem is motivated by several network monitoring and attack detection applications where network traffic can be modelled as single or distributed dynamic streams and the number of distinct elements in the data streams, such as unsuccessful TCP connection setup requests, is calculated to be used as an indicator to detect certain network events such as service outage and DDoS attacks. Although there are known tight bounds for distinct element counting in insertion-only data streams, no good bounds are known for it in dynamic data streams, neither for this new type of problem. None of the existing solutions for distinct element counting can solve our problem. In this paper, we will present the first solution to this problem, using a space-bounded data structure with a computation-efficient probabilistic data streaming algorithm to estimate the number of distinct elements in single or distributed dynamic data streams. We have done both theoretical analysis and experimental evaluations, using synthetic and real data traces, of our algorithm to show its effectiveness. © 2015 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Chen, W. and Guan, Y.",2015,Proceedings - IEEE INFOCOM,10.1109/INFOCOM.2015.7218625,scopus-search1.bib
Yang2015146,Progressive online aggregation in a distributed stream system,"Interactive query processing aims at generating approximate results with minimum response time. However, it is quite difficult for a batch-oriented processing system to progressively provide cumulatively accurate results in the context of a distributed environment. MapReduce Online extends the MapReduce framework to support online aggregation, but it is hindered by its processing speed in keeping up with ongoing real-time data events. We deploy the online aggregation algorithm over S4, a scalable stream processing system that is inspired by the combined functionalities of MapReduce and Actor model. Our system applies an asynchronous message communication mechanism from actor model to support online aggregation. It can process large scale data stream with high concurrency in a short response time. In this system, we adopt a distributed weighted random sampling algorithm to solve biased distribution between different streams. Furthermore, a multi-level query processing topology is developed to reduce overlapped processing for multiple queries. Our system can provide continuous window aggregation with a confidence interval and error bound. We have implemented our system and conducted plentiful experiments over the TPC-H benchmark. A large number of experiments are carried out to demonstrate that by using our system, high-quality query results can be generated within a short response time and that the approach outperforms MapReduce Online on data streams. (C) 2014 Elsevier Inc. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Yang, D. and Cao, J. and Wu, S. and Wang, J.",2015,Journal of Systems and Software,10.1016/j.jss.2014.11.027,scopus-search1.bib;web-of-science-search1.bib
Yan201462,Improve distributed client lifecycle control in ShadowStream,"ShadowStream is a novel Internet live streaming system that integrates performance evaluation as an intrinsic capability. An essential component in ShadowStream is distributed lifecycle control mechanism, which assigns each client a virtual arrival/lifetime to create a particular scenario to evaluate the performance of streaming system. The original design focuses on utilizing stable streaming viewers in physical world to guarantee the accuracy of ShadowStream, which, on the other hand, significantly limits the scale of the experiment. The authors' research develops a novel distributed client lifecycle control to get rid of restrictions caused by the limited number of stable viewers in live-testing streaming networks. The core idea of their research is to match the desired experimental scenario with real viewers' behavior in physical world. The result demonstrates that with the authors' methodology, the scale of experiments can be doubled. Copyright © 2014, IGI Global.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Yan, J. and Tian, C. and Sun, J. and Mao, H.",2014,International Journal of Web Services Research,10.4018/IJWSR.2014100105,scopus-search1.bib;web-of-science-search1.bib
Sui20141889,On the distributed orchestration of stochastic discrete event simulations,"Discrete event simulations are a powerful technique for modeling stochastic systems with multiple components where interactions between these components are governed by the probability distribution functions associated with them. Complex discrete event simulations are often computationally intensive with long completion times. This paper describes our solution to the problem of orchestrating the execution of a stochastic, discrete event simulation where computational hot spots evolve spatially over time. Our performance benchmarks report on our ability to balance computational loads in these settings. Copyright © 2013 John Wiley & Sons, Ltd. Copyright © 2013 John Wiley & Sons, Ltd.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Sui, Z. and Harvey, N. and Pallickara, S.",2014,Concurrency and Computation: Practice and Experience,10.1002/cpe.3121,scopus-search1.bib;web-of-science-search1.bib
Saleh2014700,On efficient processing of linked stream data,"Today, many application areas require continuous processing of data streams in an efficient manner and real-time fashion. Processing these continuous flows of data, integrating dynamic data with other data sources, and providing the required semantics lead to real challenges. Thus, Linked Stream Data (LSD) has been proposed which combines two concepts: Linked Open Data and Data Stream Processing (DSP). Recently, several LSD engines have been developed, including C-SPARQL and CQELS, which are based on SPARQL extensions for continuous query processing. However, this SPARQL-centric view makes it difficult to express complex processing pipelines. In this paper, we propose a LSD engine based on a more general stream processing approach. Instead of a variant of SPARQL, our engine provides a dataflow specification language called Pipe Flow which is compiled into native code. Pipe Flow supports native stream processing operators (e.g., window, aggregates, and joins), complex event processing as well as RDF data transformation operators such as tuplifier and triplifier to efficiently support LSD queries and provide a higher degree of expressiveness. We discuss the main concepts addressing the challenges of LSD processing and describe the usage of these concepts for processing queries from LSBench and SRBench. We show the effectiveness of our system in terms of query execution times through a comparison with existing systems as well as through a detailed performance analysis of our system implementation. © Springer-Verlag Berlin Heidelberg 2014.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Saleh, O. and Sattler, K.-U.",2014,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-662-45563-0_43,scopus-search1.bib;web-of-science-search1.bib
McCurdy2014115,Characterizing the impact of prefetching on scientific application performance,"In order to better understand the impact of hardware and software data prefetching on scientific application performance, this paper introduces two analysis techniques, one micro-architecture-centric and the other application-centric.We use these techniques to analyze representative full-scale production applications from five important Exascale target areas. We find that despite a great diversity in prefetching effectiveness across and even within applications, there is a strong correlation between regions where prefetching is most needed, due to high levels of memory traffic, and where it is most effective. We also observe that the application-centric analysis can explain many of the differences in prefetching effectiveness observed across the studied applications. © Springer International Publishing Switzerland 2014.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"McCurdy, C. and Marin, G. and Vetter, J.S.",2014,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-10214-6_6,scopus-search1.bib;web-of-science-search1.bib
Carbone2013153,Towards highly available complex event processing deployments in the cloud,"Recent advances in distributed computing have made it possible to achieve high availability on traditional systems and thus serve them as reliable services. For several offline computational applications, such as fine grained batch processing, their parallel nature in addition to weak consistency requirements allowed a more trivial transition. On the other hand, on-line processing systems such as Complex Event Processing (CEP) still maintain a monolithic architecture, being able to offer high expressiveness and vertical scalability at the expense of low distribution. Despite attempts to design dedicated distributed CEP systems there is potential for existing systems to benefit from a sustainable cloud deployment. In this work we address the main challenges of providing such a CEP service with a focus on reliability, since it is the most crucial aspect of that transition. Our approach targets low average detection latency and sustain-ability by leveraging event delegation mechanisms present on existing stream execution platforms. It also introduces redundancy and transactional logging to provide improved fault tolerance and partial recovery. Our performance analysis illustrates the benefits of our approach and shows acceptable performance costs for on-line CEP exhibited by the fault tolerance mechanisms we introduced. © 2013 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Carbone, P. and Vandikas, K. and Zaloshnja, F.",2013,"International Conference on Next Generation Mobile Applications, Services, and Technologies",10.1109/NGMAST.2013.35,scopus-search1.bib
Papadaki2013100,Mobistream: Live multimedia streaming in mobile devices,"In recent years, many techniques have been proposed so as to enable resource-constrained devices to consume or deliver live multimedia streams. The majority of the existing techniques use distributed multimedia services and powerful servers to handle streams on behalf of clients. This is due to the fact that, multimedia streaming, when smartphones act as both clients and servers, can generate many challenges due to the heterogeneity of the multimedia streaming protocols, the media formats and codecs supported by today's smartphones. In addition, multimedia processing is resource consuming and, in many cases, unsuitable for a plethora of resource-constrained devices. To overcome these challenges, we present MobiStream a device-to-device multimedia streaming system for resource-constrained devices that achieves efficient handling of live multimedia streams. The design of MobiStream architecture provides solutions to several issues including resource constraints, streaming among heterogeneous operating systems and platforms, generation, synchronization and presentation of multimedia streams. We have developed the MobiStream prototype system on Java 2 SE and Android platforms; this paper presents the implementation details and the experimental evaluation of our system.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Papadaki, C. and Kalogeraki, V.",2013,MMEDIA 2013 - 5th International Conferences on Advances in Multimedia,,scopus-search1.bib
Stapenhurst201364,Performance evaluation of objective video quality metrics on mixed spatiotemporal resolution content,"In this paper we present a study of objective video quality metric performance on test sequences which have undergone spatiotemporal resolution scaling prior to and after compression. The bit rates and resolutions tested have been chosen to typify consumer 'home theatre' wireless streaming scenarios. The aim of the study is to identify a suitable video quality metric for use in a video streaming system that meets changing bandwidth constraints through adaptation of spatiotemporal resolution in addition to quantisation parameters. We first collect subjective quality scores and then assess correlation of objective metrics with this data. Of the metrics tested, we conclude that MOVIE is the most capable of accurate subjective score prediction under changing spatiotemporal resolution conditions. © 2013 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Stapenhurst, R. and Lu, J. and Agrafiotis, D.",2013,"2013 IEEE International Conference on Image Processing, ICIP 2013 - Proceedings",10.1109/ICIP.2013.6738014,scopus-search1.bib;web-of-science-search1.bib;scholar.bib
Alias2012391,Real-time multiple video streams processing on PC-based FPGA platform,Programmable embedded media server based video surveillance system is prevalent as it has the capability to accommodate large network of cameras. The implementation of a wide range of programmable security analytics application in PC-based platform demands high processing bandwidth and high-end hardware specification requirements. This is due to insufficient compute resource by multicore CPU in performing some of the computationally intensive analytics operations at acceptable data rates. This paper presents a platform design considerations for programmable video analytics solving compute intensive video data processing leading to cost-efficient embedded platform solution. Our experimental analysis covers PC-based processing pipeline analysis for CPU resources to be used as design input for processing data offloading between multicore CPU and FPGA. The result identifies the processing bottleneck in PC-based media server with video analytics processing component consumes 81% of the total CPU processing cycles. This leads to the exploration of the PCI Express capability in FPGA for system solution as a transfer medium between these computing units. © 2012 IEEE.,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Alias, M.S. and Karuppiah, E.K. and Kit, C.P. and Tahir, S.M.",2012,"Proceedings of 2nd International Conference on Computer Science and Network Technology, ICCSNT 2012",10.1109/ICCSNT.2012.6525962,scopus-search1.bib
Sutinen2011700,Multi-interface extension to a scalable video streaming architecture,"Video service adaptation capabilities are essential for the efficient utilization of the network resources in heterogeneous multi-access environments and ensuring sufficient perceived service quality for the end users. Multihoming is seen as one important enabler for high-quality and reliable video streaming services and it is expected to be supported extensively in the future Internet. Already today, terminal devices are equipped with multiple network interfaces and able to use them simultaneously. In the future, mobile multimedia services such as video streaming can maximize the user experienced quality by utilizing the available network resources, concurrently. However, intelligent decision-making as well as dynamic mapping of traffic to network interfaces are required for optimal operation. In this paper, we introduce an overall architecture for adaptive video streaming exploiting the novel scalable video coding technology. We also propose a multi-interface streaming extension to the architecture to allow dynamic and concurrent usage of the available access networks in the video service delivery. We present a prototype implementation of the proposed multi-interface video streaming system and test its operation in the presence of network impairments in an experimental evaluation. © 2011 ACADEMY PUBLISHER.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Sutinen, T. and Rivas, H.",2011,Journal of Communications,10.4304/jcm.6.9.700-710,scopus-search1.bib
Sutinen2011,Cross-layer assisted network interface selection for multi-interface video streaming,"Multi-homing is expected to be an important enabler of the future Internet. Already today, terminal devices are equipped with multiple network interfaces and able to use them simultaneously. In the future, mobile multimedia services such as video streaming can maximize the user experienced quality by utilizing the available network resources, concurrently. However, intelligent decision-making as well as dynamic mapping of traffic to network interfaces are required for optimal operation. In this paper, we propose a dynamic cross-layer communication assisted network interface selection solution for a multi-interface streaming system designed for scalable video streams. We also present a prototype implementation and verify its operation in an experimental evaluation. © 2011 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Sutinen, T. and Rivas, H.",2011,"Proceedings - International Conference on Computer Communications and Networks, ICCCN",10.1109/ICCCN.2011.6005823,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Evans2010,Simplifying parallel and distributed simulation with the DUP system,"This paper presents how the DUP System, a straightforward POSIX-compatible framework that enables programming-language-agnostic parallel and distributed stream processing, can be used to facilitate parallel and distributed simulations. Specifically, we describe two ways of using DUP to utilize available resources for efficient simulation: (1) a straightforward technique for parallelizing multiple runs of an existing simulation program with minimal changes, and (2) FiDES, a Discrete-Event Simulation (DES) framework built atop DUP that provides a simple, yet powerful, means of implementing a parallel and/or distributed DES. We then describe a toolset for profiling, debugging and visualization that aids the development of DUP simulations. To support these claims, we present various performance benchmarks that collectively demonstrate how DUP and FiDES can make high-performance simulation accessible to everyone. © 2010 SCS.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Evans, N.S. and GauthierDickey, C. and Grothoff, C. and Grothoff, K. and Keene, J. and Rutherford, M.J.",2010,"Spring Simulation Multiconference 2010, SpringSim'10",10.1145/1878537.1878698,scopus-search1.bib;acm3-search1.bib
Gao201023,Su-PeerCast: A P2P live streaming system with Super-Node based on PeerCast,"The amount of client a live streaming system can serve by unicast is limited by the bandwidth requirement. Theoretically, IP-multicast is an efficient solution for that situation, but it suffers from poor deployment. Therefore, another solution, called Application Layer Multicast (ALM), is being increasingly recognized as a available alternative. However, this solution also has certain shortcomings. In this paper, we firstly introduce a live streaming system--PeerCast based on application layer multicast, and besides that we indicate its existing problems under practical deployment in the large-scale network. Secondly, in order to improve the PeerCast system performance, we append a Super-Node layer, which can divide the live system into different domains, and re-design the play process and heartbeat detection mechanism for our new live system. Finally, the re-designed system performance evaluation is presented.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Gao, C. and Huo, Y. and Su, Y. and Wu, J. and Ma, Y.",2010,IET Conference Publications,10.1049/cp.2010.0713,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Wu2009331,Hotspot prediction and cache in distributed stream-processing storage systems,"Storage performance is critical in today's distributed stream-processing systems. One approach to improve the performance is to use hotspot attribute in object-based storage systems. This paper discusses hotspot classification and identification, and then presents an Object Hotspot Prediction Model (OHPM) to dynamically predict hotspots. Based on this model, we discuss an efficient hotspot caching strategy to improve the performance. To demonstrate the effectiveness of our proposed approach, we have developed a prototype of Hotspot Attribute-managed Storage System (HASS) by extending Object-based Storage Device (OSD) file system and iSCSI protocols. Experimental results show that the HASS improves the throughput by up to 62% and reduces the disk I/O by as much as 25% in our VoD tests by integrating our object hotspot prediction and cache approaches. © 2009 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Wu, C. and He, X. and Wan, S. and Cao, Q. and Xie, C.",2009,"2009 IEEE 28th International Performance Computing and Communications Conference, IPCCC 2009",10.1109/PCCC.2009.5403810,scopus-search1.bib;web-of-science-search1.bib
Giacomazzi2008287,Performance analysis of peer-to-peer video streaming systems with tree and forest topology,"Peer-to-peer networks are an increasingly popular solution for the distribution of media content to a large number of users, with limited investments for network infrastructures. The distribution of a real time video stream imposes strict performance requirements such as small playback delays and few frame losses. In this paper, we focus on peer-to-peer video streaming systems with tree or forest content distribution structure and we provide a sensitivity analysis to investigate the impact of three critical parameters - rejoin time, average permanence time of peers and playback threshold - over the quality of the video stream received by users. The study, carried out through simulation, considers a general peer-to-peer video streaming reference model with tree/forest topology. © 2008 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Giacomazzi, P. and Poli, A.",2008,Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS,10.1109/ICPADS.2008.12,scopus-search1.bib;web-of-science-search1.bib
Krishnamurthy2003655,"On network CoProcessors for scalable, predictable media services","This paper presents the embedded realization and experimental evaluation of a media stream scheduler on Network Interface (NI) CoProcessor boards. When using media frames as scheduling units, the scheduler is able to operate in real-time on streams traversing the Coprocessor, resulting in its ability to stream video to remote clients at real-time rates. The contributions of this paper are its detailed evaluation of the effects of placing application or kernel-level functionality, like packet scheduling on NIs, rather than the host machines to which they are attached. The main benefits of such placement are 1) that traffic is eliminated from the host bus and memory subsystem, thereby allowing increased host CPU utilization for other tasks, and 2) that NI-based scheduling is immune to host-CPU loading, unlike host-based media schedulers that are easily affected even by transient load conditions. An outcome of this work is a proposed cluster architecture for building scalable media servers by distributing schedulers and media stream producers across the multiple NIs used by a single server and by clustering a number of such servers using commodity network hardware and software.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Krishnamurthy, R. and Schwan, K. and West, R. and Rosu, M.-C.",2003,IEEE Transactions on Parallel and Distributed Systems,10.1109/TPDS.2003.1214318,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Livaja2022282,A distributed geospatial publish/subscribe system on Apache Spark,"Publish/subscribe is a messaging pattern where message producers, called publishers, publish messages which they want to be distributed to message consumers, called subscribers. Subscribers are required to subscribe to messages of interest in advance to be able to receive them upon the publishing. In this paper, we discuss a special type of publish/subscribe systems, namely geospatial publish/subscribe systems (GeoPS systems), in which both published messages (i.e., publications) and subscriptions include a geospatial object. Such an object is used to express both the location information of a publication and the location of interest of a subscription. We argue that there is great potential for using GeoPS systems for the Internet of Things and Sensor Web applications. However, existing GeoPS systems are not applicable for this purpose since they are centralized and cannot cope with multiple highly frequent incoming geospatial data streams containing publications. To overcome this limitation, we present a distributed GeoPS system in the cluster which efficiently matches incoming publications in real-time with a set of stored subscriptions. Additionally, we propose four different (distributed) replication and partitioning strategies for managing subscriptions in our distributed GeoPS system. Finally, we present results of an extensive experimental evaluation in which we compare the throughput, latency and memory consumption of these strategies. These results clearly show that they are both efficient and scalable to larger clusters. The comparison with centralized state-of-the-art approaches shows that the additional processing overhead of our distributed strategies introduced by the Apache Spark is almost negligible. (C)\& nbsp;2022 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Livaja, I. and Pripužić, K. and Sovilj, S. and Vuković, M.",2022,Future Generation Computer Systems,10.1016/j.future.2022.02.013,scopus-search1.bib;web-of-science-search1.bib
Heinrich202285,Zero-shot cost models for distributed stream processing,"This paper proposes a learned cost estimation model for Distributed Stream Processing Systems (DSPS) with an aim to provide accurate cost predictions of executing queries. A major premise of this work is that the proposed learned model can generalize to the dynamics of streaming workloads out-of-the-box. This means a model once trained can accurately predict performance metrics such as latency and throughput even if the characteristics of the data and workload or the deployment of operators to hardware changes at runtime. That way the model can be used to solve tasks such as optimizing the placement of operators to minimize the end-to-end latency of a streaming query or maximize its throughput even under varying conditions. Our evaluation on a well-known DSPS, Apache Storm, shows that the model can predict accurately for unseen workloads and queries while generalizing across real-world benchmarks. © 2022 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Heinrich, R. and Luthra, M. and Kornmayer, H. and Binnig, C.",2022,DEBS 2022 - Proceedings of the 16th ACM International Conference on Distributed and Event-Based Systems,10.1145/3524860.3539639,scopus-search1.bib;acm1-search1.bib
Lv2022249,"Walle: An End-to-End, General-Purpose, and Large-Scale Production System for Device-Cloud Collaborative Machine Learning","To break the bottlenecks of mainstream cloud-based machine learning (ML) paradigm, we adopt device-cloud collaborative ML and build the first end-to-end and general-purpose system, called Walle, as the foundation. Walle consists of a deployment platform, distributing ML tasks to billion-scale devices in time; a data pipeline, efficiently preparing task input; and a compute container, providing a cross-platform and high-performance execution environment, while facilitating daily task iteration. Specifically, the compute container is based on Mobile Neural Network (MNN), a tensor compute engine along with the data processing and model execution libraries, which are exposed through a refined Python thread-level virtual machine (VM) to support diverse ML tasks and concurrent task execution. The core of MNN is the novel mechanisms of operator decomposition and semi-auto search, sharply reducing the workload in manually optimizing hundreds of operators for tens of hardware backends and further quickly identifying the best backend with runtime optimization for a computation graph. The data pipeline introduces an on-device stream processing framework to enable processing user behavior data at source. The deployment platform releases ML tasks with an efficient push-then-pull method and supports multi-granularity deployment policies. We evaluate Walle in practical e-commerce application scenarios to demonstrate its effectiveness, efficiency, and scalability. Extensive micro-benchmarks also highlight the superior performance of MNN and the Python thread-level VM. Walle has been in large-scale production use in Alibaba, while MNN has been open source with a broad impact in the community. © 2022 by The USENIX Association. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Lv, C. and Niu, C. and Gu, R. and Jiang, X. and Wang, Z. and Liu, B. and Wu, Z. and Yao, Q. and Huang, C. and Huang, P. and Huang, T. and Shu, H. and Song, J. and Zou, B. and Lan, P. and Xu, G. and Wu, F. and Tang, S. and Wu, F. and Chen, G.",2022,"Proceedings of the 16th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2022",,scopus-search1.bib
Garcia2022,SPBench: a framework for creating benchmarks of stream processing applications,"In a fast-changing data-driven world, real-time data processing systems are becoming ubiquitous in everyday applications. The increasing data we produce, such as audio, video, image, and, text are demanding quickly and efficiently computation. Stream Parallelism allows accelerating this computation for real-time processing. But it is still a challenging task and most reserved for experts. In this paper, we present SPBench, a framework for benchmarking stream processing applications. It aims to support users with a set of real-world stream processing applications, which are made accessible through an Application Programming Interface (API) and executable via Command Line Interface (CLI) to create custom benchmarks. We tested SPBench by implementing parallel benchmarks with Intel Threading Building Blocks (TBB), FastFlow, and SPar. This evaluation provided useful insights and revealed the feasibility of the proposed framework in terms of usage, customization, and performance analysis. SPBench demonstrated to be a high-level, reusable, extensible, and easy of use abstraction to build parallel stream processing benchmarks on multi-core architectures. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Garcia, A.M. and Griebler, D. and Schepke, C. and Fernandes, L.G.",2022,Computing,10.1007/s00607-021-01025-6,scopus-search1.bib
Gütlein202218,On-demand Simulation of Future Mobility Based on Apache Kafka,"The modeling and simulation community can benefit from building and running (co-)simulation models on-demand. In order to drive innovation further, it should be easy to set up, orchestrate, and execute simulations – even for researchers with no background in computer science. Additionally, open interfaces should be the default to enable a variety of applications. The possibility to connect external components smoothly with a simulation run allows for elaborate experiments. In this work, the details of the architecture and design of a simulation platform enabling evaluations of future mobility scenarios are presented. While the explanations are based on mobility applications, the concept can be generalized and applied to other domains. The novelty lies in the use of a big data stream processing platform called Apache Kafka. All kinds of required communication are handled by the Kafka middleware. Even the coupling of different simulators is realized on top of it. As a foundation, existing works regarding Modeling and Simulation as a Service are presented. The approach is then described by its architecture, its interfaces, and the life-cycle of a simulation run. Further information is given on the distribution of simulations and the topic-based clock synchronization mechanism. A performance evaluation shows that the approach is on one level with state-of-the art co-simulation middlewares. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Gütlein, M. and Djanatliev, A.",2022,Lecture Notes in Networks and Systems,10.1007/978-3-030-84811-8_2,scopus-search1.bib
Raza20215,Benchmarking Apache Kafka under network faults,"Network faults are often transient and hence hard to detect and difficult to resolve. Our study conducts an analysis of Kafka's network fault tolerance capabilities, one of the widely used distributed stream processing system (DSPS). Across different Kafka configurations, we observed that Kafka is fault-tolerant towards network faults to some degree, and we report observations of its shortcomings. We also define a network fault-tolerance benchmark on which other DSPSs can be evaluated. © 2021 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Raza, M. and Tahir, J. and Doblander, C. and Mayer, R. and Jacobsen, H.-A.",2021,Middleware 2021 Demos and Posters - Proceedings of the 2021 International Middleware Conference Demos and Posters,10.1145/3491086.3492470,scopus-search1.bib;acm2-search1.bib
Daghistani2021_62,SWARM: Adaptive load balancing in distributed streaming systems for big spatial data,"The proliferation of GPS-enabled devices has led to the development of numerous location-based services. These services need to process massive amounts of streamed spatial data in real-time. The current scale of spatial data cannot be handled using centralized systems. This has led to the development of distributed spatial streaming systems. Existing systems are using static spatial partitioning to distribute the workload. In contrast, the real-time streamed spatial data follows non-uniform spatial distributions that are continuously changing over time. Distributed spatial streaming systems need to react to the changes in the distribution of spatial data and queries. This article introduces SWARM, a lightweight adaptivity protocol that continuously monitors the data and query workloads across the distributed processes of the spatial data streaming system and redistributes and rebalances the workloads as soon as performance bottlenecks get detected. SWARM is able to handle multiple query-execution and data-persistence models. A distributed streaming system can directly use SWARM to adaptively rebalance the system's workload among its machines with minimal changes to the original code of the underlying spatial application. Extensive experimental evaluation using real and synthetic datasets illustrate that, on average, SWARM achieves 2 improvement in throughput over a static grid partitioning that is determined based on observing a limited history of the data and query workloads. Moreover, SWARM reduces execution latency on average 4 compared with the other technique. © 2021 Association for Computing Machinery.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Daghistani, A. and Aref, W.G. and Ghafoor, A. and Mahmood, A.R.",2021,ACM Transactions on Spatial Algorithms and Systems,10.1145/3460013,scopus-search1.bib;acm1-search1.bib
Jean-Pierre2021,Development of a Data Analytics Platform for an Electrical/Water Microgrid,"Data enabled systems can offer multiple improvements over traditional systems, including higher efficiency, higher reliability, and lower maintenance cost. There has been a large growth in the development of data enabled systems in various industrial sectors, such as energy, manufacturing, and water distribution systems. In order to achieve a data enabled system, it is paramount to develop an analytical platform by collecting data, and formulating and monitoring key performance indicators (KPIs). This paper presents a multilayer structured communication and data analytic framework to collect real-time, high-fidelity data for a full scale electrical microgrid and water system testbed. The system has deployed various electrical and water sensors, communication interfaces, data streaming libraries, cloud programming and storage, data dashboards, and an HMI. Actual water and electrical test systems were built to test this replicable platform. © 2021 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Jean-Pierre, G. and Akbarihaghighat, H. and Zhao, T. and Berger, A. and Nafsin, N. and Nasir, F.B. and Bravo, H. and Li, J. and Nasiri, A. and Nowak, M.",2021,"Proceedings of the 2021 IEEE 12th International Symposium on Power Electronics for Distributed Generation Systems, PEDG 2021",10.1109/PEDG51384.2021.9494250,scopus-search1.bib
Fang20211861,A-DSP: An adaptive join algorithm for dynamic data stream on cloud system,"The join operations, including both equi and non-equi joins, are essential to the complex data analytics in the big data era. However, they are not inherently supported by existing DSPEs (Distributed Stream Processing Engines). The state-of-the-art join solutions on DSPEs rely on either complicated routing strategies or resource-inefficient processing structures, which are susceptible to dynamic workload, especially when the DSPEs face various join predicate operations and skewed data distribution. In this paper, we propose a new cost-effective stream join framework, named A-DSP (Adaptive Dimensional Space Processing), which enhances the adaptability of real-time join model and minimizes the resource used over the dynamic workloads. Our proposal includes: 1) a join model generation algorithm devised to adaptively switch between different join schemes so as to minimize the number of processing task required; 2) a load-balancing mechanism which maximizes the processing throughput; and 3) a lightweight algorithm designed for cutting down unnecessary migration cost. Extensive experiments are conducted to compare our proposal against state-of-the-art solutions on both benchmark and real-world workloads. The experimental results verify the effectiveness of our method, especially on reducing the operational cost under pay-as-you-go pricing scheme. © 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Fang, J. and Zhang, R. and Zhao, Y. and Zheng, K. and Zhou, X. and Zhou, A.",2021,IEEE Transactions on Knowledge and Data Engineering,10.1109/TKDE.2019.2947055,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Runsewe2021504,Cloud resource scaling for time-bounded and unbounded big data streaming applications,"Recent advancements in technology have led to a deluge of big data streams that require real-time analysis with strict latency constraints. A major challenge, however, is determining the amount of resources required by applications processing these streams given their high volume, velocity and variety. The majority of research efforts on resource scaling in the cloud are investigated from the cloud provider's perspective with little consideration for multiple resource bottlenecks. We aim at analyzing the resource scaling problem from an application provider's point of view such that efficient scaling decisions can be made. This paper provides two contributions to the study of resource scaling for big data streaming applications in the cloud. First, we present a Layered Multi-dimensional Hidden Markov Model (LMD-HMM) for managing time-bounded streaming applications. Second, to cater to unbounded streaming applications, we propose a framework based on a Layered Multi-dimensional Hidden Semi-Markov Model (LMD-HSMM). The parameters in our models are evaluated using modified Forward and Backward algorithms. Our detailed experimental evaluation results show that LMD-HMM is very effective with respect to cloud resource prediction for bounded streaming applications running for shorter periods while the LMD-HSMM accurately predicts the resource usage for streaming applications running for longer periods. © 2013 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Runsewe, O. and Samaan, N.",2021,IEEE Transactions on Cloud Computing,10.1109/TCC.2018.2876242,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Ojo2021559,A reliable peer-to-peer streaming protocol in low-capacity networks,"The recent global demand for video streaming applications has paved the way for peer-to-peer streaming system (P2PSS). Strategic scheduling scheme and dynamic overlay topology are essential to maintain quality of service (QoS) and quality of experience (QoE) in P2PSS. The concept of P2PSS was tailored towards relying on active peers’ bandwidth to achieve cheap and scalable means of distribution over the Internet, such that peers with highest bandwidth serve as backbones for others. However, selecting backbone peers in low-capacity network environment is challenging due to insufficient bandwidth and poor infrastructure, thereby resulting in poor QoS and unpleasant user’s QoE. In this paper, we conducted a survey on users’ experiences with live video in selected locations in Nigeria. We designed an adaptive P2P streaming protocol and performed a packet-level simulation in Network Simulator 3(NS-3). Diverse simulation scenarios were set up to evaluate the proposed streaming protocol. Trace files data were analysed to measure end-to-end delay, start-up delay, and throughput. Furthermore, the proposed streaming protocol was benchmarked against selected existing schemes. The evaluation results revealed a 7.4% and 28% reduction in start-up and in end-to-end delays and 9% increase in throughput. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ojo, O.E. and Oluwatope, A.O. and Ajadi, S.O.",2021,Peer-to-Peer Networking and Applications,10.1007/s12083-020-01002-4,scopus-search1.bib;web-of-science-search1.bib
Qi2021,A Traffic and Resource Aware Online Storm Scheduler,"Streaming applications have become widespread with the advent of big data and IoT. They are latency-sensitive applications that aim to process vast amounts of data in near real time. They are usually modelled as directed graphs and their deployment and orchestration in a cluster of nodes are managed by distributed stream processing systems. These systems are responsible for placing the graph components within the cluster nodes, which determines the application's communication overhead and ultimately affects performance metrics such as latency and throughput. This work presents an adaptive, heuristic-based, scheduling algorithm for distributed stream processing systems that aims to minimize the latency and maximize the throughput of streaming applications deployed in heterogeneous clusters, while considering the resource constraints of the available nodes. The proposed approach uses a graph partitioning algorithm and real time traffic data monitored from a deployed application to derive a near-optimal operator placement plan that minimizes inter-node communication and balances the overall communication load distribution. We evaluated our approach using three micro-benchmark and two practical applications, and the results demonstrate that our scheduler outperforms the default scheduler of a popular stream processing system and a state-of-the-art algorithm, improving throughput by up to 106% and reducing complete latency by up to 58% for most applications. © 2021 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Qi, T. and Rodriguez, M.",2021,ACM International Conference Proceeding Series,10.1145/3437378.3444365,scopus-search1.bib;acm1-search1.bib
VanDongen2021109413,Influencing Factors in the Scalability of Distributed Stream Processing Jobs,"More and more use cases require fast, accurate, and reliable processing of large volumes of data. To do this, a distributed stream processing framework is needed which can distribute the load over several machines. In this work, we study and benchmark the scalability of stream processing jobs in four popular frameworks: Flink, Kafka Streams, Spark Streaming, and Structured Streaming. Besides that, we determine the factors that influence the performance and efficiency of scaling processing jobs with distinct characteristics. We evaluate horizontal, as well as vertical scalability. Our results show how the scaling efficiency is impacted by many factors including the initial cluster layout and direction of scaling, the pipeline design, the framework design, resource allocation, and data characteristics. Finally, we give some recommendations on how practitioners should undertake to scale their clusters. © 2013 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"VanDongen, G. and VanDenPoel, D.",2021,IEEE Access,10.1109/ACCESS.2021.3102645,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Farhat2021485,Klink: Progress-Aware Scheduling for Streaming Data Systems,"Modern stream processing engines (SPEs) process large volumes of events propagated at high velocity through multiple queries. To improve performance, existing SPEs generally aim to minimize query output latency by minimizing, in turn, the propagation delay of events in query pipelines. However, for queries containing commonly used blocking operators such as windows, this scheduling approach can be inefficient. Watermarks are events popularly utilized by SPEs to correctly process window operators. Watermarks are injected into the stream to signify that no events preceding their timestamp should be further expected. Through the design and development of Klink, we leverage these watermarks to robustly infer stream progress based on window deadlines and network delay, and to schedule query pipeline execution that reflects stream progress. Klink aims to unblock window operators and to rapidly propagate events to output operators while performing judicious memory management. We integrate Klink into the popular open source SPE Apache Flink and demonstrate that Klink delivers significant performance gains over existing scheduling policies on benchmark workloads for both scale-up and scale-out deployments. © 2021 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Farhat, O. and Daudjee, K. and Querzoni, L.",2021,Proceedings of the ACM SIGMOD International Conference on Management of Data,10.1145/3448016.3452794,scopus-search1.bib;web-of-science-search1.bib;acm1-search1.bib
Sornalakshmi2021,Dynamic Auto Reconfiguration of Operator Placement in Wireless Distributed Stream Processing Systems,"The data is generated at significant speed and volume by devices in real-time. The data generation and the growth of fog and edge computing infrastructure have led to the noteworthy development of the corresponding distributed stream processing systems (DSPS). A DSPS application has Quality of Service (QoS) restrictions in terms of resource cost and time. The physical resources are distributed and heterogeneous. The resource-constrained scheduling problem has considerable implications on the performance of the system and QoS violations. The static deployment of applications in fog or edge scenario has to be monitored continuously for runtime issues, and actions have to be taken accordingly. In this paper, we propose an adaptation capability with reinforcement learning techniques to an existing stream processing framework scheduler. This functionality enables the scheduler to make decisions on its own when the system model or knowledge of the environment is not known upfront. The reinforcement learning methods adapt to the system when the system model for different states is not available. We consider applications whose workload cannot be characterized or predicted. In such applications, predictions of input load are not helpful for online scheduling. The Q-Learning based online scheduler learns to make dynamic scaling decisions at runtime when there is performance degradation. We validated the proposed approach with real-time and benchmark applications on a DSPS cluster. We obtained an average of 6% reduction in the response time and a 15% increase in the throughput when the Q Learning module is employed in the scheduler. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Sornalakshmi, K. and Vadivu, G.",2021,Wireless Personal Communications,10.1007/s11277-021-08264-y,scopus-search1.bib
Gilroy20202957,Agent-Navigable Dynamic Graph Construction and Visualization over Distributed Memory,"Some graph analyses, such as social network and biological network, need large-scale graph construction and maintenance over distributed memory space. Distributed data-streaming tools, including MapReduce and Spark, restrict some computational freedom of incremental graph modification and run-time graph visualization. Instead, we take an agent-based approach. We construct a graph from a scientific dataset in CSV, tab, and XML formats; dispatch many reactive agents on it; and analyze the graph in the form of their collective group behavior: propagation, flocking, and collision. The key to success is how to automate the run-time construction and visualization of agent-navigable graphs mapped over distributed memory. We implemented this distributed graph-computing support in the multi-agent spatial simulation (MASS) library, coupled with the Cytoscape graph visualization software. This paper presents the MASS implementation techniques and demonstrates its execution performance in comparison to MapReduce and Spark, using two benchmark programs: (1) an incremental construction of a complete graph and (2) a KD tree construction. © 2020 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Gilroy, J. and Paronyan, S. and Acoltzi, J. and Fukuda, M.",2020,"Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",10.1109/BigData50022.2020.9378298,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Hoseinyfarahabady2020,A Dynamic Resource Controller for Resolving Quality of Service Issues in Modern Streaming Processing Engines,"Devising an elastic resource allocation controller of data analytical applications in virtualized data-center has received a great attention recently, mainly due to the fact that even a slight performance improvement can translate to huge monetary savings in practical large-scale execution. Apache Flink is among modern streamed data processing run-times that can provide both low latency and high throughput computation in to execute processing pipelines over high-volume and high-velocity data-items under tight latency constraints. However, a yet to be answered challenge in a large-scale platform with tens of worker nodes is how to resolve the run-time violation in the quality of service (QoS) level in a multi-tenant data streaming platforms, particularly when the amount of workload generated by different users fluctuates. Studies showed that a static resource allocation algorithm (round-robin), which is used by default in Apache Flink, suffer from lack of responsiveness to sudden traffic surges happening unpredictably during the run-time. In this paper, we address the problem of resource management in a Flink platform for ensuring different QoS enforcement levels in a platform with shared computing resources. The proposed solution applies theoretical principals borrowed from close-loop control theory to design a CPU and memory adjustment mechanism with the primary goal to fulfill the different QoS levels requested by submitted applications while the resource interference is considered as the critical performance-limiting factor. The performance evaluation is carried out by comparing the proposed resource allocation mechanism with two static heuristics (round robin and class-based weighted fair queuing) in a 80-core cluster under multiple traffic patterns resembling sudden changes in the incoming workloads of low-priory streaming applications. The experimental results confirm the stability of the proposed controller to regulate the underlying platform resources to smoothly follow the target values (QoS violation rates). Particularly, the proposed solution can achieve higher efficiency compared to the other heuristics by reducing the response-time of high priority applications by 53% while maintaining the enforced QoS levels during the burst traffic periods. © 2020 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Hoseinyfarahabady, M.R. and Taheri, J. and Zomaya, A.Y. and Tari, Z.",2020,"2020 IEEE 19th International Symposium on Network Computing and Applications, NCA 2020",10.1109/NCA51143.2020.9306697,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Ribezzo20204477,TAPAS-360°: A Tool for the Design and Experimental Evaluation of 360° Video Streaming Systems,"Video streaming platforms are required to innovate their delivery pipeline to allow new and more immersive video content to be supported. In particular, Omnidirectional videos enable the user to explore a 360 degrees scene by moving their heads using Head Mounted Display devices. Viewport adaptive streaming allows changing dynamically the quality of the video falling in the user's field of view. In this paper, we present TAPAS-360 degrees, an open-source tool that enables designing and experimenting all the components required to build omnidirectional video streaming systems. The tool can be used by researchers focusing on the design of viewport-adaptive algorithms and also to produce video streams to be employed for subjective and objective Quality of Experience evaluations.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ribezzo, G. and DeCicco, L. and Palmisano, V. and Mascolo, S.",2020,MM 2020 - Proceedings of the 28th ACM International Conference on Multimedia,10.1145/3394171.3414541,scopus-search1.bib;web-of-science-search1.bib
Bang2020322,Docker environment based apache storm and spark benchmark test,"With the development of various technologies such as high-speed Internet and SNS dissemination, there have been many fields that require processing of big data generated in real time. Accordingly, real-time streaming data processing technology has been developed, and representative platforms include Apache Storm, Apache Spark, and Hadoop. These processing technologies provide scalability to configure distributed systems using multiple servers because they vary in performance, such as throughput and processing speed, depending on the server environment, but the more the number of servers, the more difficult it is to manage. To solve this problem, a problem can be solved by using a docker, a kind of virtualization system that provides ease of expansion. However, there is a place to maintain a native environment without using Docker due to the problem that performance may be reduced, which is a disadvantage of all virtualization systems. In this paper, we build Apache Storm and Apache Spark, which are real-time data processing systems in Docker and Native environments and conduct performance measurements through experiments processing JSON-format data to verify how much performance decreases in Docker environments. © 2020 KICS.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Bang, J. and Choi, M.-J.",2020,APNOMS 2020 - 2020 21st Asia-Pacific Network Operations and Management Symposium: Towards Service and Networking Intelligence for Humanity,10.23919/APNOMS50412.2020.9237049,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Harini20201012,Effect of Parallel Workload on Dynamic Voltage Frequency Scaling for Dark Silicon Ameliorating,"Dynamic Voltage and Frequency Scaling (DVFS) approach is proposed to control the power consumption in devices of different types like from a small mobile device to a huge server. This paper aims to study the effect of parallel execution of two benchmark applications, one the Stanford Single Source benchmarks (lightweight parallel code) and, Stanford Parallel Applications for Shared Memory (SPLASH-2) programs (heavy real-Time data streaming parallel applications that run on multi-core clusters) on DVFS for dark silicon ameliorating. Both these benchmarks executed on a gem5 Full System simulator, booting a linaro based linux kernel. To get a holistic big picture of the power and thermal properties of systems that run on DVFS, in addition to the control feature present in gem 5, a power-estimation framework used for the evaluation of the efficiency of various DVFS policies, the MCPAT and Hotspot is also employed. Based on the execution of Stanford workloads DVFS model is analyzed in terms of memory footprint and on other critical processor performance metrics, like running time per core, bus latency, number of read, writes, access time, cache hit or miss. The gem5 is extended with full DVFS support by the addition of a framework in which easy power-model integration can be done.. © 2020 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Harini, S. and Ravikumar, A.",2020,"Proceedings - International Conference on Smart Electronics and Communication, ICOSEC 2020",10.1109/ICOSEC49089.2020.9215262,scopus-search1.bib;ieee3-search1.bib
Zhang20207156,Dynamic Component Placement and Request Scheduling for IoT Big Data Streaming,"Internet-of-Things (IoT) big data streaming applications, such as video surveillance and automatic driving, tend to use mobile-edge computing (MEC) infrastructure to enhance their performance and augment their functionalities. Although extensive previous studies have worked on offloading requests to MEC servers, none of them has comprehensively and thoroughly considered the important features of IoT data streaming applications (i.e., component dependency and dynamic arrival) and the infrastructure provisioning (i.e., capacity constraint and colocation interference). In this article, we consider the offloading problem for dynamically arrived IoT data streaming requests on MEC servers in real time. We model it as a delay-sensitive multiuser multiresource online offloading problem respecting component dependency and capacity constraint. The problem is NP-hard with offloading decisions coupling together. To solve it, we decouple the problem into component placement problem and request scheduling problem and propose a two-stage DPGPD algorithm with polynomial time complexity. We show the first stage dynamic programming (DP) algorithm is the optimal solution and the second-stage greedy primal–dual (GPD) algorithm is asymptotic optimal. The simulation results show that our solution is effective yet efficient compared to benchmark solutions. (DP provides the optimal placement layout with $12 \times $ less decision time of Gurobi; and GPD provides the asymptotic optimal scheduling with $5 \times $ less average waiting time compared to least work left (LWL) in heavy workload.) We implement a dedicated prototype and exploit several representative big data streaming applications to evaluate it. Lab-scale experiment shows that our solution can provide over $3 \times $ less total completion time compared to local execution.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zhang, Y. and Yan, J. and Pu, L. and Chen, S.",2020,IEEE Internet of Things Journal,10.1109/JIOT.2020.2982458,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Presser202039,EdgeScaler: Effective elastic scaling for graph stream processing systems,"Existing solutions for elastic scaling perform poorly with graph stream processing for two key reasons. First, when the system is scaled, the graph must be dynamically re-partitioned among workers. This requires a partitioning algorithm that is fast and offers good locality, a task that is far from being trivial. Second, existing modelling techniques for distributed graph processing systems only consider hash partitioning, and do not leverage the semantic knowledge used by more efficient partitioners. In this paper we propose EdgeScaler, an elastic scaler for graph stream processing systems that tackles these challenges by employing, in a synergistic way, two innovative techniques: MicroMacroSplitter and AccuLocal. MicroMacroSplitter is a new edge-based graph partitioning strategy that is as fast as simple hash partinioners, while achieving quality comparable to the best state-of-the-art solutions. AccuLocal is a novel performance model that takes the partitioner features into account while avoiding expensive off-line training phases. An extensive experimental evaluation offers insights on the effectiveness of the proposed mechanisms and shows that EdgeScaler is able to significantly outperform existing solutions designed for generic stream processing systems. © 2020 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Presser, D. and Siqueira, F. and Rodrigues, L. and Romano, P.",2020,DEBS 2020 - Proceedings of the 14th ACM International Conference on Distributed and Event-Based Systems,10.1145/3401025.3401734,scopus-search1.bib;acm1-search1.bib
Weißbach2020138,Performance analysis of continuous binary data processing using distributed databases within stream processing environments,"Big data applications must process increasingly large amounts of data within ever shorter time. Often a stream processing engine (SPE) is used to process incoming data with minimal latency. While these engines are designed to process data quickly, they are not made to persist and manage it. Thus, databases are still integrated into streaming architectures, which often becomes a performance bottleneck. To overcome this issue and achieve maximum performance, all system components used must be examined in terms of their throughput and latency, and how well they interact with each other. Several authors have already analyzed the performance of popular distributed database systems. While doing so, we focus on the interaction between the SPEs and the databases, as we assume that stream processing leads to changes in the access patterns to the databases. Moreover, our main focus is on the efficient storing and loading of binary data objects rather than typed data, since in our use cases the actual data analysis is not to be performed by the database, but by the SPE.We've benchmarked common databases within streaming environments to determine which software combination is best suited for these requirements. Our results show that the database performance differs significantly depending on the access pattern used and that different software combinations lead to substantial performance differences. Depending on the access pattern, Cassandra, MongoDB and PostgreSQL achieved the best throughputs, which were mostly the highest when Apache Flink was used. © Copyright 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Weißbach, M. and Hilbert, H. and Springer, T.",2020,CLOSER 2020 - Proceedings of the 10th International Conference on Cloud Computing and Services Science,10.5220/0009413301380149,scopus-search1.bib;web-of-science-search1.bib;scholar.bib
Twaty20193744,GraphOpt: A Framework for Automatic Parameters Tuning of Graph Processing Frameworks,"Finding the optimal configuration of a black-box system is a difficult problem that requires a lot of time and human labor. Big data processing frameworks are among the increasingly popular systems whose tuning is a complex and time consuming. The challenge of automatically finding the optimal parameters of big data frameworks attracted a lot of research in recent years. Some of the studies focused on optimizing specific frameworks such as distributed stream processing [1], [2], or finding the best cloud configurations [3], while others proposed general services for optimizing any black-box system [4]. In this paper, we introduce a new use case in the domain of automatic parameter tuning: optimizing the parameters of distributed graph processing frameworks. This task is notably difficult given the particular challenges of distributed graph processing that include the graph partitioning and the iterative nature of graph algorithms. To address this challenge, we designed and implemented GraphOpt: an efficient and scalable black-box optimization framework that automatically tunes distributed graph processing frameworks. GraphOpt implements state-of-the-art optimization algorithms and introduces a new hill-climbing-based search algorithm. These algorithms are used to optimize the performance of two major graph processing frameworks: Giraph and GraphX. Extensive experiments were run on GraphOpt using multiple graph benchmarks to evaluate its performance and show that it provides up to 47.8% improvement compared to random search and an average improvement of up to 5.7%. © 2019 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Twaty, M. and Ghrab, A. and Skhiri, S.",2019,"Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019",10.1109/BigData47090.2019.9006320,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Katragadda2019,Vastream: A visual analytics system for fast data streams,"Processing high-volume, high-velocity data streams is an important big data problem in many sciences, engineering, and technology domains. There are many open-source distributed stream processing and cloud platforms that offer low-latency stream processing at scale, but the visualization and user-interaction components of these systems are limited to visualizing the outcome of stream processing results. Visual analysis represents a new form of analysis where the user has more control and interactive capabilities either to dynamically change the visualization, analytics or data management processes. VAStream provides an environment for big data stream processing along with interactive visualization capabilities. The system environment consists of hardware and software modules to optimize streaming data workflow (that includes data ingest, pre-processing, analytics, visualization, and collaboration components). The system environment is evaluated for two real-time streaming applications. The real-time event detection using social media streams uses text data arriving from sources such as Twitter to detect emerging events of interest. The real-time river sensor network analysis project uses unsupervised classification methods to classify sensor network streams arriving from the US river network to detect water quality problems. We discuss implementation details and provide performance comparison results of various individual stream processing operations for both stream processing applications. © 2019 Association for Computing Machinery. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Katragadda, S. and Gottumukkala, R. and Venna, S. and Lipari, N. and Gaikwad, S. and Pusala, M. and Chen, J. and Borst, C.W. and Raghavan, V. and Bayoumi, M.",2019,ACM International Conference Proceeding Series,10.1145/3332186.3332256,scopus-search1.bib;web-of-science-search1.bib;acm1-search1.bib
Mytilinis201973,Maintaining wavelet synopses for sliding-window aggregates,"The IoT era has brought forth a computing paradigm shift from traditional high-end servers to “edge” devices of limited processing and memory capabilities. These devices, together with sensors, regularly produce very high data volumes nowadays. For many real-time applications, storing and indexing an unbounded stream may not be an option. Thus, it is important that we design algorithms and systems that can both work at the edge of the network and be able to answer queries on distributed, streaming data. Moreover, in many streaming scenarios, fresh data tend to be prioritized. A sliding-window model is an important case of stream processing, where only the most recent elements remain active and the rest are discarded. In this work, we study the problem of maintaining basic aggregate statistics over a sliding-window data stream under the constraint of limited memory. As in IoT scenarios the available memory is typically much less than the window size, queries are answered from compact synopses that are maintained in an on-line fashion. For the efficient construction of such synopses, in this work, we propose wavelet-based algorithms that provide deterministic guarantees and produce almost exact results. Our algorithms can work on any kind of numerical data and do not have the positive-numbers constraint of techniques such as the exponential histograms. Our experimental evaluation indicates that, in terms of accuracy and space-efficiency, our solution outperforms the exponential histograms and deterministic waves techniques. © 2019 Association for Computing Machinery.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Mytilinis, I. and Tsoumakos, D. and Koziris, N.",2019,ACM International Conference Proceeding Series,10.1145/3335783.3335793,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Fang2019762,A United Framework for Large-Scale Resource Description Framework Stream Processing,"Resource description framework (RDF) stream is useful to model spatio-temporal data. In this paper, we propose a framework for large-scale RDF stream processing, LRSP, to process general continuous queries over large-scale RDF streams. Firstly, we propose a formalization (named CT-SPARQL) to represent the general continuous queries in a unified, unambiguous way. Secondly, based on our formalization we propose LRSP to process continuous queries in a common white-box way by separating RDF stream processing, query parsing, and query execution. Finally, we implement and evaluate LRSP with those popular continuous query engines on some benchmark datasets and real-world datasets. Due to the architecture of LRSP, many efficient query engines (including centralized and distributed engines) for RDF can be directly employed to process continuous queries. The experimental results show that LRSP has a higher performance, specially, in processing large-scale real-world data. © 2019, Springer Science+Business Media, LLC & Science Press, China.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Fang, H. and Zhao, B. and Zhang, X.-W. and Yang, X.-X.",2019,Journal of Computer Science and Technology,10.1007/s11390-019-1941-9,scopus-search1.bib;web-of-science-search1.bib
Gokalgandhi2019596,Distributed Processing for Encoding and Decoding of Binary LDPC codes using MPI,"Low Density Parity Check (LDPC) codes are linear error correcting codes used in communication systems for Forward Error Correction (FEC). But, intensive computation is required for encoding and decoding of LDPC codes, making it difficult for practical usage in general purpose software based signal processing systems. In order to accelerate the encoding and decoding of LDPC codes, distributed processing over multiple multi-core CPUs using Message Passing Interface (MPI) is performed. Implementation is done using Stream Processing and Batch Processing mechanisms and the execution time for both implementations is compared w.r.t variation in number of CPUs and number of cores per CPU. Performance evaluation of distributed processing is shown by variation in execution time w.r.t. increase in number of processors (CPU cores). © 2019 IEEE.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Gokalgandhi, B. and Seskar, I.",2019,"INFOCOM 2019 - IEEE Conference on Computer Communications Workshops, INFOCOM WKSHPS 2019",10.1109/INFCOMW.2019.8845079,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Al-Sayeh2019117,Gray box modeling methodology for runtime prediction of apache spark jobs,"Nowadays, many data centers facilitate data processing and acquisition by developing multiple Apache Spark jobs which can be executed in private clouds with various parameters. Each job might take various application parameters which influence its execution time. Some examples of application parameters can be a selected area of interest in spatiotemporal data processing application or a time range of events in a complex event stream processing application. To predict its runtime accurately, these application parameters shall be considered during constructing its runtime model. Runtime prediction of Spark jobs allows us to schedule them efficiently in order to utilize cloud resources, increase system throughput, reduce job latency and meet customers requirements, e.g. deadlines and QoS. Also, the prediction is considered as important advantage when using a pay-as-you-go pricing model. In this paper, we present a gray box modeling methodology for runtime prediction of each individual Apache Spark job in two steps. The first one is building a white box model for predicting the input RDD size of each stage relying on prior knowledge about its behaviour and taking the application parameters into consideration. The second one is extracting a black box runtime model of each task by observing its runtime metrics according to various allocated resources and variant input RDD sizes. The modeling methodology is validated with experimental evaluation on a real-world application, and the results show a high matching accuracy which reached 83-94% of the actual runtime of the tested application. © 2019 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Al-Sayeh, H. and Sattler, K.-U.",2019,"Proceedings - 2019 IEEE 35th International Conference on Data Engineering Workshops, ICDEW 2019",10.1109/ICDEW.2019.00-23,scopus-search1.bib;ieee1-search1.bib
Zalhan2019,Marrying big data with smart data in sensor stream processing,"Widespread deployments of spatially distributed sensors are continuously generating data that require advanced analytical processing and interpretation by machines. Devising machine-interpretable descriptions of sensor data is a key issue in building a semantic stream processing engine. This paper proposes a semantic sensor stream processing pipeline using Apache Kafka to publish and subscribe semantic data streams in a scalable way. We use the Kafka Consumer API to annotate the sensor data using the Semantic Sensor Network ontology, then store the annotated output in an RDF triplestore for further reasoning or semantic integration with legacy information systems. We follow a Design Science approach addressing a Smart Airport scenario with geolocated audio sensors to evaluate the viability of the proposed pipeline under various Kafka-based configurations. Our experimental evaluations show that the multi-broker Kafka cluster setup supports read scalability thus facilitating the parallelization of the semantic enrichment of the sensor data. © ISD 2019. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zalhan, P.-G. and Silaghi, G.C. and Buchmann, R.A.",2019,"Proceedings of the 28th International Conference on Information Systems Development: Information Systems Beyond 2020, ISD 2019",,scopus-search1.bib
Pieters2019133,Faster coroutine pipelines: A reconstruction,"Spivey has recently presented a novel functional representation that supports the efficient composition, or merging, of coroutine pipelines for processing streams of data. This representation was inspired by Shivers and Might’s three-continuation approach and is shown to be equivalent to a simple yet inefficient executable specification. Unfortunately, neither Shivers and Might’s original work nor the equivalence proof sheds much light on the underlying principles allowing the derivation of this efficient representation from its specification. This paper gives the missing insight by reconstructing a systematic derivation in terms of known transformation steps from the simple specification to the efficient representation. This derivation sheds light on the limitations of the representation and on its applicability to other settings. In particular, it has enabled us to obtain a similar representation for pipes featuring two-way communication, similar to the Haskell pipes library. Our benchmarks confirm that this two-way representation retains the same improved performance characteristics. © Springer Nature Switzerland AG 2019.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Pieters, R.P. and Schrijvers, T.",2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-030-05998-9_9,scopus-search1.bib;scopus-search1.bib;web-of-science-search1.bib;web-of-science-search1.bib
Zhou201835,A real-time sensor network aggregation computing system,"With the advent of Cloud Era, real-time streaming data processing applications are used more and more widely. As a concrete example, real-time queries on a large number of sensors are highly demanding and needs to be carefully designed. Sensor monitoring analysts are inexperienced on coding techniques in spite of the rapid development of real-time processing platforms and communities. What's more, the state-of-the-art systems lacks support for multi-query processing and sharing of the original data and results with prior information of the queries. To tackle the challenges, we endeavor to design a light-weight but effective scheme to support multiple queries running on a large number of sensors. We focus on aggregations on sliding windows due to its practical importance, and hence design a query language, SAQL, for the professional analysts to construct their own streaming computational logic. We also propose the whole system, SAQS, which can interpret SAQL into stream processing programs and support the efficient execution of multiple queries in a distributed real-time environment. SAQS can detect the data sharing at different granularity and uses a greedy partition algorithm to balance the load among worker nodes. Our extensive experimental evaluations establish the convenience and efficiency of SAQS. © 2018 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zhou, Y. and Wang, P. and Wang, W.",2018,"Proceedings - 5th IEEE International Conference on Cyber Security and Cloud Computing and 4th IEEE International Conference on Edge Computing and Scalable Cloud, CSCloud/EdgeCom 2018",10.1109/CSCloud/EdgeCom.2018.00016,scopus-search1.bib
Hoseinyfarahabady2018554,Elastic CPU cap mechanism for timely dataflow applications,"Sudden surges in the incoming workload can cause adverse consequences on the run-time performance of data-flow applications. Our work addresses the problem of limiting CPU associated with the elastic scaling of timely data-flow (TDF) applications running in a shared computing environment while each application can possess a different quality of service (QoS) requirement. The key argument here is that an unwise consolidation decision to dynamically scale up/out the computing resources for responding to unexpected workload changes can degrade the performance of some (if not all) collocated applications due to their fierce competition getting the shared resources (such as the last level cache). The proposed solution uses a queue-based model to predict the performance degradation of running data-flow applications together. The problem of CPU cap adjustment is addressed as an optimization problem, where the aim is to reduce the quality of service violation incidents among applications while raising the CPU utilization level of server nodes as well as preventing the formation of bottlenecks due to the fierce competition among collocated applications. The controller uses and efficient dynamic method to find a solution at each round of the controlling epoch. The performance evaluation is carried out by comparing the proposed controller against an enhanced QoS-aware version of round robin strategy which is deployed in many commercial packages. Experimental results confirmed that the proposed solution improves QoS satisfaction by near to 148% on average while it can reduce the latency of processing data records for applications in the highest QoS classes by near to 19% during workload surges. © Springer International Publishing AG, part of Springer Nature 2018.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Hoseinyfarahabady, M.R. and Farhangsadr, N. and Zomaya, A.Y. and Tari, Z. and Khan, S.U.",2018,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-93698-7_42,scopus-search1.bib;web-of-science-search1.bib
Yang2018141,Scalability and state: A critical assessment of throughput obtainable on big data streaming frameworks for applications with and without state information,"Emerging Big Data streaming applications are facing unbounded (infinite) data sets at a scale of millions of events per second. The information captured in a single event, e.g., GPS position information of mobile phone users, loses value (perishes) over time and requires sub-second latency responses. Conventional Cloud-based batch-processing platforms are inadequate to meet these constraints. Existing streaming engines exhibit low throughput and are thus equally ill-suited for emerging Big Data streaming applications. To validate this claim, we evaluated the Yahoo streaming benchmark and our own real-time trend detector on three state-of-the-art streaming engines: Apache Storm, Apache Flink and Spark Streaming. We adapted the Kieker dynamic profiling framework to gather accurate profiling information on the throughput and CPU utilization exhibited by the two benchmarks on the Google Compute Engine. To estimate the performance overhead incurred by current streaming engines, we re-implemented our Java-based trend detector as a multi-threaded, shared-memory application in C++. The achieved throughput of 3.2 million events per second on a stand-alone 2 CPU (44 cores) Intel Xeon E5-2699 v4 server is 44 times higher than the maximum throughput achieved with the Apache Storm version of the trend detector deployed on 30 virtual machines (nodes) in the Cloud. Our experiment suggests vertical scaling as a viable alternative to horizontal scaling, especially if shared state has to be maintained in a streaming application. For reproducibility, we have open-sourced our framework configurations on GitHub [1]. © Springer International Publishing AG, part of Springer Nature 2018.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Yang, S. and Jeong, Y. and Hong, C. and Jun, H. and Burgstaller, B.",2018,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-75178-8_12,scopus-search1.bib;web-of-science-search1.bib
Walulya2018129,Viper: Communication-layer determinism and scaling in low-latency stream processing,"Stream Processing Engines (SPEs) process continuous streams of data and produce up-to-date results in a real-time fashion, typically through one-at-a-time tuple analysis. When looking into the vital SPE processing properties required from applications, determinism has a strong position besides scalability in throughput and low processing latency. SPEs scale in throughput and latency by relying on shared-nothing parallelism, deploying multiple copies of each operator to which tuples are distributed based on the semantics of the operator. The coordination of the asynchronous analysis of parallel operators required to enforce determinism is then carried out by additional dedicated sorting operators. In this work we shift such costly coordination to the communication layer of the SPE. Specifically, we extend earlier work on shared-memory implementations of deterministic operators and provide a communication module (Viper) which can be integrated in the SPE communication layer. Using Apache Storm and the Linear Road benchmark, we show the benefits that can be achieved by our approach in terms of throughput and energy efficiency of SPEs implementing one-at-a-time analysis. © Springer International Publishing AG, part of Springer Nature 2018.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Walulya, I. and Nikolakopoulos, Y. and Gulisano, V. and Papatriantafilou, M. and Tsigas, P.",2018,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-75178-8_11,scopus-search1.bib;web-of-science-search1.bib
Chakraborty201721,Priority based resource scheduling techniques for a resource constrained stream processing system,"A multitenant Storm cluster runs multiple stream processing applications and uses the default Isolation Scheduler to schedule them. Isolation Scheduler assigns resources to topologies based on static resource configuration and does not provide any means for prioritizing topologies based on their varying business requirements. Thus, performance degradation, even complete starvation of topologies with high priority is possible when the cluster is resource constrained and comprises an inadequate number of resources. Two priority based resource scheduling techniques are proposed to overcome these problems. A performance analysis based on prototyping and measurements demonstrates the effectiveness of the proposed techniques. © 2017 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Chakraborty, R. and Majumdar, S.",2017,"BDCAT 2017 - Proceedings of the 4th IEEE/ACM International Conference on Big Data Computing, Applications and Technologies",10.1145/3148055.3148066,scopus-search1.bib;web-of-science-search1.bib
Wang2017497,Performance evaluation of parallelizing algorithm using spanning tree for stream-based computing,"This paper proposes a detailed performance evaluation of an algorithm using spanning tree that automatically exploits the parallelism and determines an execution order of multiple kernel programs in distributed environment. In stream-based computing, efficient parallel execution requires careful scheduling of the invocation of the kernel programs. By mapping a kernel to a node and an I/O stream between kernels to an edge, the entire stream process can be treated as a spanning tree. The spanning tree, which allows feedback and feedforward edges, is effective for expressing dependencies that exist among kernels. In spanning tree, the nodes at the same depth do not have edges between them, and thus can be executed in parallel in the case parent nodes have been already executed. The series of the nodes can be executed in a pipelined manner. Thus, the proposed algorithm can extract both spatial and temporal parallelism. To evaluate the effectiveness of the proposed algorithm, two applications have been developed and parallelized based on the proposed algorithm. The results show that the parallel execution using four nodes of a GPU cluster obtained 3.5 times speedup in 2D-FFT and 3.0 times speedup in LU decomposition, compared to the sequential execution. © 2016 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Wang, G. and Wada, K. and Yamagiwa, S.",2016,"Proceedings - 2016 4th International Symposium on Computing and Networking, CANDAR 2016",10.1109/CANDAR.2016.62,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Schäfer2017289,Benchmarking univariate time series classifiers,"Time series are a collection of values sequentially recorded over time. Nowadays, sensors for recording time series are omnipresent as RFID chips, wearables, smart homes, or event-based systems. Time series classification aims at predicting a class label for a time series whose label is unknown. Therefore, a classifier has to train a model using labeled samples. Classification time is a key challenge given new applications like event-based monitoring, real-time decision or streaming systems. This paper is the first benchmark that compares 12 state of the art time series classifiers based on prediction and classification times. We observed that most of the state-of-the-art classifiers require extensive train and classification times, and might not be applicable for these new applications. © 2017 Gesellschaft fur Informatik (GI). All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Schäfer, P. and Leser, U.",2017,"Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)",,scopus-search1.bib
Sahni2017399,Scalable online analytics on cloud infrastructures,"The need for low latency analysis of high velocity real time continuous data streams has led to the emergence of Stream Processing Systems (SPSs). Contemporary SPSs allow a stream processing application to be hosted on Cloud infrastructures and dynamically scaled so as to adapt to the fluctuating data rates. However, the run time scalability incorporated in these SPSs are in their early adaptations and are based on simple local/global threshold based controls. This work studies the issues with the local and global auto scaling techniques that may lead to performance inefficiencies in real time traffic analysis on Cloud platforms and presents an efficient hybrid auto scaling strategy StreamScale which addresses the identified issues. The proposed StreamScale auto-scaling algorithm accounts for the gaps in the local/global scaling approaches and effectively identifies (de)parallelization opportunities in stream processing applications for maintaining QoS at reduced costs. Simulation based experimental evaluation on representative stream application topologies indicate that the proposed StreamScale auto-scaling algorithm exhibits better performance in comparison to both local and global auto-scaling approaches. © Springer Nature Singapore Pte Ltd. 2017.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Sahni, J. and Vidyarthi, D.P.",2017,Communications in Computer and Information Science,10.1007/978-981-10-5427-3_43,scopus-search1.bib;web-of-science-search1.bib
Zacheilas201719,DIsCO: Dynamic data compression in distributed stream processing systems,"Supporting high throughput in Distributed Stream Processing Systems (DSPSs) has been an important goal in recent years. Current works either focus on automatically increasing the system resources whenever the current setup is inadequate or apply load shedding techniques discarding some of the incoming data. However, both approaches have significant shortcomings as they require on the fly application reconfiguration where the application needs to be stopped and re-uploaded in the cluster with the new configurations, and can lead to significant information loss. One approach that has not yet been considered for improving the throughput of DSPSs is exploiting compression algorithms to minimize the communication overhead between components especially in cases where we have large-sized data like live CCTV camera reports. This work is the first that provides a novel framework, built on top of Apache Storm, which enables dynamic compression of incoming streaming data. Our approach uses a profiling algorithm to automatically determine the compression algorithm that should be applied and supports both lossless and lossy compression techniques. Furthermore, we propose a novel algorithm for determining when profiling should be applied. Finally, our detailed experimental evaluation with commonly used stream processing applications, indicates a clear improvement on the applications’ throughput when our proposed techniques are applied. © IFIP International Federation for Information Processing 2017.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Zacheilas, N. and Kalogeraki, V.",2017,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-59665-5_2,scopus-search1.bib;web-of-science-search1.bib
Simmhan201621,Benchmarking fast-data platforms for the aadhaar biometric database,"Aadhaar is the world’s largest biometric database with a billion records, being compiled as an identity platform to deliver social services to residents of India. Aadhaar processes streams of biometric data as residents are enrolled and updated. Besides ∼1 million enrollments and updates per day, up to 100 million daily biometric authentications are expected during delivery of various public services. These form critical Big Data applications, with large volumes and high velocity of data. Here, we propose a stream processing workload, based on the Aadhaar enrollment and Authentication applications, as a Big Data benchmark for distributed stream processing systems. We describe the application composition, and characterize their task latencies and selectivity, and data rate and size distributions, based on real observations. We also validate this benchmark on Apache Storm using synthetic streams and simulated application logic. This paper offers a unique glimpse into an operational national identity infrastructure, and proposes a benchmark for “fast data” platforms to support such eGovernance applications. © Springer International Publishing AG 2016.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Simmhan, Y. and Shukla, A. and Verma, A.",2016,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-49748-8_2,scopus-search1.bib
Gradvohl2016143,Investigating metrics to build a benchmark tool for complex event processing systems,"Despite companies' demand for data streams processing systems to handle large volumes of flowing data, we did not find many software to assess these sort of systems. In fact, up to date, there are few papers proposing metrics to evaluate these systems or describing software for benchmarks. Most of the papers focus on metrics such as throughput, latency and memory consumption. However, there are other metrics, which system administrators and users should consider, such as information latency, the correctness of results, adaptability on different workloads and others. Therefore, in this paper, we summarized some key metrics used to assess systems for processing online data streams. In addition, we discuss three benchmark tools found in the literature to assess this type of system. At the end of this paper, we propose a new benchmark tool for complex event processing distributed systems called B2-4CEP, which incorporate the metrics described in this paper. © 2016 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Gradvohl, and A.L.S.,",2016,"Proceedings - 2016 4th International Conference on Future Internet of Things and Cloud Workshops, W-FiCloud 2016",10.1109/W-FiCloud.2016.40,scopus-search1.bib
Zaichenkov2016,The cost and benefits of coordination programming: Two case studies in concurrent collections and S-NET,"This is an evaluation study of the expressiveness provided and the performance delivered by the coordination language S-NET in comparison to Intel's Concurrent Collections (CnC). An S-NET application is a network of black-box compute components connected through anonymous data streams, with the standard input and output streams linking the application to the environment. Our case study is based on two applications: a face detection algorithm implemented as a pipeline of feature classifiers and a numerical algorithm from the linear algebra domain, namely Cholesky decomposition. The selected applications are representative and have been selected by Intel researchers as evaluation testbeds for CnC in the past. We implement various versions of both algorithms in S-NET and compare them with equivalent CnC implementations, both with and without tuning, previously published by the CnC community. Our experiments on a large-scale server system demonstrate that S-Net delivers very similar scalability and absolute performance on the studied examples as tuned CnC codes do, even without specific tuning. At the same time, S-Net does achieve a much more complete separation of concerns between compute and coordination layers than CnC even intends to. © 2016 World Scientific Publishing Company.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zaichenkov, P. and Tveretina, O. and Shafarenko, A. and Gijsbers, B. and Grelck, C.",2016,Parallel Processing Letters,10.1142/S0129626416500110,scopus-search1.bib
Vögler2016190,Non-intrusive monitoring of stream processing applications,"Stream processing applications have emerged as a popular way for implementing high-volume data processing tasks. In contrast to traditional data processing models that persist data to databases and then execute queries on the stored data, stream processing applications continuously execute complex queries on incoming data to produce timely results in reaction to events observed in the processed data. To cope with the request load, components of a stream processing application are usually distributed across multiple machines. In this context, performance monitoring and testing are naturally important for stakeholders to understand as well as analyze the runtime characteristics of deployed applications to identify issues and inform decisions. Existing approaches for monitoring the performance of distributed systems, however, do not provide sufficient support for targeted monitoring of stream processing applications, and require changes to the application code to enable the integration of application-specific monitoring data. In this paper we present MOSAIC, a service oriented framework that allows for in-depth analysis of stream processing applications by non-intrusively adding functionality for acquiring and publishing performance measurements at runtime, to the application. Furthermore, MOSAIC provides a flexible mechanism for integrating different stream processing frameworks, which can be used for executing and monitoring applications independent from a specific operator model. Additionally, our framework provides an extensible approach for gathering and analyzing measurement data. In order to evaluate our solution, we developed a scenario application, which we used for testing and monitoring its performance on different stream processing engines. © 2016 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Vögler, M. and Schleicher, J.M. and Inzinger, C. and Nickel, B. and Dustdar, S.",2016,"Proceedings - 2016 IEEE Symposium on Service-Oriented System Engineering, SOSE 2016",10.1109/SOSE.2016.11,scopus-search1.bib
Maamar20161769,A performance evaluation of mobility management and multihop supplying partner strategies for 3D streaming systems over thin mobile devices,"The recent advances in technology and mobile computing led to the rapid growth of networked 3D streaming applications. The emerging services can involve augmented reality, virtual environment walkthrough, multiplayer gaming just to mention a few. Because of the limited network bandwidth of the client-server approach, research works are now turning toward mobile ad hoc networks-based streaming, where the resources of each peer are used during the streaming service. Peer-to-peer technologies are considering the solution to adapt for scalable applications. Yet, supplying partner selection and 3D data delivery are still significant challenges to face because of the dynamic wireless environment that causes link breakages, high packet loss, an adverse impact on the quality of the 3D media, and a low user satisfaction. In this paper, we propose a supplying partner selection technique coupled with a content delivery technique for peer-to-peer 3D streaming over thin mobile devices. Our proposed protocol, which we refer to as MULTIPLY, considers multihop suppliers in order to alleviate the load on the server and uses the signal strength measurement to analyze the wireless link when sending back the 3D data. Given the high dynamicity of the network due to the mobility of the users, the streaming can be greatly affected. We therefore study the impact of the mobility on MULTIPLY. The performance evaluation of our protocol obtained using an extensive set of simulation experiments is then reported. Copyright (C) 2013 John Wiley \& Sons, Ltd.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Maamar, H.R. and Boukerche, A. and Petriu, E.",2016,Concurrency and Computation: Practice and Experience,10.1002/cpe.3106,scopus-search1.bib;web-of-science-search1.bib
Rattanaopas2016,Performance analysis of a multi-tier video on demand service on virtualization platforms,"Cloud computing technology, especially virtualization is employed in many data centers nowadays. The key concept of virtualization concerns elastic or scalable infrastructure. This concept can be implemented by exploiting multi-tier web applications and hypervisors which are virtual machine management software. Xen hypervisor has presented its Version 4.4 in 2014. In this paper, we present the performance analysis comparison between Xen para-virtualization and KVM full virtualization on the case study of open source video streaming called Cumulusclips, a YouTube-like system. This investigation involves real workload mp4 video streaming on 200 clients' browser, running 3 experiments, including large video files (similar to 3 GB), small video files (similar to 120 MB) and random-size video files (the ratio of large and small video files is 25%/75%). The requests size results show that Xen para-virtualization can serve all requests better than KVM full virtualization and use less resource. Xen's performance is dropped when CPU usage is 100% in Experiment 1 (large files). In Experiments 2 (small files) and 3 (random-size files), Xen's CPU usage is under 10%, but KVM's CPU usage is over 50%. The requests size results of Xen and KVM are equal in Experiment 2, but Xen has the maximum throughput about a half (51%) of KVM's. Therefore, we can conclude that Xen paravirtualization has better performance than KVM full virtualization on multi-tier video streaming system.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Rattanaopas, K. and Tandayya, P.",2015,ICSEC 2015 - 19th International Computer Science and Engineering Conference: Hybrid Cloud Computing: A New Approach for Big Data Era,10.1109/ICSEC.2015.7401437,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Rafailidis20152836,Indexing media storms on Flink,"We propose a media storm indexing algorithm using Map-Reduce in our recently proposed CDVC framework. In this study, CDVC is built on Flink, an open-source platform for stream data processing. The question we answer is how to store massive image collections; for instance, with over one million images per second, as well as with varying incoming rate. In our experiments with two benchmark datasets of 80M and 1B image descriptors, we evaluate the proposed algorithm on different indexing workloads, that is, images that come with high volume and different velocity at the scale of 105-106 images per second. Using a limited set of computational nodes, we show that we achieve a significant speed up factor of nine, on average, compared to conventional indexing techniques, in all settings. Finally, we make our source code publicly available. © 2015 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Rafailidis, D. and Antaris, S.",2015,"Proceedings - 2015 IEEE International Conference on Big Data, IEEE Big Data 2015",10.1109/BigData.2015.7364094,scopus-search1.bib;web-of-science-search1.bib
Dilawari20131878,Optimal flow splitting for multi-path multi-interface wireless data streaming networks,"We propose optimal flow splitting for wireless data streaming networks consisting of nodes that are equipped with more than one wireless communication interface. The objective is to efficiently distribute data traffic among multiple wireless interfaces, leveraging an additional axis of freedom capable of providing improved performance. For that purpose a distributed framework based on convex optimization is developed that achieves optimal resource utilization for multi-interface multi-path network configuration. Although flow splitting can be performed using single wireless interface, our performance evaluation results show an improved performance when employing multiple wireless interfaces. Performance evaluation results reveal that 50% energy saving can be achieved when using optimal flow splitting for dual interface compared to single interface node architecture. In addition, the proposed solution is inherently robust to link outages due to the availability of multiple wireless interfaces. The proposed framework is quite flexible and can be easily extended to integrate any other performance parameters of interest. © 2013 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Dilawari, A. and Tahir, M.",2013,"IEEE International Symposium on Personal, Indoor and Mobile Radio Communications, PIMRC",10.1109/PIMRC.2013.6666449,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Allani2013423,Hyphen: A hybrid protocol for generic overlay construction in P2P environments,"Overlay networks form the core part of peer-to-peer (P2P) applications such as application-level multicast, content distribution and media streaming. To ease development, middleware solutions and toolkit libraries have been proposed in the past to help with the implementation of overlay networks. Existing solutions, however, are either too generic by only providing low-level communication abstractions, requiring developers to implement algorithms for overlay networks from scratch, or too restrictive by only supporting a particular overlay topology with fixed properties. In this paper, we argue that it is possible to find a middle ground between these two extremes. We describe Hyphen, a middleware for overlay construction and maintenance that supports a range of overlay topologies with custom properties, and show how it can replace topology construction for a variety of application-level multicast systems. Unlike previous efforts, Hyphen can construct and maintain a range of overlay topologies such as trees and forests with specific optimisation goals such as low latency or high bandwidth. By using a gossip-based mechanism to define topologies implicitly, Hyphen can scale to many peers and achieve low construction overhead. Our experimental evaluation with Bullet and Splitstream, two P2P streaming systems, shows that Hyphen can construct a bandwidth-optimised tree for Bullet that achieves a higher streaming rate than the original Bullet implementation, and that it can construct a more reliable forest for Splitstream by taking individual peer reliability into account. Copyright 2013 ACM.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Allani, M. and Garbinato, B. and Pietzuch, P.",2013,Proceedings of the ACM Symposium on Applied Computing,10.1145/2480362.2480448,scopus-search1.bib
Fernandez201311,Scalable and fault-tolerant stateful stream processing,"As users of ""big data"" applications expect fresh results, we witness a new breed of stream processing systems (SPS) that are designed to scale to large numbers of cloud-hosted machines. Such systems face new challenges: (i) to benefit from the ""pay-as-you-go"" model of cloud computing, they must scale out on demand, acquiring additional virtual machines (VMs) and parallelising operators when the workload increases; (ii) failures are common with deployments on hundreds of VMs-systems must be fault-tolerant with fast recovery times, yet low per-machine overheads. An open question is how to achieve these two goals when stream queries include stateful operators, which must be scaled out and recovered without affecting query results. Our key idea is to expose internal operator state explicitly to the SPS through a set of state management primitives. Based on them, we describe an integrated approach for dynamic scale out and recovery of stateful operators. Externalised operator state is checkpointed periodically by the SPS and backed up to upstream VMs. The SPS identifies individual operator bottlenecks and automatically scales them out by allocating new VMs and partitioning the checkpointed state. At any point, failed operators are recovered by restoring checkpointed state on a new VM and replaying unprocessed tuples. We evaluate this approach with the Linear Road Benchmark on the Amazon EC2 cloud platform and show that it can scale automatically to a load factor of L=350 with 50 VMs, while recovering quickly from failures.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Fernandez, R.C. and Migliavacca, M. and Kalyvianaki, E. and Pietzuch, P.",2013,OpenAccess Series in Informatics,10.4230/OASIcs.ICCSW.2013.11,scopus-search1.bib
Burtsev2013,Weir: A streaming language for performance analysis,"For modern software systems, performance analysis can be a challenging task. The software stack can be a complex, multi-layer, multi-component, concurrent, and parallel environment with multiple contexts of execution and multiple sources of performance data. Although much performance data is available, because modern systems incorporate many mature data-collection mechanisms, analysis algorithms suffer from the lack of a unifying programming environment for processing the collected performance data, potentially from multiple sources, in a convenient and script-like manner. This paper presents Weir, a streaming language for systems performance analysis. Weir is based on the insight that performanceanalysis algorithms can be naturally expressed as stream-processing pipelines. In Weir, an analysis algorithm is implemented as a graph composed of stages, where each stage operates on a stream of events that represent collected performance measurements. Weir is an imperative streaming language with a syntax designed for the convenient construction of stream pipelines that utilize composable and reusable analysis stages. To demonstrate practical application, this paper presents the authors' experience in using Weir to analyze performance in systems based on the Xen virtualization platform. Copyright © 2013 ACM.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Burtsev, A. and Mishrikoti, N. and Eide, E. and Ricci, R.",2013,"Proceedings of the 7th Workshop on Programming Languages and Operating Systems, PLOS 2013 - In Conjunction with the 24th ACM Symposium on Operating Systems Principles, SOSP 2013",10.1145/2525528.2525537,scopus-search1.bib;scopus-search1.bib;acm2-search1.bib;acm2-search1.bib
Yamamoto2013,An experimental evaluation of distributed data stream processing using lightweight RDBMS SQLite,"The data generated at a very high rate by sensors and RFIDs are required to be handled by continuous queries keeping real time response. DSMSs (Data Stream Management systems) are used in several cases of these large scale systems for its purpose. This paper describes the results of experimental evaluation of distributed data stream processing using SQLite which is a lightweight RDBMS as a stream processing engine node. In particular, it is necessary to correspond also to the increasing data rate flexibly in data stream processing. This paper proved that it could respond to the increase in a data rate by adding a processing node dynamically. In that case, it is necessary to perform synchronous processing in two or more processing nodes. Therefore, within the limits of this experiment, it turned out that it is realizable by performing synchronous processing by the side which divides and passes data. © 2013 The Institute of Electrical Engineers of Japan.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Yamamoto, M. and Koizumi, H.",2013,"IEEJ Transactions on Electronics, Information and Systems",10.1541/ieejeiss.133.2125,scopus-search1.bib
Zhang2012961,Exploring hybrid stream computing oriented on-chip adaptive memory structure,"In scientific applications, the computing process is composed of stream computing and general computing. The performance of computing is limited by low parallelism and hard streamlization. We propose what we call DAMS-Cache (DAMS stands for Dynamical Address Mapping Stream), which can be controlled by both the software and hardware that manage an on-chip memory structure that can, we believe, suppress effectively the above-mentioned limitation. Sections 1 through 4 of the full paper explain DAMS-Cache, whose core consists of: (1) the memory system can support both stream computing and scalar data processing in high performance, which supports irregular stream and conditionally-loaded stream computing by hardware; (2) the DAMS Cache explores both coarse-grained producer-consumer locality and fine-grained temporal/spatial locality by using replacement strategy of mixed data structure; (3) in order to avoid address mapping conflict, the dynamically adaptive storage resource assignment strategy and dynamically adaptive address mapping strategy are also presented. Section 5 presents performance analysis of DAMS Cache; it shows preliminarily that DAMS Cache has better adaptability and high performance compared with Scratchpad Memory and traditional Cache.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zhang, M. and Zhao, L. and Fan, X. and Tian, H.",2012,Xibei Gongye Daxue Xuebao/Journal of Northwestern Polytechnical University,,scopus-search1.bib
Smeding201211,A correlation preserving performance analysis for stream processing systems,"For the design of real-time embedded systems, analysis of performance and resource utilization at an early stage is crucial to evaluate design choices. Network Calculus and its variants provide the tools to perform such analyses for distributed systems processing streams of tasks, based on a max-plus algebra. However, the underlying model employed in Network Calculus cannot capture correlations between the availability of different resources and between the arrivals of tasks, leading to overly conservative performance bounds for some frequently used system topologies. We present a model based on timing constraints relative to pairs of streams, endowed with an analysis technique that can handle such correlations. © 2012 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Smeding, G. and Gössler, G.",2012,"10th ACM/IEEE International Conference on Formal Methods and Models for Codesign, MEMOCODE 2012",10.1109/MEMCOD.2012.6292295,scopus-search1.bib
Wang2012113,Adaptive approximation-based streaming skylines for similarity search query,"Actually, large database is not simply considered as a stream database because of streaming data is not only containing huge data volumes, but distributed, continuous, rapid, time varying. Therefore, the general techniques may not suit for streams exactly. Accuracy responses required of approximated answers is more important in stream processing for the similarity search. Therefore, we perform data reduction across synopsis data structure and to batch processing in a particular relevance way on the data stream computation model over sliding windows. Focus on similarity search in streaming environment, D-skyline method proposed in this paper concern useful aggregate as a preprocessing phase instead of original dataset repeatedly processing manner, in order to efficiently optimize both in space usage and error control. Our experimental evaluation would show the detailed effect on approximated analysis by using different kinds of skyline methods, then effectiveness and efficiency of our approach.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Wang, L. and Zhou, T.H. and Kim, K.A. and Cha, E.J. and Ryu, K.H.",2012,International Journal of Software Engineering and its Applications,,scopus-search1.bib
Cazalas201263,Performance Modeling of Spatio-Temporal Algorithms Over GEDS Framework,"The efficient processing of spatio-temporal data streams is an area of intense research. However, all methods rely on an unsuitable processor (Govindaraju, 2004), namely a CPU, to evaluate concurrent, continuous spatio-temporal queries over these data streams. This paper presents a performance model of the execution of spatio-temporal queries over the authors' GEDS framework (Cazalas & Guha, 2010). GEDS is a scalable, Graphics Processing Unit (GPU)-based framework, employing computation sharing and parallel processing paradigms to deliver scalability in the evaluation of continuous, spatio-temporal queries over spatio temporal data streams. Experimental evaluation shows the scalability and efficacy of GEDS in spatio-temporal data streaming environments and demonstrates that, despite the costs associated with memory transfers, the parallel processing power provided by GEDS clearly counters and outweighs any associated costs. To move beyond the analysis of specific algorithms over the GEDS framework, the authors developed an abstract performance model, detailing the relationship of the CPU and the GPU. From this model, they are able to extrapolate a list of attributes common to successful GPU-based applications, thereby providing insight into which algorithms and applications are best suited for the GPU and also providing an estimated theoretical speedup for said GPU-based applications. © 2012, IGI Global. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Cazalas, J. and Guha, R.",2012,International Journal of Grid and High Performance Computing,10.4018/jghpc.2012070104,scopus-search1.bib
Keong20122958,A push-pull chunk delivery for mesh-based P2P live streaming,"In this paper, we propose an adaptive chunk scheduling for mesh-based peer-to-peer live streaming system, a hybrid class of push and pull chunk delivery approach. The proposed rule-based push-pull scheduler simultaneously pull video chunk from lower latency peers to fill up missing chunks and push video chunk adaptively for rapid chunk delivery. We performed comparative simulation study against rarest first pushpull and status-wise push-pull to prove the efficiency of our proposed algorithm. Mesh-push is made possible by effectively exploiting the information through buffer map exchange. The findings of performance evaluation have suggested a better video continuity and achieved lower source to end delay. Copyright © 2012 The Institute of Electronics, Information and Communication Engineers.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Keong, C.Y. and Hoong, P.K. and Ting, C.-Y.",2012,IEICE Transactions on Information and Systems,10.1587/transinf.E95.D.2958,scopus-search1.bib
Cipriani201152,M-TOP: Multi-target operator placement of query graphs for data streams,"Nowadays, many applications processes stream-based data, such as financial market analysis, network intrusion detection, or visualization applications. To process stream-based data in an application-independent manner, distributed stream processing systems emerged. They typically translate a query to an operator graph, place the operators to stream processing nodes, and execute them to process the streamed data. The operator placement is crucial in such systems, as it deeply influences query execution. Often, different stream-based applications require dedicated placement of query graphs according to their specific objectives, e.g. bandwidth not less than 500 MBit/s and costs not more that 1 cost unit. This fact constraints operator placement. Existing approaches do not take into account application-specific objectives, thus not reflecting application-specific placement decisions. As objectives might conflict among each other, operator placement is subject to delicate trade-offs, such as bandwidth maximization is more important than cost reduction. Thus, the challenge is to find a solution which considers the application-specific objectives and their trade-offs. We present M-TOP, an QoS-aware multi-target operator placement framework for data stream systems. Particularly, we propose an operator placement strategy considering application-specific targets consisting of objectives, their respective trade-offs specifications, bottleneck conditions, and ranking schemes to compute a suitable placement. We integrated M-TOP into NexusDS, our distributed data stream processing middleware, and provide an experimental evaluation to show the effectiveness of M-TOP. © 2011 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Cipriani, N. and Schiller, O. and Mitschang, B.",2011,ACM International Conference Proceeding Series,10.1145/2076623.2076631,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Giacomazzi201082,Performance analysis of mesh-based peer-to-peer video streaming systems,"Peer-to-peer networks are an increasingly popular solution for the distribution of media content to a large number of users, with limited investments for network infrastructures. In this paper we focus on mesh-based, also referred to as generic, unstructured, or data-driven, peer-to-peer video streaming systems. We carry out a performance analysis of these systems, analyzing their sensitivity to the most critical system parameters. The analysis focuses on the number of neighbors of each peer, the average number of peers in the system, the permanence time of peers, and the amount of buffered video. Differently from existing studies we found that, depending on peers' permanence time, an optimal number of neighbors can be found. Moreover, moving towards a higher number of neighbors, the corresponding increase of signaling traffic causes a decrease of overall performance. ©2010 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Giacomazzi, P. and Poli, A.",2010,"2010 International Congress on Ultra Modern Telecommunications and Control Systems and Workshops, ICUMT 2010",10.1109/ICUMT.2010.5676654,scopus-search1.bib
Nanao201053,Performance analysis of data block synchronization mechanism in coolstreaming,"Coolstreaming is a Peer-to-Peer (P2P) based video streaming system in which a single video stream is decomposed into multiple sub-streams and a client-peer node receives the sub-streams from multiple parent-peer nodes, combining them into the original video stream. The buffer of the client-peer node is composed of a synchronization buffer and a cache buffer. Data blocks are stored in the synchronization buffer in a sub-stream basis, and then forwarded into the cache buffer according to their sequence numbers. Here, data-block synchronization is important to guarantee video quality. In this paper, we consider the performance of data-block synchronization scheme with which data blocks are simultaneously forwarded just after all the data blocks composing a macro data block arrive at the synchronization buffer. We model the synchronization buffer as a multiple-buffer queueing system with homogeneous Poisson arrival processes, deriving the mean forwarding interval. We also consider the frame loss probability for multiple-path video streaming, investigating how the number of sub-streams decreases the frame loss probability. Numerical examples show that increasing the number of sub-streams makes the average forwarding interval large, while the frame loss probability at the bottleneck router is improved. It is also shown that increasing the synchronization buffer decreases the average forwarding interval. © 2010 ACM.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Nanao, S. and Masuyama, H. and Kasahara, S. and Takahashi, Y.",2010,"5th International Conference on Queueing Theory and Network Applications, QTNA 2010 - Proceedings",10.1145/1837856.1837865,scopus-search1.bib
Kitchen20091,Chapter 1 The UK HPC Integration Market. Commodity-Based Clusters,"This chapter considers the ubiquitous position of commodity clusters in providing HPC capabilities to the scientific community, and the many issues faced by organizations when deciding how best to procure, maintain, and maximize the usage of such a resource. With a focus on developments within the UK, we provide an overview of the current high-performance computing (HPC) landscape from both the customer and supplier perspective. Historically HPC provision in the UK has been focused on one or two leading-edge national facilities that have helped the UK to develop and maintain an internationally competitive position in research using HPC. This HPC dynamic has, however, changed dramatically in the period 2005-2008 with the major injection of funding into University HPC sector through the Science Research Investment Fund (SRIF). This sector is now the major provider of HPC resources to the UK research base, with the capability of the sector increased 100-fold. Our primary focus lies on the role of HPC Integrators in supplying resources into this sector, and the challenges faced by the HPC service providers themselves in sustaining and growing these activities. The host sites through partnership with the selected integrator aim to maximize this entire process, from procurement through system installation and subsequent lifetime of the service. We ask whether those integrators based primarily in the UK have the ability to provide the necessary level of expertise required in all phases of the process, from procurement to ongoing support of the resource throughout its lifecycle. We consider how current HPC technology roadmaps might impinge on the role of integrators in responding to the undoubted challenges that lie ahead. Crucial issues when considering potential integrator involvement include both size of the hardware solution, that is, number of cores, number of nodes, and the ongoing robustness of open-source software solutions that might be deployed on these platforms. Informed by developments over the past 24 months associated with the deployment of systems funded under SRIF, we provide an in-depth analysis of the current status and capability of a number of the leading HPC Integrators within the UK. Our primary attention is given to the three major companies who now supply the academic community and hence are well known to us-Streamline Computing, ClusterVision, and OCF. Seven other integrators are also considered, albeit with less rigor. Consideration is also given to several of the Tier-1 suppliers of clusters. In reviewing the status of commodity-based systems in scientific and technical computing, systems representative of those supported by the integrators, we consider how an organization might best decide on the optimum technology to deploy against its intended workload. We outline our cluster performance evaluation work that uses a variety of synthetic and application-based floating-point metrics to inform this question. Our analysis relies on performance measurements of application independent tests (microbenchmarks) and a suite of scientific applications that are in active use on many large-scale systems. The microbenchmarks we used provide information on the performance characteristics of the hardware, specifically memory bandwidth and latency, and intercore/interprocessor communication performance. These measurements have been extensively used to provide insight into application performance, with the scientific applications used being taken from existing workloads within the SRIF HPC sector, representing various scientific domains and program structures-molecular dynamics, computational engineering, and materials simulation to name a few. The chapter concludes with a 10-point summary of important considerations when procuring HPC clusters, particularly those in the mid-to-high-end range. © 2009 Elsevier Inc. All rights reserved.",FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kitchen, C.A. and Guest, M.F.",2009,Advances in Computers,10.1016/S0065-2458(08)00801-2,scopus-search1.bib;web-of-science-search1.bib
Chen200894,Control and media distribution server for wireless video streaming systems adopting TCP transmission mode,"To meet high concurrency requirement of streaming service and overcome the high loss ratio of the wireless channel, a wireless video streaming server system was proposed with hybrid centralized-distributed architecture which adopts TCP transmission mode. Theoretical analysis and experimental evaluation results show that the proposed scheme exhibits reasonable scalability, high concurrency and reliable transmit quality. Therefore, the proposed scheme is able to provide good service for one kind of wireless streaming applications.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Chen, Y.-Y. and Chai, Y. and Ye, D.-J.",2008,Tongxin Xuebao/Journal on Communications,,scopus-search1.bib
Hu2008,Coordinate concurrent processing over distributed real-time multi-data streams,"Based on Client/Server model, the transactional issues in distributed real-time multi-data streams processing are first addressed. By using complex event processing, a transactional mechanism ARTs-MDS was designed to support coordinate concurrent processing on multi-data streams. The system is capable of reforming a set of concurrent tasks as a transactional unit in a self-organization way, isolating real operations on physical devices from the logical operations in the tasks by a persistent input/output queue, and achieving an atomic global effect caused by distributed coordinate tasks processing collected local data. Our performance evaluations show that by applying the system, response time on continuous collected data can be significantly enhanced and data lose can be reduced correspondingly.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Hu, K. and Liu, Y.",2008,Huazhong Keji Daxue Xuebao (Ziran Kexue Ban)/Journal of Huazhong University of Science and Technology (Natural Science Edition),,scopus-search1.bib
Kang20061736,Performance evaluation of software streaming server architecture for massive users,"In this paper, we propose the streaming server architecture for massive users and verify it by a small scale simulation with virtual users. Software streaming is one of the ASP solution that allows the execution of stream-enabled software, even while the transmission of the program may still be in progress. In this paper, we analyze workload characteristics of the software stream, and extract four requirements that software streaming system have to satisfy. Based on these requirements, we design the software streaming server architecture. The verification of the designed server is performed by virtual user simulation. The result tells us the capacity of each server and helps us to calculate the scale of the system for massive users.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Kang, S. and Ku, K.I. and Shim, J.M. and Hur, S.J. and Ju, S.H. and Choi, W.",2006,"8th International Conference Advanced Communication Technology, ICACT 2006 - Proceedings",,scopus-search1.bib;web-of-science-search1.bib
Fortino200325,Reliable multicast protocols for java-based grid middleware platforms,"Grids are becoming effective infrastructures for high-performance, network-unaware, general purpose, distributed applications. Most of Grid applications demand for large sets of data to be reliably delivered to a wide collection of resources. Even though unicast reliable protocols, such as TCP, can be adopted to implement data transmission toward multiple receivers, multicast protocols are becoming an efficient alternative. However, differently from multimedia distributed systems, which tolerate unreliable data streaming, Grids often require reliable multicast protocols to deliver data without losses and errors. In this paper, we discuss a suite of reliable multicast protocols for providing middleware platforms for hierarchical grid systems with collective communication and we show a preliminary performance evaluation that compares different reliable multicast schemes.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Fortino, G. and Russo, W. and Zimeo, E.",2003,Proceedings of the IASTED International Conference on Parallel and Distributed Computing and Systems,,scopus-search1.bib
Purcell1974385,The control data STAR-100—Performance measurements,"The CONTROL DATA STAR-100 (STring-ARray) Computer is a very large, general purpose, high speed computing system. The STAR-100 computer utilizes integrated circuitry, ferrite core memory, 400 hz power and freon cooling in the hardware implementation. The logical design of the computer combines stream processing, virtual addressing, hardware macro instructions, segmented (pipeline) arithmetic units and a 256-word high speed register file to perform arithmetic and logical operation on discrete or structured data elements (Figure 1). © ACM-CONFERENCE. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Purcell, and C.J.,",1974,"AFIPS Conference Proceedings - 1974 National Computer Conference, AFIPS 1974",10.1145/1500175.1500257,scopus-search1.bib
Henning2022,A configurable method for benchmarking scalability of cloud-native applications,"Cloud-native applications constitute a recent trend for designing large-scale software systems. However, even though several cloud-native tools and patterns have emerged to support scalability, there is no commonly accepted method to empirically benchmark their scalability. In this study, we present a benchmarking method, allowing researchers and practitioners to conduct empirical scalability evaluations of cloud-native applications, frameworks, and deployment options. Our benchmarking method consists of scalability metrics, measurement methods, and an architecture for a scalability benchmarking tool, particularly suited for cloud-native applications. Following fundamental scalability definitions and established benchmarking best practices, we propose to quantify scalability by performing isolated experiments for different load and resource combinations, which asses whether specified service level objectives (SLOs) are achieved. To balance usability and reproducibility, our benchmarking method provides configuration options, controlling the trade-off between overall execution time and statistical grounding. We perform an extensive experimental evaluation of our method’s configuration options for the special case of event-driven microservices. For this purpose, we use benchmark implementations of the two stream processing frameworks Kafka Streams and Flink and run our experiments in two public clouds and one private cloud. We find that, independent of the cloud platform, it only takes a few repetitions (≤ 5) and short execution times (≤ 5 minutes) to assess whether SLOs are achieved. Combined with our findings from evaluating different search strategies, we conclude that our method allows to benchmark scalability in reasonable time. © 2022, The Author(s).",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Henning, S. and Hasselbring, W.",2022,Empirical Software Engineering,10.1007/s10664-022-10162-1,scopus-search1.bib;web-of-science-search1.bib
Mostafaei2022270,Network-aware worker placement for wide-area streaming analytics,"Many organizations leverage Distributed Stream processing systems (DPSs) to get insights from the data generated by different users/devices, e.g., the Internet of Things (IoT) devices or user clicks on a website, on geographically distributed datacenters. The worker nodes in such environments are connected through Wide Area Network (WAN) links with various delays and bandwidth. Therefore, minimizing the execution latency of a task on the worker nodes while using the links with enough bandwidth and lower cost to steer the traffic of the applications is a challenging task. In this paper, we formulate the worker node placement for a geo-distributed DSPs network as a multi-criteria decision-making problem. Then, we propose an additive weighting-based approach to solve it. The users can prioritize the worker node placement according to the network-relevant parameters. We also propose a framework that can be integrated with the current DPSs to execute the tasks. We test our placement approach on three widely used stream processing systems, i.e., Apache Spark, Apache Storm, and Apache Flink, on three custom graphs adopted from the real cloud providers. We run the streaming query of the Yahoo! streaming benchmark on these three DPSs. The experimental results show that our approach improves the performance of Spark up to 2.2x-7.2x, Storm up to 1.2x-3.4x, and Flink up to 1.4x-3.3x compared with other placement approaches, which makes our framework useful for use in practical environments. (C) 2022 The Author(s). Published by Elsevier B.V.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Mostafaei, H. and Afridi, S. and Abawajy, J.",2022,Future Generation Computer Systems,10.1016/j.future.2022.06.009,scopus-search1.bib;web-of-science-search1.bib
Angbera2022256,A NOVEL TRUE-REAL-TIME SPATIOTEMPORAL DATA STREAM PROCESSING FRAMEWORK,"The ability to interpret spatiotemporal data streams in real time is critical for a range of systems. However, processing vast amounts of spatiotemporal data out of several sources, such as online traffic, social platforms, sensor networks and other sources, is a considerable challenge. The major goal of this study is to create a framework for processing and analyzing spatiotemporal data from multiple sources with irregular shapes, so that researchers can focus on data analysis instead of worrying about the data sources' structure. We introduced a novel spatiotemporal data paradigm for true-real-time stream processing, which enables high-speed and low-latency real-time data processing, with these considerations in mind. A comparison of two state-of-the-art real-time process architectures was offered, as well as a full review of the various open-source technologies for real-time data stream processing and their system topologies were also presented. Hence, this study proposed a brand-new framework that integrates Apache Kafka for spatiotemporal data ingestion, Apache Flink for true-real-time processing of spatiotemporal stream data, as well as machine learning for real-time predictions and Apache Cassandra at the storage layer for distributed storage in real time. The proposed framework was compared with others from the literature using the following features: Scalability (Sc), prediction tools (PT), data analytics (DA), multiple event types (MET), data storage (DS), Real-time (Rt) and performance evaluation (PE) stream processing (SP) and our proposed framework provided the ability to handle all of these tasks. © 2022, Scientific Research Support Fund of Jordan. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Angbera, A. and Chan, H.Y.",2022,Jordanian Journal of Computers and Information Technology,10.5455/jjcit.71-1646838830,scopus-search1.bib
Matteussi2022,Performance Evaluation Analysis of Spark Streaming Backpressure for Data-Intensive Pipelines,"A significant rise in the adoption of streaming applications has changed the decision-making processes in the last decade. This movement has led to the emergence of several Big Data technologies for in-memory processing, such as the systems Apache Storm, Spark, Heron, Samza, Flink, and others. Spark Streaming, a widespread open-source implementation, processes data-intensive applications that often require large amounts of memory. However, Spark Unified Memory Manager cannot properly manage sudden or intensive data surges and their related in-memory caching needs, resulting in performance and throughput degradation, high latency, a large number of garbage collection operations, out-of-memory issues, and data loss. This work presents a comprehensive performance evaluation of Spark Streaming backpressure to investigate the hypothesis that it could support data-intensive pipelines under specific pressure requirements. The results reveal that backpressure is suitable only for small and medium pipelines for stateless and stateful applications. Furthermore, it points out the Spark Streaming limitations that lead to in-memory-based issues for data-intensive pipelines and stateful applications. In addition, the work indicates potential solutions. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Matteussi, K.J. and DosAnjos, J.C.S. and Leithardt, V.R.Q. and Geyer, C.F.R.",2022,Sensors,10.3390/s22134756,scopus-search1.bib;web-of-science-search1.bib;scholar.bib
Kritharakis2022145,Detecting trading trends in streaming financial data using Apache Flink,"Modern financial analytics rely on high-volume streams of event notifications that report live market fluctuations based on supply and demand. Accurately identifying trends or breakout patterns based on the Exponential Moving Average (EMA) in the development of an instrument's price early on is an important challenge, so as to buy while the price is low and sell before a downtrend begins. This paper aims to solve the above challenge with a distributed, event-streaming solution built using Apache Flink. We present and implement a solution that leverages customized window operators to calculate the EMA and find breakout patterns, using event generation parallelism to facilitate the rapid processing of the input stream uses sinks to collect and output results, and scales easily on a distributed Flink cluster. We empirically test our design on metrics specified by the benchmarking platform for the DEBS 2022 Grand Challenge and observe a throughput of 45 batches per second and an average latency of 120 ms. © 2022 ACM.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Kritharakis, E. and Luo, S. and Unnikrishnan, V. and Vombatkere, K.",2022,DEBS 2022 - Proceedings of the 16th ACM International Conference on Distributed and Event-Based Systems,10.1145/3524860.3539647,scopus-search1.bib;acm2-search1.bib
Horchidan2022,Evaluating model serving strategies over streaming data,"We present the first performance evaluation study of model serving integration tools in stream processing frameworks. Using Apache Flink as a representative stream processing system, we evaluate alternative Deep Learning serving pipelines for image classification. Our performance evaluation considers both the case of embedded use of Machine Learning libraries within stream tasks and that of external serving via Remote Procedure Calls. The results indicate superior throughput and scalability for pipelines that make use of embedded libraries to serve pre-trained models. Whereas, latency can vary across strategies, with external serving even achieving lower latency when network conditions are optimal due to better specialized use of underlying hardware. We discuss our findings and provide further motivating arguments towards research in the area of ML-native data streaming engines in the future. © 2022 Owner/Author.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Horchidan, S. and Kritharakis, E. and Kalavri, V. and Carbone, P.",2022,"Proceedings of the 6th Workshop on Data Management for End-To-End Machine Learning, DEEM 2022 - In conjunction with the 2022 ACM SIGMOD/PODS Conference",10.1145/3533028.3533308,scopus-search1.bib;acm1-search1.bib
Wang2022,A comprehensive study on fault tolerance in stream processing systems,"Stream processing has emerged as a useful technology for applications which require continuous and low latency computation on infinite streaming data. Since stream processing systems (SPSs) usually require distributed deployment on clusters of servers in face of large-scale of data, it is especially common to meet with failures of processing nodes or communication networks, but should be handled seriously considering service quality. A failed system may produce wrong results or become unavailable, resulting in a decline in user experience or even significant financial loss. Hence, a large amount of fault tolerance approaches have been proposed for SPSs. These approaches often have their own priorities on specific performance concerns, e.g., runtime overhead and recovery efficiency. Nevertheless, there is a lack of a systematic overview and classification of the state-of-the-art fault tolerance approaches in SPSs, which will become an obstacle for the development of SPSs. Therefore, we investigate the existing achievements and develop a taxonomy of the fault tolerance in SPSs. Furthermore, we propose an evaluation framework tailored for fault tolerance, demonstrate the experimental results on two representative open-sourced SPSs and exposit the possible disadvantages in current designs. Finally, we specify future research directions in this domain. © 2022, Higher Education Press.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Wang, X. and Zhang, C. and Fang, J. and Zhang, R. and Qian, W. and Zhou, A.",2022,Frontiers of Computer Science,10.1007/s11704-020-0248-x,scopus-search1.bib;web-of-science-search1.bib;scholar.bib
Su2022538,Quantitative Verification for Monitoring Event-Streaming Systems,"High-performance data streaming technologies are increasingly adopted in IT companies to support the integration of heterogeneous and possibly distributed applications. Compared with the traditional message queuing middleware, a streaming platform enables the implementation of event-streaming systems (ESS) which include not only complex queues but also pipelines that transform and react to the streams of data. By analysing the centralised data streams, one can evaluate the Quality-of-Service for other systems and components that produce or consume those streams. We consider the exploitation of probabilistic model checking as a performance monitoring technique for ESS systems. Probabilistic model checking is a mature, powerful verification technique with successful application in performance analysis. However, an ESS system may contain quantitative parameters that are determined by event streams observed in a certain period of time. In this paper, we present a novel theoretical framework called QV4M (meaning 'quantitative verification for monitoring') for monitoring ESS systems, which is based on two recent methods of probabilistic model checking. QV4M assumes the parameters in a probabilistic system model as random variables and infers the statistical significance for the probabilistic model checking output. We also present an empirical evaluation of computational time and data cost for QV4M. © 1976-2012 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Su, G. and Liu, L. and Zhang, M. and Rosenblum, D.S.",2022,IEEE Transactions on Software Engineering,10.1109/TSE.2020.2996033,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Löff2022,DSParLib: A C++ Template Library for Distributed Stream Parallelism,"Stream processing applications deal with millions of data items continuously generated over time. Often, they must be processed in real-time and scale performance, which requires the use of distributed parallel computing resources. In C/C++, the current state-of-the-art for distributed architectures and High-Performance Computing is Message Passing Interface (MPI). However, exploiting stream parallelism using MPI is complex and error-prone because it exposes many low-level details to the programmer. In this work, we introduce a new parallel programming abstraction for implementing distributed stream parallelism named DSParLib. Our abstraction of MPI simplifies parallel programming by providing a pattern-based and building block-oriented development to inter-connect, model, and parallelize data streams found in modern applications. Experiments conducted with five different stream processing applications and the representative PARSEC Ferret benchmark revealed that DSParLib is efficient and flexible. Also, DSParLib achieved similar or better performance, required less coding, and provided simpler abstractions to express parallelism with respect to handwritten MPI programs. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Löff, J. and Hoffmann, R.B. and Pieper, R. and Griebler, D. and Fernandes, L.G.",2022,International Journal of Parallel Programming,10.1007/s10766-022-00737-2,scopus-search1.bib
Gu2022539,Meces: Latency-efficient Rescaling via Prioritized State Migration for Stateful Distributed Stream Processing Systems,"Stateful distributed stream processing engines (SPEs) usually call for dynamic rescaling due to varying workloads. However, existing state migration approaches suffer from latency spikes, or high resource usage, or major disruptions as they ignore the order of state migration during rescaling. This paper reveals the importance of state migration order to the latency performance in SPEs. Based on that, we propose Meces, an on-the-fly state migration mechanism which prioritizes the state migration of hot keys (those being processed or about to be processed by downstream operator tasks) to achieve smooth rescaling. Meces leverages a fetch-on-demand design which migrates operator states at record-granularity for state consistency. We further devise a hierarchical state data structure and gradual strategy for migration efficiency. Meces is implemented on Apache Flink and evaluated with diversified benchmarks and scenarios. Compared to state-of-the-art approaches, Meces improves stream processing performance in terms of latency and throughput during rescaling by orders of magnitude, with negligible overhead and no disruption to non-rescaling periods. © 2022 USENIX Annual Technical Conference, ATC 2022.All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Gu, R. and Yin, H. and Zhong, W. and Yuan, C. and Huang, Y.",2022,"Proceedings of the 2022 USENIX Annual Technical Conference, ATC 2022",,scopus-search1.bib
Zhang202217,MicroStream: A Distributed In-memory Caching Service for Data Production,"Data-driven innovation and optimization have become an important direction for the intelligent transformation of enterprises. Data processing tasks have been developed and orchestrated to extract data insights, creating direct or indirect data dependencies between tasks or between tasks and the presentation layer. Traditional ETL (Extract-Transformation-Load) solutions share data through persistent storage, which has certain performance bottlenecks in hybrid cloud and multisource data scenarios. In this paper, we propose MicroStream, a distributed data virtualization and caching middleware service. MicroStream shields the direct access of ETL tasks to the storage layer and converts batch access to the source database into microstream access. ETL jobs share data through the distributed in-memory caching of MicroStream. In resource-constrained scenarios, such a solution significantly improves the performance of data transformation while reducing the extra load that the transformation jobs imply on the source persistent layer. We present a detailed performance evaluation of MicroStream and show that its performance compares favorably with traditional database-oriented solutions. © 2022 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zhang, M. and Gao, Y. and He, C. and Tan, T.",2022,"Proceedings - 2022 IEEE 13th International Conference on Joint Cloud Computing, JCC 2022",10.1109/JCC56315.2022.00010,scopus-search1.bib;web-of-science-search1.bib
Verheijde20221314,S-QUERY: Opening the Black Box of Internal Stream Processor State,"Distributed streaming dataflow systems have evolved into scalable and fault-tolerant production-grade systems. Their applicability has departed from the mere analysis of streaming windows and complex-event processing, and now includes cloud applications and machine learning inference. Although the advancements in the state management of streaming systems have contributed significantly to their maturity, the internal state of streaming operators has been so far hidden from external applications. However, that internal state can be seen as a materialized view that can be used for analytics, monitoring, and debugging. In this paper we argue that exposing the internal state of streaming systems to outside applications by making it queryable, opens the road for novel use cases. To this end, we introduce S-QUERY: an approach and reference architecture where the state of stream processors can be queried - either live or through snapshots, achieving different isolation levels. We show how this new capability can be implemented in an existing open-source stream processor, and how queryable state can affect the performance of such a system. Our experimental evaluation suggests that the snapshot configuration adds only up to 8ms latency in the 99.99thpercentile and negligible increase in 0-90thpercentiles. © 2022 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Verheijde, J. and Karakoidas, V. and Fragkoulis, M. and Katsifodimos, A.",2022,Proceedings - International Conference on Data Engineering,10.1109/ICDE53745.2022.00103,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Raptis2022,On Efficiently Partitioning a Topic in Apache Kafka,"Apache Kafka addresses the general problem of delivering extreme high volume event data to diverse consumers via a publish-subscribe messaging system. It uses partitions to scale a topic across many brokers for producers to write data in parallel, and also to facilitate parallel reading of consumers. Even though Apache Kafka provides some out of the box optimizations, it does not strictly define how each topic shall be efficiently distributed into partitions. The well-formulated fine-Tuning that is needed in order to improve an Apache Kafka cluster performance is still an open research problem. In this paper, we first model the Apache Kafka topic partitioning process for a given topic. Then, given the set of brokers, constraints and application requirements on throughput, OS load, replication latency and unavailability, we formulate the optimization problem of finding how many partitions are needed and show that it is computationally intractable, being an integer program. Furthermore, we propose two simple, yet efficient heuristics to solve the problem: The first tries to minimize and the second to maximize the number of brokers used in the cluster. Finally, we evaluate its performance via largescale simulations, considering as benchmarks some Apache Kafka cluster configuration recommendations provided by Microsoft and Confluent. We demonstrate that, unlike the recommendations, the proposed heuristics respect the hard constraints on replication latency and perform better w.r.t. unavailability time and OS load, using the system resources in a more prudent way. © 2022 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Raptis, T.P. and Passarella, A.",2022,"Proceedings of the 2022 International Conference on Computer, Information and Telecommunication Systems, CITS 2022",10.1109/CITS55221.2022.9832981,scopus-search1.bib
Chen20221427,Intelligent Live Video Streaming for Object Detection,"These days, sensors and cameras are being deployed on an increasingly large scale. Furthermore, the rapid development of machine learning models for computer vision now presents novel opportunities for the use of artificial intelligence (AI) and Internet of Things (IoT) combinations in various application scenarios. However, challenges remain in supporting low-latency video streaming from distributed mobile IoT devices under dynamic network environments, and overcoming video data quality degradation that results from weather 'noise', which reduces the accuracy of AI-based data analyses such as object detection. In this paper, we propose a live video stream processing system for supporting intelligent services that integrates the following features. First, to cope with dynamic networks and achieve low latency, our approach employs a peer-to-peer (P2P)-based virtual network at the edge and a multi-tiered architecture composed of IoT cameras, edge, and cloud servers. Second, we construct a flexible messaging system for video analysis built upon SINETStream, which is a messaging system that adopts a topic-based pub/sub model. Third, we implement a framework that can remove weather-related (rain, snow, and fog) noise by applying weather classification and adaptive noise removal models that improve the accuracy of video analysis from data collected outdoors. The latency, throughput, and image quality benchmark experiments conducted to validate the feasibility of our proposed system showed that the process resulted in image quality improvements of approximately 30% (on average). © 2021 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Chen, M. and Sun, J. and Aida, K. and Figueiredo, R.J. and Ku, Y.-J. and Subratie, K.",2021,"2021 IEEE 23rd International Conference on High Performance Computing and Communications, 7th International Conference on Data Science and Systems, 19th International Conference on Smart City and 7th International Conference on Dependability in Sensor, Cloud and Big Data Systems and Applications, HPCC-DSS-SmartCity-DependSys 2021",10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00214,scopus-search1.bib;ieee1-search1.bib
Vyas2022465,Performance Evaluation of Apache Kafka-A Modern Platform for Real Time Data Streaming,"Current generation businesses become more demanding on timely availability of data. Many real-time data streaming tools and technologies are capable to meet business expectations. Apache Kafka is one of the capable open-source distributed scalable technology that enables real-time data streaming with good throughput and latency. In traditional batch processing, data is getting processed in groups or batches but in streaming services, data records are handled separately and there is a flow of data processing that is continuous and real-time. Once Data is available at the source, Kafka can detect and stream it in real-time to the target application. After doing the literature survey it was observed that there are insufficient experiments have been done till now with a variety of volumes and with different values of the number of partitions and polling intervals. The purpose of this study is to elaborate on Apache Kafka implementation and evaluate its performance. This study will analyse key performance indicators for the streaming platform and will provide useful insights from it. These insights will help to design optimized applications in Apache Kafka. Based on gaps identified after the literature survey, multiple experiments have been conducted for the producer and consumer API (Application Programming interface). Configuration of Kafka with Apache Zookeeper helped to drive the results which are captured in tabular form for different values of polling intervals, volumes, and partitions. Data for all test runs have been analysed further to drive the conclusions as mentioned in the results section. This study provides valuable insights about the utilization of CPU (Central Processing Unit) and memory for Apache Kafka streaming on changing volumes, also elaborates the impacts on streaming performance when key configurations are getting changed. © 2022 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Vyas, S. and Tyagi, R.K. and Jain, C. and Sahu, S.",2022,"Proceedings of 2nd International Conference on Innovative Practices in Technology and Management, ICIPTM 2022",10.1109/ICIPTM54933.2022.9754154,scopus-search1.bib
Mebrek2022516,A Multi-agent Based Framework for RDF Stream Processing,"When a large amount of data is generated from multiple, heterogeneous and continuous data streams, the need for continuous processing and on-the-fly consumption of the overwhelming flow of data is crucial. In this context, the W3C RDF Stream Processing (RSP) Community Group has defined a common model for continuous querying RDF Streams, giving rise to a plethora of RSP engines. However, their main limitation is that, depending on the application queries, one RSP engine may be more appropriate than another, or multiple engines are required to address complex queries. In this paper, we propose a multi-agent based framework for distributed continuous processing that gives the opportunity to use several RSP engines in the same framework in order to benefit from their advantages and to offer the possibility to use them at the same time or in a sequence to answer complex queries. A preliminary experimental evaluation with a real-world benchmark shows promising results when compared to an existing work. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Mebrek, W. and Bouzeghoub, A.",2022,Lecture Notes in Networks and Systems,10.1007/978-3-030-99584-3_45,scopus-search1.bib
Lu2022133,"AutoFlow: Hotspot-Aware, Dynamic Load Balancing for Distributed Stream Processing","Stream applications are widely deployed on the cloud. While modern distributed streaming systems like Flink and Spark Streaming can schedule and execute them efficiently, streaming dataflows are often dynamically changing, which may cause computation imbalance and backpressure. We introduce AutoFlow, an automatic, hotspot-aware dynamic load balance system for streaming dataflows. It incorporates a centralized scheduler that monitors the load balance in the entire dataflow dynamically and implements state migrations correspondingly. The scheduler achieves these two tasks using a simple asynchronous distributed control message mechanism and a hotspot-diminishing algorithm. The timing mechanism supports implicit barriers and a highly efficient state-migration without global barriers or pauses to operators. It also supports a time-window based load-balance measurement and feeds them to the hotspot-diminishing algorithm without user interference. We implemented AutoFlow on top of Ray, an actor-based distributed execution framework. Our evaluation based on various streaming benchmark datasets shows that AutoFlow achieves good load-balance and incurs a low latency overhead in a highly data-skew workload. © 2022, Springer Nature Switzerland AG.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Lu, P. and Yue, Y. and Yuan, L. and Zhang, Y.",2022,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-030-95391-1_9,scopus-search1.bib;web-of-science-search1.bib
Sharkova202296,Adaptive SQL Query Optimization in Distributed Stream Processing: A Preliminary Study,"Distributed stream processing is widely adopted for real-time data analysis and management. SQL is becoming a common language for robust streaming analysis due to the introduction of time-varying relations and event time semantics. However, query optimization in state-of-the-art stream processing engines (SPEs) remains limited: runtime adjustments to execution plans are not applied. This fact restricts the optimization capabilities because SPEs lack the statistical data properties before query execution begins. Moreover, streaming queries are often long-lived, and these properties can change over time. Adaptive optimization, used in databases for queries with insufficient or unknown data statistics, can fit the streaming scenario. In this work, we explore the main challenges that SPEs face during the adjustment of adaptive optimization, such as predicting statistical properties of streams and execution graph migration. We demonstrate potential performance gains of our approach within an extension of the NEXMark streaming benchmark and outline our further work. © 2022, Springer Nature Switzerland AG.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Sharkova, D. and Chernokoz, A. and Trofimov, A. and Sokolov, N. and Gorshkova, E. and Kuralenok, I. and Novikov, B.",2022,Communications in Computer and Information Science,10.1007/978-3-030-93849-9_7,scopus-search1.bib;web-of-science-search1.bib
Tu2022207,Research on Heterogeneous Accelerated Columnar Storage Engine Based on Co- optimization of Software and Hardware for GoldenX [面向GoldenX软硬协同优化的异构加速列式存储引擎研究],"In the era of Internet of Everything, with the emergence of various new computing technologies and emerging application fields, the traditional data processing methods are gradually evolving from a single processing method to a cloud-edge collaborative data processing method. The complex and changeable ecosystem (including multi-cloud and multi-edge) on the cloud and edge sides have brought rapid growth in data scale, complex data locations and load connections. Under this premise, how to efficiently and stably access data and information and how to speed up data query processing has become a key issue that academia and industry need to solve urgently. On the other hand, the new hardware technologies represented by GPU (graphic process unit) / FPGA (field programmable gate array) heterogeneous computing power, NVM (non-volatile memory) storage, and RDMA(remote direct memory access) network, is developing and applying rapidly. This will have a revolutionary impact on the existing software architecture system, and also provide a foundation for the evolution and performance improvement of the database system, and attract the attention from more and more researchers. Therefore, how to use these emerging new hardware technologies to empower the real database system used in the industry has become one of the current research hotspots. First of all, this paper introduces the architecture of ZTE GoldenX database system and the design of its columnar storage engine, and then focuses on the software and hardware co-design and optimization of the GoldenX's columnar storage engine using new hardware features at the computing layers and storage layers. The main work and contributions include: (1) Offload the tasks of compression/decompression and encryption/decryption from the CPU to the FPGA, and use the programmable characteristics of FPGA to design a dedicated MISD (multiple instruction stream single data stream) architecture processor, adopting ""software interface level-computing core level-functional module level"" three stage pipeline design to improve the efficiency of data stream processing; (2) Customize a vectorized execution engine for GoldenX's column storage to make full use of the new features of CPU/GPU namely SIMD (single instruction multiple data) to optimize the traditional volcano model, reducing the cost of function calls; (3) Optimize the SQL execution engine, dynamically evaluate and utilize GPU computing resources, and use the JIT compilation technology to push statistical and analysis SQL operation tasks with matrix computing characteristics (such as filtering/sorting/aggregation) down to the GPU, so that the ultra-high parallel computing powers of the GPU can be used to improve SQL query and analysis performance. Our experiments show that the software and hardware optimization method proposed in this paper can effectively improve the system performance of GoldenX. Using FPGA for compression/decompression operations can improve read and write performance by 1.2~2.4 times, and after offloading scanning/connection/grouping operations to GPU, their execution time can be reduced by 33%~92%, and after the vectorization engine is turned on, the execution time of SCAN/AGG/JOIN is reduced by 41%~83%. Finally, we conducted a system-level test on the database, among the 22 queries in the TPC-H benchmark test scenario, the system performance after optimization is 2.5~10 times higher than that before optimization. Compared with openGauss with vectorization turned on, the optimized GoldenX reduces the execution time by 17%~78%. © 2022, Science Press. All right reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Tu, Y.-F. and Chen, H.-D. and Wang, H.-Y. and Yan, Z.-S. and Qin, X.-L. and Chen, B.",2022,Jisuanji Xuebao/Chinese Journal of Computers,10.11897/SP.J.1016.2022.00207,scopus-search1.bib
Cattermole2021,Run-time adaptation of stream processing spanning the cloud and the edge,"Applications that process streams of events generated by sensors are important in a wide range of domains. It is now common to distribute stream processing across edge devices and the cloud. This exploits processing power near the sensors, reducing the load on the cloud and often the required network bandwidth. In this paper we focus on one challenge in distributed stream processing: automatically adapting the partitioning of the processing between the edge and the cloud without a loss of service. An example is when the event arrival rate increases and the edge processor can no longer meet performance requirements. Re-partitioning without loss of service involves moving computations between the edge and the cloud while events are still being processed. In this paper we describe StrIoT - a stream processing system that supports automatic re-partitioning. It is based on a set of functional stream operators, and the paper describes how the run-time system can automatically adapt applications that use them. A key feature is support for the fission and fusion of operators during adaptations. Performance evaluation shows that StrIoT can move parts of a stream processing application between the cloud and edge with only a low, temporary impact on performance. © 2021 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Cattermole, A. and Dowland, J. and Watson, P.",2021,ACM International Conference Proceeding Series,10.1145/3492323.3495627,scopus-search1.bib
Matesanz2021,Demand-driven data acquisition for large scale fleets,"Automakers manage vast fleets of connected vehicles and face an ever-increasing demand for their sensor readings. This demand originates from many stakeholders, each potentially requiring different sensors from different vehicles. Currently, this demand remains largely unfulfilled due to a lack of systems that can handle such diverse demands efficiently. Vehicles are usually passive participants in data acquisition, each continuously reading and transmitting the same static set of sensors. However, in a multi-tenant setup with diverse data demands, each vehicle potentially needs to provide different data instead. We present a system that performs such vehicle-specific minimization of data acquisition by mapping individual data demands to individual vehicles. We collect personal data only after prior consent and fulfill the requirements of the GDPR. Non-personal data can be collected by directly addressing individual vehicles. The system consists of a software component natively integrated with a major automaker’s vehicle platform and a cloud platform brokering access to acquired data. Sensor readings are either provided via near real-time streaming or as recorded trip files that provide specific consistency guarantees. A performance evaluation with over 200,000 simulated vehicles has shown that our system can increase server capacity on-demand and process streaming data within 269 ms on average during peak load. The resulting architecture can be used by other automakers or operators of large sensor networks. Native vehicle integration is not mandatory; the architecture can also be used with retrofitted hardware such as OBD readers. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Matesanz, P. and Graen, T. and Fiege, A. and Nolting, M. and Nejdl, W.",2021,Sensors,10.3390/s21217190,scopus-search1.bib;web-of-science-search1.bib
Sarathchandra2021,Resource aware scheduler for distributed stream processing in cloud native environments,"Recently distributed stream processors are increasingly being deployed in cloud computing infrastructures. In this article, we study performance characteristics of distributed stream processing applications in Google Compute Engine which is based on Kubernetes. We identify performance gaps in terms of throughput which appear in such environments when using a round robin (RR) scheduling algorithm. As a solution, we propose resource aware stream processing scheduler called resource aware scheduler for stream processing applications in cloud native environments (RaspaCN). We implement RaspaCN's job scheduler using two-step process. First, we use machine learning to identify the optimal number of worker nodes. Second, we use RR and multiple Knapsack algorithms to produce performance optimal stream processing job schedules. With three application benchmarks called HTTP Log Processor, Nexmark, and Email Processor representing real world stream processing scenarios we evaluate the performance benefits obtained via RaspaCN's scheduling algorithm. RaspaCN could produce percentage increase of average throughput values by at least 37%, 38%, and 10%, respectively, for HTTP Log Processor, Nexmark, and Email Processor benchmarks for fixed input data rates. Furthermore, we conduct experiments with varying input data rates as well and show 7% improved average throughput for HTTP Log Processor. These experiments show the effectiveness of our proposed stream processor job scheduler for producing improved performance. © 2021 John Wiley & Sons Ltd.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Sarathchandra, M. and Karandana, C. and Heenatigala, W. and Dayarathna, M. and Jayasena, S.",2021,Concurrency and Computation: Practice and Experience,10.1002/cpe.6373,scopus-search1.bib;web-of-science-search1.bib
Liu202149,Docker Container Networking Based Apache Storm and Flink Benchmark Test,"Many distributed stream computing engines have emerged to handle big data, and they can be deployed in cloud environments consisting of native networks or container networks. Most of the benchmark research on stream computing engines are carried out under the native network, and the research on the impact on container network on stream computing engines is currently inadequate. However, the use of container network will inevitably lead to performance degradation, which is the disadvantage of all virtual networks. In this work, we build Apache Storm and Apache Flink, which are Streaming Computation Engines in container network and native network environments and conduct performance measurements through experiments processing textual data to verify how much performance decreases in container network. Experiments show that the throughput in a container network environment is 1%-5% lower and CPU utilization is 11%-18% lower than in a local network environment. © 2021 IEICE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Liu, T. and Yang, Z. and Sun, Y.",2021,"2021 22nd Asia-Pacific Network Operations and Management Symposium, APNOMS 2021",10.23919/APNOMS52696.2021.9562644,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
EnekoRuizDeGauna202146,Video analytics architecture with metadata event-engine for urban safe cities,"Intelligent video analysis from sources such as urban surveillance cameras is a prolific research area today. Multiple types of computer architectures offer a wide range of possibilities when addressing the needs of computer vision technologies. When it comes to real time processing for high level and complex event detections, however, some limitations may arise, such as the computing power in the edge or the cost of sending real time video to the cloud for running advanced algorithms. In this paper, we present a functional architecture of a complete video surveillance solution and we focus on the metadata-processing event engine which takes care of the high-level video processing that is decoupled from a low-level video analysis. The low-level video analysis running in the edge generates and publishes a flow of JSON messages structure containing the details of bounding boxes detected in each frame into an asynchronous messaging service. The metadata event engine is running in a remote cloud, far from the camera locations. We present the performance evaluation of this event engine under different circumstances simulating data coming simultaneously from multiple cameras, in order to study the best strategies when deploying and partitioning distributed processing tasks. © 2021 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"EnekoRuizDeGauna, D. and Irigoyen, E. and Cejudo, I. and Arregui, H. and Leskovsky, P. and Otaegui, O.",2021,ACM International Conference Proceeding Series,10.1145/3477911.3477919,scopus-search1.bib
Stefani2021,Tiered Sampling: An Efficient Method for Counting Sparse Motifs in Massive Graph Streams,"We introduce Tiered Sampling, a novel technique for estimating the count of sparse motifs in massive graphs whose edges are observed in a stream. Our technique requires only a single pass on the data and uses a memory of fixed size M, which can be magnitudes smaller than the number of edges. Our methods address the challenging task of counting sparse motifs - sub-graph patterns - that have a low probability of appearing in a sample of M edges in the graph, which is the maximum amount of data available to the algorithms in each step. To obtain an unbiased and low variance estimate of the count, we partition the available memory into tiers (layers) of reservoir samples. While the base layer is a standard reservoir sample of edges, other layers are reservoir samples of sub-structures of the desired motif. By storing more frequent sub-structures of the motif, we increase the probability of detecting an occurrence of the sparse motif we are counting, thus decreasing the variance and error of the estimate. While we focus on the designing and analysis of algorithms for counting 4-cliques, we present a method which allows generalizing Tiered Sampling to obtain high-quality estimates for the number of occurrence of any sub-graph of interest, while reducing the analysis effort due to specific properties of the pattern of interest. We present a complete analytical analysis and extensive experimental evaluation of our proposed method using both synthetic and real-world data. Our results demonstrate the advantage of our method in obtaining high-quality approximations for the number of 4 and 5-cliques for large graphs using a very limited amount of memory, significantly outperforming the single edge sample approach for counting sparse motifs in large scale graphs. © 2021 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Stefani, L.D. and Terolli, E. and Upfal, E.",2021,ACM Transactions on Knowledge Discovery from Data,10.1145/3441299,scopus-search1.bib;web-of-science-search1.bib;acm1-search1.bib
Cermak2021736,Stream-Based IP Flow Analysis,"As the complexity of Internet services, transmission speed, and data volume increases, current IP flow monitoring and analysis approaches cease to be sufficient, especially within high-speed and large-scale networks. Although IP flows consist only of selected network traffic features, their processing faces high computational demands, analysis delays, and large storage requirements. To address these challenges, we propose to improve the IP flow monitoring workflow by stream-based collection and analysis of IP flows utilizing a distributed data stream processing. This approach requires changing the paradigm of IP flow data monitoring and analysis, which is the main goal of our research. We analyze distributed stream processing systems, for which we design a novel performance benchmark to determine their suitability for stream-based processing of IP flow data. We define a stream-based workflow of IP flow collection and analysis based on the benchmark results, which we also implement as a publicly available and open-source framework Stream4Flow. Furthermore, we propose new analytical methods that leverage the stream-based IP flow data processing approach and extend network monitoring and threat detection capabilities. © 2021 IFIP.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Cermak, M. and Celeda, P.",2021,Proceedings of the IM 2021 - 2021 IFIP/IEEE International Symposium on Integrated Network Management,,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Park2021,Development of Boiling Prediction Method in LP-EGR Cooler and Shape Optimization for Suppressing Boiling using Boiling Index,"An EGR system has been significantly used in order to cope with reinforced exhaust gas regulation and enhancement of fuel efficiency. For the well-designed EGR cooler, performance analysis is basically required. Furthermore, boiling prediction of the EGR cooler is especially essential to evaluate durability failure of abnormal operating conditions in DPF. However, due to intrinsic complexity of detailed 3-dimensional heat transfer tubes in the EGR cooler, no precise technique of boiling prediction has been developed. Therefore, this research had been performed in order to fulfill 3 goals: (1) development of 3-dimentional performance prediction technique including boiling occurrence, (2) generation and validation of a new evaluation index for boiling, (3) development of an optimized EGR cooler for suppressing boiling. In order to increase analysis accuracy and reduce analysis efforts at the same time, 3-dimensional single-phase flow analysis was developed. This technique was applied to LP-EGR cooler design of the next generation smart stream engine of HMC. Rig test results were used to validate this newly developed analysis method. Especially, in order to predict global system boiling, a new evaluation boiling index was introduced. It was defined as ratio of boiling heat transfer to total heat transfer and showed good behavior. For shape optimization, the boiling index was evaluated with 12 operating points. A base design showed poor distribution of coolant flow caused local boiling and system boiling when it gets worse. In order to achieve well distributed coolant flow and suppressing boiling, 43 different baffles were investigated using the boiling index. The shape optimized EGR cooler showed 32% reduction of boiling index and slight increment of cooling efficiency compared to base EGR cooler. Additional rig test of the optimized EGR cooler was performed to validate correlation and consistency and demonstrated good feasibility of the new method and the boiling index. © 2021 SAE International. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Park, H. and Kang, S. and Jeong, J.",2021,SAE Technical Papers,10.4271/2021-01-0228,scopus-search1.bib
Muthakshi2021,Container selection processing implementing extensive neural learning in cloud services,"The container selection processing performance analyses huge data with minimal resources and the lowest latency. The elastic management applications execute the containers with the specific hierarchy of virtual processing and machine management. The container that has performance degradation implicit provision of least expensive containers with minimal resources helps to increase the performance of containers. The specific data and stream processing prompts scrutinizing of data through the container selection process through different methodologies. To exterminate the bottleneck problem that selects efficient and required size, processing speed, and its reliability of guiding the batch processing of containers. The extensive neural learning handles container optimality involves a dynamic selection of appropriate containers in cloud service providers. The cloud service providers along with container selection contain batch processing and stream processing allocates efficient container-specific selection appropriately. In the huge data segregation of data processed data that emphasizes multiple data scrutinizing. © 2021",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Muthakshi, S. and Mahesh, K.",2021,Materials Today: Proceedings,10.1016/j.matpr.2021.05.628,scopus-search1.bib
Węcel2021257,Stream Processing Tools for Analyzing Objects in Motion Sending High-Volume Location Data,"Recently we observe a significant increase in the amount of easily accessible data on transport and mobility. This data is mostly massive streams of high velocity, magnitude, and heterogeneity, which represent a flow of goods, shipments and the movements of fleet. It is therefore necessary to develop a scalable framework and apply tools capable of handling these streams. In the paper we propose an approach for the selection of software for stream processing solutions that may be used in the transportation domain. We provide an overview of potential stream processing technologies, followed by the method for choosing the selected software for real-time analysis of data streams coming from objects in motion. We have selected two solutions: Apache Spark Streaming and Apache Flink, and benchmarked them on a real-world task. We identified the caveats and challenges when it comes to implementation of the solution in practice. © Authors.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Węcel, K. and Szmydt, M. and Stróżyna, M.",2021,Business Information Systems,10.52825/bis.v1i.41,scopus-search1.bib;web-of-science-search1.bib
Kang2021126,SLO-aware Virtual Rebalancing for Edge Stream Processing,"The Internet of Things (IoT) has enabled an abundance of geographically distributed physical devices or 'things' equipped with sensors and actuators to exchange information with the Cloud. However, this paradigm remains largely under-exploited for real-time analytic applications. The benefit of realtime data acquisition at the Edge becomes fruitless as it is not readily accessible to more powerful data analytic tools in the Cloud due to wide-area network delays. In this paper, we present VRebalance, a virtual resource orchestrator that provides an end-to-end performance guarantee for concurrent stream processing workloads at the Edge. VRebalance employs Bayesian Optimization $\mathcal{BO}$ to quickly identify near-optimal resource configurations. Experimental results with a real-time open-source IoT benchmark for Distributed Stream Processing Platforms (RIoTBench) and a representative stream processing engine (Apache Storm) demonstrate the superior performance, resource efficiency and adaptiveness of our $\mathcal{BO}$-based resource management system. VRebalance meets the performance SLO (service level objective) targets for stream processing workloads even in the presence of acute system dynamics. It decreases the SLO violation rate by at least 34% for static workloads and by 62.5% for dynamic workloads compared to a hill climbing method. Compared to Storm's default resource scaling mechanism, our method decreases the SLO violation rate by 83.7%. © 2021 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Kang, P. and Lama, P. and Khan, S.U.",2021,"Proceedings - 2021 IEEE International Conference on Cloud Engineering, IC2E 2021",10.1109/IC2E52221.2021.00027,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Gomes20213069,Railgun: Managing large streaming windows under mad requirements,"Some mission critical systems, e.g., fraud detection, require accurate, real-time metrics over long time sliding windows on applications that demand high throughput and low latencies. As these applications need to run “forever” and cope with large, spiky data loads, they further require to be run in a distributed setting. We are unaware of any streaming system that provides all those properties. Instead, existing systems take large simplifications, such as implementing sliding windows as a fixed set of overlapping windows, jeopardizing metric accuracy (violating regulatory rules) or latency (breaching service agreements). In this paper, we propose Railgun, a fault-tolerant, elastic, and distributed streaming system supporting real-time sliding windows for scenarios requiring high loads and millisecond-level latencies. We benchmarked an initial prototype of Railgun using real data, showing significant lower latency than Flink and low memory usage independent of window size. Further, we show that Railgun scales nearly linearly, respecting our msec-level latencies at high percentiles (<250ms @ 99.9%) even under a load of 1 million events per second. © The authors.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Gomes, A.S. and Oliveirinha, J. and Cardoso, P. and Bizarro, P.",2021,Proceedings of the VLDB Endowment,10.14778/3476311.3476384,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Daghistani2021_92,Guard: Attack-Resilient Adaptive Load Balancing in Distributed Streaming Systems,"The performance of distributed streaming systems relies on how even the workload is distributed among their machines. However, data and query workloads are skewed and change rapidly. Therefore, multiple adaptive load-balancing mechanisms have been proposed in the literature to rebalance distributed streaming systems according to the changes in their workloads. This paper introduces a novel attack model that targets adaptive load-balancing mechanisms of distributed streaming systems. The attack reduces the throughput and the availability of the system by making it stay in a continuous state of rebalancing. This paper proposes Guard, a component that detects and blocks attacks that target the adaptive load balancing of distributed streaming systems. Guard uses an unsupervised machine-learning technique to detect malicious users that are involved in the attack. Guard does not block any user unless it detects that the user is malicious. Guard does not depend on a specific application. Experimental evaluation for a high-intensity attack illustrates that Guard improves the throughput and the availability of the system by 85% and 86%, respectively. Moreover, Guard improves the minimum availability that the attacker achieves by 325%. IEEE",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Daghistani, A. and Khayat, M. and Felemban, M. and Aref, W.G. and Ghafoor, A.",2021,IEEE Transactions on Dependable and Secure Computing,10.1109/TDSC.2021.3123071,scopus-search1.bib;ieee3-search1.bib
Volnes202118,EXPOSE: Experimental Performance Evaluation of Stream Processing Engines Made Easy,"Experimental performance evaluation of stream processing engines (SPE) can be a great challenge. Aiming to make fair comparisons of different SPEs raises this bar even higher. One important reason for this challenge is the fact that these systems often use concepts that require expert knowledge for each SPE. To address this issue, we present Expose, a distributed performance evaluation framework for SPEs that enables a user through a declarative approach to specify experiments and conduct them on multiple SPEs in a fair way and with low effort. Experimenters with few technical skills can define and execute distributed experiments that can easily be replicated. We demonstrate Expose by defining a set of experiments based on the existing NEXMark benchmark and conduct a performance evaluation of Flink, Beam with the Flink runner, Siddhi, T-Rex, and Esper, on powerful and resource-constrained hardware. © 2021, Springer Nature Switzerland AG.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Volnes, E. and Plagemann, T. and Goebel, V. and Kristiansen, S.",2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-030-84924-5_2,scopus-search1.bib;web-of-science-search1.bib;scholar.bib
Poeira2021143,Deconstructing yield operator to enhance streams processing,"Customizing streams pipelines with new user-defined operations is a well-known pattern regarding streams processing. However, programming languages face two challenges when considering streams extensibility: 1) provide a compact and readable way to express new operations, and 2) keep streams’ laziness behavior. From here, we may find a consensus around the adoption of the generator operator, i.e. yield, as a means to fulfil both requirements, since most state-of-the-art programming languages provide this feature. Yet, what is the performance overhead of interleaving a yield-based operation in streams processing? In this work we present a benchmark based on realistic use cases of two different web APIs, namely: Last.fm and world weather online, where custom yield-based operations may degrade the streams performance in twofold. We also propose a purely functional and minimalistic design, named tinyield, that can be easily adopted in any programming language and provides a concise way of chaining extension operations fluently, with low overhead in the evaluated benchmarks. The tinyield proposal was deployed in three different libraries, namely for Java (jayield), JavaScript (tinyield4ts) and .Net (tinyield4net). Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Poeira, D. and Carvalho, F.M.",2021,"Proceedings of the 16th International Conference on Software Technologies, ICSOFT 2021",10.5220/0010541001430150,scopus-search1.bib
Son202161,A benchmark test for stateless stream partitioning over distributed network environments,"Distributed stream processing engines (DSPEs) provides various stateless stream partitioning to select the receiver tasks for each message regardless of the data fields. A representative DSPE, Apache Storm, provides the polarized stateless stream partitioning: Shuffle grouping considering the fairness only and Local-or-Shuffle grouping considering the locality only. The recently proposed Locality Aware grouping is a novel technique to solve this polarization. However, it is difficult to select an appropriate stream partitioning method considering various configurations of distributed stream applications, network capacity, and data size. In this paper, we benchmark the stateless stream partitioning methods from the perspective of different network bandwidths. To change bandwidths, we experiment on the most widely used the usual Ethernet equipment and the recent InfiniBand, a high-performance network equipment. We can use the benchmark results as the selection criteria for choosing the appropriate stream partitioning method according to the network bandwidth. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Son, S. and Moon, Y.-S.",2021,Lecture Notes in Electrical Engineering,10.1007/978-981-15-9309-3_9,scopus-search1.bib
Stein20202207,Smart Resource Management for Data Streaming using an Online Bin-packing Strategy,"Data stream processing frameworks provide reliable and efficient mechanisms for executing complex workflows over large datasets. A common challenge for the majority of currently available streaming frameworks is efficient utilization of resources. Most frameworks use static or semi-static settings for resource utilization that work well for established use cases but lead to marginal improvements for unseen scenarios. Another pressing issue is the efficient processing of large individual objects such as images and matrices typical for scientific datasets. HarmonicIO has proven to be a good solution for streams of relatively large individual objects, as demonstrated in a benchmark comparison with the Apache Spark and Kafka streaming frameworks. We here present an extension of the HarmonicIO framework based on the online bin-packing algorithm. The main focus is to compare different strategies adapted in streaming frameworks for efficient resource utilization. Based on a real world use case from large-scale microscopy pipelines, we compare two different strategies of auto-scaling implemented in the HarmonicIO and Spark Streaming frameworks. © 2020 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Stein, O. and Blamey, B. and Karlsson, J. and Sabirsh, A. and Spjuth, O. and Hellander, A. and Toor, S.",2020,"Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",10.1109/BigData50022.2020.9378241,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Rinaldi20201,High-throughput stream processing with actors,"The steady growth of data volume produced as continuous streams makes paramount the development of software capable of providing timely results to the users. The Actor Model (AM) offers a high-level of abstraction suited for developing scalable message-passing applications. It allows the application developer to focus on the application logic moving the burden of implementing fast and reliable inter-Actors message-exchange to the implementation framework. In this paper, we focus on evaluating the model in high data rate streaming applications targeting scale-up servers. Our approach leverages Parallel Patterns (PP) abstractions to model streaming computations and introduces optimizations that otherwise could be challenging to implement without violating the Actor Model's semantics. The experimental analysis demonstrates that the new implementation skeletons we propose for our PPs can bring significant performance boosts (more than 2X) in high data rate streaming applications implemented in CAF. © 2020 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Rinaldi, L. and Torquati, M. and Mencagli, G. and Danelutto, M.",2020,"AGERE 2020 - Proceedings of the 10th ACM SIGPLAN International Workshop on Programming Based on Actors, Agents, and Decentralized Control, Co-located with SPLASH 2020",10.1145/3427760.3428338,scopus-search1.bib;acm2-search1.bib
Harwood20201344,"Dragon: A lightweight, high performance distributed stream processing engine","—The performance of a distributed stream processing engine is traditionally considered in terms of fundamental measurements of latency and throughput. Recently, Apache Storm has demonstrated sub-millisecond latencies for inter-component tuple transmission, though it does so through aggressive throttling that leads to strict throughput limitations in order to keep tuple queues near empty. On the other hand, Apache Heron has excellent throughput characteristics, especially when operating near unstable conditions, but its inter-component latencies typically start around 10 milliseconds. Both of these systems require roughly 650MB of installation space. We have developed Dragon, loosely based on the same API as Storm and Heron, that is both lightweight, requiring just 7.5MB of installation space, and competitive in performance to Storm and Heron. In this paper we show experiments with all three systems using the Word Count benchmark. Dragon achieves throughput characteristics near to that of Heron and inter-component latencies less than 10ms under high load. In particular, Dragon’s maximum latency is significantly less that Storm’s maximum latency under high load. Finally Dragon managed to remain stable at higher effective throughput than Heron. We believe Dragon is a good “all-rounder” solution and is particularly suitable for Edge computing applications, given its small installation footprint. ©2020 IEEE",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Harwood, A. and Read, M.R. and Amarasinghe, G.N.",2020,Proceedings - International Conference on Distributed Computing Systems,10.1109/ICDCS47774.2020.00177,scopus-search1.bib;web-of-science-search1.bib;ieee1-search1.bib
Sundar2020,Benchmarking Distributed Stream Processing Frameworks for Real Time Classical Machine Learning Applications,"As the volume of data generated is growing at an unprecedented rate, it becomes important to analyze this data in real-time. To handle the huge volume of data streaming at a high velocity, we not only require powerful machines but also means to distribute the computation involved on the multiple machines. There are several open-source distributed stream processing frameworks such as Apache {Storm, Flink, Spark} and Confluent Kafka for building real-time machine learning applications. Prior works benchmarked some of these platforms using low-level operations like filters, joins, windowed computations etc. Our work includes benchmarking these popular frameworks for their applicability to classical machine learning models: Online K-Means, Online Linear Regression and Online Logistic Regression. We study the following quantitative metrics of evaluation: throughput, latency, CPU, and memory usage. The experiments were conducted in both standalone and clusters setups to determine the scalability of the models. This study will help system designers choose the right model and the right framework, given a specific configuration on streaming data. © 2020 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Sundar, M. and Kailasam, S. and Gonsalves, T.A.",2020,"2020 11th International Conference on Computing, Communication and Networking Technologies, ICCCNT 2020",10.1109/ICCCNT49239.2020.9225267,scopus-search1.bib;ieee2-search1.bib
Mebrek2020509,A stream reasoning framework based on a multi-agents model,"Processing on-the-fly high volume of data streams is increasingly needed. To cope with the heterogeneity of this data, RDF model is more and more being adopted leading to plethora of RDF Stream Processing (RSP) systems and languages dealing with issues such as continuous querying, incremental reasoning and complex event processing (CEP). However, most of them has implemented centralized approaches and therefore suffer from some limitations as collaboration, sharing, expressiveness and scalability. Multi-agents systems have widely proven their worth and efficiency in particular their intrinsic decentralized property along with their cooperation and communication mechanism. In this paper we propose a new framework MAS4MEAN (Multi-Agent System for streaM rEAsoNing) based on a multi-agents model to embrace their benefits and tackle the challenges of increasing the scalability and ease of deployment in highly dynamic environments. A preliminary experimental evaluation with a real-world dataset show promising results when compared to an existing work. © 2020 Owner/Author.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Mebrek, W. and Bouzeghoub, A.",2020,Proceedings of the ACM Symposium on Applied Computing,10.1145/3341105.3374111,scopus-search1.bib;web-of-science-search1.bib;acm1-search1.bib
Wang2020101,Evaluating Fault Tolerance of Distributed Stream Processing Systems,"Since failures in large-scale clusters can lead to severe performance degradation and break system availability, fault tolerance is critical for distributed stream processing systems (DSPSs). Plenty of fault tolerance approaches have been proposed over the last decade. However, there is no systematic work to evaluate and compare them in detail. Previous work either evaluates global performance during failure-free runtime, or merely measures throughout loss when failure happens. In this paper, it is the first work proposing an evaluation framework customized for quantitatively comparing runtime overhead and recovery efficiency of fault tolerance mechanisms in DSPSs. We define three typical configurable workloads, which are widely-adopted in previous DSPS evaluations. We construct five workload suites based on three workloads to investigate the effects of different factors on fault tolerance performance. We carry out extensive experiments on two well-known open-sourced DSPSs. The results demonstrate performance gap of two systems, which is useful for choice and evolution of fault tolerance approaches. © 2020, Springer Nature Switzerland AG.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Wang, X. and Jiang, C. and Fang, J. and Shu, K. and Zhang, R. and Qian, W. and Zhou, A.",2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-030-60290-1_8,scopus-search1.bib
Shaikh2019,A robust and scalable pipeline for the real-time processing and analysis of massive 3D spatial streams,"With the increase in the use of 3D scanner to sample the earth surface, there is a surge in the availability of 3D spatial data. 3D spatial data contains a wealth of information and can be of potential use if integrated, processed and analyzed in real-time. The 3D spatial data is generated as continuous data stream, however due to its size, velocity and inherent noise, it is processed offline. Many applications require real-time processing and analysis of spatial stream, for-instance, forest fire management, real-time road traffic analysis, disaster engulfed areas monitoring, etc., however they suffer from slow offline processing of traditional systems. This paper presents and demonstrates a robust and scalable pipeline for the real-time processing and analysis of 3D spatial streams. An experimental evaluation is also presented to prove the effectiveness of the proposed framework. © 2019 Association for Computing Machinery.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Shaikh, S.A. and Lee, J. and Matono, A. and Kim, K.-S.",2019,ACM International Conference Proceeding Series,10.1145/3366030.3366105,scopus-search1.bib;web-of-science-search1.bib;acm2-search1.bib
Li2019202,A holistic stream partitioning algorithm for distributed stream processing systems,"The performances of modern distributed stream processing systems are critically affected by the distribution of the load across workers. Skewed data streams in real world are very common and pose a great challenge to these systems, especially for stateful applications. Key splitting, which allows a single key to be routed to multiple workers, is a great idea to achieve good balance of load in the cluster. However, it comes with the cost of increased memory consumption and computation overhead as well as network communication. In this paper, we present a new definition of metric to model the cost of key splitting for intra-operator parallelism in stream processing systems and provide a novel perspective to reduce replication factor while keeping both overall load imbalance and processing latency low. Similar to previous work, our approach treats the head and the tail of the distribution differently in order to reduce memory requirements. For the head, it uses our proposed notion of regional load imbalance to decide dynamically whether to make one more worker responsible for the heavy hitter or not. For the tail, it simply uses hash partitioning to keep the size of the routing table for the head as small as possible. Extensive experimental evaluation demonstrates that our approach provides superior performance compared to the state-of-the-art partitioning algorithms in terms of load imbalance, replication factor and latency over different levels of skewed stream distributions. © 2019 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Li, K. and Liu, G. and Lu, M.",2019,"Proceedings - 2019 20th International Conference on Parallel and Distributed Computing, Applications and Technologies, PDCAT 2019",10.1109/PDCAT46702.2019.00046,scopus-search1.bib;ieee1-search1.bib
Prasaad2019,Scaling ordered stream processing on shared-memory multicores,"Many modern applications require realtime processing of large volumes of high speed data. Such data processing can be specified in the form of a dataflow graph that exposes multiple opportunities for parallelizing its execution, in the form of data, pipeline and task parallelism. This paper focuses on the problem of effectively parallelizing ordered streaming computations by exploiting low overhead, shared memory parallelism on a multicore machine. We propose an adaptive runtime that dynamically maps the exposed parallelism in a streaming computation to that of the machine using scheduling heuristics. Further, we address some key problems in effectively realizing ordered data parallelism. We propose a new approach for parallelizing partitioned stateful operators that can handle load imbalance across partitions effectively and mostly avoid delays due to ordering constraints. We also present a low latency, non-blocking concurrent data structure to order outputs produced by concurrent workers on an operator. Finally, we perform an in-depth empirical evaluation illustrating the trade-offs and effectiveness of our concurrent data-structures and scheduling heuristics using micro-benchmarks and on the TPCx-BB benchmark. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Prasaad, G. and Ramalingam, G. and Rajan, K.",2019,ACM International Conference Proceeding Series,10.1145/3350489.3350495,scopus-search1.bib;acm2-search1.bib
Lambachri2019,Aligning pattern extraction algorithms for the lambda architecture,"For quite some time now, data have become the new oil of the digital industry. The spread and evolution of information technologies and connectivity between people and devices have enabled a new dimension of big-data storage and analytics that could bring major improvements across industries. In this paper, we propose a new, frequent itemset mining approach. The challenge is to apply traditional extraction techniques in a distributed environment. The main originality of our mining method is to take benefits of a performant existing algorithm and use a novel data structure to maintain frequent sequential patterns coupled with a quick pruning strategy. The proposed approach has been implemented using Spark to further improve the efficiency of iterative computation. Numeric experiment results using standard benchmark datasets by comparing the proposed algorithm with the existing algorithm, FP-Growth, demonstrate that our approach has better efficiency and scalability. © 2018 IEEE",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Lambachri, T. and HajjamElHassani, A. and Andres, E.",2018,"2018 9th International Conference on Information, Intelligence, Systems and Applications, IISA 2018",10.1109/IISA.2018.8633698,scopus-search1.bib;web-of-science-search1.bib
Shah2019361,Performance comparison of chunk and peer scheduling algorithms of peer-To-peer streaming systems,"With increasing popularity of Peer to Peer systems for video streaming, it is important that the expectations of the users regarding the quality of such systems are being met. In a P2P system, the media stream is divided into small data units known as chunks. Each peer in a Peer to Peer (P2P) system has to take two important decisions at a given time. First, which chunks are to be shared and second with which peer. This paper compares the performance of different combinations of chunk/peer schedulers in terms of chunk diffusion delay, average chunk distribution delay and max chunk distribution delay. By doing so, the best possible combination of the two schedulers for the given experimental setup is explored. The results obtained under the specified experimental setup show that when chunk scheduling algorithm Deadline Based Chunk Scheduler (DLc) is combined with different peer scheduling algorithms, the best results are obtained by its combination with Chunk Earliest Free Pair Scheduler (CEFp). For a constant peer scheduler CEFp combined with different chunk schedulers, the best results are obtained by combining it with Latest Blind Chunk Scheduler (LBc). Finally, with varying neighborhood size, the best results are obtained by the combination of DLC and Chunk Almost Free Peer Scheduler (CAFp). © 2018 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Shah, S.S.H. and Said, N. and Nayab, A. and Khan, W. and Shinwari, Z.A. and Jawwad, M. and Minallah, N.",2018,"Proceedings - 2018 International Conference on Frontiers of Information Technology, FIT 2018",10.1109/FIT.2018.00070,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Huang2019163515,Cost-Minimizing Online Algorithms for Geo-Distributed Data Analytics,"Modern enterprises often manage geographically distributed datacenters around the globe. In such environment, datasets are naturally collected and stored in different data centers and were later queried for complex analytics. In this paper, we study the Wide-Area Data Analytics problem, which aims to efficiently control data movements and achieve low latency for overall queries processing, both constrained by limited and expensive network resources across datacenters. Previous papers focus on offline settings of single analytical queries and do not consider time in optimizing system performance, and therefore ignores the dynamics of data and task placement in terms of inter-DC bandwidth utilization. In this paper, we consider the online setting and formulate a cost-minimizing optimization problem over time for arbitrary Directed Acyclic Graph query processing. Considering dynamics of network resource usage, we developed two online algorithms, Online Switch Resist (OSR) and Most Fixed Horizon Control (MFHC) with good competitive ratios. We performed extensive simulations and comparative studies using the TPC-CH benchmark and verified the efficacy of proposed algorithms. The algorithm we proposed is better than the existing algorithm, and its performance approximates the theoretical optimal value. © 2013 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Huang, J. and Huang, J. and Gao, S. and Yang, B.",2019,IEEE Access,10.1109/ACCESS.2019.2951682,scopus-search1.bib;web-of-science-search1.bib
Ren201989,SRSPG: A Plugin-based Spark Framework for Large-scale RDF Streams Processing on GPU,"In this paper, we propose a plugin-based Spark framework (SRSPG) for large-scale RDF streams processing on GPU. Within this framework, We convert RDF streams to a RDF graph in a unified and simple way. Then we can apply various SPARQL query engines to process continuous queries and utilize GPU to accelerate queries. Computation Module provides a Spark-based Join algorithm utilizing GPU for parallel joining, obtaining the final results. Besides, we provide Compute Resource Management to balance the scheduling and task execution between GPU and memory resources. Finally, we evaluate our work bulit on gStore and RDF-3X on the LUBM benchmark. The experimental results show that SRSPG is effective for real-time processing of large-scale RDF streams. Copyright 2019 for this paper by its authors.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Ren, T. and Rao, G. and Zhang, X. and Feng, Z.",2019,CEUR Workshop Proceedings,,scopus-search1.bib
Kolev2019431,Pipelined implementation of a parallel streaming method for time series correlation discovery on sliding windows,"This paper addresses the problem of continuously finding highly correlated pairs of time series over the most recent time window. The solution builds upon the ParCorr parallel method for online correlation discovery and is designed to run continuously on top of the UPM-CEP data streaming engine through efficient streaming operators. The implementation takes advantage of the flexible API of the streaming engine that provides low level primitives for developing custom operators. Thus, each operator is implemented to process incoming tuples on-the-fly and hence emit resulting tuples as early as possible. This guarantees a real pipelined flow of data that allows for outputting early results, as the experimental evaluation shows. Copyright © 2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Kolev, B. and Akbarinia, R. and Jimenez-Peris, R. and Levchenko, O. and Masseglia, F. and Patino, M. and Valduriez, P.",2019,"DATA 2019 - Proceedings of the 8th International Conference on Data Science, Technology and Applications",10.5220/0008191304310436,scopus-search1.bib;web-of-science-search1.bib
Pohl2019267,Adaptive Partitioning and Order-Preserved Merging of Data Streams,"Partitioning is a key concept for utilizing modern hardware, especially to exploit parallelism opportunities from many-core CPUs. In data streaming scenarios where parameters like tuple arrival rates can vary, adaptive strategies for partitioning solve the problem of overestimating or underestimating query workloads. While there are many possibilities to partition the data flow, threads running partitions independently from each other lead to unordered output inevitably. This is a considerable difficulty for applications where tuple order matters, like in stream reasoning or complex event processing scenarios. In this paper, we address this problem by combining an adaptive partitioning approach with an order-preserving merge algorithm. Since reordering output tuples can only worsen latency, we mainly focus on the throughput of queries while keeping the delay on individual tuples minimal. We run micro-benchmarks as well as the Linear Road benchmark, demonstrating correctness and effectiveness of our approach while scaling out on a single Xeon Phi many-core CPU up to 256 partitions. © 2019, Springer Nature Switzerland AG.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Pohl, C. and Sattler, K.-U.",2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-030-28730-6_17,scopus-search1.bib;web-of-science-search1.bib
Gradvohl201848,Metrics and tool for evaluating data stream processing systems,"With the Internet of Things and many other data sources continuously generating events, service providers who analyze these data need fast and flexible software. These software, called data stream processing systems, can be created from scratch or, as is more often the case today, use frameworks that already implement many of the functionality required for stream processing. In fact, programmers implement these software as distributed systems today because they need frameworks to deal with huge, fast and high throughput streams. That is the reason why a centralized system would hardly be able to handle data streams without eventually discarding some events. Therefore, it is important that, before putting a data stream processing system in production, we can simulate the scenarios that this system will handle and analyze its behavior. In this sense, this paper presents the general characteristics of the data stream processing systems, as well as some of the main metrics for the analysis of this sort of system. In addition, we present a new tool called B2-4DaSP that facilitates the task of analyzing data stream processing systems. We also illustrate some examples of the B2-4DaSP use for the analysis of two simple data stream applications. © 2018 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Gradvohl, and A.L.S.,",2018,"Proceedings - 2018 IEEE 6th International Conference on Future Internet of Things and Cloud Workshops, W-FiCloud 2018",10.1109/W-FiCloud.2018.00014,scopus-search1.bib;ieee2-search1.bib
Prasuna2018854,A novel approach for improved data replication using HDFS,"HDFS (Hadoop Distributed File System) is intended to store huge dataset values with accurate file location with high reliability and data streaming to the application is done at high bandwidth. HDFS deals with high fault tolerance with the use of replication of data. Many researches have been done on fitting the data in the exact location. The problem occurred in Hadoop distributed file system is difficulty with information space for storage. It is the most complicated problem which reduce the performance of the file system. To overcome this issue the proposed system aims to have the better data replication which depends upon the access count estimation in Hadoop framework. The proposed system creates the better replicas and to solve the data locality problem with improved arrangement of data replicas and to assign the task for efficient workers to complete the Map Reduce task to obtain the better results. By comparison with the existing system, the proposed system performs the better replication and solves the data locality problem. An experiment has been performed for evaluating the proposed technique with default technique and previously used replication techniques using a benchmark. With respect to the results obtained the proposed method obtained a better throughput when compared to the previous techniques. © 2018 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Prasuna, T. and Pravallika, K.G. and Babu, D.C. and Sindhura, V.",2018,"2018 3rd IEEE International Conference on Recent Trends in Electronics, Information and Communication Technology, RTEICT 2018 - Proceedings",10.1109/RTEICT42901.2018.9012371,scopus-search1.bib;ieee2-search1.bib
Kuo2018179,Critical task scheduling for data stream computing on heterogeneous clouds,"Internet of Things is an emerging paradigm to enable easy data collection and exchange among a wide variety of devices. When the scale of Internet of Things enlarges, the cloud computing system could be applied to mine these big data generated by Internet of Things. This paper proposes a task scheduling approach for time-critical data streaming applications on heterogeneous clouds. The proposed approach takes the tasks in critical stages into consideration, and re-schedules these tasks to appropriate resources to shorten their processing time. In general, selecting the time-critical task to give more resources may remove the execution bottleneck. A small-scale cloud system including 3 servers is built for experiments. The performance of the proposed approach is evaluated by three micro-benchmarks. Preliminary experimental results demonstrate the performance improvement of the critical task scheduling approach. © 2018, Springer Nature Singapore Pte Ltd.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Kuo, Y.-H. and Lee, Y.-H. and Huang, K.-C. and Lai, K.-C.",2018,Lecture Notes in Electrical Engineering,10.1007/978-981-10-7398-4_19,scopus-search1.bib
Gkolemis2018157,Automatic scaling of resources in a storm topology,"In the Big Data era, the batch processing of large volumes of data is simply not enough - data needs to be processed fast to support continuous reactions to changing conditions in real-time. Distributed stream processing systems have emerged as platforms of choice for applications that rely on real-time analytics, with Apache Storm [2] being one of the most prevalent representatives. Whether deployed on physical or virtual infrastructures, distributed stream processing systems are expected to make the most out of the available resources, i.e., achieve the highest throughput or lowest latency with the minimum resource utilisation. However, for Storm - as for most such systems - this is a cumbersome trial-and-error procedure, tied to the specific workload that needs to be processed and requiring manual tweaking of resource-related topology parameters. To this end, we propose ARiSTO, a system that automatically decides on the appropriate amount of resources to be provisioned for each node of the Storm workflow topology based on user-defined performance and cost constraints. ARiSTO employs two mechanisms: a static, model-based one, used at bootstrap time to predict the resource-related parameters that better fit the user needs and a dynamic, rule-based one that elastically auto-scales the allocated resources in order to maintain the desired performance even under changes in load. The experimental evaluation of our prototype proves the ability of ARiSto to efficiently decide on the resource-related configuration parameters, maintaining the desired throughput at all times. © Springer International Publishing AG 2018.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Gkolemis, E. and Doka, K. and Koziris, N.",2018,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-74875-7_10,scopus-search1.bib;web-of-science-search1.bib
Dazzi201829,"Noa-aid: Network overlays for adaptive information aggregation, indexing and discovery at the edge","This paper presents NOA-AID a network architecture for targeting highly distributed systems, composed of a large set of distributed stream processing devices, aimed at adaptive information indexing, aggregation and discovery in streams of data. The architecture is organized on two layers. The upper layer is aimed at supporting the information discovery process by providing a distributed index structure. The lower layer is mainly devoted to resource aggregation based on epidemic protocols targeting highly distributed and dynamic scenarios, well suited to stream-oriented scenarios. We present a theoretical study on the costs of information management operations, also giving an empirical validation of such findings. Finally, we presented an experimental evaluation of the ability of our solution to be effective and efficient in retrieving meaningful information in streams on a highly-dynamic and distributed scenario. © Springer International Publishing AG, part of Springer Nature 2018.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Dazzi, P. and Mordacchini, M.",2018,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-319-75178-8_3,scopus-search1.bib;web-of-science-search1.bib
Gad2016569,Local programming language barriers in stream-based systems,"Stream-based data processing systems, such as Complex Event Processing or data stream mining systems, may be composed of several components which may be implemented in various programming languages. In distributed scenarios, computer networks typically represent important bottlenecks. However, the performance of data exchange in local contexts may be as important as the performance of data exchange via computer networks. Local programming language barriers may represent important bottlenecks for components that are located on the same computer system. In distributed scenarios, it may be beneficial to relocate components on a single physical host for exploiting the higher local data throughput. The properties of stream-based systems pose challenges like high throughput requirements but also open up optimization potential such as leveraging batched transfers. We performed an experimental analysis of ways for bridging local programming language barriers using the examples of C, Java, and Python and analyzed the impact of batched forwarding. While local data exchange can be expected to offer a higher throughput than exchange across networks, our results show that batch forwarding can increase the local throughput by factors of up to 47.6 and we measured net throughputs up to 39.5 Gbps. © 2016 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Gad, R. and Kappes, M. and Medina-Bulo, I.",2016,Proceedings - IEEE Symposium on Computers and Communications,10.1109/ISCC.2016.7543798,scopus-search1.bib;web-of-science-search1.bib
Ray2016336,Poster: SPASS: Scalable event stream processing leveraging sharing opportunities,"Complex Event Processing (CEP) offers high-performance event analytics in time-critical decision-making applications. Yet supporting high-performance event processing has become increasingly difficult due to the increasing size and complexity of event pattern workloads. In this work, we propose the SPASS framework that leverages time-based event correlations among queries for sharing computation tasks among sequence queries in a workload. We show the NP-hardness of our CEP pattern sharing problem by reducing it from the Minimum Substring Cover problem. The SPASS system finds a shared pattern plan in polynomial-time covering all sequence patterns while still guaranteeing an optimality bound. Further, the SPASS system assures concurrent maintenance and reuse of sub-patterns in the shared pattern plan. Our experimental evaluation confirms that the SPASS framework achieves over 16-fold performance gain compared to the state-of-the-art solutions. © 2016 ACM.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Ray, M. and Lei, C. and Rundensteiner, E.A.",2016,DEBS 2016 - Proceedings of the 10th ACM International Conference on Distributed and Event-Based Systems,10.1145/2933267.2933288,scopus-search1.bib
Zhao201620,Cocktail: A hybrid system combining Hadoop and Storm,"Hadoop and Storm are playing a significant role in Cloud Computing and either of them has its own applicable area. Cocktail is a new hybrid system that combines Hadoop and Storm into one single system, leveraging the functions of two computing frameworks. The design and implementation of Cocktail includes a SQL-like query language making the implementation of details transparent for users, an intelligent framework selector based on cost model to choose appropriate framework automatically, and an efficient resource scheduling and task execution framework. Cocktail has a wide range of application scenarios from batch processing to stream computing, using Storm to process real-time data and Hadoop to process large-scale data. We compare the performance, throughput and scalability of Cocktail with SummingBird to demonstrate the practicability and capability. According to benchmark, for small-scale data, the performance of Cocktail is close to Summingbird based on Storm and 20%∼40% faster than Summingbird based on Hadoop. And for large-scale data, Cocktail's throughput is 40% higher than Summingbird's throughout based on Storm. © 2015 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zhao, Y. and Zhang, Y. and Yao, Y. and Li, Y. and Liu, P.",2015,"Proceedings of 2015 IEEE Advanced Information Technology, Electronic and Automation Control Conference, IAEAC 2015",10.1109/IAEAC.2015.7428510,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Gudumasu2016,Layer-based buffer aware rate adaptation design for SHVC video streaming,"This paper proposes a layer based buffer aware rate adaptation design which is able to avoid abrupt video quality fluctuation, reduce re-buffering latency and improve bandwidth utilization when compared to a conventional simulcast based adaptive streaming system. The proposed adaptation design schedules DASH segment requests based on the estimated bandwidth, dependencies among video layers and layer buffer fullness. Scalable HEVC video coding is the latest state-of-art video coding technique that can alleviate various issues caused by simulcast based adaptive video streaming. With scalable coded video streams, the video is encoded once into a number of layers representing different qualities and/or resolutions: a base layer (BL) and one or more enhancement layers (EL), each incrementally enhancing the quality of the lower layers. Such layer based coding structure allows fine granularity rate adaptation for the video streaming applications. Two video streaming use cases are presented in this paper. The first use case is to stream HD SHVC video over a wireless network where available bandwidth varies, and the performance comparison between proposed layer-based streaming approach and conventional simulcast streaming approach is provided. The second use case is to stream 4K/UHD SHVC video over a hybrid access network that consists of a 5G millimeter wave high-speed wireless link and a conventional wired or WiFi network. The simulation results verify that the proposed layer based rate adaptation approach is able to utilize the bandwidth more efficiently. As a result, a more consistent viewing experience with higher quality video content and minimal video quality fluctuations can be presented to the user. © 2016 SPIE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Gudumasu, S. and Hamza, A. and Asbun, E. and He, Y. and Ye, Y.",2016,Proceedings of SPIE - The International Society for Optical Engineering,10.1117/12.2235795,scopus-search1.bib;web-of-science-search1.bib
Chakraborty201677,A priority based resource scheduling technique for multitenant storm clusters work in progress paper,"In this work in progress paper, we present our ongoing effort towards devising a priority based resource scheduling technique and framework for apache storm. Apache Storm is a popular distributed real time stream processing engine which has been widely adopted by key players in the industry including YAHOO and Twitter. An application running in storm is called a topology that is characterized by a Directed Acyclic Graph (DAG). To run multiple of such topologies in a storm cluster, storm provides with default, out of the box scheduler called Isolation Scheduler. Isolation Scheduler assigns resources to topologies based on static resource configuration and does not provide any means to prioritize topologies based on their varying business priority. As a result, performance degradation, even complete starvation of topologies with high business priority is possible when available cluster resources are insufficient. A priority based resource scheduling strategy is proposed in this paper to overcome this problem. A preliminary performance evaluation is performed to demonstrate effectiveness of the proposed scheduler over the default storm Isolation Scheduler.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Chakraborty, R. and Majumdar, S.",2016,Simulation Series,,scopus-search1.bib;web-of-science-search1.bib
Li2015110,Programming model and resource management of distributed stream architecture,"While providing big data computing services using Internet resources, there remains a big challenge to researchers, including heterogeneity of Internet resources, dynamics of Internet resources and long latency of Internet communication. Current influent distributed computing models still have some shortage. A novel distributed stream computing model was proposed based on the traditional stream computing model, including the distributed stream programming model and resource management can efficiently support multiple parallel execution modes. The prototype system implemented on the 10 CPU-GPU heterogeneous nodes. Seven different benchmarks used in the simulation experiment. The experimental result shows that the distributed stream architecture can achieve the speedup of at least on average over the local serial computing, with significant potential for applications. © 2015, National University of Defense Technology. All right reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Li, X. and Yang, X. and Xu, X.",2015,Guofang Keji Daxue Xuebao/Journal of National University of Defense Technology,10.11887/j.cn.201506021,scopus-search1.bib
Mao2014771,Shadow VoD: Performance Evaluation as a Capability in Production P2P-CDN Hybrid VoD Networks,"Video-on-Demand (VoD) services have achieved great success recently. Most such streaming systems are P2P-CDNhybrid systems. To ensure reliable performance, the most efficient way is to subject those VoD streaming networks to large-scale, realistic performance evaluations. Our previous Shadow Stream system is a production Internet live streaming network with performance evaluation as a built-in capability. In this paper, we extend the same idea into the VoD services. There exists significant difference between live and VoD, hence Shadow Stream cannot be directly used in VoD context. Firstly, clients in P2PVoD service are not synchronized in viewing progress, secondly, in VoD there exists interactive operations (e.g., Pause and drag), thirdly, the different play points of users also bring difficulty to replacing departed real clients. In this paper, we solve all above mentioned challenges. We implement Shadow VoD and demonstrate its benefits through extensive evaluations. © 2014 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Mao, H. and Tian, C. and Sun, J. and Yan, J. and Wu, W. and Huang, B.",2014,"Proceedings - 2014 IEEE International Conference on Ubiquitous Intelligence and Computing, 2014 IEEE International Conference on Autonomic and Trusted Computing, 2014 IEEE International Conference on Scalable Computing and Communications and Associated Symposia/Workshops, UIC-ATC-ScalCom 2014",10.1109/UIC-ATC-ScalCom.2014.77,scopus-search1.bib;web-of-science-search1.bib;ieee3-search1.bib
Hanhirova201459,Performance simulation of heterogeneous computing systems,"We have developed a simulation environment (PSE) for performance analysis of heterogeneous computing systems. Our focus is on. systems with many core accelerators. As multiprocessor chips are constantly evolving, simulation is a viable tool to explore different configurations and to understand the hardware-software interaction. PSE is a resource reservation based simulator for layered models that describe the resource provisioning and resource usage within a system. To illustrate our methodology and our simulation environment, we present a small-scale demonstrative experiment. The demonstrative experiment shows how accelerated processing can be modeled. In the model, we connect a GPU into a NPU for video stream processing.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Hanhirova, J. and Hirvisalo, V.",2014,"Modelling and Simulation 2014 - European Simulation and Modelling Conference, ESM 2014",,scopus-search1.bib
Mory201283,Towards Interoperability of distributed interactive simulations through node-based openGL stream processing,"Coupling heterogeneous simulation environments is a requirement in the engineering domain. A novel approach exploits simulations' visualizations to setup distributed simulations: OpenGL stream processors intercept the dialogue between OpenGL clients and servers, and (distributedly) process the request-reply stream. As a first step towards an holisitic approach, we describe the Vanadium node-based OpenGL stream processing framework from the viewpoint of an integrated interoperability model. Results are a systematic examination of the framework's capabilities and limits; identification of open research questions; and an initial benchmark for architectural comparison with other OpenGL stream processing frameworks.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Mory, M. and Siegmund, N. and Blankenburg, A. and Saake, G.",2012,CEUR Workshop Proceedings,,scopus-search1.bib
Hassan2012,Performance analysis of video streaming on different hybrid CDN & P2P infrastructure,"With the rapid expansion of network application over the Internet, the deployment of live streaming systems become more and more popular, significantly enhancing the user experience. As the numbers of users are expanding significantly, the traditional Client-Server architecture can't afford the number of growing users. Therefore the video quality of service and network scalability is become so deprived. Based on the demand of users and drawbacks of client-server architecture, institutes and researchers have provided effective solutions to contrive new application systems called Content Delivery Network (CDN) and Peerto-Peer (P2P) network. Recently, researchers have proposed a hybrid approach that amalgamates both CDN and P2P was proposed in the literature. The goal of this paper is to simulate and investigate the performance of hybrid CDN and P2P on live-casting video distribution, and contrast it against our propounded hybrid CDN and P2P with hierarchical arrangement called Dynamic Mobile Server (DMS), in terms of average frame loss ratio, packet loss ratio and peak signal noise ratio.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Hassan, Md.M. and Neng, C.K. and Suan, L.C.",2012,IET Conference Publications,10.1049/cp.2012.2087,scopus-search1.bib;ieee3-search1.bib
Zhang20112065,Data parallel programming model for many-core architectures,"Emerging accelerating architectures, such as GPUs, have proved successful in providing significant performance gains to various application domains. This is done by exploiting data parallelism in existing algorithms. However, programming in a data-parallel fashion imposes extra burdens to programmers, who are used to writing sequential programs. New programming models and frameworks are needed to reach a balance between programmability, portability and performance. We start from stream processing domain and propose GStream, a general-purpose, scalable data streaming framework on GPUs. The contributions of GStream are as follows: (1) We provide powerful, yet concise language abstractions suitable to describe conventional algorithms as streaming problems. (2) We project these abstractions onto GPUs to fully exploit their inherent massive data-parallelism. (3) We demonstrate the viability of streaming on accelerators. Experiments show that the proposed framework provides flexibility, programmability and performance gains for various benchmarks from a collection of domains, including but not limited to data streaming, data parallel problems, numerical codes and text search. This work lays a foundation to our future work to develop more general data parallel programming models for many-core architectures. © 2011 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zhang, and Y.,",2011,IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum,10.1109/IPDPS.2011.378,scopus-search1.bib;ieee3-search1.bib
Oiki2011,Tonegawa: Highly scalable distributed web server with data stream processing,"We developed Tonegawa, which is a distributed Web server on top of a stream processing system called System S under development by IBM Research. Tonegawa takes staged execution approach and a web request is processed over multiple stages, each of which can be processed by one multi-core node or even distributed to a cluster of nodes. We conducted the performance evaluation of Tonegawa with the use of both static contents and dynamic contents, and showed that Tonegawa on multiple nodes can be utilized in the case where large computational effort is required. In addition, we demonstrated the qualitative software productivity with regards to the implementation of a web server using such a stream-style programming, which decreases potential bugs and brings highly extensibility to the system. © 2011 IEEE.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Oiki, T. and Suzumura, T.",2011,IEEE International Conference on Communications,10.1109/iccw.2011.5963582,scopus-search1.bib;ieee2-search1.bib
Chen2010709,Data stream analytics as cloud service for mobile applications,"Many mobile applications are based on cloud services such as location service, messaging service, etc. Currently most cloud services are based on statically prepared information rather than the real-time analytics results of dynamically captured events. A paradigm shift is to take Continuous Stream Analytics (CSA) as a cloud service, which, however, poses several specific challenges in scalability, latency, time-window semantics and transaction control. In this work we extend the SQL query engine to unify the processing of static relations and dynamic streams for providing the platform support of CSA service. This platform is significantly differentiated from the current generation of stream processing systems which are in general built separately from the database engine thus unable to take advantage of the functionalities already offered by the existing data management technology, and suffer from the overhead of inter-platform data access and movement. To capture the window semantics in CSA, we introduce the cycle-based query model and support it in terms of the cut-and-rewind query execution mechanism. This mechanism allows a SQL query to run cycle by cycle for processing the unbounded stream data chunk by chunk, but without shutting the query instance down between chunks for continuously maintaining the application state across the execution cycles, as required by sliding-window oriented operations. We also propose the cycle-based transaction model with cycle-based isolation and visibility. To scale-up analytics computation, we introduce the parallel infrastructure with multi-engines cooperated and synchronized based the common data chunking criteria without centralized coordination. To scale-up service provisioning, we investigate how to stage the continuously generated analytics results efficiently through metadata manipulation without physical data moving and copying. We have prototyped our approach by extending the PostgreSQL, resulting in a new kind of tightly integrated, highly efficient platform for providing CSA service. We tested the throughput and latency of this service using a well-known stream processing benchmark and with WebOS based Palm phones. The test results show that the proposed approach is highly competitive. Providing CSA cloud service using HP Neoview parallel database engine is currently explored. © 2010 Springer-Verlag.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Chen, Q. and Hsu, M.",2010,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-642-16949-6_4,scopus-search1.bib
Giacomazzi201089,Push-pull techniques in peer-to-peer video streaming systems with tree/forest topology,"Peer-to-peer video streaming systems are overlay networks used to distribute, among other types of content, live video content to large sets of users by relying on computing and network resources directly provided by users that are receiving video streaming services. Peer-to-peer video streaming systems with tree or forest topology are typically push-based, since the video content is provided by parent peers with no need for periodical requests. In this paper we analyze the impact of two complementing pull-based mechanisms aiming at improving the overall performance of the overlay network. Results show that the proposed hybrid push-pull approaches can be beneficial when the stability of the system is low, i.e., the average permanence time of peers is short. ©2010 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Giacomazzi, P. and Poli, A.",2010,"2010 International Congress on Ultra Modern Telecommunications and Control Systems and Workshops, ICUMT 2010",10.1109/ICUMT.2010.5676653,scopus-search1.bib;ieee3-search1.bib
Giacomazzi201096,Performance analysis of optimization techniques in peer-to-peer video streaming systems with tree/forest topology,"Peer-to-peer video streaming systems are overlay networks used to distribute, among other types of content, live video content to large sets of users by relying on network and computing resources directly provided by users that are receiving the video stream. In this paper, we analyze the impact of two optimization techniques that can be adopted in peer-to-peer video streaming systems, with tree or forest topology, to cope with the negative effects of user's leaves. We carry out a performance analysis of these systems, analyzing their sensitivity to the most critical system parameters, when nearly-permanent nodes, i.e., peers with a smaller-than-average leave rate, are used to optimize the overlay topology. ©2010 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Giacomazzi, P. and Poli, A.",2010,"2010 International Congress on Ultra Modern Telecommunications and Control Systems and Workshops, ICUMT 2010",10.1109/ICUMT.2010.5676652,scopus-search1.bib;ieee3-search1.bib
Deng2010,Assessing forecasting model performance for distributed stream processing systems,"Load forecasting plays an important role in the load balancing of the distributed stream processing systems. So, the performance and cost of three models: weighted moving average (WMA), exponential smoothing (ES) and grey model (GM(1,1)) are empirically evaluated by running three typical test cases on the load traces of the distributed stream processing systems and their results are reviewed according to three metrics: mean absolute percentage errors (MAPE), root of mean square error (RMSE), processing cost. According to the metrics of MAPE and RMSE, GM(1,1) performs best while WMA and ES perform much better than GM(1,1) according to the processing cost. However, when the load fluctuates dramatically, the prediction precision of the above models is low. ©2010 IEEE.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Deng, H. and Zhong, L. and Ye, M.",2010,"International Conference on Internet Technology and Applications, ITAP 2010 - Proceedings",10.1109/ITAPP.2010.5566395,scopus-search1.bib
Giacomazzi2009,Rewarding techniques in peer-to-peer video streaming systems with tree and forest topology,"Peer-to-peer networks are an increasingly popular solution for the distribution of media content to a large number of users, with limited investments for network infrastructures. The distribution of a real time video stream imposes strict performance requirements such as small playback delays and few frame losses. However, performances are greatly affected by the upload bandwidth of the access networks of peers. In this paper we propose a set of rewarding techniques able to cleverly exploit the use of peers' upload bandwidth, and provide a sensitivity analysis through which we determine the conditions under which the rewarding techniques are beneficial. The study, carried out through simulation, considers a general peer-to-peer video streaming reference model with tree/forest topology. From our point of view, the proposed rewarding technique is simple enough to be used as a benchmark for the evaluation of more sophisticated approaches. ©2009 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Giacomazzi, P. and Poli, A.",2009,2009 International Conference on Ultra Modern Telecommunications and Workshops,10.1109/ICUMT.2009.5345467,scopus-search1.bib
Liu200925,Temporal restriction query optimization for event stream processing,"The trend that organizations are linking Service Oriented Architecture (SOA) efforts closely to real-time processes makes research and industrial community increasingly focus on the SOA and Event Stream Processing (ESP) connection. ESP needs to correlate multiple continuous events involved in complex temporal relationship and attribute logic relationship to more abstract complex events in richer semantic. Due to high speed arrival rate of events and vast volume of registered complex event queries, memory consumption and incremental event query evaluation demand a comprehensive dedicate event stream processing framework with low-latency and high scalability. In this paper, we study problems of query optimization for ESP, especially topics on temporal restriction query. We first propose a framework to integrate ESP features with business process management and monitor. We then describe a query plan-based approach to efficiently execute ESP queries. Our approach uses algebraic conversion to efficiently handle temporal restriction queries, which are a key component of complex event processing, and computes temporal relevance condition at compile time to obtain event relevance time for a given expression. We demonstrate the effectiveness of our approach through a performance evaluation of our prototype implementation. © 2009 Springer Berlin Heidelberg.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Liu, J. and Wu, Q. and Liu, W.",2009,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10.1007/978-3-642-03996-6_3,scopus-search1.bib;web-of-science-search1.bib
Liu2008,Mathematical model and analysis of peer-to-peer IPTV,"Peer-to-peer overlay is an attractive solution to distribute video streams over large-scale IP networks. A number of algorithms and frameworks have been proposed. But generic and theoretical analysis of P2P streaming is scarce in the literature. In this paper, we present a novel probability model, making the formal analysis and performance evaluation of P2P IPTV accessible. With the help of the proposed model, we then reveal that the efficiency of P2P streaming system is closely correlated to piece diversity.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Liu, H. and Riley, G. and Ingle, R.",2008,"2008 2nd International Symposium on Advanced Networks and Telecommunication Systems, ANTS 2008",10.1109/ANTS.2008.4937793,scopus-search1.bib;web-of-science-search1.bib;ieee2-search1.bib
Nishikawa2008655,VLSI design of networking-oriented chip multi-processor: CUE-v3,"To realize secure and safe information communication environment, the authors are carrying out CUE (Coordinating Users' requirements and Engineering constraints) project and have designed a data-driven chip-multiprocessor CUE-v3 for ad hoc and ubiquitous communication environment available even in the case of emergency. Since CUE-series data-driven processors were designed to be an embedded programmable component as well as a multi-processor element, particular design considerations were taken to achieve pipelined stream processing and real-time processing for multimedia communication environment. In CUE project, an emulation/simulation facility RESCUE (Real-time Execution System for CUE-series data-driven processors) was also built to develop scalable chip multiprocessors in self-evolutional manner. Through evaluations by RESCUE, the latest version named CUE-v2 was developed. CUE-v2 is build as a hybrid processor enabling simultaneous processing of data-driven and control-driven threads to achieve higher performance for parallel processing and to avoid bottlenecks in sequential parts of real-time programs frequently encountered in time-sensitive applications. After discussing requirements to a platform for the ad hoc and ubiquitous communication environment, data-driven chip multi-processor CUE-v3 has been developing by integrating 4 CUE-v2's. In this paper, the CUE-v3 chip multiprocessor architecture including processing element and inter-connection network is firstly introduced. VLSI design and its evaluation will be finally addressed showing effectiveness of the CUE-v3 architecture with special emphasis on scalability and multi-processing capability. The authors have already confirmed scalability of CUE-v3 chip multi-processor architecture through VLSI design and performance evaluations and even if it sees moderately, the CUE-v3 architecture will achieve scalable performance improvement up to 16 processing elements.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Nishikawa, H. and Tomiyasu, H. and Uchida, H.",2008,"Proceedings of the 2008 International Conference on Parallel and Distributed Processing Techniques and Applications, PDPTA 2008",,scopus-search1.bib
Mansour2008476,Delay-aware rate control for multi-user scalable video streaming over mobile wireless networks,"In this paper, we propose a delay and capacity constrained multi-user scalable video streaming scheme that improves the average end-to-end distortion of transmitted video streams compared to traditional streaming strategies. Wireless video streaming applications are characterized by their bandwidth-intensity, delay-sensitivity, and loss-tolerance. Our main contributions include: (i) an analytical expression for packet delay and play-out deadline of unequal erasure protection (UXP) protected scalable video, (ii) an analysis of the performance of delay-aware, capacity-aware rate allocation for optimized UXP streaming scenarios, (iii) proof that unequal error protection causes a rate-constrained optimization problem to be non-convex. Performance evaluations using a 3GPP network simulator show that, for different channel capacities and packet loss rates, delay-aware non-stationary rate-allocation delivers significant gains which range between 1.65dB to 2dB in average Y-PSNR of the received video streams over delay-unaware strategies. These gains come at a cost of increased off-line computation which is performed prior to the streaming session and therefore, do not affect the run-time performance of the streaming system. © 2008 IEEE.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Mansour, H. and Krishnamurthy, V. and Nasiopoulos, P.",2008,IWCMC 2008 - International Wireless Communications and Mobile Computing Conference,10.1109/IWCMC.2008.83,scopus-search1.bib
Chan2008263,An efficient disk-array-based server design for a multicast video streaming system,"Recently, new Video-on-Demand (VoD) architectures using batching, patching and periodic broadcasting are introduced that are much more scalable than traditional unicast VoD systems. However the problem of designing an efficient server to implement these new multicast VoD architectures has received little attention. While existing server designs using round-based schedulers can still be used, results show that such designs are sub-optimal as they do not exploit the characteristics of fixed-schedule periodic broadcasting channels. This work addresses this challenge by presenting an efficient server design that can increase the system capacity by up to 60% compared to traditional video server designs. Copyright © 2008, Inderscience Publishers.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Chan, P.H. and Lee, J.Y.B.",2008,International Journal of Embedded Systems,10.1504/IJES.2008.022397,scopus-search1.bib
Asif2006,A multiprocessor framework for rapid-prototyping and evaluation of soft transceivers,"Recent years have seen rapid evolution in the architectures being explored for realizing high-speed software-defined radios. There is, however, a distinct need for a low-cost programmable platform where algorithms for base-band transceivers can be rapidly prototyped and tested with real-world data, streaming in from diverse sources of telecommunication traffic. This paper explores an analytical method for laying out such a generic platform. It investigates the constraints involved in realizing such a platform, and the minimum functionality needed within the solution so as to provide adequate scalability to allow the implementation of a wide variety of communication algorithms. The paper concludes with a case study of a multi-channel communication system that has been successfully implemented on the proposed platform, highlighting the performance benchmarks it had to meet in order to prove suitable for the task of communication system evaluation.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Asif, M.S. and Omer, M. and Luna, A. and Sheikh, N.M.",2006,"2006 IEEE GCC Conference, GCC 2006",10.1109/IEEEGCC.2006.5686260,scopus-search1.bib;ieee1-search1.bib
Huang2005241,An experimental analysis of DCT-based approaches for fine-grain multi-resolution video,"This paper presents the architectural trade-offs to support fine-grain multi-resolution video over a wide range of resolutions. In the future, video streaming systems will have to support video adaptation over an extremely large range of display requirements (e.g. 90×60 to 1920×1080), While several techniques have been proposed for multi-resolution video adaptation, which is also known as spatial scalability, they have focused mainly on limited spatial resolutions. In this paper, we examine the ability of current techniques to support wide-range spatial scalability. Based upon experiments with real video, we propose an architecture that can support wide-range adaptation more effectively. Our results indicate that multiple encodings with limited spatial adaptation from each encoding provides the best trade-off between efficient coding and the ability to adapt the stream to various resolutions. © 2005 SPIE and IS&T.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Huang, J. and Feng, W.-C. and Walpole, J. and Jouve, W.",2005,Proceedings of SPIE - The International Society for Optical Engineering,10.1117/12.592317,scopus-search1.bib;web-of-science-search1.bib
WOS:000242373900285,Minimizing delivery cost in hybrid overlay networks for streaming media,"There are three key issues on streaming system in Internet: scalability, delivery cost and QoS. The scalability and QoS was improved by means of pushing the streaming objects to the client sides in a CDNs-based streaming system, but the cost of deploying and maintaining was very high. However it was difficult to provide good QoS in a P2P-based streaming system due to the heterogeneous peers and arbitrary network connection of peers. Under the hybrid architecture proposed recently, this paper presents a new content delivery approach with which the streaming media is segmented, cached on proxy in CDNs and stored on peers in P2P dispersedly, hence it takes less resource of peers and be fairer. It is shown that traffic in CDNs and workloads of edge server are reduced effectively, the reliability of streaming delivery in P2P is ensured by using this approach according to performance analysis.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Tan, Jin and Chen, XiaoZhu",2006,"DCABES 2006 Proceedings, Vols 1 and 2",,web-of-science-search1.bib
WOS:000080978400002,Bandwidth-efficient continuous media streaming through optimal multiplexing,"Maximizing bandwidth efficiency in distributed continuous media streaming systems is the key in delivering cost-effective multimedia services to distributed and heterogeneous receivers. We introduce a technique based on stream multiplexing to achieve the highest possible bandwidth efficiency, while preserving stringent and deterministic quality of service guarantees. The technique accomplishes the optimal multiplexing (i.e. resulting in the lowest possible bandwidth allocation) by exploiting both the temporal and the spatial structures among a group of continuous media streams. We present a family of optimal multiplexing schedules. The adverse per-stream effects of optimal multiplexing are studied and a technique based on transmission rearrangement is proposed to mitigates these effects, without sacrificing the achieved multiplexing optimality. The results presented in the paper provide some fundamental criteria and limits in the design and evaluation of resource allocation, admission control and stream scheduling policies for bandwidth efficient continuous media streaming.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zhao, W and Tripathi, SK",1999,"PERFORMANCE EVALUATION REVIEW, SPECIAL ISSUE, VOL 27 NO 1, JUNE 1999: ACM SIGMETRICS `99, PROCEEDINGS - INTERNATIONAL CONFERENCE ON MEASUREMENT AND MODELING OF COMPUTER SYSTEMS",10.1145/301453.301476,web-of-science-search1.bib
WOS:000222679300006,Harmonic proportional bandwidth allocation and scheduling for service differentiation on streaming servers,"To provide ubiquitous access to the proliferating rich media on the Internet, scalable streaming servers must be able to provide differentiated services to various client requests. Recent advances of transcoding technology make network-I/O bandwidth usages at the server communication ports controllable by request schedulers on the fly. In this article, we propose a transcoding-enabled bandwidth allocation scheme for service differentiation on streaming servers. It aims to deliver high bit rate streams to high priority request classes without overcompromising low priority request classes. We investigate the problem of providing differentiated streaming services at application level in two aspects: stream bandwidth allocation and request scheduling. We formulate the bandwidth allocation problem as an optimization of a harmonic utility function of the stream quality factors and derive the optimal streaming bit rates for requests of different classes under various server load conditions. We prove that the optimal allocation, referred to as harmonic proportional allocation, not only maximizes the system utility function, but also guarantees proportional fair sharing between classes with different prespecified differentiation weights. We evaluate the allocation scheme, in combination with two popular request scheduling approaches, via extensive simulations and compare it with an absolute differentiation strategy and a proportional-share strategy tailored from relative differentiation in networking. Simulation results show that the harmonic proportional allocation scheme can meet the objective of relative differentiation in both short and long timescales and greatly enhance the service availability and maintain low queueing delay when the streaming system is highly loaded.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zhou, XB and Xu, CZ",2004,IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS,10.1109/TPDS.2004.43,web-of-science-search1.bib
WOS:000369860500090,ReMA: Real-Time 3D Video Streaming System for Mobile Devices,"User's multimedia interaction is facing a paradigm shift from 2D to 3D videos. Nonetheless, it is still difficult to watch 3D videos with a mobile device. With current technological barrier in wireless networking, it is hardly imagined that the timely transmission for a 3D video streaming could be feasible with the mobile device. In this paper, we propose ReMA, a novel 3D video distribution system based on a lightweight compression, a link-adaptive transmission scheme, and a network-side assistance for processing capability. ReMA consists of a 3D data transmitter, a receiver, and an infrastructure for generating and distributing 3D videos. We implemented the proposed system in a real test-bed and conducted a thorough empirical evaluation study. Based on the empirical results, the proposed system presents a great promise in streaming 3D video in real-time to the mobile device.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Lee, Suk and Kim, Hyunsoon and Lee, Woonghee and Kim, Hwantae and Jung, Jongtack and Kim, Hwangnam",2014,2014 IEEE INTERNATIONAL PERFORMANCE COMPUTING AND COMMUNICATIONS CONFERENCE (IPCCC),10.1109/PCCC.2014.7017111,web-of-science-search1.bib;ieee3-search1.bib
WOS:000458738400019,HSTREAM: A directive-based language extension for heterogeneous stream computing,"Big data streaming applications require utilization of heterogeneous parallel computing systems, which may comprise multiple multi-core CPUs and many-core accelerating devices such as NVIDIA GPUs and Intel Xeon Phis. Programming such systems require advanced knowledge of several hardware architectures and device-specific programming models, including OpenMP and CUDA. In this paper, we present HSTREAM, a compiler directive-based language extension to support programming stream computing applications for heterogeneous parallel computing systems. HSTREAM source-to-source compiler aims to increase the programming productivity by enabling programmers to annotate the parallel regions for heterogeneous execution and generate target specific code. The HSTREAM runtime automatically distributes the workload across CPUs and accelerating devices. We demonstrate the usefulness of HSTREAM language extension with various applications from the STREAM benchmark. Experimental evaluation results show that HSTREAM can keep the same programming simplicity as OpenMP, and the generated code can deliver performance beyond what CPUs-only and GPUs-only executions can deliver.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Memeti, Suejb and Pllana, Sabri",2018,2018 21ST IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE 2018),10.1109/CSE.2018.00026,web-of-science-search1.bib;ieee3-search1.bib
WOS:000443244400010,Cross-layer optimization for many-to-one wireless video streaming systems,This paper develops a cross-layer optimization solution for video streaming from multiple sources to a central proxy station over a wireless network. The proposed solution manages the application rates and transmission opportunities of various video sources based on the dynamic network conditions in such a way that minimizes the overall video distortion. The solution includes a new online approach for estimating the effective network airtime and a new video bitrate-distortion model. We demonstrate the effectiveness of the proposed solution through extensive experiments. The results show that the proposed solution substantially enhances the perceptual video quality while reducing the power consumed by the video sources and that the solution is highly adaptable to the existence of interfering network traffic.,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Alsmirat, Mohammad and Sarhan, Nabil",2018,MULTIMEDIA TOOLS AND APPLICATIONS,10.1007/s11042-018-5698-x,web-of-science-search1.bib
WOS:000318700200033,"Smart, Adaptive Mapping of Parallelism in the Presence of External Workload","Given the wide scale adoption of multi-cores in main stream computing, parallel programs rarely execute in isolation and have to share the platform with other applications that compete for resources. If the external workload is not considered when mapping a program, it leads to a significant drop in performance. This paper describes an automatic approach that combines compile-time knowledge of the program with dynamic runtime workload information to determine the best adaptive mapping of programs to available resources. This approach delivers increased performance for the target application without penalizing the existing workload. This approach is evaluated on NAS and SpecOMP parallel bench-mark programs across a wide range of workload scenarios. On average, our approach achieves performance gain of 1.5x over a state-of-art scheme on a 12 core machine.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Emani, Murali and Wang, Zheng and O'Boyle, Michael",2013,PROCEEDINGS OF THE 2013 IEEE/ACM INTERNATIONAL SYMPOSIUM ON CODE GENERATION AND OPTIMIZATION (CGO),10.1109/CGO.2013.6495010,web-of-science-search1.bib;ieee2-search1.bib
WOS:000283808600021,Stochastic analysis of a randomized detection algorithm for pollution attack in P2P live streaming systems,"Pollution attack is known to have a disastrous effect on existing P2P infrastructures it can reduce the number of legitimate P2P users by as much as 85% and it generates abundant bogus data which may deplete the communication bandwidth We propose a distributed defense and detection mechanism to resolve pollution attacks The mechanism is composed of a set of randomized and fully distributed algorithms that can be executed by any legitimate peer We present the analytical framework to quantify (a) the probability of false negative (b) the probability of false positive, and (c) the distribution of time needed for detection In our detection algorithm and analysis we consider the case of (1) single attacker within the neighborhood (2) multiple attackers within the neighborhood Furthermore we show how to `optimize the system parameters so as to quickly discover and eliminate malicious peers from the system (C) 2010 Elsevier B V All rights reserved",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Li, Yongkun and Lui, John",2010,PERFORMANCE EVALUATION,10.1016/j.peva.2010.08.005,web-of-science-search1.bib
WOS:000297212300011,Optimizing Linpack Benchmark on GPU-Accelerated Petascale Supercomputer,"In this paper we present the programming of the Unpack benchmark on TianHe-1 system, the first petascale supercomputer system of China, and the largest GPU-accelerated heterogeneous system ever attempted before. A hybrid programming model consisting of MPI, OpenMP and streaming computing is described to explore the task parallel, thread parallel and data parallel of the Unpack. We explain how we optimized the load distribution across the CPUs and GPUs using the two-level adaptive method and describe the implementation in details. To overcome the low-bandwidth between the CPU and GPU communication, we present a software pipelining technique to hide the communication overhead. Combined with other traditional optimizations, the Unpack we developed achieved 196.7 GFLOPS on a single compute element of TianHe-1. This result is 70.1% of the peak compute capability, 3.3 times faster than the result by using the vendor's library. On the full configuration of TianHe-1 our optimizations resulted in a Unpack performance of 0.563 PFLOPS, which made TianHe-1 the 5th fastest supercomputer on the Top500 list in November, 2009.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Wang, Feng and Yang, Can-Qun and Du, Yun-Fei and Chen, Juan and Yi, Hui-Zhan and Xu, Wei-Xia",2011,JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY,10.1007/s11390-011-0184-1,web-of-science-search1.bib
WOS:000296543000013,A game theory framework for ISP streaming traffic management,"The overlay/underlay topology mismatch affects the performance of existing P2P platforms that can generate large volumes of unnecessary inter-ISP network traffic. Although recent works have shown the benefits of network awareness P2P solutions, no studies have focused on the investigation of the ISP behavior and their cooperative/non-cooperative attitudes. This paper proposes a game theoretic framework to help the design of techniques promoting the ISP cooperation in P2P streaming platforms and decreasing unnecessary inter-domain streaming traffic. We first analyze some simple scenarios to discuss the existence of Nash equilibria, the Pareto optimality, and a fairness criterion to refine the equilibrium points. Moreover, we apply ideas from Evolutionary Game Theory to design a distributed schemata that the ISPs can use to reach ``socially acceptable{''} equilibrium points in a large ISP population. Furthermore, we develop a discrete event simulation to evaluate the effectiveness of the Evolutionary Game Theory framework. The study presented in the paper shows that the proposed strategies can effectively stimulate ISP cooperation aiming at the minimization of inter-ISP traffic and help to provide reliable P2P streaming service. (C) 2011 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Bioglio, V. and Gaeta, R. and Grangetto, M. and Sereno, M. and Spoto, S.",2011,PERFORMANCE EVALUATION,10.1016/j.peva.2011.07.007,web-of-science-search1.bib
WOS:000271224100012,Performance Optimization Strategies of High Performance Computing on GPU,"Recently GPU is widely utilized in scientific computing and engineering applications, owing primarily to the evolution of GPU architecture. Firstly, we analyze some key performance characters of GPU in detail, and the relationships among GPU architecture programming model and memory hierarchy. Secondly, we present three performance optimization strategies. Prefetching, Streamlining, and Task Division. Adequate experiments have been done to abstract the relationships among different factors and efficiency. Finally, we map the HPL benchmark to testify our strategies and achieve certain speedup.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ma, Anguo and Cai, Jing and Cheng, Yu and Ni, Xiaoqiang and Tang, Yuxing and Xing, Zuocheng",2009,"ADVANCED PARALLEL PROCESSING TECHNOLOGIES, PROCEEDINGS",,web-of-science-search1.bib
WOS:000851014500005,"Supporting Advanced Patterns in GRPPI, a Generic Parallel Pattern Interface","The emergence of generic interfaces, encapsulating algorithmic aspects in pattern-based constructions, has greatly alleviated the development of data-intensive and stream-processing applications. In this paper, we complement the basic patterns supported by GRPPI, a C++ General and Reusable Parallel Pattern Interface of the state-of-the-art, with the advanced parallel patterns Pool, Windowed-Farm, and Stream-Iterator. This collection of advanced patterns is basically oriented to some domain-specific applications, ranging from the evolutionary to the real-time computing areas, where compositions of basic patterns are not capable of fully mimicking algorithmic behavior of their original sequential codes. The experimental evaluation of the advanced patterns on a set of domain-specific use-cases, using different back-ends (C++ Threads, OpenMP and Intel TBB) and pattern-specific parameters, reports remarkable performance gains. We also demonstrate the benefits of the GRPPI pattern interface from the usability and flexibility points of view.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"RioAstorga, David and Dolz, Manuel and Fernandez, Javier and DanielGarcia, J.",2018,EURO-PAR 2017: PARALLEL PROCESSING WORKSHOPS,10.1007/978-3-319-75178-8_5,web-of-science-search1.bib
WOS:000284423900011,Exploiting Memory Access Patterns to Improve Memory Performance in Data-Parallel Architectures,"The introduction of General-Purpose computation on GPUs (GPGPUs) has changed the landscape for the future of parallel computing. At the core of this phenomenon are massively multithreaded, data-parallel architectures possessing impressive acceleration ratings, offering low-cost supercomputing together with attractive power budgets. Even given the numerous benefits provided by GPGPUs, there remain a number of barriers that delay wider adoption of these architectures. One major issue is the heterogeneous and distributed nature of the memory subsystem commonly found on data-parallel architectures. Application acceleration is highly dependent on being able to utilize the memory subsystem effectively so that all execution units remain busy. In this paper, we present techniques for enhancing the memory efficiency of applications on data-parallel architectures, based on the analysis and characterization of memory access patterns in loop bodies; we target vectorization via data transformation to benefit vector-based architectures (e. g., AMD GPUs) and algorithmic memory selection for scalar-based architectures (e. g., NVIDIA GPUs). We demonstrate the effectiveness of our proposed methods with kernels from a wide range of benchmark suites. For the benchmark kernels studied, we achieve consistent and significant performance improvements (up to 11.4 x and 13.5 x over baseline GPU implementations on each platform, respectively) by applying our proposed methodology.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Jang, Byunghyun and Schaa, Dana and Mistry, Perhaad and Kaeli, David",2011,IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS,10.1109/TPDS.2010.107,web-of-science-search1.bib
WOS:000249805400019,Load shedding and distributed resource control of stream processing networks,"Recent advances in networking and information technology boost the development of new and advanced services offered over communication systems that integrate a widely heterogeneous mix of applications and computer devices. Without careful traffic control and resource management, the implied dramatic increase in the demand for networking resources and remote application services may lead to substantial degradation of the Quality of Service as experienced by the end users. In this paper, we consider the problem of joint admission control and dynamic resource allocation in a stream processing network so as to optimize the overall system utility. With a primal-dual-based optimization approach, we show that the resource allocation problem and the admission control problem can be decomposed. We then present a distributed algorithm which incorporates a push-and-pull-based admission control mechanism, and a pressure-based c mu rule for resource allocation. We show that the algorithm guarantees the stability of the network and converges to the optimal solution. Various numerical experiments are then presented to demonstrate the quality of the solution and the speed of convergence. (c) 2007 Published by Elsevier B.V.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Feng, Hanhua and Liu, Zhen and Xia, Cathy and Zhang, Li",2007,PERFORMANCE EVALUATION,10.1016/j.peva.2007.06.023,web-of-science-search1.bib;scholar.bib
WOS:000401963300050,A Performance comparison Open-Source Stream Processing Platforms,"Distributed stream processing platforms are a new class of real-time monitoring systems that analyze and extract knowledge from large continuous streams of data. These type of systems are crucial for providing high throughput and low latency required by Big Data or Internet of Things monitoring applications. This paper describes and analyzes three main open-source distributed stream-processing platforms: Storm, Flink, and Spark Streaming. We analyze the system architectures and we compare their main features. We carry out two experiments concerning threats detection on network traffic to evaluate the throughput efficiency and the resilience to node failures. Results show that the performance of native stream processing systems, Storm and Flink, is up to 15 times higher than the micro-batch processing system, Spark Streaming. However, Spark Streaming is robust to node failures and provides recovery without losses.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Lopez, Martin and Lobato, Antonio and Duarte, Otto",2016,2016 IEEE GLOBAL COMMUNICATIONS CONFERENCE (GLOBECOM),,web-of-science-search1.bib
WOS:000720503200003,Amnis: Optimized stream processing for edge computing,"The proliferation of Internet-of-Things (IoT) devices is rapidly increasing the demands for efficient processing of low latency stream data generated close to the edge of the network. Edge computing-based stream processing techniques that carefully consider the heterogeneity of the computational and network resources available in the infrastructure provide significant benefits in optimizing the throughput and end-to-end latency of the data streams. In this paper, we propose a novel stream query processing framework called Amnis that optimizes the performance of the stream processing applications through a careful allocation of computational and network resources available at the edge. The Amnis approach differentiates itself through its consideration of data locality and resource constraints during physical plan generation and operator placement for the stream queries. Additionally, Amnis considers the coflow dependencies to optimize the network resource allocation through an application-level rate control mechanism. We implement a prototype of Amnis in Apache Storm. Our performance evaluation carried out in a real testbed shows that the proposed techniques achieve as much as 200X improvement on the end-to-end latency and 10X improvement on the overall throughput compared to the default resource aware scheduler in Storm. Keywords: Stream processing Edge computing Data locality Operator placement Coflow (C) 2021 Elsevier Inc. All rights reserved.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Xu, Jinlai and Palanisamy, Balaji and Wang, Qingyang and Ludwig, Heiko and Gopisetty, Sandeep",2022,JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING,10.1016/j.jpdc.2021.10.001,web-of-science-search1.bib;scholar.bib
WOS:000485736800013,Multi-Level Elasticity for Data Stream Processing,"This paper investigates reactive elasticity in stream processing environments where the performance goal is to analyze large amounts of data with low latency and minimum resources. Working in the context of Apache Storm, we propose an elastic management strategy which modulates the parallelism degree of applications' components while explicitly addressing the hierarchy of execution containers (virtual machines, processes and threads). We show that provisioning the wrong kind of container may lead to performance degradation and propose a solution that provisions the least expensive container (with minimum resources) to increase performance. We describe our monitoring metrics and show how we take into account the specifics of an execution environment. We provide an experimental evaluation with real-world applications which validates the applicability of our approach.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Marangozova-Martin, Vania and Palma, Noel and ElRheddane, Ahmed",2019,IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS,10.1109/TPDS.2019.2907950,web-of-science-search1.bib
WOS:000638398900001,Fine-Grained Multi-Query Stream Processing on Integrated Architectures,"Exploring the sharing opportunities among multiple stream queries is crucial for high-performance stream processing. Modern stream processing necessitates accelerating multiple queries by utilizing heterogeneous coprocessors, such as GPUs, and this has shown to be an effective method. Emerging CPU-GPU integrated architectures 6integrate CPU and GPU on the same chip and eliminate PCI-e bandwidth bottleneck. Such a novel architecture provides new opportunities for improving multi-query performance in stream processing but has not been fully explored by existing systems. We introduce a stream processing engine, called FineStream, for efficient multi-query window-based stream processing on CPU-GPU integrated architectures. FineStream's key contribution is a novel fine-grained workload scheduling mechanism between CPU and GPU to take advantage of both architectures. Particularly, FineStream is able to efficiently handle multiple queries in both static and dynamic streams. Our experimental results show that 1) on integrated architectures, FineStream achieves an average 52 percent throughput improvement and 36 percent lower latency over the state-of-the-art stream processing engine; 2) compared to the coarse-grained strategy of applying different devices for multiple queries, FineStream achieves 32 percent throughput improvement; 3) compared to the stream processing engine on the discrete architecture, FineStream on the integrated architecture achieves 10.4x price-throughput ratio, 1.8x energy efficiency, and can enjoy lower latency benefits.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zhang, Feng and Zhang, Chenyang and Yang, Lin and Zhang, Shuhao and He, Bingsheng and Lu, Wei and Du, Xiaoyong",2021,IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS,10.1109/TPDS.2021.3066407,web-of-science-search1.bib
WOS:000554828700057,Investigating Edge vs. Cloud Computing Trade-offs for Stream Processing,"The recent spectacular rise of the Internet of Things and the associated augmentation of the data deluge motivated the emergence of Edge computing as a means to distribute processing from centralized Clouds towards decentralized processing units close to the data sources. This led to new challenges in ways to distribute processing across Cloud-based, Edge-based or hybrid Cloud/Edge-based infrastructures. In particular, a major question is: how much can one improve (or degrade) the performance of an application by performing computation closer to the data sources rather than in the Cloud? This paper proposes a methodology to understand such performance trade-offs and illustrates it through experimental evaluation with two real-life stream processing use-cases executed on fully-Cloud and hybrid Cloud-Edge testbeds using state-of-the-art processing engines for each environment. We derive a set of take-aways for the community, highlighting the limitations of each environment, the scenarios that could benefit from hybrid Edge-Cloud deployments, what relevant parameters impact performance and how.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Silva, Pedro and Costan, Alexandru and Antoniu, Gabriel",2019,2019 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),10.1109/BigData47090.2019.9006139,web-of-science-search1.bib;ieee1-search1.bib
WOS:000414279000016,Towards Automatic Parameter Tuning of Stream Processing Systems,"Optimizing the performance of big-data streaming applications has become a daunting and time-consuming task: parameters may be tuned from a space of hundreds or even thousands of possible configurations. In this paper, we present a framework for automating parameter tuning for stream-processing systems. Our framework supports standard black-box optimization algorithms as well as a novel gray-box optimization algorithm. We demonstrate the multiple benefits of automated parameter tuning in optimizing three benchmark applications in Apache Storm. Our results show that a hill-climbing algorithm that uses a new heuristic sampling approach based on Latin Hypercube provides the best results. Our gray-box algorithm provides comparable results while being two to five times faster.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Bilal, Muhammad and Canini, Marco",2017,PROCEEDINGS OF THE 2017 SYMPOSIUM ON CLOUD COMPUTING (SOCC `17),10.1145/3127479.3127492,web-of-science-search1.bib
WOS:000415405200004,Empowering Stream Processing through Edge Clouds,"CHive is a new streaming analytics platform to run distributed SQL-style queries on edge clouds. However, CHive is currently tightly coupled to a specific stream processing system (SPS), Apache Storm. In this paper we address the decoupling of the CHive query planner and optimizer from the runtime environment, and also extend the latter to support pluggable runtimes through a common API. As runtimes, we currently support Apache Spark and Flink streaming. The fundamental contribution of this paper is to assess the cost of employing interstream parallelism in SPS. Experimental evaluation indicates that we can enable popular SPS to be distributed on edge clouds with stable overhead in terms of throughput.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Esteves, Sergio and Janssens, Nico and Theeten, Bart and Veiga, Luis",2017,SIGMOD RECORD,10.1145/3156655.3156661,web-of-science-search1.bib;acm2-search1.bib
WOS:000649540400007,NAMB: A Quick and Flexible Stream Processing Application Prototype Generator,"The importance of Big Data is nowadays established, both in industry and research fields, especially stream processing for its capability to analyze continuous data streams and provide statistics in real-time. Several data stream processing (DSP) platforms exist like the Storm, Flink, Spark Streaming and Heron Apache projects, or industrial products such as Google MillWheel. Usually, each platform is tested and analyzed using either specifically crafted benchmarks or realistic applications. Unfortunately, these applications are only briefly described and their source code is generally not available. Hence, making quick evaluations often involves rewriting complete applications on different platforms. The lack of a generic prototype application also makes it difficult for a developer to quickly evaluate the impact of some design choices. To address these issues, we present NAMB (Not only A Micro-Benchmark), a generic application prototype generator for DSP platforms. Given a high-level description of a stream processing application and its workload, NAMB automatically generates the code for different platforms. It features a flexible architecture which makes it easy to support new platforms. We demonstrate the benefits of our proposal to quickly generate application prototypes as well as benchmarks used in published papers. Overall, our approach provides easily replicable, comparable and customizable prototypes for data stream platforms. Moreover, NAMB provides similar performance in terms of latency and throughput to existing benchmarks, while only requiring a simple high-level description.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Pagliari, Alessio and Huet, Fabrice and Urvoy-Keller, Guillaume",2020,"2020 20TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET COMPUTING (CCGRID 2020)",10.1109/CCGrid49817.2020.00-87,web-of-science-search1.bib
WOS:000541051600075,Data Stream Processing at Network Edges,"This paper studies the problem of finding an assignment of data stream processing components onto servers under the objective to minimize both energy consumption and average delay experienced by end users within the system. The aforementioned problem is studied under the context of internet of things (IoT), where servers belonging to micro-datacenters are placed at network edges and thus close to data. We propose two algorithms to tackle the aforementioned problem taking into account limited server and network resources at microdatacenters. The first algorithm is called Delay Aware Algorithm (DA) and results in a delay efficient assignment without taking into account energy consumption. The second algorithm is called Energy Efficient and Delay Aware Algorithm (EFDA) and results in a both energy and delay efficient assignment of application processing components onto servers within the system. We provide an experimental evaluation to show the behavior of the proposed algorithms against algorithms in the literature.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Loukopoulos, Thanasis and Tziritas, Nikos and Koziri, Maria and Stamoulis, George and Khan, Samee and Xu, Cheng-Zhong and Zomaya, Albert",2018,2018 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW 2018),10.1109/IPDPSW.2018.00106,web-of-science-search1.bib
WOS:000851014500006,A Topology and Traffic Aware Two-Level Scheduler for Stream Processing Systems in a Heterogeneous Cluster,"To efficiently handle a large volume of data, scheduling algorithms in stream processing systems need to minimise the data movement between communicating tasks to improve system throughput. However, finding an optimal scheduling algorithm for these systems is NP-hard. In this paper, we propose a heuristic scheduling algorithm for a heterogeneous cluster-T3 Scheduler-that can efficiently identify the communicating tasks and assign them to the same node, up to a specified level of utilisation for that node. Using three common micro-benchmarks and an evaluation using a real-world application, we demonstrate that T3-Scheduler outperforms current state-of-the-art scheduling algorithms, such as Aniello et al.'s popular `Online scheduler', improving throughput by 20-72% for micro-benchmarks and 60% for the real-world application.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Eskandari, Leila and Mair, Jason and Huang, Zhiyi and Eyers, David",2018,EURO-PAR 2017: PARALLEL PROCESSING WORKSHOPS,10.1007/978-3-319-75178-8_6,web-of-science-search1.bib
WOS:000800208500019,OneOS: Middleware for Running Edge Computing Applications as Distributed POSIX Pipelines,"Edge computing application developers often need to employ a combination of software tools in order to deal with the challenges of heterogeneity and network dynamism. As a result, developers write extra code irrelevant to the core application logic, to provide interoperability between interacting tools. Existing software frameworks offer programming models and cloud-hosted services to ease the overall development process. However, the framework-specific APIs exacerbate the technology fragmentation problem, requiring developers to write more glue code between competing frameworks. In this paper, we present a middleware called OneOS, which provides a distributed computing environment through the standard POSIX API. OneOS maintains a global view of the computer network, presenting the same file system and process space to any user application running in the network. OneOS intercepts POSIX API calls and transparently handles the interaction with the corresponding I/O resource in the network. Using the OneOS Domain-Specific Language (DSL), users can distribute a legacy POSIX pipeline over the network. We evaluate the performance of OneOS against an open-source IoT Platform, ThingsJS, using an IoT stream processing benchmark suite, and a distributed video processing application. OneOS executes the programs about 3x faster than ThingsJS, and reduces the code size by about 25%.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Jung, Kumseok and Gascon-Samson, Julien and Pattabiraman, Karthik",2021,2021 ACM/IEEE 6TH SYMPOSIUM ON EDGE COMPUTING (SEC 2021),10.1145/3453142.3493505,web-of-science-search1.bib;ieee3-search1.bib
WOS:000543704600113,Stream Processing on Multi-Cores with GPUs: Parallel Programming Models' Challenges,"The stream processing paradigm is used in several scientific and enterprise applications in order to continuously compute results out of data items coming from data sources such as sensors. The full exploitation of the potential parallelism offered by current heterogeneous multi-cores equipped with one or more GPUs is still a challenge in the context of stream processing applications. In this work, our main goal is to present the parallel programming challenges that the programmer has to face when exploiting CPUs and GPUs' parallelism at the same time using traditional programming models. We highlight the parallelization methodology in two use-cases (the Mandelbrot Streaming benchmark and the PARSEC's Dedup application) to demonstrate the issues and benefits of using heterogeneous parallel hardware. The experiments conducted demonstrate how a high-level parallel programming model targeting stream processing like the one offered by SPar can be used to reduce the programming effort still offering a good level of performance if compared with state-of-the-art programming models.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Rockenbach, Dinei and Stein, Charles and Griebler, Dalvan and Mencagli, Gabriele and Torquati, Massimo and Danelutto, Marco and Fernandes, Luiz",2019,2019 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW),10.1109/IPDPSW.2019.00137,web-of-science-search1.bib
WOS:000468511200102,Radar: Reducing Tail Latencies for Batched Stream Processing with Blank Scheduling,"Real time processing of stream data has become increasingly vital. Batched stream systems which discretize stream data into micro-batches and leverage batch system to process these micro-batch stream jobs have attracted wide attention from academia and industry. Such batched stream system always works on heterogeneous environments which have heterogeneous resources and heterogeneous tasks. Unfortunately, current batched stream system implementations designed and optimized for homogeneous environments perform poorly on heterogeneous environments. We attribute suboptimal performance in heterogeneous environments to schedule tasks according to data locality and free slots. On the one hand, data locality creates a barrier between large tasks of slow node and powerful capacity of fast node because slow nodes prefer local large tasks rather than remote small tasks. On another hand, due to scheduler's blind eye to task size, there is a very high probability that large tasks are scheduled in the last few waves. These two aspects hinder perfect load balancing, causing tail latencies of large tasks. To address these issues, we propose a blank scheduling framework called Radar. Being aware of node capacity and task size, Radar pre-steals large tasks from slow nodes and schedules tasks according to the principle of large task first. Then Radar fills the small free slots by choosing small tasks corresponding to node's capacity. We implement Radar in Spark-2.1.1. Experimental results with benchmark show that Radar can reduce job completion time by 27.78% to 42.79% over Spark Streaming. Experimental results with real Tencent production application show that Radar can reduce response time by 28.57%.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Chen, Fei and Wu, Song and Jin, Hai and Lin, Liwei and Li, Rui",2018,IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS),10.1109/HPCC/SmartCity/DSS.2018.00134,web-of-science-search1.bib
WOS:000399141700119,A Case Study in Coordination Programming: Performance Evaluation of S-Net vs Intel's Concurrent Collections,"We present a programming methodology and runtime performance case study comparing the declarative data flow coordination language S-NET with Intel's Concurrent Collections (CnC). As a coordination language S-NET achieves a near-complete separation of concerns between sequential software components implemented in a separate algorithmic language and their parallel orchestration in an asynchronous data flow streaming network. We investigate the merits of S-NET and CnC with the help of a relevant and non-trivial linear algebra problem: tiled Cholesky decomposition. We describe two alternative S-NET implementations of tiled Cholesky factorization and compare them with two CnC implementations, one with explicit performance tuning and one without, that have previously been used to illustrate Intel CnC. Our experiments on a 48-core machine demonstrate that S-NET manages to outperform CnC on this problem.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zaichenkov, Pavel and Gijsbers, Bert and Grelck, Clemens and Tveretina, Olga and Shafarenko, Alex",2014,PROCEEDINGS OF 2014 IEEE INTERNATIONAL PARALLEL & DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW),10.1109/IPDPSW.2014.118,web-of-science-search1.bib
WOS:000827652300002,Evaluating Micro-batch and Data Frequency for Stream Processing Applications on Multi-cores,"In stream processing, data arrives constantly and is often unpredictable. It can show large fluctuations in arrival frequency, size, complexity, and other factors. These fluctuations can strongly impact application latency and throughput, which are critical factors in this domain. Therefore, there is a significant amount of research on self-adaptive techniques involving elasticity or micro-batching as a way to mitigate this impact. However, there is a lack of benchmarks and tools for helping researchers to investigate micro-batching and data stream frequency implications. In this paper, we extend a benchmarking framework to support dynamic micro-batching and data stream frequency management. We used it to create custom benchmarks and compare latency and throughput aspects from two different parallel libraries. We validate our solution through an extensive analysis of the impact of micro-batching and data stream frequency on stream processing applications using Intel TBB and FastFlow, which are two libraries that leverage stream parallelism on multi-core architectures. Our results demonstrated up to 33% throughput gain over latency using micro-batches. Additionally, while TBB ensures lower latency, FastFlow ensures higher throughput in the parallel applications for different data stream frequency configurations.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Garcia, Adriano and Griebler, Dalvan and Schepke, Claudio and Fernandes, Luiz",2022,"30TH EUROMICRO INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND NETWORK-BASED PROCESSING (PDP 2022)",10.1109/PDP55904.2022.00011,web-of-science-search1.bib
WOS:000437997500018,Paving the way towards high-level parallel pattern interfaces for data stream processing,"The emergence of the Internet of Things (IoT) data stream applications has posed a number of new challenges to existing infrastructures, processing engines, and programming models. In this sense, high-level interfaces, encapsulating algorithmic aspects in pattern-based constructions, have considerably reduced the development and parallelization efforts of this type of applications. An example of parallel pattern interface is GRPPI, a C++ generic high-level library that acts as a layer between developers and existing parallel programming frameworks, such as C++ threads, OpenMP and Intel TBB. In this paper, we complement the basic patterns supported by GRPPI with the new stream operators Split-Join and Window, and the advanced parallel patterns Stream-Pool, Windowed-Farm and Stream-Iterator for the aforementioned back ends. Thanks to these new stream operators, complex compositions among streaming patterns can be expressed. On the other hand, the collection of advanced patterns allows users to tackle some domain-specific applications, ranging from the evolutionary to the real-time computing areas, where compositions of basic patterns are not capable of fully mimicking the algorithmic behavior of their original sequential codes. The experimental evaluation of the new advanced patterns and the stream operators on a set of domain-specific use-cases, using different back ends and pattern-specific parameters, reports considerable performance gains with respect to the sequential versions. Additionally, we demonstrate the benefits of the GRPPI pattern interface from the usability, flexibility and readability points of view. (C) 2018 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"RioAstorga, David and Dolz, Manuel and Fernandez, Javier and DanielGarcia, J.",2018,FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE,10.1016/j.future.2018.05.011,web-of-science-search1.bib
WOS:000336665300526,Optimization of real-time ultrasound PCIe data streaming and OpenCL processing for SAFT imaging,"Our goal is to develop a complete ultrasound platform based on real-time SAFT (Synthetic Aperture Focusing Technique) GPU processing. We are planning to integrate all the ultrasound modules and processing resources (GPU) in a single rack enclosure with the PCIe switch fabric backplane. The first developed module (RX64) provides acquisition and streaming of 64 ultrasound channels. We implemented and benchmarked data streaming from the RX64 to the GPU memory and the SAFT image reconstruction on the GPU. A high system performance was achieved using hardware assisted direct memory transfers and pipelined processing workflow. The complete system throughput, including 128 channel data transfer at 16kS per line and low-resolution 256x256 pixel image SAFT reconstruction on a single Nvidia K5000 GPU, reached 450 fps. The obtained results proved the feasibility of the ultrasound real-time imaging system with GPU SAFT processing.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Walczak, M. and Lewandowski, M. and Zolek, N.",2013,2013 IEEE INTERNATIONAL ULTRASONICS SYMPOSIUM (IUS),10.1109/ULTSYM.2013.0527,web-of-science-search1.bib;ieee3-search1.bib
WOS:000238329200078,<bold>Calder Query Grid Service: Insights and Experimental Evaluation</bold>,"We have architected and evaluated a new kind of data resource, one that is composed of a logical collection of ephemeral data streams that could be viewed as a collection of publish-subscribe ``channels{''} over which rich data-access and semantic operations can be performed. This paper contributes new insight to stream processing under the highly asynchronous stream workloads often found in data-driven scientific applications, and presents insights gained through porting a distributed stream processing system to a Grid services framework. Experimental results reveal limits on stream processing rates that are directly tied to differences in stream rates.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Vijayakumar, Nithya and Liu, Ying and Plale, Beth",2006,SIXTH IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID: SPANNING THE WORLD AND BEYOND,,web-of-science-search1.bib
WOS:000433473700009,Stream Processing Dual-Track CGRA for Object Inference,"With the development of machine learning technology, the exploration of energy-efficient and flexible architectures for object inference algorithms is of growing interest in recent years. However, not many publications concentrate on a coarse-grained reconfigurable architecture (CGRA) for object inference algorithms. This paper provides a stream processing, dual-track programming CGRA-based approach to address the inherent computing characteristics of algorithms in object inference. Based on the proposed approach, an architecture called stream dual-track CGRA (SDT-CGRA) is presented as an implementation prototype. To evaluate the performance, the SDT-CGRA is realized in Verilog HDL and implemented in Semiconductor Manufacturing International Corporation 55-nm process, with the footprint of 5.19 mm(2) at 450 MHz. Seven object inference algorithms, including convolutional neural network (CNN), k-means, principal component analysis (PCA), spatial pyramid matching (SPM), linear support vector machine (SVM), Softmax, and Joint Bayesian, are selected as benchmarks. The experimental results show that the SDT-CGRA can gain on average 343.8 times and 17.7 times higher energy efficiency for Softmax, PCA, and CNN, 621.0 times and 1261.8 times higher energy efficiency for k-means, SPM, linear-SVM, and Joint-Bayesian algorithms when compared with the Intel Xeon E5-2637 CPU and the Nvidia TitanX graphics processing unit. When compared with the state-of-the-art solutions of AlexNet on field-programmable gate array and CGRA, the proposed SDT-CGRA can achieve a 1.78 times increase in energy efficiency and a 13 times speedup, respectively.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Fan, Xitian and Wu, Di and Cao, Wei and Luk, Wayne and Wang, Lingli",2018,IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS,10.1109/TVLSI.2018.2797600,web-of-science-search1.bib;ieee2-search1.bib
WOS:000565234200096,"F3C: Fog-enabled Joint Computation, Communication and Caching Resource Sharing for Energy-Efficient IoT Data Stream Processing","Fog/edge computing has been recently regarded as a promising approach for supporting emerging mission-critical Internet of Things (IoT) applications on capacity and battery constrained devices. By harvesting and collaborating a massive crowd of devices in close proximity for computation, communication and caching resource sharing (i.e., 3C resources), it enables great potentials in low-latency and energy-efficient IoT task execution. To efficiently exploit 3C resources of fog devices in proximity, we propose F3C, a fog-enabled 3C resource sharing framework for energy-efficient IoT data stream processing by solving an energy cost minimization problem under 3C constraints. Nevertheless, the minimization problem proves to be NP-hard via reduction to a Generalized Assignment Problem (GAP). To cope with such challenge, we propose an efficient F3C algorithm based on an iterative task team formation mechanism which regards each task's 3C resource sharing as a subproblem solved by the elaborated min cost flow transformation. Via utility improving iterations, the proposed F3C algorithm is shown to converge to a stable system point. Extensive performance evaluations demonstrate that our F3C algorithm can achieve superior performance in energy saving compared to various benchmarks.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Luo, Siqi and Chen, Xu and Zhou, Zhi",2019,2019 39TH IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS (ICDCS 2019),10.1109/ICDCS.2019.00105,web-of-science-search1.bib
WOS:000167653300232,An investigation of arbitration in servers for distributed multimedia applications,"For many client-server based multimedia applications, server performance is a crucial factor. Such applications often require the reliable support of continuous real-time data streaming to deliver audio-visual data to end users. In conventional multimedia servers, storage and network controllers can operate independently and concurrently. Conflicting accesses to shared resources, such as the system bus and main memory are traditionally resolved by arbitration, which can hence affect a server's ability to deliver streams to the network concurrently. We use simulations to study a number of arbitration protocols and their effects on server performance in a video-on-demand scenario. Our findings suggest that these protocol yield comparable performance (parallel data streams), as long as storage controllers are not treated preferentially. Moreover, the maximum bus tenure of I/O devices should be restricted to avoid starvation of network controllers operating with small block size.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Maierhofer, M and Bailey, C and Batatia, H and Sotudeh, R",1999,"INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED PROCESSING TECHNIQUES AND APPLICATIONS, VOLS I-V, PROCEEDINGS",,web-of-science-search1.bib
WOS:000426811500005,In-Memory Stream Indexing of Massive and Fast Incoming Multimedia Content,"In this article, a media storm indexing mechanism is presented, where media storms are defined as fast incoming batches. We propose an approximate media storm indexing mechanism to index/store massive image collections with varying incoming image rate. To evaluate the proposed indexing mechanism, two architectures are used: i) a baseline architecture, which utilizes a disk-based processing strategy and ii) an in-memory architecture, which uses the Flink distributed stream processing framework. This study is the first in the literature to utilize an in-memory processing strategy to provide a media storm indexing mechanism. In the experimental evaluation conducted on two image datasets, among the largest publicly available with 80 M and 1 B images, a media storm generator is implemented to evaluate the proposed media storm indexing mechanism on different indexing workloads, that is, images that come with high volume and different velocity at the scale of 105 and 106 incoming images per second. Using the approximate media storm indexing mechanism a significant speedup factor, equal to 26.32 on average, is achieved compared with conventional indexing techniques, while maintaining high search accuracy, after having indexed the media storms. Finally, the implementations of both architectures and media storm indexing mechanisms are made publicly available.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Antaris, Stefanos and Rafailidis, Dimitrios",2018,IEEE TRANSACTIONS ON BIG DATA,10.1109/TBDATA.2017.2697441,web-of-science-search1.bib;ieee1-search1.bib
WOS:000628649800041,Poster: Generating Reproducible Out-of-Order Data Streams,"Evaluating modern stream processing systems in a reproducible manner requires data streams with different data distributions, data rates, and real-world characteristics such as delayed and out-of-order tuples. In this paper, we present an open source stream generator which generates reproducible and deterministic out-of-order streams based on real data files, simulating arbitrary fractions of out-of-order tuples and their respective delays.",FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Grulich, Philipp and Traub, Jonas and Bress, Sebastian and Katsifodimos, Asterios and Markl, Volker and Rabl, Tilmann",2019,DEBS'19: PROCEEDINGS OF THE 13TH ACM INTERNATIONAL CONFERENCE ON DISTRIBUTED AND EVENT-BASED SYSTEMS,10.1145/3328905.3332511,web-of-science-search1.bib;acm1-search1.bib
WOS:000613217600001,"Mapping the Big Data Landscape: Technologies, Platforms and Paradigms for Real-Time Analytics of Data Streams","The `Big Data' of yesterday is the `data' of today. As technology progresses, new challenges arise and new solutions are developed. Due to the emergence of Internet of Things applications within the last decade, the field of Data Mining has been faced with the challenge of processing and analysing data streams in real-time, and under high data throughput conditions. This is often referred to as the Velocity aspect of Big Data. Whereas there are numerous reviews on Data Stream Mining techniques and applications, there is very little work surveying Data Stream processing paradigms and associated technologies, from data collection through to pre-processing and feature processing, from the perspective of the user, not that of the service provider. In this article, we evaluate a particular type of solution, which focuses on streaming data, and processing pipelines that permit online analysis of data streams that cannot be stored as-is on the computing platform. We review foundational computational concepts such as distributed computation, fault-tolerant computing, and computational paradigms/architectures. We then review the available technological solutions, and applications that pertain to data stream mining as case studies of these theoretical concepts. We conclude with a discussion of the field of data stream processing/analytics, future directions and research challenges.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Dubuc, Timothee and Stahl, Frederic and Roesch, Etienne",2021,IEEE ACCESS,10.1109/ACCESS.2020.3046132,web-of-science-search1.bib;ieee2-search1.bib
WOS:000529303200020,Multi-tenant Pub/Sub Processing for Real-Time Data Streams,"Devices and sensors generate streams of data across a diversity of locations and protocols. That data usually reaches a central platform that is used to store and process the streams. Processing can be done in real time, with transformations and enrichment happening on-the-fly, but it can also happen after data is stored and organized in repositories. In the former case, stream processing technologies are required to operate on the data; in the latter batch analytics and queries are of common use. This paper introduces a runtime to dynamically construct data stream processing topologies based on user-supplied code. These dynamic topologies are built on-the-fly using a data subscription model defined by the applications that consume data. Each user-defined processing unit is called a Service Object. Every Service Object consumes input data streams and may produce output streams that others can consume. The subscription-based programing model enables multiple users to deploy their own data-processing services. The runtime does the dynamic forwarding of data and execution of Service Objects from different users. Data streams can originate in real-world devices or they can be the outputs of Service Objects. The runtime leverages Apache STORM for parallel data processing, that combined with dynamic user-code injection provides multi-tenant stream processing topologies. In this work we describe the runtime, its features and implementation details, as well as we include a performance evaluation of some of its core components.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Villalba, Alvaro and Carrera, David",2019,EURO-PAR 2018: PARALLEL PROCESSING WORKSHOPS,10.1007/978-3-030-10549-5_20,web-of-science-search1.bib
WOS:000323832900005,Stream-monitoring with BlockMon: Convergence of Network Measurements and Data Analytics Platforms,"Recent work in network measurements focuses on scaling the performance of monitoring platforms to 10Gb/s and beyond. Concurrently, IT community focuses on scaling the analysis of big-data over a cluster of nodes. So far, combinations of these approaches have targeted fexibility and usability over real-timeliness of results and efficient allocation of resources. In this paper we show how to meet both objectives with BlockMon, a network monitoring platform originally designed to work on a single node, which we extended to run distributed stream-data analytics tasks. We compare its performance against Storm and Apache S4, the state-of-the-art open-source stream-processing platforms, by implementing a phone call anomaly detection system and a Twitter trending algorithm: our enhanced BlockMon has a gain in performance of over 2.5x and 23x, respectively. Given the different nature of those applications and the performance of BlockMon as single-node network monitor {[}1], we expect our results to hold for a broadrange of applications, making distributed BlockMon a good candidate for the convergence of network-measurement and IT-analysis platforms.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Simoncelli, Davide and Dusi, Maurizio and Gringoli, Francesco and Niccolini, Saverio",2013,ACM SIGCOMM COMPUTER COMMUNICATION REVIEW,10.1145/2479957.2479962,web-of-science-search1.bib;acm1-search1.bib
WOS:000502789700016,DeepChunk: Deep Q-Learning for Chunk-Based Caching in Wireless Data Processing Networks,"A Data Processing Network (DPN) streams massive volumes of data collected and stored by the network to multiple processing units to compute desired results in a timely fashion. Due to ever-increasing traffic, distributed cache nodes can be deployed to store hot data and rapidly deliver them for consumption. However, prior work on caching policies has primarily focused on the potential gains in network performance, e.g., cache hit ratio and download latency, while neglecting the impact of cache on data processing and consumption. In this paper, we propose a novel framework, DeepChunk, which leverages deep Q-learning for chunk-based caching in wireless DPN. We show that cache policies must be optimized for both network performance during data delivery and processing efficiency during data consumption. Specifically, DeepChunk utilizes a model-free approach by jointly learning limited network, data streaming, and processing statistics at runtime and making cache update decisions under the guidance of deep Q-learning. It enables a joint optimization of multiple objectives including chunk hit ratio, processing stall time, and object download time while being self-adaptive under the time-varying workload and network conditions. We build a prototype implementation of DeepChunk with Ceph, a popular distributed object storage system. Based on real-world Wifi and 4G traces, our extensive experiments and evaluation demonstrate significant improvement, i.e., 52% increase in total reward and 68% decrease in processing stall time, over a number of baseline caching policies.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Wang, Yimeng and Li, Yongbo and Lan, Tian and Aggarwal, Vaneet",2019,IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING,10.1109/TCCN.2019.2947550,web-of-science-search1.bib
WOS:000622094200008,"Pebbles: Leveraging Sketches for Processing Voluminous, High Velocity Data Streams","Voluminous, time-series data streams originating in continuous sensing environments pose data ingestion and processing challenges. We present a holistic methodology centered around data sketching to address both challenges. We introduce an order-preserving sketching algorithm that we have designed for space-efficient representation of multi-feature streams with native support for stream processing related operations. Observational streams are preprocessed at the edges of the network generating sketched streams to reduce data transfer costs and energy consumption. Ingested sketched streams are then processed using sketch-aware extensions to existing stream processing APIs delivering improved performance. Our benchmarks with real-world datasets show up to a similar to 8x reduction in data volumes transferred and a similar to 27x improvement in throughput.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Buddhika, Thilina and Pallickara, Sangmi and Pallickara, Shrideep",2021,IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS,10.1109/TPDS.2021.3055265,web-of-science-search1.bib
WOS:000380462900025,"Large-Scale Network Traffic Monitoring with DBStream, a System for Rolling Big Data Analysis","The complexity of the Internet has rapidly increased, making it more important and challenging to design scalable network monitoring tools. Network monitoring typically requires rolling data analysis, i.e., continuously and incrementally updating (rolling-over) various reports and statistics over high-volume data streams. In this paper, we describe DBStream, which is an SQL-based system that explicitly supports incremental queries for rolling data analysis. We also present a performance comparison of DBStream with a parallel data processing engine (Spark), showing that, in some scenarios, a single DBStream node can outperform a cluster of ten Spark nodes on rolling network monitoring workloads. Although our performance evaluation is based on network monitoring data, our results can be generalized to other big data problems with high volume and velocity.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Baer, Arian and Finamore, Alessandro and Casas, Pedro and Golab, Lukasz and Mellia, Marco",2014,2014 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),,web-of-science-search1.bib
WOS:000352123000002,Time- and Space-Efficient Sliding Window Top-k Query Processing,"A sliding window top-k (top-k/w) query monitors incoming data stream objects within a sliding window of size w to identify the k highest-ranked objects with respect to a given scoring function over time. Processing of such queries is challenging because, even when an object is not a top-k/w object at the time when it enters the processing system, it might become one in the future. Thus a set of potential top-k/w objects has to be stored in memory while its size should be minimized to efficiently cope with high data streaming rates. Existing approaches typically store top-k/w and candidate sliding window objects in a k-skyband over a two-dimensional score-time space. However, due to continuous changes of the k-skyband, its maintenance is quite costly. Probabilistic k-skyband is a novel data structure storing data stream objects from a sliding window with significant probability to become top-k/w objects in future. Continuous probabilistic k-skyband. maintenance offers considerably improved runtime performance compared to k-skyband maintenance, especially for large values of k, at the expense of a small and controllable error rate. We propose two possible probabilistic k-skyband usages: (i) When it is used to process all sliding window objects, the resulting top-k/w algorithm is approximate and adequate for processing random-order data streams. (ii) When probabilistic k-skyband is used to process only a subset of most recent sliding window objects, it can improve the runtime performance of continuous k-skyband maintenance, resulting in a novel exact top-k/w algorithm. Our experimental evaluation systematically compares different top-k/w processing algorithms and shows that while competing algorithms offer either time efficiency at the expanse of space efficiency or vice-versa, our algorithms based on the probabilistic k-skyband are both time and space efficient.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Pripuzic, Kresimir and Zarko, Ivana and Aberer, Karl",2015,ACM TRANSACTIONS ON DATABASE SYSTEMS,10.1145/2736701,web-of-science-search1.bib
WOS:000861398600011,EdgeFaaSBench: Benchmarking Edge Devices Using Serverless Computing,"Due to the development of small-size, energy-efficient, and powerful CPUs and GPUs for single board computers, various edge devices are widely adopted for hosting real-world applications, including real-time object detection, autonomous driving, and sensor stream processing. At the same time, serverless computing receives increasing attention as a new application deployment model because of its simplicity, scalability, event-driven processing, and short-lived computation. Therefore, there is a growing demand for applying serverless computing to edge computing environments. However, due to the lack of characterization of serverless edge computing (e.g., application performance and impact from resource heterogeneity), researchers and practitioners have to conduct tedious measurements to understand the performance of serverless applications on edge devices in non-systematic ways. We create EdgeFaaSBench, a novel benchmark suite for serverless computing on edge devices, to bridge this gap. EdgeFaaSBench is developed on top of Apache OpenFaaS with Docker Swarm and can run various serverless benchmark workloads on edge devices with different hardware specifications (e.g., GPUs). EdgeFaaSBench contains 14 different benchmark workloads running on heterogeneous edge devices and captures various system-level, application-level, and serverless-specific metrics, including system utilization, response time, cold/warm start times, and impact of concurrent function executions. Experimental studies are conducted on two widely used edge devices, Raspberry Pi 4B and Jetson Nano, to show EdgeFaaSBench's capabilities to benchmark serverless computing on edge devices.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Rajput, Kaustubh and Kulkarni, Chinmay and Cho, Byungjin and Wang, Wei and Kim, In",2022,2022 IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING & COMMUNICATIONS (IEEE EDGE 2022),10.1109/EDGE55608.2022.00024,web-of-science-search1.bib;ieee3-search1.bib
WOS:000266241500012,Scalability of Fork/Join Queueing Networks with Blocking,"This paper investigates how the through put of a general fork-join queueing network with blocking behaves as the number of nodes increases to infinity while the processing speed and buffer space of each node stay unchanged. The problem is motivated by applications arising from distributed systems and computer networks. One example is large-scale distributed stream processing systems where TCP is used as the transport protocol for data transfer in between processing components. Other examples include reliable multicast in overlay networks, and reliable data transfer in ad hoc networks. Using an analytical approach, the paper establishes bounds on the asymptotic throughput of such a network. For a subclass of networks which are balanced, we obtain sufficient conditions under which the network stays scalable in the sense that the throughput is lower bounded by a positive constant as the network size increases. Necessary conditions of throughput scalability are derived for general networks. The special class of series-parallel networks is then studied in greater detail, where the asymptotic behavior of the throughput is characterized.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Xia, Cathy and Liu, Zhen and Towsley, Don and Lelarge, Marc",2007,SIGMETRICS Perform. Eval. Rev.,10.1145/1269899.1254898,web-of-science-search1.bib;acm1-search1.bib;acm1-search1.bib
WOS:000259128800002,A business process monitor for a mobile phone recharging system,"Dependable (i.e. accurate and timely) monitoring is a key aspect of business process management, since it provides information which is crucial for determining the actual Quality of Service (QoS) delivered to individual parties, and for promptly handling off-plan deviations. This paper describes a business process monitor for the recharging system of a mobile phone network provider. The monitored system is currently in operation for the major mobile phone company in Italy, namely Telecom Italia Mobile (TIM). Due to the amazingly high throughput of the monitored system, meeting the performance requirements for the monitor was a challenging issue. A buffer-based implementation of the monitor system failed to meet such requirements. In this paper, we propose a stream-based architecture, which exceeds the performance requirements imposed by the monitored application. The paper provides a detailed description of the monitor system architecture, including a discussion of technology choices, and an experimental evaluation of the performance boost achieved by resorting to a streaming approach. The proposed solution also exploits grammar-based pluggable parsers for rapid and seamless integration of heterogeneous data feeds. (c) 2008 Elsevier B.V. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Campanile, Ferdinando and Coppolino, Luigi and Giordano, Salvatore and Romano, Luigi",2008,JOURNAL OF SYSTEMS ARCHITECTURE,10.1016/j.sysarc.2008.02.005,web-of-science-search1.bib
WOS:000416492900011,A Holistic View of Stream Partitioning Costs,"Stream processing has become the dominant processing model for monitoring and real-time analytics. Modern Parallel Stream Processing Engines (pSPEs) have made it feasible to increase the performance in both monitoring and analytical queries by parallelizing a query's execution and distributing the load on multiple workers. A determining factor for the performance of a pSPE is the partitioning algorithm used to disseminate tuples to workers. Until now, partitioning methods in pSPEs have been similar to the ones used in parallel databases and only recently load-aware algorithms have been employed to improve the effectiveness of parallel execution. We identify and demonstrate the need to incorporate aggregation costs in the partitioning model when executing stateful operations in parallel, in order to minimize the overall latency and/or throughput. Towards this, we propose new stream partitioning algorithms, that consider both tuple imbalance and aggregation cost. We evaluate our proposed algorithms and show that they can achieve up to an order of magnitude better performance, compared to the current state of the art.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Katsipoulakis, Nikos and Labrinidis, Alexandros and Chrysanthis, Panos",2017,PROCEEDINGS OF THE VLDB ENDOWMENT,10.14778/3137628.3137639,web-of-science-search1.bib
WOS:000467257000029,Should PARSEC Benchmarks be More Parametric? A Case Study with Dedup,"Parallel applications of the same domain can present similar patterns of behavior and characteristics. Characterizing common application behaviors can help for understanding performance aspects in the real-world scenario. One way to better understand and evaluate applications' characteristics is by using customizable/parametric benchmarks that enable users to represent important characteristics at run-time. We observed that parameterization techniques should be better exploited in the available benchmarks, especially on stream processing domain. For instance, although widely used, the stream processing benchmarks available in PARSEC do not support the simulation and evaluation of relevant and modern characteristics. Therefore, our goal is to identify the stream parallelism characteristics present in PARSEC. We also implemented a ready to use parameterization support and evaluated the application behaviors considering relevant performance metrics for stream parallelism (service time, throughput, latency). We choose Dedup to be our case study. The experimental results have shown performance improvements in our parameterization support for Dedup. Moreover, this support increased the customization space for benchmark users, which is simple to use. In the future, our solution can be potentially explored on different parallel architectures and parallel programming frameworks.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Maron, Carlos and Vogel, Adriano and Griebler, Dalvan and Fernandes, Luiz",2019,"2019 27TH EUROMICRO INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND NETWORK-BASED PROCESSING (PDP)",10.1109/EMPDP.2019.8671592,web-of-science-search1.bib
WOS:000628649800039,Poster: Benchmarking Financial Data Feed Systems,"Data-driven solutions for the investment industry require eventbased backend systems to process high-volume financial data feeds with low latency, high throughput, and guaranteed delivery modes. At vwd we process an average of 18 billion incoming event notifications from 500+ data sources for 30 million symbols per day and peak rates of 1+ million notifications per second using custom-built platforms that keep audit logs of every event. We currently assess modern open source event-processing platforms such as Kafka, NATS, Redis, Flink or Storm for the use in our ticker plant to reduce the maintenance effort for cross-cutting concerns and leverage hybrid deployment models. For comparability and repeatability we benchmark candidates with a standardized workload we derived from our real data feeds. We have enhanced an existing light-weight open source benchmarking tool in its processing, logging, and reporting capabilities to cope with our workloads. The resulting tool wrench can simulate workloads or replay snapshots in volume and dynamics like those we process in our ticker plant. We provide the tool as open source. As part of ongoing work we contribute details on (a) our workload and requirements for benchmarking candidate platforms for financial feed processing; (b) the current state of the tool wrench.",FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Coenen, Manuel and Wagner, Christoph and Echler, Alexander and Frischbier, Sebastian",2019,DEBS'19: PROCEEDINGS OF THE 13TH ACM INTERNATIONAL CONFERENCE ON DISTRIBUTED AND EVENT-BASED SYSTEMS,10.1145/3328905.3332506,web-of-science-search1.bib;acm2-search1.bib
WOS:000823983100001,C3PO: Cloud-based Confidentiality-preserving Continuous Query Processing,"With the advent of the Internet of things (IoT), billions of devices are expected to continuously collect and process sensitive data (e.g., location, personal health factors). Due to the limited computational capacity available on IoT devices, the current de facto model for building IoT applications is to send the gathered data to the cloud for computation. While building private cloud infrastructures for handling large amounts of data streams can be expensive, using low-cost public (untrusted) cloud infrastructures for processing continuous queries including sensitive data leads to strong concerns over data confidentiality. This article presents C3PO, a confidentiality-preserving, continuous query processing engine, that leverages the public cloud. The key idea is to intelligently utilize partially homomorphic and property-preserving encryption to perform as many computationally intensive operations as possible-without revealing plaintext-in the untrusted cloud. C3PO provides simple abstractions to the developer to hide the complexities of applying complex cryptographic primitives, reasoning about the performance of such primitives, deciding which computations can be executed in an untrusted tier, and optimizing cloud resource usage. An empirical evaluation with several benchmarks and case studies shows the feasibility of our approach. We consider different classes of IoT devices that differ in their computational and memory resources (from a Raspberry Pi 3 to a very small device with a Cortex-M3 microprocessor) and through the use of optimizations, we demonstrate the feasibility of using partially homomorphic and property-preserving encryption on IoT devices.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Savvides, Savvas and Kumar, Seema and Stephen, Julian and Eugster, Patrick",2022,ACM TRANSACTIONS ON PRIVACY AND SECURITY,10.1145/3472717,web-of-science-search1.bib
WOS:000428513600196,Multi-Carrier Backscatter Communication System for Concurrent Wireless and Batteryless Sensing,"Wireless and batteryless sensing has recently attracted significant attention of researchers in IoT and WSN applications. It turns out to be more challenging when simultaneous data acquisition from multiple sensors is required. This paper introduces a non-orthogonal multiple access technique MSMA, using extremely simple wireless and batteryless sensor tags and a reader to support concurrent streaming from multiple sensors. By simultaneously handling non-orthogonal subcarriers, produced either by multiple or single sensor tag, it can realize concurrent sensor data streaming, which can be used in health monitoring of machinery and civil structures. The paper explains the two primary challenges in MSMA, the optimal assignment of subcarrier frequencies and the unavoidable harmonics from one subcarrier to others. Since the mutual interference among subcarriers is unevenly distributed over the available frequency band, random allocation of subcarrier frequencies may result in degraded system performance. Results show that the interference can be canceled out with the signal processing technique and the system communication capacity can be increased significantly with a proposed heuristic approach compared to random allocation of subcarrier frequencies to the sensor tags.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Rajoria, Nitish and Kamei, Hiromu and Mitsugi, Jin and Kawakita, Yuusuke and Ichikawa, Haruhisa",2017,"2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)",,web-of-science-search1.bib
WOS:000309229600029,PREPARE: Predictive Performance Anomaly Prevention for Virtualized Cloud Systems,"Virtualized cloud systems are prone to performance anomalies due to various reasons such as resource contentions, software bugs, and hardware failures. In this paper, we present a novel PREdictive Performance Anomaly pREvention (PREPARE) system that provides automatic performance anomaly prevention for virtualized cloud computing infrastructures. PREPARE integrates online anomaly prediction, learning-based cause inference, and predictive prevention actuation to minimize the performance anomaly penalty without human intervention. We have implemented PREPARE on top of the Xen platform and tested it on the NCSU's Virtual Computing Lab using a commercial data stream processing system (IBM System S) and an online auction benchmark (RUBiS). The experimental results show that PREPARE can effectively prevent performance anomalies while imposing low overhead to the cloud infrastructure.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Tan, Yongmin and Nguyen, Hiep and Shen, Zhiming and Gu, Xiaohui and Venkatramani, Chitra and Rajan, Deepak",2012,2012 IEEE 32ND INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS (ICDCS),10.1109/ICDCS.2012.65,web-of-science-search1.bib
WOS:000165049300044,The ManArray (TM) embedded processor architecture,"The BOPS(R) ManArray(TM) architecture is presented as a scalable DSP platform for the embedded processor domain. In this domain, ManArray-based processors use a single architecture definition, that supports multiple configurations of processing elements (PEs) from low end single PE to large arrays of PEs, and single tool set. The ManArray (selectable) parallelism architecture mixes control oriented operations, VLIWs, packed data operations, and distributed array processing in a cohesive, independently selectable manner. In addition, scalable conditional execution and single-cycle communications across a high connectivity, low cast network are integrated in the architecture. This allows another level of selectivity that enhances the application of the parallel resources to high performance algorithms. Coupled,with the array DSP is a scalable DMA engine that runs in the background and provides programmer-selectable data-distribution patterns and a high-bandwidth data-streaming interface to system peripherals and global memory. This paper introduces the embedded scalable MonArray architecture and a number of benchmarks. For example, a standard ASIC flow DSP/coprocessor core, the BOPS2040, can process a distributed 256-point complex FFT in 425 cycles and an 8x8 2D IDCT that meets IEEE standards in 34 cycles.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Pechanek, GG and Vassiliadis, S",2000,"PROCEEDINGS OF THE 26TH EUROMICRO CONFERENCE, VOLS I AND II",,web-of-science-search1.bib
WOS:000284931600008,Energy- and Performance-Efficient Communication Framework for Embedded MPSoCs through Application-Driven Release Consistency,"We present a framework for performance-, bandwidth-, and energy-efficient intercore communication in embedded MultiProcessor Systems-on-a-Chip (MPSoC). The methodology seamlessly integrates compiler, operating system, and hardware support to achieve a low-cost communication between synchronized producers and consumers. The technique is especially beneficial for data-streaming applications exploiting pipeline parallelism with computational phases mapped to separate cores. Code transformations utilizing a simple ISA support ensure that producer writes are propagated to consumers with a single interconnect transaction per cache block just prior to the producer exiting its synchronization region. Furthermore, in order to completely eliminate misses to shared data caused by interference with private data and also to minimize the cache energy, we integrate to the proposed framework a cache way partitioning policy based on a simple cache configurability support, which isolates the shared buffers from other cache traffic. This mechanism results in significant power savings since only a subset of the cache ways needs to be looked up for each cache access. The end result of the proposed framework is a single communication transaction per shared cache block between a producer and a consumer with no coherence misses on the consumer caches. Our experiments demonstrate significant reductions in interconnect traffic, cache misses, and energy for a set of multiprocessor benchmarks.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Yu, Chenjie and Petrov, Peter",2010,ACM TRANSACTIONS ON DESIGN AUTOMATION OF ELECTRONIC SYSTEMS,10.1145/1870109.1870117,web-of-science-search1.bib;acm3-search1.bib
WOS:000311921300003,Efficient local search on the GPU-Investigations on the vehicle routing problem,"We study how to implement local search efficiently on data parallel accelerators such as Graphics Processing Units. The Distance-constrained Capacitated Vehicle Routing Problem, a computationally very hard discrete optimization problem with high industrial relevance, is the selected vehicle for our investigations. More precisely, we investigate local search with the Best Improving strategy for the 2-opt and 3-opt operators on a giant tour representation. Resource extension functions are used for constant time move evaluation. Using CUDA, a basic implementation called The Benchmark Version has been developed and deployed on a Fermi architecture Graphics Processing Unit. Both neighborhood setup and evaluation are performed entirely on the device. The Benchmark Version is the initial step of an incremental improvement process where a number of important implementation aspects have been systematically studied. Ten well-known test instances from the literature are used in computational experiments, and profiling tools are used to identify bottlenecks. In the final version, the device is fully saturated, given a large enough problem instance. A speedup of almost an order of magnitude relative to The Benchmark Version is observed. We conclude that, with some effort, local search may be implemented very efficiently on Graphics Processing Units. Our experiments show that a maximum efficiency, however, requires a neighborhood cardinality of at least one million. Full exploration of a billion neighbors takes a few seconds and may be deemed too expensive with the current technology. Reduced neighborhoods through filtering is an obvious remedy. Experiments on simple models of neighborhood filtering indicate, however, that the speedup effect is limited on data parallel accelerators. We believe these insights are valuable in the design of new metaheuristics that fully utilize modern, heterogeneous processors. (C) 2012 Elsevier Inc. All rights reserved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Schulz, and Christian,",2013,JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING,10.1016/j.jpdc.2012.02.020,web-of-science-search1.bib
WOS:000284328500007,Stream processors: a new platform for Monte Carlo calculations,"Graphics processing units (GPUs) and similar stream processors are increasingly used for general-purpose calculations. Their pipelined architecture can be exploited to accelerate various algorithms, sometimes with spectacular results. Monte Carlo codes, being computationally intensive, are likely to benefit from the development of stream processing platforms. We explore this potential here with a simple subroutine sometimes used in Monte Carlo techniques. More specifically, a ray tracing algorithm that computes the exact radiological path in a voxel grid was implemented in CPU and GPU versions, which then were compared in terms of execution speed. This benchmarking experiment was conducted under various conditions, in order to assess the memory and bandwidth limitations of each platform. The results show that the GPU provides a significant speed improvement factor over the CPU. For the specific hardware used in this work, namely a nVidia 7600 GS GPU, a speed increase factor up to 6 was achieved over an Xeon 2.4 GHz CPU. With the development of faster stream processors, this factor is expected to reach levels that can potentially change how Monte Carlo techniques are used, for example in radiation therapy planning. The ongoing development of simpler language extensions and programming interfaces also promises to increase the accessibility of these devices. Overall, stream processors are likely to play an increasingly larger role in scientific computing, and in particular in Monte Carlo techniques.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Despres, Philippe and Rinkel, Jean and Hasegawa, Bruce and Prevrhal, Sven",2008,INTERNATIONAL WORKSHOP ON MONTE CARLO TECHNIQUES IN RADIOTHERAPY DELIVERY AND VERIFICATION - THIRD MCGILL INTERNATIONAL WORKSHOP,10.1088/1742-6596/102/1/012007,web-of-science-search1.bib
WOS:000403774200001,Big Data on Clouds and HPC,"We review several questions at the intersection of Big Data, Clouds and HPC with the large scale simulations usually run on supercomputers and the target of the exascale initiative. We base this on an analysis of many big data and simulation problems and a set of properties - the Big Data Ogres - characterizing them where we distinguish data and model properties. We consider broad topics: What are the application and user requirements? e.g. is the data streaming, how similar are commercial and scientific requirements? What is execution structure of problems? e.g. is it dataflow or more like MPI? Should we use threads or processes'? Is execution pleasingly parallel? What about the many choices for infrastructure and middleware? Should we use classic HPC cluster, Docker or OpenStack? Where are Big Data (Apache) approaches superior/inferior to those familiar from Grid and HPC work? The choice of language - C++, Java, Scala, Python, R highlights perfoimance v. productivity trade-offs. What is actual performance of Big Data implementations and what are good benchmarks? Is software sustainability important and is the Apache model a good approach to this? The difference between capability and capacity computing on HPC clusters.",FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Fox, and Geoffrey,",2016,"2016 17TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT)",,web-of-science-search1.bib
WOS:000286677100007,QoS-Aware Dynamic Adaptation for Cooperative Media Streaming in Mobile Environments,"Media streaming is expected to be one of the most promising services in mobile environments. Effective data streaming management techniques are, therefore, in strong demand. In an earlier paper, the ideas and benefits of two-level cooperative media streaming with headlight prefetching and dynamic chaining were demonstrated {[}1]. Though complementary to each other, they operate in session-wide static and distinctive modes. Moreover, users do not have control over the quality and cost levels of the streaming services. The performance degradation or cost increment can reach an unacceptable level under fast or highly unstable moving patterns. In this paper, we propose the QoS-based dynamic adaptation techniques for the flexible employment and smooth integration of headlight prefetching and dynamic chaining to continuously provide quality streaming services to mobile users. The QoS-aware dynamic headlight prefetching is for the cooperation between streaming access points to dynamically adjust the prefetching scheme in response to the fast changing moving patterns. Adaptive P2P media streaming is for the cooperation between mobile users such that multiple peers can be used as streaming sources to increase the likelihood of successful chaining. Furthermore, a QoS-based technique is developed to dynamically trigger and proportionally adjust the prefetching degree when the stability and quality of P2P streaming service vary. With extensive simulation and performance evaluation, we demonstrate that the proposed dynamic adaptation techniques significantly improve the service quality and streaming performance of cooperative media streaming in mobile environments.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Wu, Shiow-yang and He, Cheng-en",2011,IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS,10.1109/TPDS.2010.81,web-of-science-search1.bib
WOS:000364835300005,Cut-and-Rewind: Extending Query Engine for Continuous Stream Analytics,"Combining data warehousing and stream processing technologies has great potential in offering low-latency data-intensive analytics. Unfortunately, such convergence has not been properly addressed so far. The current generation of stream processing systems is in general built separately from the data warehouse and query engine, which can cause significant overhead in data access and data movement, and is unable to take advantage of the functionalities already offered by the existing data warehouse systems. In this work we tackle some hard problems in integrating stream analytics capability into the existing query engine. We define an extended SQL query model that unifies queries over both static relations and dynamic streaming data, and develop techniques to extend query engines to support the unified model. We propose the cut-and-rewind query execution model to allow a query with full SQL expressive power to be applied to stream data by converting the latter into a sequence of ``chunks{''}, and executing the query over each chunk sequentially, but without shutting the query instance down between chunks for continuously maintaining the application context across the execution cycles as required by sliding-window operators. We also propose the cycle-based transaction model to support Continuous Querying with Continuous Persisting (CQCP) with cycle-based isolation and visibility. We have prototyped our approach by extending the PostgreSQL. This work has resulted in a new kind of tightly integrated, highly efficient system with the advanced stream processing capability as well as the full DBMS functionality. We demonstrate the system with the popular Linear Road benchmark, and report the performance. By leveraging the matured code base of a query engine to the maximal extent, we can significantly reduce the engineering investment needed for developing the streaming technology. Providing this capability on proprietary parallel analytics engine is work in progress.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Chen, Qiming and Hsu, Meichun",2015,TRANSACTIONS ON LARGE-SCALE DATA- AND KNOWLEDGE-CENTERED SYSTEMS XXI,10.1007/978-3-662-47804-2_5,web-of-science-search1.bib
WOS:000345643500036,Publication of RDF Streams with Ztreamy,"There is currently an interest in the Semantic Web community for the development of tools and techniques to process RDF streams. Implementing an effective RDF stream processing system requires to address several aspects including stream generation, querying, reasoning, etc. In this work we focus on one of them: the distribution of RDF streams through the Web. In order to address this issue, we have developed Ztreamy, a scalable middleware which allows to publish and consume RDF streams through HTTP. The goal of this demo is to show the functionality of Ztreamy in two different scenarios with actual, heterogeneous streaming data.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"AriasFisteus, Jesus and FernandezGarcia, Norberto and SanchezFernandez, Luis and Fuentes-Lorenzo, Damaris",2014,SEMANTIC WEB: ESWC 2014 SATELLITE EVENTS,10.1007/978-3-319-11955-7_36,web-of-science-search1.bib
WOS:000261953900003,Cache-aware timing analysis of streaming applications,"Of late, there has been a considerable interest in models, algorithms and methodologies specifically targeted towards designing hardware and software for streaming applications. Such applications process potentially infinite streams of audio/video data or network packets and are found in a wide range of devices, starting from mobile phones to set-top boxes. Given a streaming application and an architecture, the timing analysis problem is to determine the timing properties of the processed data stream, given the timing properties of the input stream. This problem arises while determining many common performance metrics related to streaming applications and the mapping of such applications onto hardware architectures. Such metrics include the maximum delay experienced by any data item of the stream and the maximum backlog or the buffer requirement to store the incoming stream. Most of the previous work related to estimating or optimizing these metrics take a high-level view of the architecture and neglect micro-architectural features such as caches. In this paper, we show that an accurate estimation of these metrics, however, heavily relies on an appropriate modeling of the processor micro-architecture. Towards this, we present a novel framework for cache-aware timing analysis of stream processing applications. Our framework accurately models the evolution of the instruction cache of the underlying processor as a stream is processed, and the fact that the execution time involved in processing any data item depends on all the previous data items occurring in the stream. The main contribution of our method lies in its ability to seamlessly integrate program analysis techniques for micro-architectural modeling with known analytical methods for analyzing streaming applications, which treat the arrival/service of event streams as mathematical functions. This combination is powerful as it allows to model the code/cache-behavior of the streaming application, as well as the manner in which it is triggered by event arrivals. We employ our analysis method to an MPEG-2 encoder application and our experiments indicate that detailed modeling of the cache behavior is efficient, scalable and leads to more accurate timing/buffer size estimates.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Chakraborty, Samarjit and Mitra, Tulika and Roychoudhury, Abhik and Thiele, Lothar",2009,REAL-TIME SYSTEMS,10.1007/s11241-008-9062-5,web-of-science-search1.bib
WOS:000732312200001,A Fast Cross-Layer Dynamic Power Estimation Method by Tracking Cycle-Accurate Activity Factors With Spark Streaming,"The advent of autonomous power-limited systems poses a new challenge for early design space exploration. The existing architecture-level power evaluation tools lose accuracy due to ignoring features of circuit-level behaviors and influences of process, voltage, and temperature variations. Although power estimations based on SPICE or PrimeTime PX (PTPX) are accurate enough, they come at the cost of long simulation time and are available only in very late phases of design flow. In this article, a fast and accurate dynamic power evaluation method is proposed, which estimates activity factors at the circuit level. The impact of process variation at the gate level is considered through the proposed effective capacitance model. Activity factors are then estimated by the model and input vectors of the circuit. Input vectors are generated by architecture-level simulations in the form of streaming. For real-time and high-speed power evaluation, a data streaming framework is proposed for massive parallelism. The cross-layer estimation is verified based on the functional units of PULPino processor running SPEC CPU2006 benchmarks. Compared with the SPICE results using SMIC 28-nm PDK, our cycle-by-cycle dynamic power analysis shows an average error of 5.4%. Meanwhile, our approach realizes 65.2% faster than the traditional PTPX simulation and 48.8% faster compared with the state-of-art cross-level evaluation method.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Jin, Leilei and Fu, Wenjie and Ling, Ming and Shi, Longxing",2022,IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS,10.1109/TVLSI.2021.3111000,web-of-science-search1.bib;ieee2-search1.bib
WOS:000703983200018,Perph: A Workload Co-location Agent with Online Performance Prediction and Resource Inference,"Striking a balance between improved cluster utilization and guaranteed application QoS is a long-standing research problem in cluster resource management. The majority of current solutions require a large number of sandboxed experimentation for different workload combinations and leverage them to predict possible interference for incoming workloads. This results in non-negligible time complexity that severely restricts its applicability to complex workload co-locations. The nature of pure offline profiling may also lead to model aging problem that drastically degrades the model precision. In this paper, we present Perph, a runtime agent on a per node basis, which decouples ML-based performance prediction and resource inference from centralized scheduler. We exploit the sensitivity of long-running applications to multi-resources for establishing a relationship between resource allocation and consequential performance. We use Online Gradient Boost Regression Tree (OGBRT) to enable the continuous model evolution. Once performance degradation is detected, resource inference is conducted to work out a proper slice of resources that will be reallocated to recover the target performance. The integration with Node Manager (NM) of Apache YARN shows that the throughput of Kafka data-streaming application is 2.0x and 1.82x times that of isolation execution schemes in native YARN and pure cgroup cpu subsystem. In TPC-C benchmarking, the throughput can also be improved by 35% and 23% respectively against YARN native and cgroup cpu subsystem.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zhu, Jianyong and Yang, Renyu and Hu, Chunming and Wo, Tianyu and Xue, Shiqing and Ouyang, Jin and Xu, Jie",2021,"21ST IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET COMPUTING (CCGRID 2021)",10.1109/CCGrid51090.2021.00027,web-of-science-search1.bib
WOS:000577624800030,pAElla: Edge AI-Based Real-Time Malware Detection in Data Centers,"The increasing use of Internet-of-Things (IoT) devices for monitoring a wide spectrum of applications, along with the challenges of ``big data{''} streaming support they often require for data analysis, is nowadays pushing for increased attention to the emerging edge computing paradigm. In particular, smart approaches to manage and analyze data directly on the network edge, are more and more investigated, and artificial intelligence (AI)-powered edge computing is envisaged to be a promising direction. In this article, we focus on data centers (DCs) and supercomputers (SCs), where a new generation of high-resolution monitoring systems is being deployed, opening new opportunities for analysis like anomaly detection and security, but introducing new challenges for handling the vast amount of data it produces. In detail, we report on a novel lightweight and scalable approach to increase the security of DCs/SCs, which involves AI-powered edge computing on high-resolution power consumption. The method-called pAElla-targets real-time malware detection (MD), it runs on an out-of-band IoT-based monitoring system for DCs/SCs, and involves power spectral density of power measurements, along with autoencoders. Results are promising, with an F1-score close to 1, and a false alarm and malware miss rate close to 0%. We compare our method with State-of-the-Art (SoA) MD techniques and show that, in the context of DCs/SCs, pAElla can cover a wider range of malware, significantly outperforming SoA approaches in terms of accuracy. Moreover, we propose a methodology for online training suitable for DCs/SCs in production, and release open data set and code.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Libri, Antonio and Bartolini, Andrea and Benini, Luca",2020,IEEE INTERNET OF THINGS JOURNAL,10.1109/JIOT.2020.2986702,web-of-science-search1.bib
WOS:000351437800003,Analysis of Fork/Join and Related Queueing Systems,"Fork/join (F/J) requests arise in contexts such as parallel computing, query processing in parallel databases, and parallel disk access in RAID. F/J requests spawn K tasks that are sent to K parallel servers, and the completion of all K tasks marks the completion of an F/J request. The exact formula for the mean response time of K = 2-way F/J requests derived under Markovian assumptions (R-2(F/J)) served as the starting point for an approximate expression for R-K(F/J) for 2 < K <= 32. When servers process independent requests in addition to F/J requests, the mean response time of F/J requests is better approximated by R-K(max), which is the maximum of the response times of tasks constituting F/J requests. R-K(max) is easier to compute and serves as an upper bound to R-K(F/J). We discuss techniques to compute R-K(max) and generally the maximum of K random variables denoting the processing times of the tasks of a parallel computation (X) over bar (max)(K). Graph models of computations such as Petri nets-a more general form of parallelism than F/J requests-are also discussed in this work. Jobs with precedence constraints may require multiple resources, which are represented by a queueing network model. We also discuss various queueing systems related to F/J queueing systems and outline their analysis.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Thomasian, and Alexander,",2015,ACM COMPUTING SURVEYS,10.1145/2628913,web-of-science-search1.bib
4756433,Enterprise Communications Platform Support for Integrated Location-Based Applications,"Location-based services can be used by enterprises to enhance the customer experience and improve workforce operational efficiency. The focus of our work is to provide a scalable architecture for location-based services which integrates into the enterprise communications platform to support new types of converged communications services involving real-time location processing. Unlike prior work in location servers and middleware, we separate application-level processing and raw location event stream processing into two separate components. We show analytically that this leads to performance advantage. By leveraging existing event driven architecture technologies, our approach integrates with the enterprise event bus, is highly scalable, and permits other real-time event streams to be used by location-based applications. We have implemented a prototype to demonstrate the generality and validity of this approach.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Buford, John and Wu, Xiaotao and Bajpai, Ratan and Karthikeyan, S. and Krishnaswamy, Venkatesh",2008,"2008 The Second International Conference on Next Generation Mobile Applications, Services, and Technologies",10.1109/NGMAST.2008.86,ieee1-search1.bib
5560099,On Tree Construction of Super Peers for Hybrid P2P Live Media Streaming,"This paper considers a hybrid hierarchical P2P overlay network structure that consists of both super and normal peers. The media streaming architecture is built upon a tree-structured network of super peers and the tree construction process has a significant impact on the overall system performance. We build network cost models and formulate a specific type of problem to maximize the minimum node throughput in Tree Construction (max-minTC), which aims at optimizing the system's stream rate by constructing an efficient spanning tree among super peers. We consider two scenarios: (i) When the overlay network has an arbitrary topology, we prove max-minTC to be NP-complete by reducing from the Degree Constrained Spanning Tree problem and propose an efficient heuristic algorithm. The performance superiority of the proposed algorithm is justified by experimental results collected by a live media streaming system deployed in real networks and is also illustrated by extensive simulations performed on a large set of simulated networks of various sizes from small to large scales in comparison with other methods, (ii) When the topology of the overlay network is complete, we rigorously prove that the same heuristic algorithm yields an optimal solution.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Lu, Xukang and Wu, Qishi and Li, Runzhi and Lin, Yunyue",2010,2010 Proceedings of 19th International Conference on Computer Communications and Networks,10.1109/ICCCN.2010.5560099,ieee1-search1.bib
5504759,A Methodology for the Systematic Evaluation of ANN Classifiers for BSN Applications,"While many BSN applications require that sensor nodes be able to operate for extended periods of time, they also often require the wireless transmission of copious amounts of sensor data to a data aggregator or base station, where the raw data is processed into application-relevant information. The energy requirements of such streaming can be prohibitive, given the competing considerations of form factor and battery life requirements. Making intelligent decisions on the node about which data to store or transmit, and which to ignore, is a promising method of reducing energy consumption. Artificial neural network (ANN) classifiers are among several competitive techniques for such data selection. However, no systematic metrics exist for determining if an ANN classifier is suited for a particular resource constrained computing environment of a typical BSN node. An especially difficult task is assessing, at the design stage, which classifier architectures are feasible on a given resource-constrained node, what computational resources are required to execute a given classifier, and what classification performance might be achieved by a particular classifier on a given set of resources. This paper describes techniques for quantifying and predicting the performance of ANN classifiers on wearable sensor nodes using scalable synthetic test data. Additionally, the paper shows a comparison of synthetic data with gait data collected using an inertial BSN node, and classification results of the gait data using a cerebellar model arithmetic computer (CMAC) architecture show excellent agreement with theoretical predictions.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"PowellJr., Harry and Brandt-Pearce, Maïté and Barth, Adam and Lach, John",2010,2010 International Conference on Body Sensor Networks,10.1109/BSN.2010.48,ieee1-search1.bib
9833963,"Spatially redundant, precision-constrained transmit precoding for mmWave LoS MIMO","Line of sight (LoS) multi-input multi-output (MIMO) systems have attractive scaling properties with increase in carrier frequency, with the potential for 100+Gbps links over 10s to 100s of meters with the reasonable form using the millimeter wave (mmWave) and terahertz (THz) bands. We propose and investigate an approach to all-digital LoS MIMO which addresses the difficulty of limited available precision for digital-to-analog converters (DACs) and analog-to-digital converters (ADCs). In order to reduce dynamic range requirements at the receiver, we consider spatially redundant transmit precoding (more transmit antennas than number of spatially multiplexed data streams) with 1-bit DACs. We introduce a novel approach for attaining the higher dynamic range required for precoding over the air (OTA), which we term OTA-DAC: the 1-bit DACs for clusters of transmit elements synthesize approximations to zero-forcing precoding across clusters. We illustrate our ideas for 64×4 and 16×4 LoS MIMO systems, comparing with a benchmark approach of 1-bit quantized ZF precoding for transmit elements evenly spaced across the aperture. Our OTA-DAC approach substantially outperforms the benchmark, and does not exhibit the error floors incurred by the latter.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Sezer, Ahmet and Madhow, Upamanyu",2022,2022 IEEE 23rd International Workshop on Signal Processing Advances in Wireless Communication (SPAWC),10.1109/SPAWC51304.2022.9833963,ieee1-search1.bib
5210817,CHAOS: A Data Stream Analysis Architecture for Enterprise Applications,"In this paper, we describe the design of our architecture for continuous, heterogeneous analysis over streams, aka CHAOS that combines stream processing, approximation techniques, mining, complex event processing and visualization. CHAOS, with the novel concept of computational stream analysis Cube, provides an effective, scalable platform for near real time processing of business and enterprise streams. We describe our approach with a real data center temperature analysis application.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Gupta, Chetan and Wang, Song and Ari, Ismail and Hao, Ming and Dayal, Umeshwar and Mehta, Abhay and Marwah, Manish and Sharma, Ratnesh",2009,2009 IEEE Conference on Commerce and Enterprise Computing,10.1109/CEC.2009.74,ieee1-search1.bib
9770381,Watertight Incremental Heightfield Tessellation,"In this paper, we propose a method for the interactive visualization of medium-scale dynamic heightfields without visual artifacts. Our data fall into a category too large to be rendered directly at full resolution, but small enough to fit into GPU memory without pre-filtering and data streaming. We present the real-world use case of unfiltered flood simulation data of such medium scale that need to be visualized in real time for scientific purposes. Our solution facilitates compute shaders to maintain a guaranteed watertight triangulation in GPU memory that approximates the interpolated heightfields with view-dependent, continuous levels of detail. In each frame, the triangulation is updated incrementally by iteratively refining the cached result of the previous frame to minimize the computational effort. In particular, we minimize the number of heightfield sampling operations to make adaptive and higher-order interpolations viable options. We impose no restriction on the number of subdivisions and the achievable level of detail to allow for extreme zoom ranges required in geospatial visualization. Our method provides a stable runtime performance and can be executed with a limited time budget. We present a comparison of our method to three state-of-the-art methods, in which our method is competitive to previous non-watertight methods in terms of runtime, while outperforming them in terms of accuracy.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Cornel, Daniel and Zechmeister, Silvana and Groeller, Eduard and Waser, Jurgen",2022,IEEE Transactions on Visualization and Computer Graphics,10.1109/TVCG.2022.3173081,ieee1-search1.bib
5466996,Interactive streaming of structured data,"We present ChunkStream, a system for efficient streaming and interactive editing of online video. Rather than using a specialized protocol and stream format, ChunkStream makes use of a generic mechanism employing chunks. Chunks are fixed-size arrays that contain a mixture of scalar data and references to other chunks. Chunks allow programmers to expose large, but fine-grained, data structures over the network. ChunkStream represents video clips using simple data types like linked lists and search trees, allowing a client to retrieve and work with only the portions of the clips that it needs. ChunkStream supports resource-adaptive playback and “live” streaming of real-time video as well as fast, frame-accurate seeking; bandwidth-efficient high-speed playback; and compilation of editing decisions from a set of clips. Benchmarks indicate that ChunkStream uses less bandwidth than HTTP Live Streaming while providing better support for editing primitives.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"MazzolaPaluska, Justin and Pham, Hubert",2010,2010 IEEE International Conference on Pervasive Computing and Communications (PerCom),10.1109/PERCOM.2010.5466996,ieee1-search1.bib
9552915,Hybrid Workflow Scheduling on Edge Cloud Computing Systems,"Internet of Things applications can be represented as workflows in which stream and batch processing are combined to accomplish data analytics objectives in many application domains such as smart home, health care, bioinformatics, astronomy, and education. The main challenge of this combination is the differentiation of service quality constraints between batch and stream computations. Stream processing is highly latency-sensitive while batch processing is more likely resource-intensive. In this work, we propose an end-to-end hybrid workflow scheduling on an edge cloud system as a two-stage framework. In the first stage, we propose a resource estimation algorithm based on a linear optimization approach, gradient descent search (GDS), and in the second stage, we propose a cluster-based provisioning and scheduling technique for hybrid workflows on heterogeneous edge cloud resources. We provide a multi-objective optimization model for execution time and monetary cost under constraints of deadline and throughput. Results demonstrate the framework performance in controlling the execution of hybrid workflows by efficiently tuning several parameters including stream arrival rate, processing throughput, and workflow complexity. In comparison to a meta-heuristics technique using Particle Swarm Optimization (PSO), the proposed scheduler provides significant improvement for large-scale hybrid workflows in terms of execution time and cost with an average of 8% and 35%, respectively.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Alsurdeh, Raed and Calheiros, Rodrigo and Matawie, Kenan and Javadi, Bahman",2021,IEEE Access,10.1109/ACCESS.2021.3116716,ieee1-search1.bib
8996300,Convolutional Neural Networks on Apache Storm,"the performance of deep learning largely depends on the size of data. One data source is real-time streaming data, produced from mobile devices, sensors or social media, etc. Streaming data is high-speed and large-scale, which needs real-time processing. However, current mainstream frameworks are mainly designed for off-line data. To suit this, we first propose a deep learning framework based on Apache Storm, which is a distributed stream processing frame, fast and fault-tolerant. Our framework implements the distributed training of CNNs. which is different from MMLSpark or TensorFlowOnSpark that is a pure Java implementation. The design of message passing and synchronization is also suitable to other MapReduce-family distributed computing platforms. To validate our work, MNIST and Cifar -10 datasets are used for evaluation and comparison with similar architectures. The results show our framework, in resource-limited environment, realizes about 10 times speedup.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zhang, Wenyu and Lu, Yanfeng and Li, Yi and Qiao, Hong",2019,2019 Chinese Automation Congress (CAC),10.1109/CAC48633.2019.8996300,ieee1-search1.bib
9179188,Architecture for IDS Log Processing using Spark Streaming,"In a large network enterprise system, the use network intrusion detection system (N-IDS) become popular since it has very important role and a challenging task to the network manager in term of security management. Existing network systems develop and expand both in terms of network size, load, and application traffic so the processing of a single IDS is not enough and imposed a high overload on the system. Therefore, there is a need for upgrading a novel IDS system to adapt to the new challenges. To improve the performance of the entire N-IDS system, the traditional way is to replace it with a higher performance server to meet the requirements of processing and storage or using several N-IDS systems. However, in those types of systems, the cost is often expensive but the processing and representation data real-time is still very limited and it does not meet the urgent requirements of security manager. In this paper, we propose novel architecture of distributed log processing and storage tools to improve N-IDS data processing. Our goal is to improve overall system performance and cost-efficient. In this paper, we recommend the use of distributed processing and storage tools to improve N-IDS data processing by Apache Spark and make a comparison with previous works using Hadoop Cluster. Our proposed model introduces a real-time data streaming tool, e.g., Apache Spark Streaming, for near real-time analysis of log processing.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Hai, Tran and Khiem, Nguyen",2020,"2020 International Conference on Electrical, Communication, and Computer Engineering (ICECCE)",10.1109/ICECCE49384.2020.9179188,ieee1-search1.bib
8944449,Application of Compressed Sensing using a Reed Solomon (RS) code based Deterministic Measurement Matrix,"Compressed Sensing (CS) is an emerging technique in the field of acquiring and compressing signals as this technique allows for sampling a signal which is sparse in some domain with a rate well below the limit prescribed by the conventional Shannon-Nyquist sampling theorem. As a result, this new sensing paradigm is applicable to many fields like medical imaging, Data streaming, UWB-based communication systems, wireless sensor networks etc. A sensing matrix is one of the principal components in the architecture of compressed sensing. Traditionally, random sensing matrices have been used for CS but these matrices prove difficult for practical implementation and hence the development of deterministic sensing matrix have gathered recent momentum. In this paper, CS is applied to gray scale images using the deterministic sensing matrix based on Reed-Solomon (RS) code with asymptotically optimal coherence. The performance is compared with random measurement matrix for different reconstruction algorithms like Orthogonal Matching Pursuit (OMP) and Basis Pursuit (BP). The performance metrics considered for comparison of the original and reconstructed images are Structural Similarity Index (SSIM), PSNR, SNR and run time. Also, the role of the level of signal sparsity in CS is analyzed using simulation results.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Yadav, Shekhar and Patel, Jigisha",2019,"2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)",10.1109/ICCCNT45670.2019.8944449,ieee1-search1.bib
1557051,A parameterizable SIMD stream processor,"Stream processing is a data processing paradigm in which long sequences of homogeneous data records are passed through one or more computational kernels to produce sequences of processed output data. Applications that fit this model include polygon rendering (computer graphics), matrix multiplication (scientific computing), 2D convolution (media processing), and data encryption (security). Computers that exploit stream computations process data faster than conventional microcomputers because they utilize a memory system and an execution model that increases on-chip bandwidth and delivers high throughput. We have designed a general-purpose, parameterizable, SIMD stream processor that operates on IEEE single-precision floating point data. The system is implemented in VHDL, and consists of a configurable FPU, execution unit array, and memory interface. The FPU supports pipelined operations for multiplication, addition, division, and square root. The data width is configurable. The execution array operates in lock-step with an instruction controller, which issues 32-bit instructions to the execution array. To exploit stream parallelism, the number of execution units as well as the number of interleaved threads is specified as a parameter at compilation time. The memory system allows all execution units to access one element of data from memory in every clock cycle. All memory accesses also pass through a routing network to support conditional reads and writes of stream data. Functional and timing simulations have been performed using a variety of benchmark programs. The system has also been synthesized into an Altera FPGA to verify resource utilization.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Munshi, A. and Wong, A. and Clinton, A. and Braganza, S. and Bishop, W. and McCool, M.",2005,"Canadian Conference on Electrical and Computer Engineering, 2005.",10.1109/CCECE.2005.1557051,ieee1-search1.bib
7889547,Real Time Evaluation of Quality of Search Terms During Query Expansion for Streaming Text Data Using Velocity and Relevance,"The traditional methods of evaluation of data cannot be used to evaluate the quality of the streaming twitter data due to the restriction on access to historic tweets, and dynamic nature of the microblogging posts. For this purpose, we propose a novel method to quantify the quality of data independent of the underlying model. Using the change in velocity of tweets with addition of search terms, and the relevance computed by the underlying model, we evaluated the impact of each search term on the quality of data retrieved.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Bhattacharya, Nilayan and Arpinar, I. and Kursuncu, Ugur",2017,2017 IEEE 11th International Conference on Semantic Computing (ICSC),10.1109/ICSC.2017.105,ieee2-search1.bib
6984705,A Study on Content Delivery Strategy for QoE Enhancement in P2P IPTV,"Nowadays the peer-to-peer (P2P) systems have been widely deployed for the Internet television and live streaming. The real-time P2P service features advantages of scalability and heterogeneity in the existing network without modifying the underlay infrastructure. However, most of the common IPTV applications did not consider the user's surfing behavior which causes great burden to the IPTV streaming system. In addition, the high churn rate and insufficient upload capacity may lead to the unstable playback smoothness, and result in a poor quality of experience (QoE). In this paper, we propose a QoE-aware content delivery mechanism to distribute the important and instant data first. I-frame chunks near playback deadline are assigned the top priority. We discuss the comparison of overlay performance and demonstrate that the proposed scheme is workable via a series of experiments on OMNeT++.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Huang, Yu and Chen, Yaw",2014,2014 IEEE International Conference on Computer and Information Technology,10.1109/CIT.2014.131,ieee2-search1.bib
9680451,Model-based Reinforcement Learning for Elastic Stream Processing in Edge Computing,"Low-latency data processing is critical for enabling next generation Internet-of-Things(IoT) applications. Edge computing-based stream processing techniques that optimize for low latency and high throughput provide a promising solution to ensure a rich user experience by meeting strict application requirements. However, manual performance tuning of stream processing applications in heterogeneous and dynamic edge computing environments is not only time consuming but also not scalable. Our work presented in this paper achieves elasticity for stream processing applications deployed at the edge by automatically tuning the applications to meet the performance requirements. The proposed approach adopts a learning model to configure the parallelism of the operators in the stream processing application using a reinforcement learning(RL) method. We model the elastic control problem as a Markov Decision Process(MDP) and solve it by reducing it to a contextual Multi-Armed Bandit(MAB) problem. The techniques proposed in our work uses Upper Confidence Bound(UCB)-based methods to improve the sample efficiency in comparison to traditional random exploration methods such as the e-greedy method. It achieves a significantly improved rate of convergence compared to other RL methods through its innovative use of MAB methods to deal with the tradeoff between exploration and exploitation. In addition, the use of model-based pre-training results in sub-stantially improved performance by initializing the model with appropriate and well-tuned parameters. The proposed techniques are evaluated using realistic and synthetic workloads through both simulation and real testbed experiments. The experiment results demonstrate the effectiveness of the proposed approach compared to standard methods in terms of cumulative reward and convergence speed.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Xu, Jinlai and Palanisamy, Balaji",2021,"2021 IEEE 28th International Conference on High Performance Computing, Data, and Analytics (HiPC)",10.1109/HiPC53243.2021.00043,ieee2-search1.bib
7859259,Dataflow in MATLAB: Algorithm Acceleration Through Concurrency,"In this paper, we present a novel Data-Flow architecture for MATLAB. This architecture provides thread-level pipelining of MATLAB functions as well as general concurrency support. The proposed approach yields a significant speedup of current MATLAB implementations that rely on streaming data or employ data-dependent operations. Following the development of increased CPU core counts, this proposed framework will provide additional benefit only as this trend continues. A performance analysis of the proposed framework is performed, and we are able to demonstrate high-level throughput gains of specific applications. Discussions on implementation guidelines, as well as limitations of the framework, are proposed in this paper. Through the use of this tool, we have demonstrated a 802.11a receiver employing Software-Defined Radio hardware running in real time. From the user's perspective, this tool requires interaction only from the MATLAB language, handling all threading and data transfer without user intervention.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Collins, Travis and Wyglinski, Alexander",2017,IEEE Access,10.1109/ACCESS.2017.2672200,ieee2-search1.bib
4664147,Experimental comparison of peer-to-peer streaming overlays: An application perspective,"We compare two representative streaming systems using mesh-based and multiple tree-based overlay routing through deployments on the PlanetLab wide-area experimentation platform. To the best of our knowledge, this is the first study to compare streaming overlay architectures in real Internet settings, considering not only intuitive aspects such as scalability and performance under churn, but also less studied factors such as bandwidth and latency heterogeneity of overlay participants. Overall, our study indicates that mesh-based systems are superior for nodes with high bandwidth capabilities and low round trip times, while multi-tree based systems currently cope better with stringent real time deadlines under heterogeneous conditions.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Seibert, Jeff and Zage, David and Fahmy, Sonia and Nita-Rotaru, Cristina",2008,2008 33rd IEEE Conference on Local Computer Networks (LCN),10.1109/LCN.2008.4664147,ieee2-search1.bib
598075,Comparison of two middleware data dissemination services in a wide-area distributed system,"The paper provides an experimental comparison of two middleware data dissemination services: a distributed object based service, and a message based service. The paper compares these two services in the context of a common application: a wide area network collaboratory, namely the Upper Atmospheric Research Collaboratory (UARC). UARC is an example of an application that reliably streams data from a set of suppliers to a set of receivers. This comparison highlights the tradeoffs between ease of implementation and performance for a data streaming middleware service. By relying on a rigid language primitive, namely remote method invocation, the object based dissemination service gave up the control over its transport policies. In contrast, the lower level socket based service was specifically constructed to provide a flexible interface to its applications. This flexibility allowed the middleware to better support data delivery to a heterogeneous set of receivers. This is important in a wide area distributed system where hosts are connected together over a broad spectrum of network links. The paper provides a concrete example of the effects of high level design choices in the implementation of a wide area distributed system's communication middleware.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Malan, G.R. and Jahanian, F. and Knoop, P.",1997,Proceedings of 17th International Conference on Distributed Computing Systems,10.1109/ICDCS.1997.598075,ieee2-search1.bib
9000079,AutoConfig: Automatic Configuration Tuning for Distributed Message Systems,"Distributed message systems (DMSs) serve as the communication backbone for many real-time streaming data processing applications. To support the vast diversity of such applications, DMSs provide a large number of parameters to configure. However, It overwhelms for most users to configure these parameters well for better performance. Although many automatic configuration approaches have been proposed to address this issue, critical challenges still remain: 1) to train a better and robust performance prediction model using a limited number of samples, and 2) to search for a high-dimensional parameter space efficiently within a time constraint. In this paper, we propose AutoConfig - an automatic configuration system that can optimize producer-side throughput on DMSs. AutoConfig constructs a novel comparison-based model (CBM) that is more robust that the prediction-based model (PBM) used by previous learning-based approaches. Furthermore, AutoConfig uses a weighted Latin hypercube sampling (wLHS) approach to select a set of samples that can provide a better coverage over the high-dimensional parameter space. wLHS allows AutoConfig to search for more promising configurations using the trained CBM. We have implemented AutoConfig on the Kafka platform, and evaluated it using eight different testing scenarios deployed on a public cloud. Experimental results show that our CBM can obtain better results than that of PBM under the same random forests based model. Furthermore, AutoConfig outperforms default configurations by 215.40% on average, and five state-of-the-art configuration algorithms by 7.21%-64.56%.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Bao, Liang and Liu, Xin and Xu, Ziheng and Fang, Baoyin",2018,2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE),10.1145/3238147.3238175,ieee2-search1.bib
9075192,Learning Over Multitask Graphs—Part II: Performance Analysis,"Part I of this paper formulated a multitask optimization problem where agents in the network have individual objectives to meet, or individual parameter vectors to estimate, subject to a smoothness condition over the graph. A diffusion strategy was devised that responds to streaming data and employs stochastic approximations in place of actual gradient vectors, which are generally unavailable. The approach relied on minimizing a global cost consisting of the aggregate sum of individual costs regularized by a term that promotes smoothness. We examined the first-order, the second-order, and the fourth-order stability of the multitask learning algorithm. The results identified conditions on the step-size parameter, regularization strength, and data characteristics in order to ensure stability. This Part II examines steady-state performance of the strategy. The results reveal explicitly the influence of the network topology and the regularization strength on the network performance and provide insights into the design of effective multitask strategies for distributed inference over networks.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Nassif, Roula and Vlaski, Stefan and Richard, Cédric and Sayed, Ali",2020,IEEE Open Journal of Signal Processing,10.1109/OJSP.2020.2989031,ieee2-search1.bib
5161036,Elastic scaling of data parallel operators in stream processing,"We describe an approach to elastically scale the performance of a data analytics operator that is part of a streaming application. Our techniques focus on dynamically adjusting the amount of computation an operator can carry out in response to changes in incoming workload and the availability of processing cycles. We show that our elastic approach is beneficial in light of the dynamic aspects of streaming workloads and stream processing environments. Addressing another recent trend, we show the importance of our approach as a means to providing computational elasticity in multicore processor-based environments such that operators can automatically find their best operating point. Finally, we present experiments driven by synthetic workloads, showing the space where the optimizing efforts are most beneficial and a radioastronomy imaging application, where we observe substantial improvements in its performance-critical section.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Schneider, Scott and Andrade, Henrique and Gedik, Bugra and Biem, Alain and Wu, Kun-Lung",2009,2009 IEEE International Symposium on Parallel & Distributed Processing,10.1109/IPDPS.2009.5161036,ieee2-search1.bib;scholar.bib
4802361,Investigating the Scheduling Sensitivity of P2P Video Streaming: An Experimental Study,"Peer-to-peer (P2P) technology has recently been employed to deliver large scale video multicast services on the Internet. Considerable efforts have been made by both academia and industry on P2P streaming design. While academia mostly focus on exploring design space to approach the theoretical performance bounds, our recent measurement study on several commercial P2P streaming systems indicates that they are able to deliver good user quality of experience with seemingly simple designs. One intriguing question remains: how elaborate should a good P2P video streaming design be? Towards answering this question, we developed and implemented several representative P2P streaming designs, ranging from theoretically proved optimal designs to straightforward ldquonaiverdquo designs. Through an extensive comparison study on PlanetLab, we unveil several key factors contributing to the successes of simple P2P streaming designs, including system resource index, server capacity and chunk scheduling rule, peer download buffering and peering degree. We also identify regions where naive designs are inadequate and more elaborate designs can improve things considerably. Our study not only brings us better understandings and more insights into the operation of existing systems, it also sheds lights on the design of future systems that can achieve a good balance between the performance and the complexity.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Liang, Chao and Guo, Yang and Liu, Yong",2009,IEEE Transactions on Multimedia,10.1109/TMM.2009.2012909,ieee2-search1.bib
4401052,How to scalably and accurately skip past streams,"Data stream methods look at each new item of the stream, perform a small number of operations while keeping a small amount of memory, and still perform much-needed analyses. However, in many situations, the update speed per item is extremely critical and not every item can be extensively examined. In practice, this has been addressed by only examining every Nth item from the input; decreasing the input rate by a fraction 1/N. but resulting in loss of guarantees on the accuracy of the post-hoc analyses. In this paper, we present a technique of skipping past streams and looking at only a fraction of the input. Unlike traditional methods, our skipping is performed in a principled manner based on the ""norm"" of the stream seen. Using this technique on top of well-known sketches, we show several-fold improvement in the update time for processing streams with a given guaranteed accuracy, for a number of stream processing problems including data summarization, heavy hitters detection and self-join size estimation. We present experimental results of our methods over synthetic data and integrate our methods into Sprint's Continuous Monitoring (CMON) system for live network traffic analyses. Furthermore, aiming at future scalable stream processing systems and going beyond state-of-art packet header analyses, we show how the packet contents can be analyzed at streaming speeds, a more challenging task because each packet content can result in many updates.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Bhattacharyya, Supratik and Madeira, Andre and Muthukrishnan, S. and Ye, Tao",2007,2007 IEEE 23rd International Conference on Data Engineering Workshop,10.1109/ICDEW.2007.4401052,ieee2-search1.bib
8304764,A Fast and Power-Efficient Hardware Architecture for Visual Feature Detection in Affine-SIFT,"Visual feature detection has been widely used in many computer vision applications, with increasing concern on feature robustness, processing speed, and power efficiency. In comparison with popular feature detection algorithms, affine-SIFT achieves the strongest robustness on the image illumination, image rotation, and image scale transformation, but exhibits extreme high computation complexity. To improve its computing efficiency, this work first proposes three hardware optimization methods to address three main performance bottlenecks. The first method is the reverse affine-based pipelined computing with optimized memory accessing. The second method is about stream processing with full parallel Gaussian pyramid. The third method is the rotation invariant binary pattern based feature vector generation. Then by incorporating these three optimization methods, this paper designs a high-efficient pipelined and parallel hardware architecture with optimized parallel memory accessing. Postlayout simulations using TSMC 65-nm 1P9M low power process show that this work achieves a processing speed of 97 fps at 1080p (1000 feature points per frame on average) under 200 MHz, with power consumption at 300 mW. In comparison, its computing efficiency (1005.6K pixels/s at 1 MHz) and power efficiency (670.5K pixels/s at 1 mW) are higher than state-of-the-art works and it is more promising for broad vision applications especially the embedded vision and mobile vision applications.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ouyang, Peng and Yin, Shouyi and Liu, Leibo and Zhang, Youguang and Zhao, Weisheng and Wei, Shaojun",2018,IEEE Transactions on Circuits and Systems I: Regular Papers,10.1109/TCSI.2018.2806447,ieee2-search1.bib
5502540,On the System Parameters of Peer-to-Peer Video Streaming with Network Coding,"Random linear network coding has been recently proved as a feasible solution to large-scale, peer-to-peer video dissemination over the Internet. In this paper, we use a simple analytical model to characterize and verify the efficiency of network coding in peer-to-peer video streaming systems. Several system parameters such as block size, server capacity, and peer aggressiveness are investigated with their influence on the system performance under flash crowd scenarios. Both our theoretical analysis and simulation results demonstrate that network coding can perform very close to the idealized scheduling algorithm for peer-to-peer video streaming.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Chang, L. and Pan, J.",2010,2010 IEEE International Conference on Communications,10.1109/ICC.2010.5502540,ieee2-search1.bib
5488439,On topology construction in layered P2P live streaming networks,"Peer-to-peer (P2P) overlay networks provide a highly effective and scalable solution to live media streaming systems that require the collective use of massively distributed network resources. A P2P media streaming architecture is typically built completely or partially upon a tree-structured network topology and the process of tree construction has a significant impact on the overall system performance. We build network cost models and formulate a specific type of topology construction problem, Maximum Average Bandwidth Spanning Tree (MABST), which aims at optimizing the system's average stream rate. We prove that MABST is NP-complete by reducing from Hamiltonian Path problem and propose an efficient heuristic algorithm. The performance superiority of the proposed algorithm is justified by experimental results using a live media streaming system deployed in real networks and is also illustrated by an extensive set of simulations on simulated networks of various sizes in comparison with other methods based on a degree constraint or a greedy strategy.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Li, Runzhi and Wu, Qishi and Lin, Yunyue and Lu, Xukang and Wang, Zongmin",2010,2010 IEEE Network Operations and Management Symposium - NOMS 2010,10.1109/NOMS.2010.5488439,ieee2-search1.bib
7502952,Real-time analysis of NetFlow data for generating network traffic statistics using Apache Spark,"In this paper, we present a framework for the real-time generation of network traffic statistics on Apache Spark Streaming, a modern distributed stream processing system. Our previous results showed that stream processing systems provide enough throughput to process a large volume of NetFlow data and hence they are suitable for network traffic monitoring. This paper describes the integration of Apache Spark Streaming into a current network monitoring architecture. We prove that it is possible to implement the same basic methods for NetFlow data analysis in the stream processing framework as in the traditional ones. Moreover, our stream processing implementation discovers new information which is not available when using traditional network monitoring approaches.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Čermák, Milan and Jirsík, Tomáš and Laštovička, Martin",2016,NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium,10.1109/NOMS.2016.7502952,ieee2-search1.bib
4741191,Pseudo-DHT: Distributed Search Algorithm for P2P Video Streaming,"In this paper, we propose pseudo-DHT, an efficient resource location algorithm in peer-to-peer (P2P) streaming systems. A lookup overlay formed by participating peers provides a foundation for pseudo-DHT's register (key, value) and retrieve (key) services. Using pseudo-DHT, peers register their video contents information (key) with their network identity (value). To reduce retrieval latency, register (ldr) performs the alteration of a given key on a key collision. For retrieve (ldr), a query for a key returns a value associated with the key or a key closest to the key. We apply pseudo-DHT to P2TSS, a P2P system that provides both live and time-shifted streams. In P2TSS, a live video is divided and spread out in peers' buffers. Peers construct a chord overlay that serves as the base of pseudo-DHT. A theoretical analysis is presented to predict the search performance of P2TSS with pseudo-DHT. Extensive simulations show that our pseudo-DHT provides good scalability and low overhead, matching our analysis.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Noh, Jeonghun and Deshpande, Sachin",2008,2008 Tenth IEEE International Symposium on Multimedia,10.1109/ISM.2008.57,ieee2-search1.bib
9150458,Smart Streaming: A High-Throughput Fault-tolerant Online Processing System,"In recent years, there has been considerable interest in developing frameworks for processing streaming data. Like the precursor commercial systems for data-intensive processing, these systems have largely not used methods popular within the HPC community (for example, MPI for communication). In this paper, we demonstrate a system for stream processing that offers a high-level API to the users (similar to MapReduce), is fault-tolerant, and is also more efficient and scalable than current solutions. Particularly, a cost-efficient MPI/OpenMP based fault-tolerant scheme is incorporated so that the system can survive node failures with only a modest degradation of performance. We evaluate both the functionality and efficiency of Smart Streaming using four common applications in machine learning and data analytics. A comparison against state-of-the-art streaming frameworks shows our system boosts the throughput of test cases by up to 10X and achieve desirable parallelism when scaled out. Additionally, the performance loss upon failures is only proportional to the share of failed resources.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Guo, Jia and Agrawal, Gagan",2020,2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW),10.1109/IPDPSW50202.2020.00075,ieee2-search1.bib
9932034,"Blue Danube: A Large-Scale, End-to-End Synchronous, Distributed Data Stream Processing Architecture for Time-Sensitive Applications","An extensive list of time-sensitive applications requiring ultra-low latency ranging from a few microseconds to a few milliseconds are presented in recent publications and IEEE standards. Time-sensitive applications, include industrial, critical healthcare and transportation applications as also applications for Smart Grids and the Internet of Vehicles – one of the most active research fields of Intelligent Transportation Systems of Smart Cities. In this work, we mainly set our focus on the suite of safety applications which attracts strong interest from the research community, as it aims to avoid road accidents and save lives. The IEEE Time-Sensitive Networking (TSN) set of standards specifies fundamental real-time characteristics. Nevertheless, as TSN works on Data Link layer (Layer 2 of the OSI model) the benefits of these characteristics fade away when other layers are crossed from the Application layer (Layer 7). Indicatively, recent research works report latencies on the order of tens of seconds when benchmarking Data Stream Processing and IoT platforms, and thus they are not suited for time-critical applications. Such platforms mainly use loosely coupled components with asynchronous communication. On Application layer, we propose a novel End-to-End Synchronous, Distributed Architecture for Large-Scale, High-Bandwidth, Ultra-Low Latency Data Stream Processing. Through our Big Data Stream analysis experiments (4.7 Gbit/s total average aggregated throughput, 1 Terabyte in-memory distributed database, 4 milliseconds average query latency) we have demonstrated the suitability of our architecture for time-sensitive applications such as accident avoidance for the Internet of Vehicles.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Michael, Panayiotis and Tsanakas, Panayiotis and Parker, D.",2022,2022 IEEE/ACM 26th International Symposium on Distributed Simulation and Real Time Applications (DS-RT),10.1109/DS-RT55542.2022.9932034,ieee2-search1.bib
8889581,A Highly Parametrizable Chisel HCL Generator of Single-Path Delay Feedback FFT Processors,"A configurable fast Fourier transform (FFT) engines and their inverse counterparts are indispensable in modern wireless communication and radar systems. The FFT processors are usually customized per use case. Therefore, a design generator of single-path delay feedback type of an FFT processor, that permits continuous input and output data streaming has been captured inside Chisel hardware construction language. It supports a wide range of parameter settings, like input data and twiddle factor widths, FFT sizes and number of stages, three radices, different scaling and rounding methods after each butterfly or dragonfly stage, among others, thus enabling an agile design space exploration. A comparison with commercially available FFTs which were specifically tailored for the particular FPGA platforms proves that FFT generator instances can be both performance-and resource-competitive with state of the art designs.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Milovanović, V. and Petrović, M.",2019,2019 IEEE 31st International Conference on Microelectronics (MIEL),10.1109/MIEL.2019.8889581,ieee2-search1.bib
4595868,Is Random Scheduling Sufficient in P2P Video Streaming?,"Peer-to-peer (P2P) has recently been employed to deliver large scale video multicast services on the Internet. Considerable efforts have been made by both academia and industry on P2P streaming design. While academia mostly focus on exploring design space to approach the theoretical performance bounds, our recent measurement study on several commercial P2P streaming systems indicates that they are able to deliver good user quality of experience with seemingly simple designs. One intriguing question remains: how elaborate should a good P2P video streaming design be? Towards answering this question, we developed and implemented several representative P2P streaming designs, ranging from theoretically proved optimal designs to straight forward ""naive"" designs. Through an extensive comparison study on PlanetLab, we unveil several key factors contributing to the successes of simple P2P streaming designs, including system resource index, sever capacity and chunk scheduling rule, peer download buffering and peering degree. We also identify regions where naive designs are inadequate and more elaborate designs can improve things considerably. Our study not only brings us better understandings and more insights into the operation of existing systems, it also sheds lights on the design of future systems that can achieve a good balance between the performance and the complexity.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Liang, Chao and Guo, Yang and Liu, Yong",2008,2008 The 28th International Conference on Distributed Computing Systems,10.1109/ICDCS.2008.103,ieee2-search1.bib
5361399,Delay Bounds of Chunk-Based Peer-to-Peer Video Streaming,"Peer-to-peer (P2P) systems exploit the uploading bandwidth of individual peers to distribute content at low server cost. While the P2P bandwidth sharing design is very efficient for bandwidth-sensitive applications, it imposes a fundamental performance constraint for delay-sensitive applications: The uploading bandwidth of a peer cannot be utilized to upload a piece of content until it completes the download of that content. This constraint sets up a limit on how fast a piece of content can be disseminated to all peers in a P2P system. In this paper, we theoretically study the impact of this inherent delay constraint and derive the minimum delay bounds for P2P live streaming systems. We show that the bandwidth heterogeneity among peers can be exploited to significantly improve the delay performance of all peers. We further propose a conceptual snowball streaming algorithm to approach the minimum delay bound in a dynamic P2P networking environment. Our analysis and simulation suggest that the proposed algorithm has better delay performance and more robust than static balanced multi-tree-based streaming solutions. Insights brought forth by our study can be used to guide the design of new P2P systems with shorter streaming delays.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Liu, and Yong,",2010,IEEE/ACM Transactions on Networking,10.1109/TNET.2009.2038155,ieee2-search1.bib
7827608,Arbitrary streaming permutations with minimum memory and latency,"Streaming architectures are a popular choice for data intensive application due to their high throughput requirements. When assembling components for a streaming application, it is often necessary to build translation blocks between them to match the ordering of the data elements required for the subsequent processing. This paper addresses this need by developing a technique that realizes arbitrary permutations in a streaming architecture. It is parametrized to accommodate any size data sequence and streaming width. This technique is applied to an architecture that receives continuous input at a rate of k elements per clock cycle, and after an initial start-up latency, outputs continuously at the same rate. In addition, the memory usage and latency through the memory array is minimized. This design is evaluated for permutations parametrized by size and stream width in terms of the memory elements and depths required. The class of stride permutation is considered for specific experimental evaluation. On average, this technique and architecture has only half the latency and requires half the memory of other techniques.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Koehn, Thaddeus and Athanas, Peter",2016,2016 IEEE/ACM International Conference on Computer-Aided Design (ICCAD),10.1145/2966986.2967004,ieee2-search1.bib
4351520,Characterizing PPStream across Internet,"Since the appearance of various P2P IPTV systems which timely broadcast live streaming to peers, they have attracted millions of users from all over the world. It is reported that the online audience have reached more than 1.2 million in peak time by the official website of PPStream, one of the most popular IPTV system in China. However, at the same time the popularity of these systems make the amounts of video traffic grow exponentially. In order to study the global playback performance, users ' behaviors and network characteristics as well, we developed our dedicated crawler of PPStream. Based on the measurements, we make some extensive performance evaluation on this commercially successful P2P IPTV system, and some characteristics on geographic clustering, connection stability, arrival/departure pattern, playback quality, sharing ratio and topology have been revealed. We think these findings can help other researchers model such streaming systems and system operators make further optimizations.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Jia, Jinkang and Li, Chunxi and Chen, Changjia",2007,2007 IFIP International Conference on Network and Parallel Computing Workshops (NPC 2007),10.1109/NPC.2007.34,ieee2-search1.bib
6877240,Communication-Efficient Distributed Variance Monitoring and Outlier Detection for Multivariate Time Series,"Modern scale-out services are comprised of thousands of individual machines, which must be continuously monitored for unexpected failures. One recent approach to monitoring is latent fault detection, an adaptive statistical framework for scale-out, load-balanced systems. By periodically measuring hundreds of performance metrics and looking for outlier machines, it attempts to detect subtle problems such as misconfigurations, bugs, and malfunctioning hardware, before they manifest as machine failures. Previous work on a large, real-world Web service has shown that many failures are indeed preceded by such latent faults. Latent fault detection is an offline framework with large bandwidth and processing requirements. Each machine must send all its measurements to a centralized location, which is prohibitive in some settings and requires data-parallel processing infrastructure. In this work we adapt the latent fault detector to provide an online, communication- and computation-reduced version. We utilize stream processing techniques to trade accuracy for communication and computation. We first describe a novel communication-efficient online distributed variance monitoring algorithm that provides a continuous estimate of the global variance within guaranteed approximation bounds. Using the variance monitor, we provide an online distributed outlier detection framework for non-stationary multivariate time series common in scale-out systems. The adapted framework reduces data size and central processing cost by processing the data in situ, making it usable in wider settings. Like the original framework, our adaptation admits different comparison functions, supports non-stationary data, and provides statistical guarantees on the rate of false positives. Simulations on logs from a production system show that we are able to reduce bandwidth by an order of magnitude, with below 1% error compared to the original algorithm.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Gabel, Mohse and Schuster, Assaf and Keren, Daniel",2014,2014 IEEE 28th International Parallel and Distributed Processing Symposium,10.1109/IPDPS.2014.16,ieee2-search1.bib
5735684,On a decentralized approach to tree construction in hybrid P2P networks,"The client-server architecture widely adopted on the Internet is not adequate to meet the ever-increasing user loads and bandwidth demands in live streaming systems especially for multimedia content delivery. Peer-to-peer (P2P) overlay networks provide excellent system scalability and high resource utilization, which make it an attractive solution to this problem. We consider a hybrid hierarchical P2P overlay network that consists of both super and normal peers to support live streaming applications. This architecture is built upon a tree-structured network of super peers, which organize normal peers into clusters. The tree construction process has a significant impact on the overall system performance. We formulate a specific type of problem, max-minTC, to maximize the minimum node throughput in tree construction, where the system's stream rate is optimized by constructing an efficient spanning tree among super peers. We present a decentralized approach where super peers run the same algorithm in parallel to derive a tree from an identical database describing the topology of the streaming system. This approach is able to quickly converge to a new tree upon the detection of any topological changes in super peers. The performance superiority of the proposed solution is illustrated by extensive simulations on a large set of simulated networks of various sizes from small to large scales in comparison with other methods.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Lu, Xukang and Wu, Qishi and Lin, Yunyue and Li, Runzhi",2010,IEEE Local Computer Network Conference,10.1109/LCN.2010.5735684,ieee2-search1.bib
8079733,A Comparison of Stream Processing Frameworks,"This study compares the performance of Big Data Stream Processing frameworks including Apache Spark, Flink, and Storm. Also, it measures the resource usage and performance scalability of the frameworks against a varying number of cluster sizes. It has been observed that, Flink outperforms both Spark and Storm under equal constraints. However, Spark can be optimized to provide the higher throughput than Flink with the cost of higher latency.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Karakaya, Ziya and Yazici, Ali and Alayyoub, Mohammed",2017,2017 International Conference on Computer and Applications (ICCA),10.1109/COMAPP.2017.8079733,ieee2-search1.bib
9188142,A Comparative Analysis and Evaluation of MapReduce Cloud Computing Simulators,"The application of MapReduce cloud computing simulators for research and development is becoming popular, due to their efficiency and ease of utilization. This ignited the development of several cloud simulators for algorithm testing and performance analysis of dynamic MapReduce environments. The selection of appropriate simulator for a specific research remains a challenge. We have designed a MapReduce classification framework to guide cloud and big data researchers towards suitable tools. We have reviewed eleven MapReduce specific simulators. Our evaluation first revealed thirty general functional requirements for more widely applicable cloud simulators. Then, we focused on specific concerns of MapReduce related simulations and filtered the general requirements down to the most relevant thirteen. Our evaluation highlighted the strengths and weakness of several MapReduce simulators. IoT-based applications, stream processing and replaying of production cluster workloads are key criteria absent from many simulators. Therefore, we identified these as gaps, that simulator developers could focus on when extending their works towards MapReduce oriented simulations. Finally, researchers simulating dynamic behaviors of Hadoop clusters should select simulators efficient in parameter tuning.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Gavua, Ebenezer and Kecskemeti, Gabor",2019,2019 International Conference on High Performance Computing & Simulation (HPCS),10.1109/HPCS48598.2019.9188142,ieee2-search1.bib
5764567,Hybrid CDN-P2P architectures for live video streaming: Comparative study of connected and unconnected meshes,"There are two main scalable methods for streaming live video over the Internet: Content Delivery Networks (CDNs) and Peer-to-Peer (P2P) networks. Though both have their own problems, P2P streaming systems challenge delivering video with constant quality and CDNs approaches require deployment of large number of servers throughout the Internet that is costly. Recently, using hybrid architectures based on both CDN and P2P networks has shown to be an efficient approach for large-scale video distribution over the Internet. This paper is compared the performance of two main hybrid CDN-P2P architectures includes: (i) CDN-P2P unconnected mesh in which independent P2P mesh networks are constructed under each CDN node, and (ii) CDN-P2P connected mesh in which CDN nodes and peers participate in construction of a single P2P mesh network. The comparison is preformed in addition, to the pure mesh-based P2P video streaming, using extensive simulation and based on different QoS metrics.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Seyyedi, S. and Akbari, B.",2011,2011 International Symposium on Computer Networks and Distributed Systems (CNDS),10.1109/CNDS.2011.5764567,ieee2-search1.bib
5421671,PartnerVoD: Improving P2P-VoD with Partnership Overlay,"Recently video-on-demand (VoD) has become a popular Internet application due to its promising usage in a variety of Internet-based services. However, it remains a challenging problem to provide scalable and fluent VoD services over Internet especially when including VCR operations into VoD service. Supporting user interactivities such as random seek, rewind and fast forward is desirable while these operations surely introduce extra complexity and overhead into the VoD system. Moreover, users may probably have to wait for a long time because new data needs to be buffered and this would greatly deteriorate user experiences. In this paper, we propose an overlay-constructing method called PartnerVoD, aiming at maximizing the collaboration among peers and the utility of upload bandwidth. In PartnerVoD, peers with close playing positions become partners and stream media data to each other. In order to support fast streaming and efficient neighbor discovery, we not only takes advantage of P2P-VoD network's hierarchical characteristic in time domain but also takes locality awareness into account. Additionally, performance evaluation shows that it can help improve VCR performance at the same time.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Wen, Ke and Zhao, Li",2010,2010 7th IEEE Consumer Communications and Networking Conference,10.1109/CCNC.2010.5421671,ieee2-search1.bib
7056925,The Berkeley Data Analytics Stack (BDAS),"Summary form only given. The session on “The Berkeley Data Analytics Stack” shall elucidate its current components which include Spark, Shark and Mesos with emphasis on Spark and it's real-time extension called Spark-Streaming which adds stream processing capabilities to Spark. One-liners describing each of these technologies are as follows: 1) BDAS is an open source, next-generation data analytics stack under development at the UC Berkeley AMPLab. 2) Spark, a high-speed cluster computing system compatible with Hadoop that can outperform it by up to 100x thanks to its ability to perform computations in memory. 3) Shark, a port of Apache Hive onto Spark that is compatible with existing Hive warehouses and queries. Shark can answer HiveQL queries up to 100x faster than Hive without modification to the data and queries, and is also open source as part of BDAS. 4) Mesos is a cluster manager that provides efficient resource isolation and sharing across distributed applications or frameworks. It can run Hadoop, MPI, Hypertable, Spark, and other applications on a dynamically shared pool of nodes. 5) Apart, from an elaborate explanation of various facets of Spark, the session would also aim to walk through machine learning algorithm benchmarking and examples that would substantiate the concepts covered.",FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Jayati,",2014,"2014 Conference on IT in Business, Industry and Government (CSIBIG)",10.1109/CSIBIG.2014.7056925,ieee2-search1.bib
1410192,High-availability algorithms for distributed stream processing,"Stream-processing systems are designed to support an emerging class of applications that require sophisticated and timely processing of high-volume data streams, often originating in distributed environments. Unlike traditional data-processing applications that require precise recovery for correctness, many stream-processing applications can tolerate and benefit from weaker recovery guarantees. In this paper, we study various recovery guarantees and pertinent recovery techniques that can meet the correctness and performance requirements of stream-processing applications. We discuss the design and algorithmic challenges associated with the proposed recovery techniques and describe how each can provide different guarantees with proper combinations of redundant processing, checkpointing, and remote logging. Using analysis and simulations, we quantify the cost of our recovery guarantees and examine the performance and applicability of the recovery techniques. We also analyze how the knowledge of query network properties can help decrease the cost of high availability.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Hwang, J.-H. and Balazinska, M. and Rasin, A. and Cetintemel, U. and Stonebraker, M. and Zdonik, S.",2005,21st International Conference on Data Engineering (ICDE'05),10.1109/ICDE.2005.72,ieee2-search1.bib
8644799,K-Means Clustering with Feature Selection for Stream Data,"K-means clustering is popular for its efficiency and is often chosen for analyzing large-scale data. However, it is hard to deal with high-dimensional data, which often contain lots of redundant features. In addition, in real-world applications, we usually confront with massive data streams, such as transport system and social media, which are often periodically generated in high-dimensional space. Although existing K-means extensions have achieved great success on high-dimensional data by integrating with dimension reduction methods, they are limited to off-line data. To solve these problems, we propose a streaming Kmeans clustering with feature selection. The proposed algorithm divides the traditional clustering procedure into several related multiple clustering tasks and selects the representative features by the group sparsity regularization technique. Besides, within such framework, the shared information among neighbor streams can be properly explored. Experimental results on several benchmark datasets demonstrate the effectiveness of the proposed model.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Wang, Xiao-Dong and Chen, Rung-Ching and Yan, Fei and Hendry, Hendry",2018,"2018 International Symposium on Computer, Consumer and Control (IS3C)",10.1109/IS3C.2018.00120,ieee2-search1.bib
7336545,Detection of Superpoints Using a Vector Bloom Filter,"Internet attacks, such as distributed denial-of-service attacks and worm attacks, are increasing in severity and frequency. Identifying and mitigating realtime attacks are an important and challenging task for network administrators. An infected host can make a large number of connections to distinct destinations during a short time. Such a host is called a superpoint. Detecting superpoints can be utilized for traffic engineering and anomaly detection. This paper proposes a novel data streaming method for detecting superpoints and proves guarantees on its accuracy with low memory requirements. The superior performance of this method comes from a new data structure, called vector bloom filter (VBF), which is a variant of standard BF. The VBF consists of six hash functions, four of which take some consecutive bits from the input string as the corresponding value, respectively. The information of superpoints is obtained by using the overlapping of hash bit strings of the VBF. Theoretical analysis and experimental results show that the proposed method can detect superpoints precisely and efficiently through comparison with other existing approaches.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Liu, Weijiang and Qu, Wenyu and Gong, Jian and Li, Keqiu",2016,IEEE Transactions on Information Forensics and Security,10.1109/TIFS.2015.2503269,ieee2-search1.bib
6775008,Wireless Streaming of Interactive Multi-View Video via Network Compression and Path Diversity,"We formulate a system framework for network compression of interactive multi-view streaming video. The setup comprises a media server that delivers the content over two independent network paths to a client. Our system features a proxy-server located at the junction of the wired and wireless portions of each path. The proxy dynamically adapts the content data sent over the wireless links, in response to channel quality feedback from the client, such that video distortion at the client is minimized. We analyze the performance of our system and contrast its characteristics with dynamic content adaptation at the source and conventional streaming architectures, including scalable video. We numerically simulate the operation of all streaming systems under comparison and establish a close agreement between our analysis and the experimental findings. The proposed system delivers superior video quality over the reference competitors, while enabling notable transmission rate savings, at the same time.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Chakareski, and Jacob,",2014,IEEE Transactions on Communications,10.1109/TCOMM.2014.022314.120890,ieee2-search1.bib
6831304,Wireless streaming of interactive multi-view video: Network compression meets path diversity,"I formulate a system framework for network compression of interactive multi-view streaming video. The setup comprises a media server that delivers the content over two independent network paths to a client. My system features a proxy-server located at the junction of the wired and wireless portions of each path. The proxy dynamically adapts the content data sent over the wireless links, in response to channel quality feedback from the client, such that video distortion at the client is minimized. I analyze the performance of my system and contrast its characteristics with dynamic content adaptation at the source and conventional streaming architectures, including scalable video. I numerically simulate the operation of all streaming systems under comparison and establish a close agreement between my analysis and the experimental findings. The proposed system delivers superior video quality over the reference competitors, while enabling notable transmission rate savings, at the same time.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Chakareski, and Jacob,",2013,2013 IEEE Global Communications Conference (GLOBECOM),10.1109/GLOCOM.2013.6831304,ieee2-search1.bib
6888904,MOLStream: A Modular Rapid Development and Evaluation Framework for Live P2P Streaming,"We present MOL Stream, a modular framework for rapid development and evaluation of P2P live streaming systems. MOL Stream allows P2P streaming protocols to be decomposed into basic blocks, each associated with a standard functional specification. By exposing structural commonalities between these components, MOL Stream enables specific implementations of these building blocks to be combined in order to devise, refine and evaluate new P2P live streaming protocols. Our approach offers several benefits. First, block encapsulation entails that more advanced individual components, e.g., the overlay, can seamlessly replace existing ones without affecting the rest of the system. As a case study, we show how MOL Stream can seamlessly substitute the overlay used by DONet/Coolstreaming, a popular P2P live streaming implementation, for an improved version. Second, MOL Stream facilitates the comparison between various protocols over local clusters or wide-area test beds such as Planet Lab. The combination of rapid prototyping and minimum effort valuation enables researchers and students to faster understand how various design choices at different levels impact the performance and scalability of the protocol, as shown through several examples in this paper. MOL Stream is written in Java and is freely available as an open-source project at https://sourceforge.net/projects/molstream/.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Friedman, Roy and Libov, Alexander and Vigfusson, Ymir",2014,2014 IEEE 34th International Conference on Distributed Computing Systems,10.1109/ICDCS.2014.36,ieee2-search1.bib
4014007,BASS: BitTorrent Assisted Streaming System for Video-on-Demand,"This paper introduces a hybrid server/P2P streaming system called bittorrent-assisted streaming system (BASS) for large-scale video-on-demand (VoD) services. By distributing the load among P2P connections as well as maintaining active server connections, BASS can increase the system scalability while decreasing media playout wait times. To analyze the benefits of BASS, we examine torrent trace data collected in the first week of distribution for Fedora Core 3 and develop an empirical model of bittorrent client performance. Based on this, we run trace-based simulations to evaluate BASS and show that it is more scalable than current unicast solutions and can greatly decrease the average waiting time before playback",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Dana, Chris and Li, Danjue and Harrison, David and Chuah, Chen-nee",2005,2005 IEEE 7th Workshop on Multimedia Signal Processing,10.1109/MMSP.2005.248586,ieee3-search1.bib
8035150,MERCATOR: A GPGPU Framework for Irregular Streaming Applications,"GPUs have a natural affinity for streaming applications exhibiting consistent, predictable dataflow. However, many high-impact irregular streaming applications, including sequence pattern matching, decision-tree and decision-cascade evaluation, and large-scale graph processing, exhibit unpredictable dataflow due to data-dependent filtering or expansion of the data stream. Existing GPU frameworks do not support arbitrary irregular streaming dataflow tasks, and developing application-specific optimized implementations for such tasks requires expert GPU knowledge. We introduce MERCATOR, a lightweight framework supporting modular CUDA streaming application development for irregular applications. A developer can use MERCATOR to decompose an irregular application for the GPU without explicitly remapping work to threads at runtime. MERCATOR applications are efficiently parallelized on the GPU through a combination of replication across blocks and queueing between nodes to accommodate irregularity. We quantify the performance impact of MERCATOR's support for irregularity and illustrate its utility by implementing a biological sequence comparison pipeline similar to the well-known NCBI BLASTN algorithm. MERCATOR code is available by request to the first author.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Cole, Stephen and Buhler, Jeremy",2017,2017 International Conference on High Performance Computing & Simulation (HPCS),10.1109/HPCS.2017.111,ieee3-search1.bib
4740992,Real-Time Performance vs. Server Bandwidth Cost in Peer-to-Peer Streaming System,"In P2P streaming system, real-time performance is very important for evaluating quality of service, which directly determines the user experience. However, real-time performance is restricted by server bandwidth cost. Based on the proposed data transmitting model, this paper investigates the recursiveness of real-time performance through theoretical analysis, and computes its relationship with server bandwidth cost. The impact of system scale and service capacity of peer is also discussed. Especially, we consider both overlay diameter and the one hop delay in the investigation, hence can obtain more exact results. Our findings are of great importance for the design and deployment of P2P streaming system.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Lu, Yifeng and Ren, Hao and Wang, Jinlin",2008,2008 International Conference on Computer and Electrical Engineering,10.1109/ICCEE.2008.31,ieee3-search1.bib
6413677,An Improvement of OpenMP Pipeline Parallelism with the BatchQueue Algorithm,"In the context of multicore programming, pipeline parallelism is a solution to easily transform a sequential program into a parallel one without requiring a whole rewriting of the code. The OpenMP stream-computing extension presented by Pop and Cohen proposes an extension of OpenMP to handle pipeline parallelism. However, their communication algorithm relies on Multiple-producer-Multiple-Consumer queues, while pipelined applications mostly deal with linear chains of communication, i.e., with only a single producer and a single consumer. To improve the performance of the OpenMP stream-extension, we propose to add a more specialized Single-Producer-Single-Consumer communication algorithm called Batch Queue and to select it for one-to-one communication. Our evaluation shows that Batch Queue is then able to improve the throughput up to a factor 2 on an 8-core machine both for example application and real applications. Our study shows therefore that using specialized and efficient communication algorithms can have a significant impact on the overall performance of pipelined applications.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Preud'Homme, Thomas and Sopena, Julien and Thomas, Gaël and Folliot, Bertil",2012,2012 IEEE 18th International Conference on Parallel and Distributed Systems,10.1109/ICPADS.2012.55,ieee3-search1.bib
5364699,Topology Optimization in Multi-tree Based P2P Streaming System,"In recent years, peer-to-peer (P2P) technology has been demonstrated tremendously effective in delivering large-scale video streaming services. Although P2P streaming is scalable and robust, the network-oblivious peering and scheduling in the current designs impede the further improvement in streaming quality and the efficient usage of network resources. New P2P streaming systems exploit network information provided by Internet service providers (ISPs) to achieve a higher level of application performance and generate lower traffic stress. In this paper, utilizing information from ISPs, we investigate the strategies on the topology construction and maintenance of multi-tree based P2P streaming systems. We study topology optimization to minimize the average height of sub-stream trees and the average propagation latency in each tree. We first present the optimization formulations, and then propose a set of heuristic algorithms for the construction and dynamic management of the multiple sub-stream trees for practical implementation. Through numerical comparison study, we show that our algorithms can significantly improve the delay performance of existing P2P streaming systems.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Liang, Chao and Liu, Yong and Ross, Keith",2009,2009 21st IEEE International Conference on Tools with Artificial Intelligence,10.1109/ICTAI.2009.17,ieee3-search1.bib
9912882,BenchPilot: Repeatable & Reproducible Benchmarking for Edge Micro-DCs,"Micro-Datacenters (DCs) are emerging as key en-ablers for Edge computing and 5G mobile networks by pro-viding processing power closer to IoT devices to extract timely analytic insights. However, the performance evaluation of data stream processing on micro-DCs is a daunting task due to difficulties raised by the time-consuming setup, configuration and heterogeneity of the underlying environment. To address these challenges, we introduce BenchPilot, a modular and highly customizable benchmarking framework for edge micro-DCs. BenchPilot provides a high-level declarative model for describing experiment testbeds and scenarios that automates the bench-marking process on Streaming Distributed Processing Engines (SDPEs). The latter enables users to focus on performance analysis instead of dealing with the complex and time-consuming setup. BenchPilot instantiates the underlying cluster, performs repeatable experimentation, and provides a unified monitoring stack in heterogeneous Micro-DCs. To highlight the usability of BenchPilot, we conduct experiments on two popular streaming engines, namely Apache Storm and Flink. Our experiments compare the engines based on performance, CPU utilization, energy consumption, temperature, and network I/O.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Georgiou, Joanna and Symeonides, Moysis and Kasioulis, Michalis and Trihinas, Demetris and Pallis, George and Dikaiakos, Marios",2022,2022 IEEE Symposium on Computers and Communications (ISCC),10.1109/ISCC55528.2022.9912882,ieee3-search1.bib
7923779,Introducing SECURESTREAMS: Scalable Middleware for Reactive and Secure Data Stream Processing,"We introduce SECURESTREAMS, a middleware framework for secure stream processing. Its design builds on Intel's Secure Guard Extensions (SGX) to guarantee the privacy and the integrity of the data being processed. Our initial experimental results of SECURESTREAMS are promising: the framework is easy to use, and delivers high throughput, enabling developers to implement complex processing pipelines in a few lines of scripting code.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Havet, Aurelien and Schiavoni, Valerio and Felber, Pascal and Rouvoy, Romain",2017,2017 IEEE International Conference on Cloud Engineering (IC2E),10.1109/IC2E.2017.50,ieee3-search1.bib
5695643,Bandwidth Constrained Tree Construction for Live Streaming Systems in P2P Networks,"The traditional client-server architecture widely adopted on the Internet is not adequate to meet the increasing user loads and bandwidth demands in live streaming systems especially for multimedia content delivery. Peer-to-peer P2P) overlay networks provide excellent system scalability and high resource utilization, which make it an attractive solution to this problem. This paper considers a hybrid hierarchical P2P overlay network structure that consists of both super and normal peers. The media streaming architecture is built upon a tree structured network of super peers and the tree construction process has a significant impact on the overall system performance. We construct network cost models and formulate a Bandwidth Constrained Tree (BCT) construction problem, which aims at maximizing the number of peers that satisfy a specified bandwidth constraint. We prove that BCT is NP-complete and propose optimal algorithms in two special cases and a heuristic approach in a general case. The performance superiority of the proposed method is illustrated by an extensive set of experiments on simulated networks of various sizes in comparison with existing greedy and degree constrained algorithms.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Lin, Yunyue and Wu, Qishi and Lu, Xukang and Gu, Yi",2010,2010 IEEE 16th International Conference on Parallel and Distributed Systems,10.1109/ICPADS.2010.39,ieee3-search1.bib
6025323,A Survey and Synthesis of User Behavior Measurements in P2P Streaming Systems,"In terms of scalability, cost and ease of deployment, the Peer-to-Peer (P2P) approach has emerged as a promising solution for video streaming applications. Its architecture enables end-hosts, called peers, to relay the video stream to each other. P2P systems are in fact networks of users who control peers. Thus, user behavior is crucial to the performance of these systems because it directly impacts the streaming flow. To understand user behavior, several measurement studies have been carried out over different video streaming systems. Each measurement analyzes a particular system focusing on specific metrics and presents insights. However, a single study based on a particular system and specific metrics is not sufficient to provide a complete model of user behavior considering all of its components and the impact of external factors on them. In this paper, we propose a comparison and a synthesis of these measurements. First of all, we review video streaming architectures, followed by a survey on the user behavior measurements in these architectures. Then, we gather insights revealed in these measurements and compare them for consensual and contrasting points. Finally, we extract components of user behavior, their external impacting factors and relationships among them. We also point out those aspects of user behavior which require further investigations.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ullah, Ihsan and Doyen, Guillaume and Bonnet, Gregory and Gaiti, Dominique",2012,IEEE Communications Surveys & Tutorials,10.1109/SURV.2011.082611.00134,ieee3-search1.bib
4459148,The MeDICi Integration Framework: A Platform for High Performance Data Streaming Applications,"Building high performance analytical applications for data streams generated from sensors is a challenging software engineering problem. Such applications typically comprise a complex pipeline of processing components that capture, transform and analyze the incoming data stream. In addition, applications must provide high throughput, be scalable and easily modifiable so that new analytical components can be added with minimum effort. In this paper we describe the MeDICi integration framework (MIF), which is a middleware platform we have created to address these challenges. The MIF extends an open source messaging platform with a component-based API for integrating components into analytical pipelines. We describe the features and capabilities of the MIF, and show how it has been used to build a production analytical application for detecting cyber security attacks. The application was composed from multiple independently developed components using several different programming languages. The resulting application was able to process network sensor traffic in real time and provide insightful feedback to network analysts as soon as potential attacks were recognized.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Gorton, Ian and Wynne, Adam and Almquist, Justin and Chatterton, Jack",2008,Seventh Working IEEE/IFIP Conference on Software Architecture (WICSA 2008),10.1109/WICSA.2008.21,ieee3-search1.bib
1015491,Efficient pipelining of nested loops: unroll-and-squash,"The size and complexity of current custom VLSI have forced the use of high-level programming languages to describe hardware, and compiler and synthesis technology to map abstract designs into silicon. Since streaming data processing in DSP applications is typically described by loop constructs in a high-level language, loops are the most critical portions of the hardware description and special techniques are developed to optimally synthesize them. We introduce a new method for mapping and pipelining nested loops efficiently into hardware. It achieves fine-grain parallelism even on strong intra- and inter-iteration data-dependent inner loops and, by sharing resources economically, improves performance at the expense of a small amount of additional area. We implemented the transformation within the Nimble Compiler environment and evaluated its performance on several signal processing benchmarks. The method achieves up to 2× improvement in the area efficiency compared to the best known optimization techniques.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Petkov, D. and Harr, R. and Amarasinghe, S.",2002,Proceedings 16th International Parallel and Distributed Processing Symposium,10.1109/IPDPS.2002.1015491,ieee3-search1.bib
8596544,Scalable and Real-Time Time Series Analytics: Telemedicine as Use Case,"Real-time processing and data analytics of big data has become a main operation in different business, such as extracting manufacturing, healthcare, smart Cities, social and media network data, ... etc. Also another concept has been appear that significant interest in building new system refers to high-speed real-time and near real-time data streams. Big data workloads in the wild show a strong temporal variability that not only poses the risk of slow responsiveness in data analysis, but also leads to a high risk of service outage. The recent development of batch streaming systems based on the MapReduce framework is shown effective on non-overloaded systems. However, little is known on how to enhance the performance of the batch streaming systems for bursty workloads. In this paper, we propose a latency-driven data controller, which aims to process as much data as possible, while processing these as fast as the application target latency and system capacity allow. In particular by implementing Spark Streaming as emerging and complex batch streaming system which include features that allow placing data in an augmented distributed memory, shedding out-of-date data, (improving the processing locality of Map tasks, and delaying data processing in transient overloads.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Bouslama, Abdelilah and Laaziz, Yassin and Tali, Abdelhak",2018,2018 IEEE 5th International Congress on Information Science and Technology (CiSt),10.1109/CIST.2018.8596544,ieee3-search1.bib
5235330,A Scheduling Strategy to Avoid Playout Interruptions in Video Streaming Systems,"In Internet multimedia streaming, a raw quality base layer is adaptively enriched with one or more enhancement layers to fully use the available bandwidth. In this work, using a control theoretic approach, we design and implement an innovative scheduling strategy for properly distributing the network available bandwidth among base and enhancement layers, in order to avoid playout interruptions due to base layer underflows at the decoder side. The proposed solution has been casted in a H.264/AVC SVC video streaming architecture. Experimental results, collected using a single bottleneck testbed and three different benchmarking video sequences, have demonstrated that the proposed scheduling strategy is able to avoid or strongly limit the number of playout interruptions under moderate or high traffic conditions, respectively.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Boggia, G. and Camarda, P. and Fortuna, R. and Grieco, L.",2009,2009 Proceedings of 18th International Conference on Computer Communications and Networks,10.1109/ICCCN.2009.5235330,ieee3-search1.bib
9671679,A Scalable System for Searching Large-scale Multi-sensor Remote Sensing Image Collections,"Huge amounts of remote sensing data collected from hundreds of operational satellites in conjunction with on-demand UAV based imaging products are offering unprecedented capabilities towards monitoring dynamic earth resources. However, searching for the right combination of imagery products that satisfy an application requirement is a daunting task. Earlier efforts at streamlining remote sensing data discovery include NASA’s Earth Observing System (EOS) Data and Information System (EOSDIS), USGS Global Visualization Viewer (GloVis), and several other research systems like Minnesota MapServer. These systems were built on top of metadata harvesting, indexing, keyword searching modules which were not scalable and interoperable. To address these challenges, recently the SpatioTemporal Asset Catalog (STAC) specification was developed to provide a common language to describe a range of geospatial information, so that data products can be more easily indexed and discovered. In this paper we present an highly scalable STAC API based system with spatiotemporal indexing support. Experimental evaluation shows that our spatiotemporal indexing based queries are 1000x faster than standard STAC API server.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zhao, Yifan and Yang, Xian and Vatsavai, Ranga",2021,2021 IEEE International Conference on Big Data (Big Data),10.1109/BigData52589.2021.9671679,ieee3-search1.bib
5433193,Highly scalable algorithm for distributed real-time text indexing,"Stream computing research is moving from terascale to petascale levels. It aims to rapidly analyze data as it streams in from many sources and make decisions with high speed and accuracy in fields as diverse as security surveillance and financial services including stock trading. We specifically consider real-time text indexing and search with high input data rates (10 GB/s or more) along with small index age-off (expiry) time. This makes it necessary to have maximal indexing rates for large volumes of data as well as minimal latency for indexing (time between start of indexing for a document and its availability for search) while maintaining very-low search response time. In addition, future massively parallel architectures with storage class memories will enable high speed in-memory real-time indexing, where index can be completely stored in a high capacity storage class memory. In this paper, we present the design of distributed data-structures and distributed real-time text indexing algorithm for parallel systems having large (thousands to hundred thousand) number of cores/processors, while simultaneously providing acceptable search performance [1]. The inherent trade-offs involved in index space, indexing throughput and search response time make this problem particularly challenging. Our algorithm uses group-based index construction and leverages novel index data structures that reduce load imbalance and make text indexing and merge process more scalable and efficient. We show analytically that the asymptotic parallel time complexity of our distributed indexing algorithm, is at least ?(log(P)) factor better than typical indexing approaches, where P is the number of indexing nodes in a group. We further demonstrate the performance and scalability of our distributed indexing algorithm, on an MPP architecture (Blue Gene/L) using actual IBM intranet data. We achieved high indexing throughput of around 312 GB/min on an 8 K node Blue Gene/L machine. In comparison with parallel indexing implemented using typical approaches like CLucene, this is 3?-7? better. To the best of our knowledge, this is the first published result on indexing throughput at such a large scale, with sustained search performance. We further show that our approach is scalable to 128 K nodes, giving an estimated indexing throughput of 5 T B/min. We also achieved indexing latency that is around 10? better than typical indexing approaches.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Narang, Ankur and Agarwal, Vikas and Kedia, Monu and Garg, Vijay",2009,2009 International Conference on High Performance Computing (HiPC),10.1109/HIPC.2009.5433193,ieee3-search1.bib
5395356,A Population Dynamics Model for Data Streaming over P2P Networks,"Data streaming (DS) over peer-to-peer (P2P) networks has been intensively studied in recent years and there have been various schemes proposed already. To evaluate these schemes, either measurement in experimental implementations, or simulation and theoretical analysis have been used. The former is inadequate as data are collected from different experiments, while the latter lacks a proper theoretical dynamics model. Our research aims at providing a general theoretical model to evaluate DS over P2P systems and analyze their dynamic behaviors. In this paper, with the analysis and abstraction of the characteristics of peers and their organization in DS over P2P, we propose a general population dynamics model for DS over P2P with fixed population. The model depicts the dynamic distribution of peers as a closed Markov queuing network. In particular, the model is scheme-independent and can be used with various schemes. Through theoretical analysis, we prove the model has equilibrium and only one closed-form solution. Besides, we verify the model through simulations, and show that it is a helpful analytical tool with a case study.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Xu, Jialing and Yang, Guang-Hua and Li, Victor",2009,2009 15th International Conference on Parallel and Distributed Systems,10.1109/ICPADS.2009.56,ieee3-search1.bib
6038734,Efficient stereo segment scheduling in peer-to-peer 3D/multi-view video streaming,"3D (or stereo) video has been a visually appealing and costly affordable technology. More sophisticated multi-view videos have also been demonstrated. Yet their remarkably increased data volume poses greater challenges to the conventional client/server streaming systems, which has already suffered from supporting 2D videos. The stringent multi-stream synchronization further complicate the system design. In this paper, we present an initial attempt toward efficient streaming of stereo/multi-view videos over a peer-to-peer network. We show that the inherent multi-stream nature of stereo video makes segment scheduling more difficult, which is particularly acute with the existence of multiple senders in a peer-to-peer overlay. We formulate the stereo segment scheduling problem as a Binary Quadratic Programming problem and optimally solve it using an MIQP solver. However, given the high peer dynamics and the stringent playback deadline in real-time streaming, the optimal solution is too costly to be obtained. Thus, we develop two efficient algorithms to allow peers frequently compute the scheduling. We show that one of the proposed algorithms can achieve an analytical guarantee in the worst case performance, in particular, the approximation factor is at most 3 comparing with the optimal solution. We implement the proposed algorithms and the optimal in a peer-to-peer simulating system, and show that the proposed algorithms can achieve near-optimal performance efficiently. We further implement two other scheduling algorithms that are used in popular peer-to-peer streaming systems for comparison, and extend our design to support multi-view video with view diversity and dynamics. Under different end-system and network configurations with both stereo and multi-view streaming, the simulation results demonstrate that our algorithms outperform others in terms of streaming quality, stream synchronization/smoothness and scalability.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ding, Yan and Liu, Jiangchuan",2011,2011 IEEE International Conference on Peer-to-Peer Computing,10.1109/P2P.2011.6038734,ieee3-search1.bib
6176388,SCnC: Efficient Unification of Streaming with Dynamic Task Parallelism,"Stream processing is a special form of the dataflow execution model that offers extensive opportunities for optimization and automatic parallelization. To take full advantage of the paradigm, however, typically requires programmers to learn a new language and re-implement their applications. This work shows that it is possible to exploit streaming as a safe and automatic optimization of a more general dataflow-based modelâ€""one in which computation kernels are written in standard, general-purpose languages and organizedas a coordination graph.We propose Streaming Concurrent Collections (SCnC), a streaming system that can efficiently run a subset of programs supported by Concurrent Collections (CnC). CnC is a general purpose parallel programming paradigm with a task-parallel look and feel but based on dataflow graph principles. Its expressiveness extends to any arbitrary task graph. Integration of these models would allow application developers to benefit from the performance and tight memory footprint of stream parallelism for eligible subgraphs of their application.In this paper we formally define the requirements (streaming access patterns) needed for using SCnC, and outline a static decision procedure for identifying and processing eligible SCnC subgraphs.We present initial results on an prototype implementation that show that transitioning from general CnC to SCnC leads to a throughput increase of up to 40x for certain benchmarks, and also enable programs with large data sizes to execute in available memory for cases where CnC execution may run out of memory.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Sbirlea, Dragos and Shirako, Jun and Newton, Ryan and Sarkar, Vivek",2011,2011 First Workshop on Data-Flow Execution Models for Extreme Scale Computing,10.1109/DFM.2011.13,ieee3-search1.bib
5158431,REMO: Resource-Aware Application State Monitoring for Large-Scale Distributed Systems,"To observe, analyze and control large scale distributed systems and the applications hosted on them, there is an increasing need to continuously monitor performance attributes of distributed system and application states. This results in application state monitoring tasks that require fine-grained attribute information to be collected from relevant nodes efficiently. Existing approaches either treat multiple application state monitoring tasks independently and build ad-hoc monitoring trees for each task, or construct a single static monitoring tree for multiple tasks. We argue that a careful planning of multiple application state monitoring tasks by jointly considering multi-task optimization and node level resource constraints can provide significant gains in performance and scalability. In this paper, we present REMO, a REsource-aware application state MOnitoring system. REMO produces a forest of optimized monitoring trees through iterations of two phases, one phase exploring cost sharing opportunities via estimation and the other refining the monitoring plan through resource-sensitive tree construction. Our experimental results include those gathered by deploying REMO on a BlueGene/P rack running IBM's large-scale distributed streaming system - System S. Using REMO running over 200 monitoring tasks for an application deployed across 200 nodes results in a 35%-45% decrease in the percentage error of collected attributes compared to existing schemes.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Meng, Shicong and Kashyap, Srinivas and Venkatramani, Chitra and Liu, Ling",2009,2009 29th IEEE International Conference on Distributed Computing Systems,10.1109/ICDCS.2009.15,ieee3-search1.bib
5729398,Maximizing video quality for several unicast streams in a multipath overlay network,"A streaming system that uses an overlay network for multipath streaming needs to make decisions concerning the distribution of the available bandwidth among all of its clients. This decision making should aim at delivering the best possible quality to all clients while providing an optimal utilization of the network resources. We consider a scenario where videos are hierarchically layered-encoded and most requests are negligibly overlapped in time. It implies that using multicast is not efficient, and instead, the streams are striped and allocated to multiple paths from the server to the client. To evaluate how well the rate-allocation algorithms approach optimality, we have earlier built a benchmarking system that provides the optimal solution for assigning available bandwidth to delivery paths. However, as video quality is not linearly related to bitrate, the trivial maximization of the total consumed bandwidth does not necessarily maximize the video quality. To address this problem, we define a metric that assesses video quality for a group of clients that we use as a utility function in the revised benchmarking system. Due to its concavity, this utility function distributes the bandwidth resources proportionally fair between the clients of the system.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Boudko, Svetlana and Leister, Wolfgang and Griwodz, Carsten and Halvorsen, Pål",2010,2010 IEEE 4th International Conference on Internet Multimedia Services Architecture and Application,10.1109/IMSAA.2010.5729398,ieee3-search1.bib
5425308,Scalability and Peer Churning in IP-TV: An Analytical Insight,"Abstract-Peer-to-peer (P2P) technology for TV broadcasting over the Internet is becoming more and more popular in the very last years. This paper introduces a network-wide metric to assess the efficiency of P2P streaming systems and develops a mathematical model to explain: (i) the scalability of such architectures with the number of peers, as evidenced by recent measurements; (ii) the initial decrement of efficiency (hence, quality) when a sharp increase in the number of peers in system occurs, as reported by experimental data. As for the second point, the proposed model builds upon the fundamental remark that when a peer first joins the system, it has no video content to share with others: its upload contribution is null for an initial time interval and the new peer behaves as a free rider. Three situations concerning the system reaction to the requests of the new entering peers are examined: full compensation; partial compensation; no reaction at all. Depending on the system answer and on its extent, system efficiency is shown to exhibit different time trends.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Merani, M. and Leonardi, G. and Saladino, D.",2009,GLOBECOM 2009 - 2009 IEEE Global Telecommunications Conference,10.1109/GLOCOM.2009.5425308,ieee3-search1.bib
8113470,Dynamic Chameleon Authentication Tree for Verifiable Data Streaming in 5G Networks,"Chameleon authentication tree (CAT) is an important authenticated data structure for verifiable data streaming in 5G networks. But the typical CAT cannot support the dynamic scenario very well because it cannot expend freely since its height is fixed. Therefore, we proposed a dynamic CAT (DCAT) with the feature of adaptive expansion. We divided the algorithms of the DCAT with the following phases: setup, append, query, and verification. The DCAT removes the drawbacks of the static CAT. In the setup phase, it is not required for the scale of the tree to be determined, and the scale of the tree can be adaptively expanded during the data-appending phase. Therefore, the DCAT can suit the data stream environment better. During the data querying phase, the average authentication path length has been reduced, which leads to less space requirement and better verification efficiency. Finally, we performed theoretical analysis and drew a comparison between the static CAT and the DCAT in terms of performance. The result indicates that the DCAT provides improvements in the performance of the data-appending, data-querying, and data verification processes.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Xu, Jian and Li, Fuxiang and Chen, Ke and Zhou, Fucai and Choi, Junho and Shin, Juhyun",2017,IEEE Access,10.1109/ACCESS.2017.2771281,ieee3-search1.bib
9751185,Hardware-Efficient Deconvolution-Based GAN for Edge Computing,"Generative Adversarial Networks (GAN) are cutting-edge algorithms for generating new data samples based on the learned data distribution. However, its performance comes at a significant cost in terms of computation and memory requirements. In this paper, we proposed an HW/SW co-design approach for training quantized deconvolution GAN (QDCGAN) implemented on FPGA using a scalable streaming dataflow architecture capable of achieving higher throughput versus resource utilization trade-off. The developed accelerator is based on an efficient deconvolution engine that offers high parallelism with respect to scaling factors for GAN-based edge computing. Furthermore, various precisions, datasets, and network scalability were analyzed for low-power inference on resource-constrained platforms. Lastly, an end-to-end open-source framework is provided for training, implementation, state-space exploration, and scaling the inference using Vivado high-level synthesis for Xilinx SoC-FPGAs, and a comparison testbed with Jetson Nano.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Alhussain, Azzam and Lin, Mingjie",2022,2022 56th Annual Conference on Information Sciences and Systems (CISS),10.1109/CISS53076.2022.9751185,ieee3-search1.bib
5462030,UUSee: Large-Scale Operational On-Demand Streaming with Random Network Coding,"Since the inception of network coding in information theory, we have witnessed a sharp increase of research interest in its applications in communications and networking, where the focus has been on more practical aspects. However, thus far, network coding has not been deployed in real-world commercial systems in operation at a large scale, and in a production setting. In this paper, we present the objectives, rationale, and design in the first production deployment of random network coding, where it has been used in the past year as the cornerstone of a large-scale production on-demand streaming system, operated by UUSee Inc., delivering thousands of on-demand video channels to millions of unique visitors each month. To achieve a thorough understanding of the performance of network coding, we have collected 200 Gigabytes worth of real-world traces throughout the 17-day Summer Olympic Games in August 2008, and present our lessons learned after an in-depth trace-driven analysis.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Liu, Zimu and Wu, Chuan and Li, Baochun and Zhao, Shuqiao",2010,2010 Proceedings IEEE INFOCOM,10.1109/INFCOM.2010.5462030,ieee3-search1.bib
5684743,Scalable video transmission over multiuser MIMO-OFDM systems,"With the proliferation of wireless services, multimedia interactivities are quickly becoming ubiquitous. As multimedia traffics generally have large packets volume, high data rate requirements in wireless transmission are critical. Next generation wireless systems, e.g., multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM), provide high throughput and support flexible resource management strategies for multimedia services. By fully exploiting spatial, temporal, and frequency diversities of MIMO-OFDM systems, intelligent resource allocation schemes can increase the overall performance of the multimedia streaming system significantly. In this paper, we describe a general framework of cross-layer resource allocation design for scalable video transmission over multiuser MIMO-OFDM systems. Scalable video coding provides an efficient solution for video adaptation to satisfy diverse requirements from heterogeneous mobile clients according to their system specifications and channel conditions. Generally, the base layer of a scalable video bitstream is more important than the enhancement layer as the enhancement layer can only be used for decoding if the base layer is available. Scalable video packets are entitled with different priorities in video reconstructions. Adaptation can be achieved by discarding some enhancement layer packets when network is congested. Based on the characteristics of scalable video, our objective is to optimize the overall system performance for multiple scalable video downlink over the Space Division Multiple Access (SDMA)-OFDM system from a multiple-antenna base station. Our cross-layer optimization is achieved by jointly linking packet prioritization from application layer and radio resource allocation at the physical layer. Based on packet priority of scalable video, time-frequency resource, power and modulation schemes are adaptively selected based on a prioritized water filling algorithm to maximize the overall system performance and to ensure fairness among different users. The performance of the proposed strategy is demonstrated by experimental comparisons with conventional radio resource allocation schemes.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Li, Maodong and Chen, Zhenzhong and Tan, Yap-Peng",2010,2010 5th International ICST Conference on Communications and Networking in China,,ieee3-search1.bib
5062193,Keep Cache Replacement Simple in Peer-Assisted VoD Systems,"Peer-assisted Video-on-Demand (VoD) systems have not only received substantial recent research attention, but also been implemented and deployed with success in large-scale real- world streaming systems, such as PPLive. Peer-assisted Video- on-Demand systems are designed to take full advantage of peer upload bandwidth contributions with a cache on each peer. Since the size of such a cache on each peer is limited, it is imperative that an appropriate cache replacement algorithm is designed. There exists a tremendous level of flexibility in the design space of such cache replacement algorithms, including the simplest alternatives such as Least Recently Used (LRU). Which algorithm is the best to minimize server bandwidth costs, so that when peers need a media segment, it is most likely available from caches of other peers? Such a question, however, is arguably non-trivial to answer, as both the demand and supply of media segments are stochastic in nature. In this paper, we seek to construct an analytical framework based on optimal control theory and dynamic programming, to help us form an in-depth understanding of optimal strategies to design cache replacement algorithms. With such analytical insights, we have shown with extensive simulations that, the performance margin enjoyed by optimal strategies over the simplest algorithms is not substantial, when it comes to reducing server bandwidth costs. In most cases, the simplest choices are good enough as cache replacement algorithms in peer-assisted VoD systems.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Wu, J. and Li, B.",2009,IEEE INFOCOM 2009,10.1109/INFCOM.2009.5062193,ieee3-search1.bib
7727557,Benchmarking a coevolutionary streaming classifier under the individual household electric power consumption dataset,"The application of genetic programming (GP) to streaming data analysis appears, on the face of it, to be a less than obvious choice. If nothing else, the (perceived) computational cost of model building under GP would preclude its application to tasks with non-stationary properties. Conversely, there is a rich history of applying GP to various tasks associated with trading agent design for currency and stock markets. In this work, we investigate the utility of a coevolutionary framework originally proposed for trading agent design to the related streaming data task of predicting individual household electric power consumption. In addition, we address several benchmarking issues, such as effective preprocessing of stream data using a candlestick representation originally developed for financial market analysis, and quantification of performance using a novel `area under the curve' style metric for streaming data. The computational cost of evolving GP solutions is demonstrated to be suitable for real-time operation under this task and shown to provide classification performance competitive with current established methods for streaming data classification. Finally, we note that the individual household electric power consumption dataset is more flexible than the more widely used electricity utility prediction dataset, because it supports benchmarking at multiple temporal time scales.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Loginov, Alexander and Heywood, Malcolm and Wilson, Garnett",2016,2016 International Joint Conference on Neural Networks (IJCNN),10.1109/IJCNN.2016.7727557,ieee3-search1.bib
9671517,A Scalable Linear-Time Algorithm for Horizontal Visibility Graph Construction Over Long Sequences,"The horizontal visibility graph (HVG) representation of a time series is a structured graph whose connectivity properties have been used to study the dynamics of a wide range of nonlinear systems. Applications range from the brain (EEG), the heart (ECG) and the financial markets (bid prices), to the sun (solar intensity readings) and river flows. HVGs have also been extended to image-based pattern recognition. Efficient and scalable online HVG construction is vital to extending HVG-based time series analysis to long, streaming, and distributed real-world time series data.The fastest scalable method for constructing HVGs today is the binary search tree (BST) encoding–decoding algorithm, which is O(n log n) in time series length for balanced data such as noise. However, in practice BST is highly sensitive to the geometric structure of a time series and its performance degrades significantly towards O(n2) when data possess long term dependencies or when the sample frequency is high, which occur regularly in practice. To avoid these problems we leverage an O(n) ordered rooted tree representation of time series that is (graph) dual to the HVG. We demonstrate that this representation leads to an algorithm for HVG construction that is agnostic with respect to the geometry and auto-correlations of the underlying data. Moreover, it possesses an efficient branch fusion operation for tree merging, leading to the idea of a bipartite HVG introduced in this paper, which allows HVGs for very large time series to be constructed efficiently in parallel.After introducing our method and algorithms for parallel construction of HVGs we report on experimental benchmarks comparing their real-world performance to existing approaches on long time series. On data sampled from fractional Brownian motions, deterministic chaotic systems, brain EEG recordings, and the financial markets, our dual tree algorithms significantly outperform previous methods.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Stephen, and Colin,",2021,2021 IEEE International Conference on Big Data (Big Data),10.1109/BigData52589.2021.9671517,ieee3-search1.bib
10.1145/1071690.1064221,A Data Streaming Algorithm for Estimating Subpopulation Flow Size Distribution,"Statistical information about the flow sizes in the traffic passing through a network link helps a network operator to characterize network resource usage, infer traffic demands, detect traffic anomalies, and improve network performance through traffic engineering. Previous work on estimating the flow size distribution for the complete population of flows has produced techniques that either make inferences from sampled network traffic, or use data streaming approaches. In this work, we identify and solve a more challenging problem of estimating the size distribution and other statistical information about arbitrary subpopulations of flows. Inferring subpopulation flow statistics is more challenging than the complete population counterpart, since subpopulations of interest are often specified a posteriori (i.e., after the data collection is done), making it impossible for the data collection module to ""plan in advance"".Our solution consists of a novel mechanism that combines data streaming with traditional packet sampling to provide highly accurate estimates of subpopulation flow statistics. The algorithm employs two data collection modules operating in parallel --- a NetFlow-like packet sampler and a streaming data structure made up of an array of counters. Combining the data collected by these two modules, our estimation algorithm uses a statistical estimation procedure that correlates and decodes the outputs (observations) from both data collection modules to obtain flow statistics for any arbitrary subpopulation. Evaluations of this algorithm on real-world Internet traffic traces demonstrate its high measurement accuracy.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Kumar, Abhishek and Sung, Minho and Xu, Jun and Zegura, Ellen",2005,SIGMETRICS Perform. Eval. Rev.,10.1145/1071690.1064221,acm1-search1.bib;acm1-search1.bib
10.1145/1140103.1140295,Data Streaming Algorithms for Estimating Entropy of Network Traffic,"Using entropy of traffic distributions has been shown to aid a wide variety of network monitoring applications such as anomaly detection, clustering to reveal interesting patterns, and traffic classification. However, realizing this potential benefit in practice requires accurate algorithms that can operate on high-speed links, with low CPU and memory requirements. In this paper, we investigate the problem of estimating the entropy in a streaming computation model. We give lower bounds for this problem, showing that neither approximation nor randomization alone will let us compute the entropy efficiently. We present two algorithms for randomly approximating the entropy in a time and space efficient manner, applicable for use on very high speed (greater than OC-48) links. The first algorithm for entropy estimation is inspired by the structural similarity with the seminal work of Alon et al. for estimating frequency moments, and we provide strong theoretical guarantees on the error and resource usage. Our second algorithm utilizes the observation that the performance of the streaming algorithm can be enhanced by separating the high-frequency items (or elephants) from the low-frequency items (or mice). We evaluate our algorithms on traffic traces from different deployment scenarios.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Lall, Ashwin and Sekar, Vyas and Ogihara, Mitsunori and Xu, Jun and Zhang, Hui",2006,SIGMETRICS Perform. Eval. Rev.,10.1145/1140103.1140295,acm1-search1.bib;acm1-search1.bib;scholar.bib
10.1145/1140103.1140328,A Multicommodity Flow Model for Distributed Stream Processing,,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Broberg, James and Liu, Zhen and Xia, Cathy and Zhang, Li",2006,SIGMETRICS Perform. Eval. Rev.,10.1145/1140103.1140328,acm1-search1.bib;acm1-search1.bib
10.1145/2796314.2745882,Scheduling Storms and Streams in the Cloud,"Motivated by emerging big streaming data processing paradigms (e.g., Twitter Storm, Streaming MapReduce), we investigate the problem of scheduling graphs over a large cluster of servers. Each graph is a job, where nodes represent compute tasks and edges indicate data-flows between these compute tasks. Jobs (graphs) arrive randomly over time, and upon completion, leave the system. When a job arrives, the scheduler needs to partition the graph and distribute it over the servers to satisfy load balancing and cost considerations. Specifically, neighboring compute tasks in the graph that are mapped to different servers incur load on the network; thus a mapping of the jobs among the servers incurs a cost that is proportional to the number of ""broken edges''. We propose a low complexity randomized scheduling algorithm that, without service preemptions, stabilizes the system with graph arrivals/departures; more importantly, it allows a smooth trade-off between minimizing average partitioning cost and average queue lengths. Interestingly, to avoid service preemptions, our approach does not rely on a Gibbs sampler; instead, we show that the corresponding limiting invariant measure has an interpretation stemming from a loss system.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Ghaderi, Javad and Shakkottai, Sanjay and Srikant, Rayadurgam",2015,SIGMETRICS Perform. Eval. Rev.,10.1145/2796314.2745882,acm1-search1.bib;acm1-search1.bib;acm2-search1.bib
10.1145/1379272.1379282,Optimizing Away Joins on Data Streams,"Monitoring aggregates on network traffic streams is a compelling application of data stream management systems. Often, streaming aggregation queries involve joining multiple inputs (e.g., client requests and server responses) using temporal join conditions (e.g., within 5 seconds), followed by computation of aggregates (e.g., COUNT) over temporal windows (e.g., every 5 minutes). These types of queries help identify malfunctioning servers (missing responses), malicious clients (bursts of requests during a denial-of-service attack), or improperly configured protocols (short timeout intervals causing many retransmissions). However, while such query expression is natural, its evaluation over massive data streams is inefficient.In this paper, we develop rewriting techniques for streaming aggregation queries that join multiple inputs. Our techniques identify conditions under which expensive joins can be optimized away, while providing error bounds for the results of the rewritten queries. The basis of the optimization is a powerful but decidable theory in which constraints over data streams can be formulated. We show the efficiency and accuracy of our solutions via experimental evaluation on real-life IP network data using the Gigascope stream processing engine.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Golab, Lukasz and Johnson, Theodore and Koudas, Nick and Srivastava, Divesh and Toman, David",2008,Proceedings of the 2nd International Workshop on Scalable Stream Processing System,10.1145/1379272.1379282,acm1-search1.bib
10.1145/1012888.1005709,Data Streaming Algorithms for Efficient and Accurate Estimation of Flow Size Distribution,"Knowing the distribution of the sizes of traffic flows passing through a network link helps a network operator to characterize network resource usage, infer traffic demands, detect traffic anomalies, and accommodate new traffic demands through better traffic engineering. Previous work on estimating the flow size distribution has been focused on making inferences from sampled network traffic. Its accuracy is limited by the (typically) low sampling rate required to make the sampling operation affordable. In this paper we present a novel data streaming algorithm to provide much more accurate estimates of flow distribution, using a ""lossy data structure"" which consists of an array of counters fitted well into SRAM. For each incoming packet, our algorithm only needs to increment one underlying counter, making the algorithm fast enough even for 40 Gbps (OC-768) links. The data structure is lossy in the sense that sizes of multiple flows may collide into the same counter. Our algorithm uses Bayesian statistical methods such as Expectation Maximization to infer the most likely flow size distribution that results in the observed counter values after collision. Evaluations of this algorithm on large Internet traces obtained from several sources (including a tier-1 ISP) demonstrate that it has very high measurement accuracy (within 2%). Our algorithm not only dramatically improves the accuracy of flow distribution measurement, but also contributes to the field of data streaming by formalizing an existing methodology and applying it to the context of estimating the flow-distribution.",FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Kumar, Abhishek and Sung, Minho and Xu, Jun and Wang, Jia",2004,SIGMETRICS Perform. Eval. Rev.,10.1145/1012888.1005709,acm1-search1.bib;acm1-search1.bib
10.1145/3093742.3093902,A New Application Benchmark for Data Stream Processing Architectures in an Enterprise Context: Doctoral Symposium,"Against the backdrop of ever-growing data volumes and trends like the Internet of Things (IoT) or Industry 4.0, Data Stream Processing Systems (DSPSs) or data stream processing architectures in general receive a greater interest. Continuously analyzing streams of data allows immediate responses to environmental changes. A challenging task in that context is assessing and comparing data stream processing architectures in order to identify the most suitable one for certain settings.The present paper provides an overview about performance benchmarks that can be used for analyzing data stream processing applications. By describing shortcomings of these benchmarks, the need for a new application benchmark in this area, especially for a benchmark covering enterprise architectures, is highlighted. A key role in such an enterprise context is the combination of streaming data and business data, which is barely covered in current data stream processing benchmarks. Furthermore, first ideas towards the development of a solution, i.e., a new application benchmark that is able to fill the existing gap, are depicted.",FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,UNCERTAIN,EXCLUDED,look for new results,"Hesse, Guenter and Matthies, Christoph and Reissaus, Benjamin and Uflacker, Matthias",2017,Proceedings of the 11th ACM International Conference on Distributed and Event-Based Systems,10.1145/3093742.3093902,acm1-search1.bib
10.1145/2675743.2776763,The PipeFlow Approach,"In this paper, we present a description of our solution for solving the DEBS Grand Challenge 2015 that targets the analysis of taxi trips. Our implementation of this challenge is based on a general-purpose stream processing system called PipeFlow, which is designed and implemented to efficiently process continuous queries over high volume/speed data streams with low latency. Moreover, we present an experimental evaluation to show the effectiveness of the proposed solution with respect to query throughput and latency.",FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Saleh, Omran and Sattler, Kai-Uwe",2015,Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems,10.1145/2675743.2776763,acm1-search1.bib
10.1145/3465480.3467844,Web Stream Processing with RSP4J,"Social Media Analysis, Internet of Things, and Fake News detection have unveiled the relevance of real-time analytics on the Web. As a consequence, the Web infrastructure is evolving to enable continuous and reactive data access. Since data streams available on the Web originate from a variety of sources, they are highly heterogeneous. Indeed, addressing data variety and velocity simultaneously is inevitable. Stream Reasoning is the research field that studies how to combine data integration techniques with stream processing technologies. In particular, solutions for RDF Stream Processing (RSP) combine stream processing notions with data integration standards. This tutorial paper presents RSP4J, a innovative API that aims at fostering the adoption of RSP by simplifying the usage, benchmarking, and fast prototyping of Web Stream Processing applications.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Tommasini, Riccardo and Bonte, Pieter",2021,Proceedings of the 15th ACM International Conference on Distributed and Event-Based Systems,10.1145/3465480.3467844,acm1-search1.bib
10.1145/2488222.2488255,Dynamic Expressivity with Static Optimization for Streaming Languages,"Developers increasingly use streaming languages to write applications that process large volumes of data with high throughput. Unfortunately, when picking which streaming language to use, they face a difficult choice. On the one hand, dynamically scheduled languages allow developers to write a wider range of applications, but cannot take advantage of many crucial optimizations. On the other hand, statically scheduled languages are extremely performant, but have difficulty expressing many important streaming applications.This paper presents the design of a hybrid scheduler for stream processing languages. The compiler partitions the streaming application into coarse-grained subgraphs separated by dynamic rate boundaries. It then applies static optimizations to those subgraphs. We have implemented this scheduler as an extension to the StreamIt compiler. To evaluate its performance, we compare it to three scheduling techniques used by dynamic systems (OS thread, demand, and no-op) on a combination of micro-benchmarks and real-world inspired synthetic benchmarks. Our scheduler not only allows the previously static version of StreamIt to run dynamic rate applications, but it outperforms the three dynamic alternatives. This demonstrates that our scheduler strikes the right balance between expressivity and performance for stream processing languages.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Soul\'{e}, Robert and Gordon, Michael and Amarasinghe, Saman and Grimm, Robert and Hirzel, Martin",2013,Proceedings of the 7th ACM International Conference on Distributed Event-Based Systems,10.1145/2488222.2488255,acm1-search1.bib
10.1145/3401025.3401732,Leaving Stragglers at the Window: Low-Latency Stream Sampling with Accuracy Guarantees,"Stream Processing Engines (SPEs) are used to process large volumes of application data to emit high velocity output. Under high load, SPEs aim to minimize output latency by leveraging sample processing for many applications that can tolerate approximate results. Sample processing limits input to only a subset of events such that the sample is statistically representative of the input while ensuring output accuracy guarantees. For queries containing window operators, sample processing continuously samples events until all events relevant to the window operator have been ingested. However, events can suffer from large ingestion delays due to long or bursty network latencies. This leads to stragglers that are events generated within the window's timeline but are delayed beyond the window's deadline. Window computations that account for stragglers can add significant latency while providing inconsequential accuracy improvement. We propose Aion, an algorithm that utilizes sampling to provide approximate answers with low latency by minimizing the effect of stragglers. Aion quickly processes the window to minimize output latency while still achieving high accuracy guarantees. We implement Aion in Apache Flink and show using benchmark workloads that Aion reduces stream output latency by up to 85% while providing 95% accuracy guarantees.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Farhat, Omar and Bindra, Harsh and Daudjee, Khuzaima",2020,Proceedings of the 14th ACM International Conference on Distributed and Event-Based Systems,10.1145/3401025.3401732,acm1-search1.bib
10.1145/1385989.1386014,"WebLogic Event Server: A Lightweight, Modular Application Server for Event Processing","This paper describes WebLogic Event Server (WL EvS), an application server designed for hosting event-driven applications that require low latency and deterministic behavior. WL EvS is based on a modular architecture in which both server components and applications are represented as modules. The application programming model supports applications that are a mixture of reusable Java components and EPL (Event Processing Language), a query language that extends SQL with stream processing capabilities. WL EvS applications are meta-data driven, in that application behavior can be changed without recompilation or redeploying an application. The paper also presents the results of a benchmark performance study. The results show that the approach used by WL EvS can handle extremely high volumes of events while providing deterministic latency.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"White, Seth and Alves, Alexandre and Rorke, David",2008,Proceedings of the Second International Conference on Distributed Event-Based Systems,10.1145/1385989.1386014,acm1-search1.bib
10.1145/3571158,SDN-Enabled Resource Provisioning Framework for Geo-Distributed Streaming Analytics,"Geographically distributed (geo-distributed) datacenters for stream data processing typically comprise multiple edges and core datacenters connected through Wide-Area Network (WAN) with a master node responsible for allocating tasks to worker nodes. Since WAN links significantly impact the performance of distributed task execution, the existing task assignment approach is unsuitable for distributed stream data processing with low latency and high throughput demand. In this paper, we propose a resource provisioning framework using the Software-Defined Networking (SDN) concept with an SDN controller responsible for monitoring the WAN, selecting an appropriate subset of worker nodes, and assigning tasks to the designated worker nodes. We implemented the data plane of the framework in P4 and the control plane components in Python. We tested the performance of the proposed system on Apache Spark, Apache Storm, and Apache Flink using the Yahoo! streaming benchmark on a set of custom topologies. The results of the experiments validate that the proposed approach is viable for distributed stream processing and confirm that it can improve at least 1.64x the processing time of incoming events of the current stream processing systems.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Mostafaei, Habib and Afridi, Shafi",2022,ACM Trans. Internet Technol.,10.1145/3571158,acm1-search1.bib
10.1145/2955193.2955206,New Techniques to Curtail the Tail Latency in Stream Processing Systems,"This paper presents a series of novel techniques for reducing the tail latency in stream processing systems like Apache Storm. Concretely, we present three mechanisms: (1) adaptive timeout coupled with selective replay to catch straggler tuples; (2) shared queues among different tasks of the same operator to reduce overall queueing delay; (3) latency feedback-based load balancing, intended to mitigate heterogenous scenarios. We have implemented these techniques in Apache Storm, and present experimental results using sets of micro-benchmarks as well as two topologies from Yahoo! Inc. Our results show improvement in tail latency up to 72.9%.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Du, Guangxiang and Gupta, Indranil",2016,Proceedings of the 4th Workshop on Distributed Cloud Computing,10.1145/2955193.2955206,acm1-search1.bib
10.1145/3410048.3410060,Staleness Control for Edge Data Analytics,"A new generation of cyber-physical systems has emerged with a large number of devices that continuously generate and consume massive amounts of data in a distributed and mobile manner. Accurate and near real-time decisions based on such streaming data are in high demand in many areas of optimization for such systems. Edge data analytics bring processing power in the proximity of data sources, reduce the network delay for data transmission, allowlargescale distributed training, and consequently help meeting real-time requirements. Nevertheless, the multiplicity of data sources leads to multiple distributed machine learning models that may suffer from sub-optimal performance due to the inconsistency in their states. In this work, we tackle the insularity, concept drift, and connectivity issues in edge data analytics to minimize its accuracy handicap without losing its timeliness benefits. Thus, we propose an efficient model synchronization mechanism for distributed and stateful data analytics. Staleness Control for Edge Data Analytics (SCEDA) ensures the high adaptability of synchronization frequency in the face of an unpredictable environment by addressing the trade-off between the generality and timeliness of the model.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Aral, Atakan and Erol-Kantarci, Melike and Brandi\'{c}, Ivona",2020,SIGMETRICS Perform. Eval. Rev.,10.1145/3410048.3410060,acm1-search1.bib
10.1145/1384529.1375493,Performance Bounds for Peer-Assisted Live Streaming,"Peer-assisted streaming is a promising way for service providers to offer high-quality IPTV to consumers at reasonable cost. In peer-assisted streaming, the peers exchange video chunks with one another, and receive additional data from the central server as needed. In this paper, we analyze how to provision resources for the streaming system, in terms of the server capacity, the video quality, and the depth of the distribution trees that deliver the content. We derive the performance bounds for minimum server load, maximum streaming rate, and minimum tree depth under different peer selection constraints. Furthermore, we show that our performance bounds are actually tight, by presenting algorithms for constructing trees that achieve our bounds.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Liu, Shao and Zhang-Shen, Rui and Jiang, Wenjie and Rexford, Jennifer and Chiang, Mung",2008,SIGMETRICS Perform. Eval. Rev.,10.1145/1384529.1375493,acm1-search1.bib;acm1-search1.bib
10.1145/1639562.1639596,A Distributed Data Streaming Algorithm for Network-Wide Traffic Anomaly Detection,"Nowadays, Internet has serious security problems and network failures that are hard to resolve, for example, botnet attacks, polymorphic worm/virus spreading, DDoS, and flash crowds. To address many of these problems, we need to have a network-wide view of the traffic dynamics, and more importantly, be able to detect traffic anomaly in a timely manner. To our knowledge, Principle Component Analysis (PCA)is the best-known spatial detection method for the network-wide traffic anomaly. However, existing PCA-based solutions have scalability problems in that they require O(m2 n)running time and O(mn)space to analyze traffic measurements from m aggregated traffic flows within a sliding window of the length n. We propose a novel data streaming algorithm for PCA-based network-wide traffic anomaly detection in a distributed fashion. Our algorithm can archive O(wn log n)running time and O(wn)space at local monitors,and O(m2 log n)running time and O(m log n) space at Network Operation Center (NOC), where w denotes the maximum number of traffic flows at a local monitor.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Liu, Yang and Zhang, Linfeng and Guan, Yong",2009,SIGMETRICS Perform. Eval. Rev.,10.1145/1639562.1639596,acm1-search1.bib;scholar.bib
10.1145/2933267.2933300,RFID-Based Logistics Monitoring with Semantics-Driven Event Processing,"In this paper a real-life counterfeit and theft detection scenario from pharmaceutical manufacturing is modelled using events encoded as XML and RDF. With Esper and Instans event processing platforms, the second one from the semantic web domain, the same task is configured and an experimental performance evaluation is carried out. Our results show that even though the starting points are very different, the same core task can be accomplished on both platforms. We provide quantitative performance comparisons that corroborate our analysis. For an understanding of what can be expected from each framework outside the core task, the differences between the two tools and their respective domains are qualitatively analysed.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Rinne, Mikko and Solanki, Monika and Nuutila, Esko",2016,Proceedings of the 10th ACM International Conference on Distributed and Event-Based Systems,10.1145/2933267.2933300,acm1-search1.bib
10.1145/3319498,Production Application Performance Data Streaming for System Monitoring,"In this article, we present an approach to streaming collection of application performance data. Practical application performance tuning and troubleshooting in production high-performance computing (HPC) environments requires an understanding of how applications interact with the platform, including (but not limited to) parallel programming libraries such as Message Passing Interface (MPI). Several profiling and tracing tools exist that collect heavy runtime data traces either in memory (released only at application exit) or on a file system (imposing an I/O load that may interfere with the performance being measured). Although these approaches are beneficial in development stages and post-run analysis, a systemwide and low-overhead method is required to monitor deployed applications continuously. This method must be able to collect information at both the application and system levels to yield a complete performance picture.In our approach, an application profiler collects application event counters. A sampler uses an efficient inter-process communication method to periodically extract the application counters and stream them into an infrastructure for performance data collection. We implement a tool-set based on our approach and integrate it with the Lightweight Distributed Metric Service (LDMS) system, a monitoring system used on large-scale computational platforms. LDMS provides the infrastructure to create and gather streams of performance data in a low overhead manner. We demonstrate our approach using applications implemented with MPI, as it is one of the most common standards for the development of large-scale scientific applications.We utilize our tool-set to study the impact of our approach on an open source HPC application, Nalu. Our tool-set enables us to efficiently identify patterns in the behavior of the application without source-level knowledge. We leverage LDMS to collect system-level performance data and explore the correlation between the system and application events. Also, we demonstrate how our tool-set can help detect anomalies with a low latency. We run tests on two different architectures: a system enabled with Intel Xeon Phi and another system equipped with Intel Xeon processor. Our overhead study shows our method imposes at most 0.5% CPU usage overhead on the application in realistic deployment scenarios.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Izadpanah, Ramin and Allan, Benjamin and Dechev, Damian and Brandt, Jim",2019,ACM Trans. Model. Perform. Eval. Comput. Syst.,10.1145/3319498,acm2-search1.bib;scholar.bib
10.1145/2933267.2933516,Experience of Event Stream Processing for Top-k Queries and Dynamic Graphs,"Solving 2016 ACM DEBS Grand Challenge problems entails both dynamic graph processing and top-k query processing. A straightforward implementation of solutions would not guarantee good performance or prompt responses. This paper shows our experience in implementing solutions of the problems, including rationales of top-k list management techniques we used in our implementation. We also shows the performance evaluation results among three top-k list management schemes and present the reason for our choice for the final result.",FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Choi, Joong-Hyun and Lee, Kang-Woo and Cho, Eun-Sun",2016,Proceedings of the 10th ACM International Conference on Distributed and Event-Based Systems,10.1145/2933267.2933516,acm2-search1.bib
10.1145/3401025.3402684,The DEBS 2020 Grand Challenge,"The ACM DEBS 2020 Grand Challenge is the tenth in a series of challenges which seek to provide a common ground and evaluation criteria for a competition aimed at both research and industrial event-based systems. The focus of the ACM DEBS 2020 Grand Challenge is on Non-Intrusive Load Monitoring (NILM). The goal of the challenge is to detect when appliances contributing to an aggregated stream of voltage and current readings from a smart meter are switched on or off. NILM is leveraged in many contexts, ranging from monitoring of energy consumption to home automation. This paper describes the specifics of the data streams provided in the challenge, as well as the benchmarking platform that supports the testing of the solutions submitted by the participants.",FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Gulisano, Vincenzo and Jorde, Daniel and Mayer, Ruben and Najdataei, Hannaneh and Palyvos-Giannas, Dimitris",2020,Proceedings of the 14th ACM International Conference on Distributed and Event-Based Systems,10.1145/3401025.3402684,acm2-search1.bib
10.1145/3524860.3539645,Detecting Trading Trends in Financial Tick Data: The DEBS 2022 Grand Challenge,"The DEBS Grand Challenge (GC) is an annual programming competition open to practitioners from both academia and industry. The GC 2022 edition focuses on real-time complex event processing of high-volume tick data provided by Infront Financial Technology GmbH. The goal of the challenge is to efficiently compute specific trend indicators and detect patterns in these indicators like those used by real-life traders to decide on buying or selling in financial markets. The data set Trading Data used for benchmarking contains 289 million tick events from approximately 5500+ financial instruments that had been traded on the three major exchanges Amsterdam (NL), Paris (FR), and Frankfurt am Main (GER) over the course of a full week in 2021. The data set is made publicly available. In addition to correctness and performance, submissions must explicitly focus on reusability and practicability. Hence, participants must address specific nonfunctional requirements and are asked to build upon open-source platforms. This paper describes the required scenario and the data set Trading Data, defines the queries of the problem statement, and explains the enhancements made to the evaluation platform Challenger that handles data distribution, dynamic subscriptions, and remote evaluation of the submissions.",FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Frischbier, Sebastian and Tahir, Jawad and Doblander, Christoph and Hormann, Arne and Mayer, Ruben and Jacobsen, Hans-Arno",2022,Proceedings of the 16th ACM International Conference on Distributed and Event-Based Systems,10.1145/3524860.3539645,acm2-search1.bib
10.1145/2931028.2931033,ActorX10: An Actor Library for X10,"The APGAS programming model is a powerful computing paradigm for multi-core and massively parallel computer architectures. It allows for the dynamic creation and distribution of thousands of threads amongst hundreds of nodes in a cluster computer within a single application. For programs of such a complexity, appropriate higher level abstractions on computation and communication are necessary for performance analysis and optimization. In this work, we present actorX10, an X10 library of a formally specified actor model based on the APGAS principles. The realized actor model explicitly exposes communication paths and decouples these from the control flow of the concurrently executed application components. Our approach provides the right abstraction for a wide range of applications. Its capabilities and advantages are introduced and demonstrated for two applications from the embedded system and HPC domain, i.e., an object detection chain and a proxy application for the simulation of tsunami events.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Roloff, Sascha and P\""{o}ppl, Alexander and Schwarzer, Tobias and Wildermann, Stefan and Bader, Michael and Gla\ss{}, Michael and Hannig, Frank and Teich, J\""{u}rgen",2016,Proceedings of the 6th ACM SIGPLAN Workshop on X10,10.1145/2931028.2931033,acm2-search1.bib
10.1145/3093742.3093911,Hardware Accelerated Application Integration Processing: Industry Paper,"The growing number of (cloud) applications and devices massively increases the communication rate and volume pushing integration systems to their (throughput) limits. While the usage of modern hardware like Field Programmable Gate Arrays (FPGAs) led to low latency when employed for query and event processing, application integration adds yet unexplored processing opportunities. In this industry paper, we explore how to program integration semantics (e. g., message routing and transformation) in form of Enterprise Integration Patterns (EIP) on top of an FPGA, thus complementing the existing research on FPGA data processing. We focus on message routing, re-define the EIP for stream processing and propose modular hardware implementations as templates that are synthesized to circuits. For our real-world ""connected car"" scenario (i. e., composed patterns), we discuss common and new optimizations especially relevant for hardware integration processes. Our experimental evaluation shows competitive throughput compared to modern general-purpose CPUs and discusses the results.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Ritter, Daniel and Dann, Jonas and May, Norman and Rinderle-Ma, Stefanie",2017,Proceedings of the 11th ACM International Conference on Distributed and Event-Based Systems,10.1145/3093742.3093911,acm2-search1.bib
10.1145/2335484.2335506,Partition and Compose: Parallel Complex Event Processing,"Complex event processing uses patterns to detect composite events in streams of simple events. Typically, the events are logically partitioned by some key. For instance, the key can be the stock symbol in stock quotes, the author in tweets, the vehicle in transportation, or the patient in health-care. Composite event patterns often become meaningful only after partitioning. For instance, a pattern over stock quotes is typically meaningful over quotes for the same stock symbol. This paper proposes a pattern syntax and translation scheme organized around the notion of partitions. Besides making patterns meaningful, partitioning also benefits performance, since different keys can be processed in parallel. We have implemented partitioned parallel complex event processing as an extension to IBM's System S high-performance streaming platform. Our experiments with several benchmarks from finance and social media demonstrate processing speeds of up to 830,000 events per second, and substantial speedups for expensive patterns parallelized on multi-core machines as well as multi-machine clusters. Partitioning the event stream before detecting composite events makes event processing both more intuitive and parallel.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Hirzel, and Martin,",2012,Proceedings of the 6th ACM International Conference on Distributed Event-Based Systems,10.1145/2335484.2335506,acm2-search1.bib
10.1145/3093742.3095100,Anomaly Detection of Manufacturing Equipment via High Performance RDF Data Stream Processing: Grand Challenge,"The ACM DEBS Grand Challenge 2017 focuses on anomaly detection of manufacturing equipment. The goal of the challenge is to detect abnormal behavior of a manufacturing machine based on the observations of the stream of measurements provided. The data produced by each sensor is clustered and the state transitions between the observed clusters are modeled as a Markov chain. In this paper we present how we used WSO2 Data Analytics Server (DAS), an open source, comprehensive enterprise data analytics platform, to solve the problem. On the HOBBIT (Holistic Benchmarking of Big Linked Data) platform our solution processed 35 megabytes/second with an end-to-end mean latency of 7.5 ms at an input rate of 1 ms, while the events spent only 1 ms time on average within our grand challenge solution. The paper describes the solution we propose, the experiments' results and presents how we optimized the performance of our solution.",FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Akram, Nihla and Siriwardene, Sachini and Jayasinghe, Malith and Dayarathna, Miyuru and Perera, Isuru and Fernando, Seshika and Perera, Srinath and Bandara, Upul and Suhothayan, Sriskandarajah",2017,Proceedings of the 11th ACM International Conference on Distributed and Event-Based Systems,10.1145/3093742.3095100,acm2-search1.bib
10.1145/1993498.1993559,Mining Hot Calling Contexts in Small Space,"Calling context trees (CCTs) associate performance metrics with paths through a program's call graph, providing valuable information for program understanding and performance analysis. Although CCTs are typically much smaller than call trees, in real applications they might easily consist of tens of millions of distinct calling contexts: this sheer size makes them difficult to analyze and might hurt execution times due to poor access locality. For performance analysis, accurately collecting information about hot calling contexts may be more useful than constructing an entire CCT that includes millions of uninteresting paths. As we show for a variety of prominent Linux applications, the distribution of calling context frequencies is typically very skewed. In this paper we show how to exploit this property to reduce the CCT size considerably.We introduce a novel run-time data structure, called Hot Calling Context Tree (HCCT), that offers an additional intermediate point in the spectrum of data structures for representing interprocedural control flow. The HCCT is a subtree of the CCT that includes only hot nodes and their ancestors. We show how to compute the HCCT without storing the exact frequency of all calling contexts, by using fast and space-efficient algorithms for mining frequent items in data streams. With this approach, we can distinguish between hot and cold contexts on the fly, while obtaining very accurate frequency counts. We show both theoretically and experimentally that the HCCT achieves a similar precision as the CCT in a much smaller space, roughly proportional to the number of distinct hot contexts: this is typically several orders of magnitude smaller than the total number of calling contexts encountered during a program's execution. Our space-efficient approach can be effectively combined with previous context-sensitive profiling techniques, such as sampling and bursting.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"D'Elia, Daniele and Demetrescu, Camil and Finocchi, Irene",2011,SIGPLAN Not.,10.1145/1993498.1993559,acm2-search1.bib;acm2-search1.bib
10.1145/3152116,Delay-Aware Quality Optimization in Cloud-Assisted Video Streaming System,"Cloud-assisted video streaming has emerged as a new paradigm to optimize multimedia content distribution over the Internet. This article investigates the problem of streaming cloud-assisted real-time video to multiple destinations (e.g., cloud video conferencing, multi-player cloud gaming, etc.) over lossy communication networks. The user diversity and network dynamics result in the delay differences among multiple destinations. This research proposes <underline>D</underline>ifferentiated cloud-<underline>A</underline>ssisted <underline>VI</underline>deo <underline>S</underline>treaming (DAVIS) framework, which proactively leverages such delay differences in video coding and transmission optimization. First, we analytically formulate the optimization problem of joint coding and transmission to maximize received video quality. Second, we develop a quality optimization framework that integrates the video representation selection and FEC (Forward Error Correction) packet interleaving. The proposed DAVIS is able to effectively perform differentiated quality optimization for multiple destinations by taking advantage of the delay differences in cloud-assisted video streaming system. We conduct the performance evaluation through extensive experiments with the Amazon EC2 instances and Exata emulation platform. Evaluation results show that DAVIS outperforms the reference cloud-assisted streaming solutions in video quality and delay performance.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Wu, Jiyan and Cheng, Bo and Yang, Yuan and Wang, Ming and Chen, Junliang",2017,ACM Trans. Multimedia Comput. Commun. Appl.,10.1145/3152116,acm2-search1.bib
10.14778/3402707.3402752,Massive Scale-out of Expensive Continuous Queries,"Scalable execution of expensive continuous queries over massive data streams requires input streams to be split into parallel sub-streams. The query operators are continuously executed in parallel over these sub-streams. Stream splitting involves both partitioning and replication of incoming tuples, depending on how the continuous query is parallelized. We provide a stream splitting operator that enables such customized stream splitting. However, it is critical that the stream splitting itself keeps up with input streams of high volume. This is a problem when the stream splitting predicates have some costs. Therefore, to enable customized splitting of high-volume streams, we introduce a parallelized stream splitting operator, called parasplit. We investigate the performance of parasplit using a cost model and experimentally. Based on these results, a heuristic is devised to automatically parallelize the execution of parasplit. We show that the maximum stream rate of parasplit is network bound, and that the parallelization is energy efficient. Finally, the scalability of our approach is experimentally demonstrated on the Linear Road Benchmark, showing an order of magnitude higher stream processing rate over previously published results, allowing at least 512 expressways.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Zeitler, Erik and Risch, Tore",2020,Proc. VLDB Endow.,10.14778/3402707.3402752,acm3-search1.bib
li2016service,Service Intelligence Oriented Distributed Data Stream Integration,,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Li, Feng-Lin and Chi, Chi-Hung and Wang, Yue and Liu, Cong",2016,arXiv preprint arXiv:1604.03453,,scholar.bib
monsakul2010performance,Performance analysis of traffic control MIPv6 on Linux base,"Application on mobile device and wireless are popularly used. Such as Multimedia, VDO Conference, VoIP need different bandwidth. In order to support real-time and data streaming application. This paper analysis of traffic control and performance classes Mobile IPv6 (MIPv6). Author implement on Redhat Linux OS and test to control resource on Access Router (AR) by Differentiated Service (Diffserv) architecture. The bandwidths that can declare type of each class and control the traffic in network.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Monsakul, and Annop,",2010,2010 2nd International Conference on Computer Engineering and Technology,,scholar.bib
grelck2012engineering,Engineering concurrent software guided by statistical performance analysis,"This paper introduces the ADVANCE approach to engineering concurrent systems using a new component-based approach. A cost-directed tool-chain maps concurrent programs onto emerging hardware architectures, where costs are expressed in terms of programmer annotations for the throughput, latency and jitter of components. These are then synthesized using advanced statistical analysis techniques to give overall cost information about the concurrent system that can be exploited by the hardware virtualisation layer to drive mapping and scheduling decisions. Initial performance results are presented, showing that the ADVANCE technologies provide a promising approach to dealing with near- and future-term complexities of programming heterogeneous multi-core systems.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Grelck, Clemens and Hammond, Kevin and Hertlein, Heinz and H{\""o}lzenspies, Philip and Jesshope, Chris and Kirner, Raimund and Scheuermann, Bernd and Shafarenko, Alex and Boekhorst, Iraneus and Wieser, Volkmar",2012,"Applications, Tools and Techniques on the Road to Exascale Computing",,scholar.bib
komisarek2020real,Real-time stream processing tool for detecting suspicious network patterns using machine learning,"In this paper, the performance of stream processing and accuracy in the prediction of suspicious flows in simulated network traffic is investigated. In addition, concepts of an engine that integrates with novel solutions like the Elastic-search database and Apache Kafka that allows easy definition of streams and implementation of any machine learning algorithm are presented",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Komisarek, Miko{\l}aj and Chora{\'s}, Micha{\l} and Kozik, Rafa{\l} and Pawlicki, Marek",2020,"Proceedings of the 15th International Conference on Availability, Reliability and Security",,scholar.bib
alaasam2019stateful,Stateful stream processing for digital twins: Microservice-based kafka stream dsl,"Digital Twin is a virtual representation of a technological process or a piece of equipment, that supports monitoring, control and state prediction based on the data, gathered from the sensor networks. To parallelize event processing and produce near-real-time insights over data streams, Digital Twin should be implemented based on an Event-Driven architecture. The Event-Driven architecture is loosely-coupled by its nature. One of the recent possible solutions for loose coupling system is a Microservice approach, a cohesive and independent process that interacts using messages. Stateless behavior is the nature of the microservice, but on the other hand, the vast majority of stream processing in Digital Twin imply stateful operations. Thus, in this paper, we propose a case-study of the possibility to use Apache Kafka Stream API (Kafka stream DSL) to build stateful microservice for real-time manufacturing data analysis. Also, in the presented work we discuss the fulfillment of such requirements as fault tolerance, processing latency, and scalability to support the stateful stream processing in Digital Twins implementation.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Alaasam, Ameer and Radchenko, Gleb and Tchernykh, Andrey",2019,"2019 International Multi-Conference on Engineering, Computer and Information Sciences (SIBIRCON)",,scholar.bib
chen2008measure,Measure and model P2P streaming system by buffer bitmap,"The correct evaluation of P2P streaming system models needs the validation in real world system. However, there is lack of systematic and integrated measurement method for real world P2P streaming system. In this paper, we propose a P2P streaming network measurement method based on a peer's buffer occupancy probability. Our method is based on the fixed duration buffer property of commercial P2P streaming systems. We prove the measured buffer occupancy probability reflects the chunk propagation process in the P2P network. We then propose a P2P streaming chunk propagation model and verify it in the commercial P2P streaming network using our measurement method. Our measurement method is useful for measuring and analyzing miscellaneous P2P streaming systems. And our model and parameter estimation are useful for existing P2P simulators to choose correct parameters and are meaningful for researchers to understand the real meaning behind the parameters.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Chen, Yishuai and Chen, Changjia and Li, Chunxi",2008,2008 10th IEEE International Conference on High Performance Computing and Communications,,scholar.bib
al2019spatial,Spatial-aware approximate big data stream processing,"The widespread adoption of ubiquitous IoT edge devices and modern telemetry spewing out unprecedented avalanches of spatially-tagged datasets that if could interactively be explored would offer deep insights into interesting natural phenomena, which might remain otherwise illusive. Online application of spatial queries is expensive, a problem that is further inflated by the fact that we, more than often, do not have access to a full dataset population in non- stationary settings. As a way of coping up, sampling stands out as a natural solution for approximating estimators such as averages and totals of some interesting correlated parameters. In any sampling design, representativeness remains the main issue upon which a method is regarded good or bad. In a loose way, in a spatial context, this means fairly sampling quantities in a way that preserves spatial characteristics so as to provide more accurate approximates for spatial query responses. Current big data management systems either do not offer over-the-counter spatial-aware online sampling solutions or, at best, rely on randomness, which causes too many imponderables for an overall estimation. We herein have designed a QoS- spatial-aware online sampling method that outperforms vanilla baselines by statically significant magnitudes. Our method sits atop Apache Spark Structured Streaming's codebase and have been tested against a benchmark that is consisting of millions-records of spatially- augmented dataset.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"AlJawarneh, Isam and Bellavista, Paolo and Foschini, Luca and Montanari, Rebecca",2019,2019 IEEE global communications conference (GLOBECOM),,scholar.bib
milosevic2015wearable,Wearable inertial sensor for jump performance analysis,"Wearable devices enable the unobtrusive sensing of a wide range of human activities and the development of innovative applications. While the consumer market is pushing them particularly as activity or heart rate trackers, their adoption in healthcare is still restricted to few cases, primarily due to their limited accuracy and reliability. An interesting field of application is the jump performance assessment. It is frequently used by therapists to estimate neuromuscular imbalances, since it helps to monitor training progress in athletes or injured patients. Measurements are typically captured with accurate but expensive instrumentation (e.g. force plates). In this work, we propose the use of a versatile low-cost wearable device equipped with inertial sensors for the evaluation of jump height, which can be easily employed at home. We consider two categories of jumps, the counter-movement jump (a single vertical jump) and the plyometric jump (the fast repetition of 4 jumps). The proposed approach, after an initialization phase, uses gyroscope data to continuously track the orientation of the device and align it with the vertical plane and the accelerometer data to estimate the jump trajectory. To validate the system, we collected 200 jumps performed with our device and the Myotest and we observed a mean difference of 0.7 cm (max. 1.9 cm) for the counter-movement jumps and 0.6 (max. 2.1 cm) for the plyometric jumps.",FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Milosevic, Bojan and Farella, Elisabetta",2015,Proceedings of the 2015 workshop on Wearable Systems and Applications,,scholar.bib
zhao2005data,Data streaming algorithms for accurate and efficient measurement of traffic and flow matrices,"The traffic volume between origin/destination (OD) pairs in a network, known as traffic matrix, is essential for efficient network provisioning and traffic engineering. Existing approaches of estimating the traffic matrix, based on statistical inference and/or packet sampling, usually cannot achieve very high estimation accuracy. In this work, we take a brand new approach in attacking this problem. We propose a novel data streaming algorithm that can process traffic stream at very high speed (e.g., 40 Gbps) and produce traffic digests that are orders of magnitude smaller than the traffic stream. By correlating the digests collected at any OD pair using Bayesian statistics, the volume of traffic flowing between the OD pair can be accurately determined. We also establish principles and techniques for optimally combining this streaming method with sampling, when sampling is necessary due to stringent resource constraints. In addition, we propose another data streaming algorithm that estimates flow matrix, a finer-grained characterization than traffic matrix. Flow matrix is concerned with not only the total traffic between an OD pair (traffic matrix), but also how it splits into flows of various sizes. Through rigorous theoretical analysis and extensive synthetic experiments on real Internet traffic, we demonstrate that these two algorithms can produce very accurate estimation of traffic matrix and flow matrix respectively.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Zhao, Qi and Kumar, Abhishek and Wang, Jia and Xu, Jun",2005,ACM SIGMETRICS Performance Evaluation Review,,scholar.bib
chauhan2012performance,Performance evaluation of Yahoo! S4: A first look,"Processing large data sets has been dominated recently by the map/reduce programming model [1], originally proposed by Google and widely adopted through the Apache Hadoop1 implementation. Over the years, developers have identified weaknesses of processing data sets in batches as in MapReduce and have proposed alternatives. One such alternative is continuous processing of data streams. This is particularly suitable for applications in online analytics, monitoring, financial data processing and fraud detection that require timely processing of data, making the delay introduced by batch processing highly undesirable. This processing paradigm has led to the development of systems such as Yahoo! S4 [2] and Twitter Storm.2 Yahoo! S4 is a general-purpose, distributed and scalable platform that allows programmers to easily develop applications for processing continuous unbounded streams of data. As these frameworks are quite young and new, there is a need to understand their performance for real time applications and find out the existing issues in terms of scalability, execution time and fault tolerance. We did an empirical evaluation of one application on Yahoo! S4 and focused on the performance in terms of scalability, lost events and fault tolerance. Findings of our analyses can be helpful towards understanding the challenges in developing stream-based data intensive computing tools and thus providing a guideline for the future development.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Chauhan, Jagmohan and Chowdhury, Shaiful and Makaroff, Dwight",2012,"2012 Seventh International Conference on P2P, Parallel, Grid, Cloud and Internet Computing",,scholar.bib
ryoo2008optimization,Optimization principles and application performance evaluation of a multithreaded GPU using CUDA,"GPUs have recently attracted the attention of many application developers as commodity data-parallel coprocessors. The newest generations of GPU architecture provide easier programmability and increased generality while maintaining the tremendous memory bandwidth and computational power of traditional GPUs. This opportunity should redirect efforts in GPGPU research from ad hoc porting of applications to establishing principles and strategies that allow efficient mapping of computation to graphics hardware. In this work we discuss the GeForce 8800 GTX processor's organization, features, and generalized optimization strategies. Key to performance on this platform is using massive multithreading to utilize the large number of cores and hide global memory latency. To achieve this, developers face the challenge of striking the right balance between each thread's resource usage and the number of simultaneously active threads. The resources to manage include the number of registers and the amount of on-chip memory used per thread, number of threads per multiprocessor, and global memory bandwidth. We also obtain increased performance by reordering accesses to off-chip memory to combine requests to the same or contiguous memory locations and apply classical optimizations to reduce the number of executed operations. We apply these strategies across a variety of applications and domains and achieve between a 10.5X to 457X speedup in kernel codes and between 1.16X to 431X total application speedup.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Ryoo, Shane and Rodrigues, Christopher and Baghsorkhi, Sara and Stone, Sam and Kirk, David and Hwu, Wen-mei",2008,Proceedings of the 13th ACM SIGPLAN Symposium on Principles and practice of parallel programming,,scholar.bib
amaxilatis2017enabling,Enabling stream processing for people-centric IoT based on the fog computing paradigm,"The world of machine-to-machine (M2M) communication is gradually moving from vertical single purpose solutions to multi-purpose and collaborative applications interacting across industry verticals, organizations and people - a world of Internet of Things (IoT). The dominant approach for delivering IoT applications relies on the development of cloud-based IoT platforms that collect all the data generated by the sensing elements and centrally process the information to create real business value. In this paper, we present a system that follows the Fog Computing paradigm where the sensor resources, as well as the intermediate layers between embedded devices and cloud computing datacenters, participate by providing computational, storage, and control. We discuss the design aspects of our system and present a pilot deployment for the evaluating the performance in a real-world environment. Our findings indicate that Fog Computing can address the ever-increasing amount of data that is inherent in an IoT world by effective communication among all elements of the architecture.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Amaxilatis, Dimitrios and Akrivopoulos, Orestis and Chatzigiannakis, Ioannis and Tselios, Christos",2017,2017 22nd IEEE International Conference on Emerging Technologies and Factory Automation (ETFA),,scholar.bib
shukla2017riotbench_47,Riotbench: A real-time iot benchmark for distributed stream processing platforms,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Shukla, Anshu and Chaturvedi, Shilpa and Simmhan, Yogesh",2017,arXiv preprint arXiv:1701.08530,,scholar.bib
balakrishna2019performance,Performance analysis of linked stream big data processing mechanisms for unifying IoT smart data,"The linked smart data is coming from various IoT devices are enormous in nature. Therefore, capturing and real-time processing IoT smart data is a challenging task these days. The linked stream Big Data processing mechanisms play a crucial role in capturing and real-time data processing on IoT data. In this paper, calculated the performance analysis of a four processing mechanisms namely - Continuous Simple Protocol and RDF Query Language (C-SPARQL), Continuous Query Evaluation over Linked Streams (CQELS), Event Processing Simple Protocol and RDF Query Language (EP-SPARQL), Event TrAnsaction Logic in Information System (ETALIS) and Scalable Two-Level Index Scheme (STLIS). These are the mainly used mechanisms by researchers for Big Data linked stream processing. Using REFIT Smart home dataset, the experiments are conducted by taking several SPARQL queries. Finally, the STLIS mechanism is outperforms compared to the other streaming mechanisms.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Balakrishna, Sivadi and Solanki, Vijender and Gunjan, Vinit and Thirumaran, M",2019,International Conference on Intelligent Computing and Communication Technologies,,scholar.bib
peng2015data,A data streaming model in MPI,"Data streaming model is an effective way to tackle the challenge of data-intensive applications. As traditional HPC applications generate large volume of data and more data-intensive applications move to HPC infrastructures, it is necessary to investigate the feasibility of combining message-passing and streaming programming models. MPI, the de facto standard for programming on HPC, cannot intuitively express the communication pattern and the functional operations required in streaming models. In this work, we designed and implemented a data streaming library MPIStream atop MPI to allocate data producers and consumers, to stream data continuously or irregularly and to process data at run-time. In the same spirit as the STREAM benchmark, we developed a parallel stream benchmark to measure data processing rate. The performance of the library largely depends on the size of the stream element, the number of data producers and consumers and the computational intensity of processing one stream element. With 2,048 data producers and 2,048 data consumers in the parallel benchmark, MPIStream achieved 200 GB/s processing rate on a Blue Gene/Q supercomputer. We illustrate that a streaming library for HPC applications can effectively enable irregular parallel I/O, application monitoring and threshold collective operations.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Peng, Ivy and Markidis, Stefano and Laure, Erwin and Holmes, Daniel and Bull, Mark",2015,Proceedings of the 3rd Workshop on Exascale MPI,,scholar.bib
lenas2015bundle,"Bundle streaming service: design, implementation and performance evaluation","We present bundle streaming service (BSS), a communication framework that allows for reliable data streaming over delay/disruptive tolerant networks. BSS improves the reception and storage of data streams through the application of sophisticated forwarding tactics and the exploitation of inherent delay/disruptive tolerant networking (DTN) architecture features. The proposed framework, which targets easy configuration and deployment, comprises two elements: a bundle forwarder and a software library. Both elements were implemented as part of the interplanetary overlay network DTN platform. Using European Space Agency's DTN testbed, we experimentally evaluate BSS performance across a wide range of network scenarios. Based on these emulation results, we discuss the associated performance trade-offs along with potential improvement opportunities and demonstrate BSS's suitability for both terrestrial and space environments. Copyright © 2013 John Wiley & Sons, Ltd.",FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,EXCLUDED,EXCLUDED,,"Lenas, Sotirios-Angelos and Burleigh, Scott and Tsaoussidis, Vassilis",2015,Transactions on Emerging Telecommunications Technologies,,scholar.bib
trimmer2006performance,Performance of high-bandwidth TRABOL protocol for radar data streaming,"TCP-friendly Rate Adaptation Based on Loss (TRABOL) is a high bandwidth overlay transport protocol that dynamically adapts the data transmission rate based on the packet loss feedback received from an end user. TRABOL performs AIMD based congestion control such that transmission rate satisfies minimum and target rate requirements of the end user. Additionally, rate is adapted, while remaining friendly to the TCP cross traffic and efficiently using the bottleneck link bandwidth. This paper investigates the impact of different AIMD increase and decrease functions for congestion control on performance of the TRABOL protocol. A network emulator test bed is used for the performance evaluation, measuring the effectiveness of different AIMD rate control schemes in meeting bandwidth requirements of the end user, TCP-friendliness, bandwidth efficiency, and response time of the protocol.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Trimmer, Ashley and Banka, Tarun and Lee, Panho and Jayasumana, Anura and Chandrasekar, V",2006,2006 IEEE Region 5 Conference,,scholar.bib
kross2017model,Model-based performance evaluation of batch and stream applications for big data,"Batch and stream processing represent the two main approaches implemented by big data systems such as Apache Spark and Apache Flink. Although only stream applications are intended to satisfy real-time requirements, both approaches are required to meet certain response time constraints. In addition, cluster architectures continuously expand and computing resources constitute high investments and expenses for organizations. Therefore, planning required capacities and predicting response times is crucial. In this work, we present a performance modeling and simulation approach by using and extending the Palladio component model. We predict performance metrics of batch and stream applications and its underlying processing systems by the example of Apache Spark on Apache Hadoop. Whereas most related work concentrates on one specific processing technique and focuses on the metric response time, we propose a general approach and consider the utilization of resources as well. In different experiments we evaluated our approach using applications and data workloads of the HiBench benchmark suite. The results indicate accurate predictions for upscaling cluster sizes as well as workloads with errors less than 18%.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Kro{\ss}, Johannes and Krcmar, Helmut",2017,"2017 IEEE 25th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)",,scholar.bib
wullink2016entrada,ENTRADA: A high-performance network traffic data streaming warehouse,"We present ENTRADA, a high-performance data streaming warehouse that enables researchers and operators to analyze vast amounts of network traffic and measurement data within interactive response times (seconds to few minutes), even in a small computer cluster. ENTRADA delivers such performance by employing a optimized file format and a high-performance query engine, both open-source. ENTRADA has been operational for more than 1.5 years, having ingested more than 100 TB of pcap files from two .nl DNS authoritative servers. As we discuss, we use this data in projects that aim at further increasing the security and stability of the .nl zone. We present in this paper our design choices, experiences, and a performance evaluation of ENTRADA. Finally, we open-source ENTRADA, which can be used “out-of-the-box” by researchers, operators, and registries to deploy their own networking analysis clusters for DNS traffic, and can be easily extended to handle any other structured data.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"Wullink, Maarten and Moura, Giovane and M{\""u}ller, Moritz and Hesselman, Cristian",2016,NOMS 2016-2016 IEEE/IFIP Network Operations and Management Symposium,,scholar.bib
van2018machine,Machine learning-based qoe performance analysis for dash streaming in nfv,"In this research, we present a machine learning-based research for QoE evaluation method which mainly focuses on DASH streaming in NFV. In detail, we virtualize each component of a QoE assessment system in NFV environment. All streaming session information is employed at a video optimizer and a QoE assessment component. We implement a machine learning method in the video optimizer, and QoE assessment critics the video optimizer to improve its mechanism of retrieving DASH segments.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"VanMa, Linh and Ashiquzzaman, Akm and Kim, Sang and Lee, Dongsu and Kim, Jinsul",2018,Proceedings of KIIT Conference,,scholar.bib
syafrudin2018performance,"Performance analysis of IoT-based sensor, big data processing, and machine learning model for real-time monitoring system in automotive manufacturing","With the increase in the amount of data captured during the manufacturing process, monitoring systems are becoming important factors in decision making for management. Current technologies such as Internet of Things (IoT)-based sensors can be considered a solution to provide efficient monitoring of the manufacturing process. In this study, a real-time monitoring system that utilizes IoT-based sensors, big data processing, and a hybrid prediction model is proposed. Firstly, an IoT-based sensor that collects temperature, humidity, accelerometer, and gyroscope data was developed. The characteristics of IoT-generated sensor data from the manufacturing process are: real-time, large amounts, and unstructured type. The proposed big data processing platform utilizes Apache Kafka as a message queue, Apache Storm as a real-time processing engine and MongoDB to store the sensor data from the manufacturing process. Secondly, for the proposed hybrid prediction model, Density-Based Spatial Clustering of Applications with Noise (DBSCAN)-based outlier detection and Random Forest classification were used to remove outlier sensor data and provide fault detection during the manufacturing process, respectively. The proposed model was evaluated and tested at an automotive manufacturing assembly line in Korea. The results showed that IoT-based sensors and the proposed big data processing system are sufficiently efficient to monitor the manufacturing process. Furthermore, the proposed hybrid prediction model has better fault prediction accuracy than other models given the sensor data as input. The proposed system is expected to support management by improving decision-making and will help prevent unexpected losses caused by faults during the manufacturing process.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Syafrudin, Muhammad and Alfian, Ganjar and Fitriyani, Norma and Rhee, Jongtae",2018,Sensors,,scholar.bib
vyas2022performance,Performance Evaluation of Apache Kafka–A Modern Platform for Real Time Data Streaming,"Current generation businesses become more demanding on timely availability of data. Many real-time data streaming tools and technologies are capable to meet business expectations. Apache Kafka is one of the capable open-source distributed scalable technology that enables real-time data streaming with good throughput and latency. In traditional batch processing, data is getting processed in groups or batches but in streaming services, data records are handled separately and there is a flow of data processing that is continuous and real-time. Once Data is available at the source, Kafka can detect and stream it in real-time to the target application. After doing the literature survey it was observed that there are insufficient experiments have been done till now with a variety of volumes and with different values of the number of partitions and polling intervals. The purpose of this study is to elaborate on Apache Kafka implementation and evaluate its performance. This study will analyse key performance indicators for the streaming platform and will provide useful insights from it. These insights will help to design optimized applications in Apache Kafka. Based on gaps identified after the literature survey, multiple experiments have been conducted for the producer and consumer API (Application Programming interface). Configuration of Kafka with Apache Zookeeper helped to drive the results which are captured in tabular form for different values of polling intervals, volumes, and partitions. Data for all test runs have been analysed further to drive the conclusions as mentioned in the results section. This study provides valuable insights about the utilization of CPU (Central Processing Unit) and memory for Apache Kafka streaming on changing volumes, also elaborates the impacts on streaming performance when key configurations are getting changed.",FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,INCLUDED,INCLUDED,,"Vyas, Shubham and Tyagi, Rajesh and Jain, Charu and Sahu, Shashank",2022,2022 2nd International Conference on Innovative Practices in Technology and Management (ICIPTM),,scholar.bib
fowdur2019implementation,Implementation and Performance Analysis of a Video Streaming System using WEBRTC and Equal Cost Load Balancing,"Real-time Internet based video communication applications are becoming widely adopted by internet users. However, the exponentially rising numbers of internet users is proving to be a real challenge to guarantee a good Quality of Service (QoS) for such applications. This paper investigates how video streaming quality is impacted by the increasing number of users using a video streaming application developed with Web Real Time Communications (WebRTC). The application considers both live video streaming from of an event captured by the initiator's webcam and live streaming of a video file from the initiator's device. Tests were performed using a Wi-Fi connection with different types of video sources. Moreover, equal cost load balancing was used to assess the impact on the video quality two servers are used at the initiator's site. Videos were recorded for five minutes on both the initiator and client sides using the application's record function and the Peak Signal to Noise Ratio (PSNR) was used to assess the quality of the videos. Results showed that with equal cost load balancing using two servers a maximum gain of up to 5.39 dB in PSNR could be obtained with live streaming from a webcam to ten clients.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Fowdur, TP and Anooroop, N and Beeharry, Y",2019,"2019 14th International Conference on Advanced Technologies, Systems and Services in Telecommunications (TELSIKS)",,scholar.bib
tie2022security,Security Performance Analysis for An OTFS-based Joint Unicast-Multicast Streaming System,"This paper investigates the security performance of a joint unicast-multicast streaming system, where different users present heterogeneous mobilities. The orthogonal time frequency space (OTFS) scheme is employed to overcome severe Doppler effect caused by high mobility. The closed-form expression is derived for the maximum secrecy rate of unicast transmission with high privacy. Furthermore, the positive secure capacity probability (PSCP) of unicast transmission is also obtained and analyzed. Our analytical results show that compared with high-mobility eavesdroppers, low-mobility eavesdroppers pose a greater threat to unicast secrecy. Moreover, when the outage probability of unicast is greater than 1/2, more time frequency (TF) resources should be allocated to unicast, in order to guarantee the security performance of unicast.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"Tie, Zhuangzhuang and Shi, Jia and Li, Zan and Li, Shuangyang and Liang, Wei",2022,IEEE Transactions on Communications,,scholar.bib
liu2009distributed,RIoTBench: An IoT benchmark for distributed stream processing systems,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"duplicated, no year (Google Scholar)",,,,
marooperformance,"Performance Analysis of TRABOL, A Transport Protocol for Digitized Radar Data Streaming","TCP-friendly Rate Adaptation Based on Loss (TRABOL) is a high bandwidth overlay transport protocol that dynamically adapts the data transmission rate based on the packet loss feedback received from an end user. TRABOL performs AIMD based congestion control such that transmission rate satisfies minimum and target rate requirements of the end user. Additionally, rate is adapted, while remaining friendly to the TCP cross traffic and efficiently using the bottleneck link bandwidth. This paper investigates the impact of different AIMD increase and decrease functions for congestion control on performance of the TRABOL protocol. A network emulator test bed is used for the performance evaluation, measuring the effectiveness of different AIMD rate control schemes in meeting bandwidth requirements of the end user, TCP-friendliness, bandwidth efficiency, and response time of the protocol.",FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,EXCLUDED,EXCLUDED,,no year (Google Scholar),,,,
 WOS:000619394400009,Dynamic Auto Reconfiguration of Operator Placement in Wireless  Distributed Stream Processing Systems,"The data is generated at significant speed and volume by devices in real-time. The data generation and the growth of fog and edge computing infrastructure have led to the noteworthy development of the corresponding distributed stream processing systems (DSPS). A DSPS application has Quality of Service (QoS) restrictions in terms of resource cost and time. The physical resources are distributed and heterogeneous. The resource-constrained scheduling problem has considerable implications on the performance of the system and QoS violations. The static deployment of applications in fog or edge scenario has to be monitored continuously for runtime issues, and actions have to be taken accordingly. In this paper, we propose an adaptation capability with reinforcement learning techniques to an existing stream processing framework scheduler. This functionality enables the scheduler to make decisions on its own when the system model or knowledge of the environment is not known upfront. The reinforcement learning methods adapt to the system when the system model for different states is not available. We consider applications whose workload cannot be characterized or predicted. In such applications, predictions of input load are not helpful for online scheduling. The Q-Learning based online scheduler learns to make dynamic scaling decisions at runtime when there is performance degradation. We validated the proposed approach with real-time and benchmark applications on a DSPS cluster. We obtained an average of 6% reduction in the response time and a 15% increase in the throughput when the Q Learning module is employed in the scheduler.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,"no year (Web of Science), duplicated",,,,
WOS:000873531200001,"Short text topic modelling approaches in the context of big data: taxonomy, survey, and analysis","Social media platforms such as (Twitter, Facebook, and Weibo) are being increasingly embraced by individuals, groups, and organizations as a valuable source of information. This social media generated information comes in the form of tweets or posts, and normally characterized as short text, huge, sparse, and low density. Since many real-world applications need semantic interpretation of such short texts, research in Short Text Topic Modeling (STTM) has recently gained a lot of interest to reveal unique and cohesive latent topics. This article examines the current state of the art in STTM algorithms. It presents a comprehensive survey and taxonomy of STTM algorithms for short text topic modelling. The article also includes a qualitative and quantitative study of the STTM algorithms, as well as analyses of the various strengths and drawbacks of STTM techniques. Moreover, a comparative analysis of the topic quality and performance of representative STTM models is presented. The performance evaluation is conducted on two real-world Twitter datasets: the Real-World Pandemic Twitter (RW-Pand-Twitter) dataset and Real-world Cyberbullying Twitter (RW-CB-Twitter) dataset in terms of several metrics such as topic coherence, purity, NMI, and accuracy. Finally, the open challenges and future research directions in this promising field are discussed to highlight the trends of research in STTM. The work presented in this paper is useful for researchers interested in learning state-of-the-art short text topic modelling and researchers focusing on developing new algorithms for short text topic modelling.",FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,EXCLUDED,EXCLUDED,,no year (Web of Science),,,,
WOS:000875805600001,DSParLib: A C plus plus Template Library for Distributed Stream Parallelism,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"no year (Web of Science), duplicated",,,,
WOS:000736445900001,Energy efficient resource controller for Apache Storm,"Apache Storm is a distributed processing engine that can reliably process unbounded streams of data for real-time applications. While recent research activities mostly focused on devising a resource allocation and task scheduling algorithm to satisfy high performance or low latency requirements of Storm applications across a distributed and multi-core system, finding a solution that can optimize the energy consumption of running applications remains an important research question to be further explored. In this article, we present a controlling strategy for CPU throttling that continuously optimize the level of consumed energy of a Storm platform by adjusting the voltage and frequency of the CPU cores while running the assigned tasks under latency constraints defined by the end-users. The experimental results running over a Storm cluster with 4 physical nodes (total 24 cores) validates the effectiveness of proposed solution when running multiple compute-intensive operations. In particular, the proposed controller can keep the latency of analytic tasks, in terms of 99th latency percentile, within the quality of service requirement specified by the end-user while reducing the total energy consumption by 18% on average across the entire Storm platform.",FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,EXCLUDED,EXCLUDED,,no year (Web of Science),,,,
spaeren2021performance,Performance Analysis and Improvements for Apache Beam,,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,no publisher (Google Scholar),,,,
zhang2019performance,Performance Analysis of Cloud-Based Stream Processing Pipelines for Real-Time Vehicle Data,,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,no publisher (Google Scholar),,,,
marooperformance,"Performance Analysis of TRABOL, A Transport Protocol for Digitized Radar Data Streaming",,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"duplicated, no publisher (Google Scholar)",,,,
simmhanriotbench,RIoTBench: An IoT benchmark for distributed stream processing systems,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"duplicated, no publisher (Google Scholar)",,,,
truong2019framework,A Framework for Performance-Oriented Real-time Stream Processing over the Cloud,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,EXCLUDED,EXCLUDED,,"duplicated, no publisher (Google Scholar)",,,,