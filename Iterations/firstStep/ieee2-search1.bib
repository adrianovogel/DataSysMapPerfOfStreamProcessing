@INPROCEEDINGS{7164926,
author={Lohrmann, Björn and Janacik, Peter and Kao, Odej},
booktitle={2015 IEEE 35th International Conference on Distributed Computing Systems},
title={Elastic Stream Processing with Latency Guarantees},
year={2015},
volume={},
number={},
pages={399-410},
abstract={Many Big Data applications in science and industry have arisen, that require large amounts of streamed or event data to be analyzed with low latency. This paper presents a reactive strategy to enforce latency guarantees in data flows running on scalable Stream Processing Engines (SPEs), while minimizing resource consumption. We introduce a model for estimating the latency of a data flow, when the degrees of parallelism of the tasks within are changed. We describe how to continuously measure the necessary performance metrics for the model, and how it can be used to enforce latency guarantees, by determining appropriate scaling actions at runtime. Therefore, it leverages the elasticity inherent to common cloud technology and cluster resource management systems. We have implemented our strategy as part of the Nephele SPE. To showcase the effectiveness of our approach, we provide an experimental evaluation on a large commodity cluster, using both a synthetic workload as well as an application performing real-time sentiment analysis on real-world social media data.},
keywords={Throughput;Runtime;Quality of service;Parallel processing;Engines;Real-time systems;Storms;Stream Processing;Big Data;Streaming;Stream Processing Engine;Autoscaling;Elastic Scaling;Latency Constraint;Latency Guarantee},
doi={10.1109/ICDCS.2015.48},
ISSN={1063-6927},
month={June},}
@INPROCEEDINGS{7889547,
author={Bhattacharya, Nilayan and Arpinar, I. Budak and Kursuncu, Ugur},
booktitle={2017 IEEE 11th International Conference on Semantic Computing (ICSC)},
title={Real Time Evaluation of Quality of Search Terms During Query Expansion for Streaming Text Data Using Velocity and Relevance},
year={2017},
volume={},
number={},
pages={280-281},
abstract={The traditional methods of evaluation of data cannot be used to evaluate the quality of the streaming twitter data due to the restriction on access to historic tweets, and dynamic nature of the microblogging posts. For this purpose, we propose a novel method to quantify the quality of data independent of the underlying model. Using the change in velocity of tweets with addition of search terms, and the relevance computed by the underlying model, we evaluated the impact of each search term on the quality of data retrieved.},
keywords={Games;Semantics;Computational modeling;Large scale integration;Tagging;Twitter;Benchmark testing},
doi={10.1109/ICSC.2017.105},
ISSN={},
month={Jan},}
@ARTICLE{9123756,
author={Tantalaki, Nicoleta and Souravlas, Stavros and Roumeliotis, Manos and Katsavounis, Stefanos},
journal={IEEE Access},
title={Pipeline-Based Linear Scheduling of Big Data Streams in the Cloud},
year={2020},
volume={8},
number={},
pages={117182-117202},
abstract={Nowadays, there is an accelerating need to efficiently and timely handle large amounts of data that arrives continuously. Streams of big data led to the emergence of several Distributed Stream Processing Systems (DSPS) that assign processing tasks to the available resources (dynamically or not) and route streaming data between them. Efficient scheduling of processing tasks can reduce application latencies and eliminate network congestions. However, the available DSPSs' in-built scheduling techniques are far from optimal. In this work, we extend our previous work, where we proposed a linear scheme for the task allocation and scheduling problem. Our scheme takes advantage of pipelines to handle efficiently applications, where there is need for heavy communication (all-to-all) between tasks assigned to pairs of components. In this work, we prove that our scheme is periodic, we provide a communication refinement algorithm and a mechanism to handle many-to-one assignments efficiently. For concreteness, our work is illustrated based on Apache Storm semantics. The performance evaluation depicts that our algorithm achieves load balance and constraints the required buffer space. For throughput testing, we compared our work to the default Storm scheduler, as well as to R-Storm. Our scheme was found to outperform both the other strategies and achieved an average of 25%-40% improvement compared to Storm's default scheduler under different scenarios, mainly as a result of reduced buffering (≈ 45% less memory). Compared to R-storm, the results indicate an average of 35%-45% improvement.},
keywords={Task analysis;Storms;Topology;Scheduling;Resource management;Fasteners;Big Data;Stream processing;scheduling;big data;pipelines;distributed systems},
doi={10.1109/ACCESS.2020.3004612},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{6984705,
author={Huang, Yu Wei and Chen, Yaw Chung},
booktitle={2014 IEEE International Conference on Computer and Information Technology},
title={A Study on Content Delivery Strategy for QoE Enhancement in P2P IPTV},
year={2014},
volume={},
number={},
pages={520-527},
abstract={Nowadays the peer-to-peer (P2P) systems have been widely deployed for the Internet television and live streaming. The real-time P2P service features advantages of scalability and heterogeneity in the existing network without modifying the underlay infrastructure. However, most of the common IPTV applications did not consider the user's surfing behavior which causes great burden to the IPTV streaming system. In addition, the high churn rate and insufficient upload capacity may lead to the unstable playback smoothness, and result in a poor quality of experience (QoE). In this paper, we propose a QoE-aware content delivery mechanism to distribute the important and instant data first. I-frame chunks near playback deadline are assigned the top priority. We discuss the comparison of overlay performance and demonstrate that the proposed scheme is workable via a series of experiments on OMNeT++.},
keywords={Relays;Peer-to-peer computing;IPTV;Streaming media;Media;Bandwidth;Delays;Peer-to-peer computing;Peer-to-peer live streaming;IPTV;channel zapping;surfing behavior;data scheduling},
doi={10.1109/CIT.2014.131},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6005823,
author={Sutinen, Tiia and Rivas, Helena},
booktitle={2011 Proceedings of 20th International Conference on Computer Communications and Networks (ICCCN)},
title={Cross-Layer Assisted Network Interface Selection for Multi-Interface Video Streaming},
year={2011},
volume={},
number={},
pages={1-6},
abstract={Multi-homing is expected to be an important enabler of the future Internet. Already today, terminal devices are equipped with multiple network interfaces and able to use them simultaneously. In the future, mobile multimedia services such as video streaming can maximize the user experienced quality by utilizing the available network resources, concurrently. However, intelligent decision-making as well as dynamic mapping of traffic to network interfaces are required for optimal operation. In this paper, we propose a dynamic cross-layer communication assisted network interface selection solution for a multi-interface streaming system designed for scalable video streams. We also present a prototype implementation and verify its operation in an experimental evaluation.},
keywords={Static VAr compensators;Network interfaces;Streaming media;Context;Servers;Routing;IP networks},
doi={10.1109/ICCCN.2011.6005823},
ISSN={1095-2055},
month={July},}
@INPROCEEDINGS{9225267,
author={Sundar, Merlin and Kailasam, Sriram and Gonsalves, Timothy A.},
booktitle={2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)},
title={Benchmarking Distributed Stream Processing Frameworks for Real Time Classical Machine Learning Applications},
year={2020},
volume={},
number={},
pages={1-7},
abstract={As the volume of data generated is growing at an unprecedented rate, it becomes important to analyze this data in real-time. To handle the huge volume of data streaming at a high velocity, we not only require powerful machines but also means to distribute the computation involved on the multiple machines. There are several open-source distributed stream processing frameworks such as Apache {Storm, Flink, Spark} and Confluent Kafka for building real-time machine learning applications. Prior works benchmarked some of these platforms using low-level operations like filters, joins, windowed computations etc. Our work includes benchmarking these popular frameworks for their applicability to classical machine learning models: Online K-Means, Online Linear Regression and Online Logistic Regression. We study the following quantitative metrics of evaluation: throughput, latency, CPU, and memory usage. The experiments were conducted in both standalone and clusters setups to determine the scalability of the models. This study will help system designers choose the right model and the right framework, given a specific configuration on streaming data.},
keywords={Machine learning;Storms;Logistics;Clustering algorithms;Machine learning algorithms;Linear regression;Sparks;distributed stream processing frameworks;classical machine learning;latency;throughput},
doi={10.1109/ICCCNT49239.2020.9225267},
ISSN={},
month={July},}
@INPROCEEDINGS{7930015,
author={Zhang, Shuhao and He, Bingsheng and Dahlmeier, Daniel and Zhou, Amelie Chi and Heinze, Thomas},
booktitle={2017 IEEE 33rd International Conference on Data Engineering (ICDE)},
title={Revisiting the Design of Data Stream Processing Systems on Multi-Core Processors},
year={2017},
volume={},
number={},
pages={659-670},
abstract={Driven by the rapidly increasing demand for handling real-time data streams, many data stream processing (DSP) systems have been proposed. Regardless of the different architectures of those DSP systems, they are mostly aiming at scaling out using a cluster of commodity machines and built around a number of key design aspects: a) pipelined processing with message passing, b) on-demand data parallelism, and c) JVM based implementation. However, there lacks a study on those key design aspects on modern scale-up architectures, where more CPU cores are being put on the same die, and the onchip cache hierarchies are getting larger, deeper, and complex. Multiple sockets bring non-uniform memory access (NUMA) effort. In this paper, we revisit the aforementioned design aspects on a modern scale-up server. Specifically, we use a series of applications as micro benchmark to conduct detailed profiling studies on Apache Storm and Flink. From the profiling results, we observe two major performance issues: a) the massively parallel execution model causes serious front-end stalls, which are a major performance bottleneck issue on a single CPU socket, b) the lack of NUMA-aware mechanism causes major drawback on the scalability of DSP systems on multi-socket architectures. Addressing these issues should allow DSP systems to exploit modern scale-up architectures, which also benefits scaling out environments. We present our initial efforts on resolving the above-mentioned performance issues, which have shown up to 3.2x and 3.1x improvement on the performance of Storm and Flink, respectively.},
keywords={Digital signal processing;Sockets;Storms;Message passing;Parallel processing;Pipelines;Multicore processing},
doi={10.1109/ICDE.2017.119},
ISSN={2375-026X},
month={April},}
@INPROCEEDINGS{8276879,
author={Grulich, Philipp M. and Zukunft, Olaf},
booktitle={2017 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)},
title={Smart Stream-Based Car Information Systems that Scale: An Experimental Evaluation},
year={2017},
volume={},
number={},
pages={1030-1037},
abstract={Real-time information from embedded sources is hard to process if the number of sources is high. One typical example of this application area are car information systems where the cyber-physical system of a car connects to arbitrary sources in and outside of the car to deliver value-adding information to the driver of the car. In this paper, we propose a new architecture for such a car information system based on a smart data streaming infrastructure. This architecture has been implemented and we have run several experiments to examine the quality of our proposed solution. The current implementation is based on Spark Streaming, Couchbase and written in Scala. We have deployed our implementation on a distributed system using cloud services. This allows us to perform experiments with a high load as typical for the application scenario. First results from our experiments show that our proposed solution for a smart data based car information system is resilient to typical failures and scales for the described use-cases.},
keywords={Automobiles;Computer architecture;Sparks;Information systems;Batch production systems;Sensors},
doi={10.1109/iThings-GreenCom-CPSCom-SmartData.2017.181},
ISSN={},
month={June},}
@INPROCEEDINGS{8456434,
author={Tran, Geoffrey Phi C. and Walters, John Paul and Crago, Stephen P.},
booktitle={2018 IEEE International Conference on Services Computing (SCC)},
title={Reducing Tail Latencies While Improving Resiliency to Timing Errors for Stream Processing Workloads},
year={2018},
volume={},
number={},
pages={278-281},
abstract={Stream processing is an increasingly popular model for online data processing that can be partitioned into streams of elements. It is commonly used in data analytics services, such as processing Twitter tweets. Current stream processing frameworks boast high throughput and low average latency. However, lower tail latencies and better real-time performance are desirable to stream processing users. In practice, there are issues that can affect the performance of these applications and cause unacceptable violations of real-time constraints. Some examples of these issues are garbage collection pauses and resource contention. In this paper, we propose applying redundancy in the data processing pipeline to increase the resiliency of stream processing applications to timing errors. This results in better real-time performance and a reduction in tail latency. We present a methodology and apply this redundancy in a framework based on Twitter's Heron. Then, we then evaluate the effectiveness of this technique against a range of injected timing errors using benchmarks from Intel's Storm Benchmark. Furthermore, we also study the potential effects of duplication when applied at different stages in the topology. Finally, we evaluate the additional overhead that duplicating tuples brings to a stream processing topology. Our results show that redundant tuple processing can effectively reduce the tail latency by up to 63% and that the number of missed deadlines can also be reduced by up to 94% in the best case. Overall we conclude that redundancy through duplicated tuples is indeed a powerful tool for increasing the resiliency to intermittent runtime timing errors.},
keywords={Topology;Redundancy;Timing;Generators;Resilience;Benchmark testing;Storms;stream processing;fault-tolerance;garbage collection;resiliency;real-time;tail latency},
doi={10.1109/SCC.2018.00048},
ISSN={2474-2473},
month={July},}
@INPROCEEDINGS{9680451,
author={Xu, Jinlai and Palanisamy, Balaji},
booktitle={2021 IEEE 28th International Conference on High Performance Computing, Data, and Analytics (HiPC)},
title={Model-based Reinforcement Learning for Elastic Stream Processing in Edge Computing},
year={2021},
volume={},
number={},
pages={292-301},
abstract={Low-latency data processing is critical for enabling next generation Internet-of-Things(IoT) applications. Edge computing-based stream processing techniques that optimize for low latency and high throughput provide a promising solution to ensure a rich user experience by meeting strict application requirements. However, manual performance tuning of stream processing applications in heterogeneous and dynamic edge computing environments is not only time consuming but also not scalable. Our work presented in this paper achieves elasticity for stream processing applications deployed at the edge by automatically tuning the applications to meet the performance requirements. The proposed approach adopts a learning model to configure the parallelism of the operators in the stream processing application using a reinforcement learning(RL) method. We model the elastic control problem as a Markov Decision Process(MDP) and solve it by reducing it to a contextual Multi-Armed Bandit(MAB) problem. The techniques proposed in our work uses Upper Confidence Bound(UCB)-based methods to improve the sample efficiency in comparison to traditional random exploration methods such as the e-greedy method. It achieves a significantly improved rate of convergence compared to other RL methods through its innovative use of MAB methods to deal with the tradeoff between exploration and exploitation. In addition, the use of model-based pre-training results in sub-stantially improved performance by initializing the model with appropriate and well-tuned parameters. The proposed techniques are evaluated using realistic and synthetic workloads through both simulation and real testbed experiments. The experiment results demonstrate the effectiveness of the proposed approach compared to standard methods in terms of cumulative reward and convergence speed.},
keywords={Computational modeling;Parallel processing;Markov processes;Elasticity;User experience;Low latency communication;Tuning;edge computing;stream processing;elasticity;model based reinforcement learning;multi armed bandit},
doi={10.1109/HiPC53243.2021.00043},
ISSN={2640-0316},
month={Dec},}
@ARTICLE{7859259,
author={Collins, Travis F. and Wyglinski, Alexander M.},
journal={IEEE Access},
title={Dataflow in MATLAB: Algorithm Acceleration Through Concurrency},
year={2017},
volume={5},
number={},
pages={2308-2318},
abstract={In this paper, we present a novel Data-Flow architecture for MATLAB. This architecture provides thread-level pipelining of MATLAB functions as well as general concurrency support. The proposed approach yields a significant speedup of current MATLAB implementations that rely on streaming data or employ data-dependent operations. Following the development of increased CPU core counts, this proposed framework will provide additional benefit only as this trend continues. A performance analysis of the proposed framework is performed, and we are able to demonstrate high-level throughput gains of specific applications. Discussions on implementation guidelines, as well as limitations of the framework, are proposed in this paper. Through the use of this tool, we have demonstrated a 802.11a receiver employing Software-Defined Radio hardware running in real time. From the user's perspective, this tool requires interaction only from the MATLAB language, handling all threading and data transfer without user intervention.},
keywords={MATLAB;Parallel processing;Instruction sets;Throughput;Concurrent computing;Computer architecture;Real-time systems;Software-defined radio;dataflow;HPC},
doi={10.1109/ACCESS.2017.2672200},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9378298,
author={Gilroy, Justin and Paronyan, Satine and Acoltzi, Jonathan and Fukuda, Munehiro},
booktitle={2020 IEEE International Conference on Big Data (Big Data)},
title={Agent-Navigable Dynamic Graph Construction and Visualization over Distributed Memory},
year={2020},
volume={},
number={},
pages={2957-2966},
abstract={Some graph analyses, such as social network and biological network, need large-scale graph construction and maintenance over distributed memory space. Distributed data-streaming tools, including MapReduce and Spark, restrict some computational freedom of incremental graph modification and run-time graph visualization. Instead, we take an agent-based approach. We construct a graph from a scientific dataset in CSV, tab, and XML formats; dispatch many reactive agents on it; and analyze the graph in the form of their collective group behavior: propagation, flocking, and collision. The key to success is how to automate the run-time construction and visualization of agent-navigable graphs mapped over distributed memory. We implemented this distributed graph-computing support in the multi-agent spatial simulation (MASS) library, coupled with the Cytoscape graph visualization software. This paper presents the MASS implementation techniques and demonstrates its execution performance in comparison to MapReduce and Spark, using two benchmark programs: (1) an incremental construction of a complete graph and (2) a KD tree construction.},
keywords={Data visualization;XML;Big Data;Benchmark testing;Libraries;Biology;Sparks;multi-agent systems;agent-based modeling;data analysis;data visualization;parallel programming},
doi={10.1109/BigData50022.2020.9378298},
ISSN={},
month={Dec},}
@INPROCEEDINGS{4627291,
author={Picconi, Fabio and Massoulié, Laurent},
booktitle={2008 Eighth International Conference on Peer-to-Peer Computing},
title={Is There a Future for Mesh-Based live Video Streaming?},
year={2008},
volume={},
number={},
pages={289-298},
abstract={Peer-to-peer live streaming systems allow a bandwidth-constrained source to broadcast a video feed to a large number of users. In addition, a design with high link utilization can achieve high stream rates, supporting high-quality video. Until now, only tree-based designs have been shown to achieve close-to-optimal rates in real-life conditions, leaving the question open as to the attainable efficiency of completely unstructured mesh-based approaches. In this paper we answer that question by showing that a carefully-designed mesh-based system can achieve close-to-optimal stream rates. Specifically, we implement and evaluate a design based on a mesh-based algorithm called DP/LU. Contrary to tree-based designs, DP/LU uses an unstructured overlay, which is easier to construct and is highly resistant to churn. In addition, we introduce mechanisms for overlay rewiring and source scheduling that lead to significant performance improvements. Our experimental evaluation shows that our design achieves 95% of the maximum achievable stream rate in a static environment, and 90% under high churn. This demonstrates that mesh-based designs are an excellent choice for scalable and robust high-quality peer-to-peer live streaming.},
keywords={Peer to peer computing;Delay;Bandwidth;Streaming media;Algorithm design and analysis;Prototypes;Optimization;peer-to-peer;live streaming},
doi={10.1109/P2P.2008.18},
ISSN={2161-3567},
month={Sep.},}
@INPROCEEDINGS{6123478,
author={Ericson, Kathleen and Pallickara, Shrideep},
booktitle={2011 Fourth IEEE International Conference on Utility and Cloud Computing},
title={On the Performance of Distributed Clustering Algorithms in File and Streaming Processing Systems},
year={2011},
volume={},
number={},
pages={33-40},
abstract={There is often a need to cluster voluminous amounts of data. Such clustering has application in fields such as pattern recognition, data mining, bioinformatics, and recommendation systems. Here we evaluate the performance of 4 clustering algorithms viz. K-means, Fuzzy k-means, Dirichlet, and Latent Dirichlet Allocation within two different cloud runtimes: Hadoop and Granules. Our benchmarks use identical clustering code with both Hadoop and Granules. The difference between these implementations stem from how the Hadoop and Granules runtimes (1) support and manage the lifecycle of individual computations, and (2) how they orchestrate exchange of data between different stages of the computational pipeline during successive iterations of the clustering algorithm. We also include an analysis of our results for each of these clustering algorithms in a distributed setting.},
keywords={Clustering algorithms;Runtime;Algorithm design and analysis;Processor scheduling;Distributed databases;Pipelines;Semantics;Machine Learning;Distributed Stream Processing;Hadoop;Mahout;Clustering;Granules},
doi={10.1109/UCC.2011.15},
ISSN={},
month={Dec},}
@ARTICLE{1214318,
author={Krishnamurthy, R. and Schwan, K. and West, R. and Rosu, M.C.},
journal={IEEE Transactions on Parallel and Distributed Systems},
title={On network CoProcessors for scalable, predictable media services},
year={2003},
volume={14},
number={7},
pages={655-670},
abstract={This paper presents the embedded realization and experimental evaluation of a media stream scheduler on network interface (NI) CoProcessor boards. When using media frames as scheduling units, the scheduler is able to operate in real-time on streams traversing the CoProcessor, resulting in its ability to stream video to remote clients at real-time rates. This paper presents a detailed evaluation of the effects of placing application or kernel-level functionality, like packet scheduling on NIs, rather than the host machines to which they are attached. The main benefits of such placement are: 1) that traffic is eliminated from the host bus and memory subsystem, thereby allowing increased host CPU utilization for other tasks, and 2) that NI-based scheduling is immune to host-CPU loading, unlike host-based media schedulers that are easily affected even by transient load conditions. An outcome of this work is a proposed cluster architecture for building scalable media servers by distributing schedulers and media stream producers across the multiple NIs used by a single server and by clustering a number of such servers using commodity network hardware and software.},
keywords={Coprocessors;Streaming media;Network servers;Hardware;Network interfaces;Quality of service;Scalability;Scheduling algorithm;Multicast protocols;Ethernet networks},
doi={10.1109/TPDS.2003.1214318},
ISSN={1558-2183},
month={July},}
@INPROCEEDINGS{4664147,
author={Seibert, Jeff and Zage, David and Fahmy, Sonia and Nita-Rotaru, Cristina},
booktitle={2008 33rd IEEE Conference on Local Computer Networks (LCN)},
title={Experimental comparison of peer-to-peer streaming overlays: An application perspective},
year={2008},
volume={},
number={},
pages={20-27},
abstract={We compare two representative streaming systems using mesh-based and multiple tree-based overlay routing through deployments on the PlanetLab wide-area experimentation platform. To the best of our knowledge, this is the first study to compare streaming overlay architectures in real Internet settings, considering not only intuitive aspects such as scalability and performance under churn, but also less studied factors such as bandwidth and latency heterogeneity of overlay participants. Overall, our study indicates that mesh-based systems are superior for nodes with high bandwidth capabilities and low round trip times, while multi-tree based systems currently cope better with stringent real time deadlines under heterogeneous conditions.},
keywords={Peer to peer computing;Bandwidth;Throughput;Internet;Scalability;Streaming media;Pediatrics},
doi={10.1109/LCN.2008.4664147},
ISSN={0742-1303},
month={Oct},}
@INPROCEEDINGS{598075,
author={Malan, G.R. and Jahanian, F. and Knoop, P.},
booktitle={Proceedings of 17th International Conference on Distributed Computing Systems},
title={Comparison of two middleware data dissemination services in a wide-area distributed system},
year={1997},
volume={},
number={},
pages={411-419},
abstract={The paper provides an experimental comparison of two middleware data dissemination services: a distributed object based service, and a message based service. The paper compares these two services in the context of a common application: a wide area network collaboratory, namely the Upper Atmospheric Research Collaboratory (UARC). UARC is an example of an application that reliably streams data from a set of suppliers to a set of receivers. This comparison highlights the tradeoffs between ease of implementation and performance for a data streaming middleware service. By relying on a rigid language primitive, namely remote method invocation, the object based dissemination service gave up the control over its transport policies. In contrast, the lower level socket based service was specifically constructed to provide a flexible interface to its applications. This flexibility allowed the middleware to better support data delivery to a heterogeneous set of receivers. This is important in a wide area distributed system where hosts are connected together over a broad spectrum of network links. The paper provides a concrete example of the effects of high level design choices in the implementation of a wide area distributed system's communication middleware.},
keywords={Middleware;Collaborative work;Collaboration;Internet;Application software;Instruments;Context-aware services;Concrete;Biomedical imaging;Focusing},
doi={10.1109/ICDCS.1997.598075},
ISSN={1063-6927},
month={May},}
@INPROCEEDINGS{8621949,
author={Zacheilas, Nikos and Dedousis, Dimitris and Kalogeraki, Vana},
booktitle={2018 IEEE International Conference on Big Data (Big Data)},
title={Scalable Distributed Top-k Join Queries in Topic-Based Pub/Sub Systems},
year={2018},
volume={},
number={},
pages={378-383},
abstract={In this paper, we provide a novel approach that enables the execution of top-k join queries over sliding windows in a way that reduces the amount of data that need to be analyzed by the stream processing operators. The main idea is that brokers individually invoke the query on their received messages and forward the top-k results to a stream processing operator that performs the merging of the results and provides to the end-user the final top-k results. Moreover, our system exploits the Bayesian Optimization technique to determine automatically the number of top-k results that should be provided by each broker. Our approach has been developed in the Kappa architecture that exploits topic-based scalable publish/subscribe (pub/sub) systems like Apache Kafka to efficiently forward the high volume of incoming messages to distributed processing systems (i.e., Apache Spark or Apache Flink) that perform the batch and stream analytics operations. Our detailed experimental evaluation on our local cluster illustrates that we can efficiently execute top-k join queries on our system with high accuracy and low latency.},
keywords={Computer architecture;Big Data;Bayes methods;Optimization;Data dissemination;Microsoft Windows;Streaming media;pub/sub systems;stream processing;Kappa architecture;top-k joins},
doi={10.1109/BigData.2018.8621949},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8291931,
author={Wang, Yidan and Tari, Zahir and HoseinyFarahabady, M.Reza and Zomaya, Albert Y.},
booktitle={2017 IEEE 19th International Conference on High Performance Computing and Communications; IEEE 15th International Conference on Smart City; IEEE 3rd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)},
title={Model-Based Scheduling for Stream Processing Systems},
year={2017},
volume={},
number={},
pages={215-222},
abstract={Stream processing is emerging to react to the changing business situations of real-time processing. The main aim of this paradigm is to deal with the huge volume of data in the format of information flows originating from distributed devices. This consequently poses challenges to the scheduling problem in cloud data centers regarding the time-varying velocity of data ingesting and processing. In response to the uncertainties and complexities of streaming data, we propose a model-based scheduling scheme for stream processing systems, capturing the system behavior and providing an optimal allocation strategy to adapt to the changing work conditions. The proposed scheduling policy is implemented in Apache Storm, and micro-benchmarks with various shapes (e.g line, star, and diamond) were used in the evaluation. A topology that tracks trending topics on Twitter is also used, where the input is feeding with tweets in real-time. Experimental results show that the proposed solution can perform estimations that are well aligned with the system performance. The proposed scheduling policy achieves an improved performance with regards throughput and latency under varying ingesting rates.},
keywords={Mathematical model;Real-time systems;Throughput;Resource management;Computational modeling;Estimation;Analytical models;Streaming Data Processing;Resource Allocation/Scheduling;Apache Storm},
doi={10.1109/HPCC-SmartCity-DSS.2017.28},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9000079,
author={Bao, Liang and Liu, Xin and Xu, Ziheng and Fang, Baoyin},
booktitle={2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)},
title={AutoConfig: Automatic Configuration Tuning for Distributed Message Systems},
year={2018},
volume={},
number={},
pages={29-40},
abstract={Distributed message systems (DMSs) serve as the communication backbone for many real-time streaming data processing applications. To support the vast diversity of such applications, DMSs provide a large number of parameters to configure. However, It overwhelms for most users to configure these parameters well for better performance. Although many automatic configuration approaches have been proposed to address this issue, critical challenges still remain: 1) to train a better and robust performance prediction model using a limited number of samples, and 2) to search for a high-dimensional parameter space efficiently within a time constraint. In this paper, we propose AutoConfig - an automatic configuration system that can optimize producer-side throughput on DMSs. AutoConfig constructs a novel comparison-based model (CBM) that is more robust that the prediction-based model (PBM) used by previous learning-based approaches. Furthermore, AutoConfig uses a weighted Latin hypercube sampling (wLHS) approach to select a set of samples that can provide a better coverage over the high-dimensional parameter space. wLHS allows AutoConfig to search for more promising configurations using the trained CBM. We have implemented AutoConfig on the Kafka platform, and evaluated it using eight different testing scenarios deployed on a public cloud. Experimental results show that our CBM can obtain better results than that of PBM under the same random forests based model. Furthermore, AutoConfig outperforms default configurations by 215.40% on average, and five state-of-the-art configuration algorithms by 7.21%-64.56%.},
keywords={distributed message system;automatic configuration tuning;comparison-based model;weighted Latin hypercube sampling},
doi={10.1145/3238147.3238175},
ISSN={2643-1572},
month={Sep.},}
@INPROCEEDINGS{8488174,
author={Sampaio Gradvohl, Andre Leon},
booktitle={2018 6th International Conference on Future Internet of Things and Cloud Workshops (FiCloudW)},
title={Metrics and Tool for Evaluating Data Stream Processing Systems},
year={2018},
volume={},
number={},
pages={48-55},
abstract={With the Internet of Things and many other data sources continuously generating events, service providers who analyze these data need fast and flexible software. These software, called data stream processing systems, can be created from scratch or, as is more often the case today, use frameworks that already implement many of the functionality required for stream processing. In fact, programmers implement these software as distributed systems today because they need frameworks to deal with huge, fast and high throughput streams. That is the reason why a centralized system would hardly be able to handle data streams without eventually discarding some events. Therefore, it is important that, before putting a data stream processing system in production, we can simulate the scenarios that this system will handle and analyze its behavior. In this sense, this paper presents the general characteristics of the data stream processing systems, as well as some of the main metrics for the analysis of this sort of system. In addition, we present a new tool called B2-4DaSP that facilitates the task of analyzing data stream processing systems. We also illustrate some examples of the B2-4DaSP use for the analysis of two simple data stream applications.},
keywords={Measurement;Tools;Throughput;Benchmark testing;Computer architecture;Software;Time factors;data stream processing;metrics;benchmark},
doi={10.1109/W-FiCloud.2018.00014},
ISSN={},
month={Aug},}
@ARTICLE{9075192,
author={Nassif, Roula and Vlaski, Stefan and Richard, Cédric and Sayed, Ali H.},
journal={IEEE Open Journal of Signal Processing},
title={Learning Over Multitask Graphs—Part II: Performance Analysis},
year={2020},
volume={1},
number={},
pages={46-63},
abstract={Part I of this paper formulated a multitask optimization problem where agents in the network have individual objectives to meet, or individual parameter vectors to estimate, subject to a smoothness condition over the graph. A diffusion strategy was devised that responds to streaming data and employs stochastic approximations in place of actual gradient vectors, which are generally unavailable. The approach relied on minimizing a global cost consisting of the aggregate sum of individual costs regularized by a term that promotes smoothness. We examined the first-order, the second-order, and the fourth-order stability of the multitask learning algorithm. The results identified conditions on the step-size parameter, regularization strength, and data characteristics in order to ensure stability. This Part II examines steady-state performance of the strategy. The results reveal explicitly the influence of the network topology and the regularization strength on the network performance and provide insights into the design of effective multitask strategies for distributed inference over networks.},
keywords={Laplace equations;Aggregates;Stability analysis;Signal processing algorithms;Signal processing;Steady-state;Network topology;Multitask distributed inference;diffusion strategy;smoothness prior;graph Laplacian regularization;gradient noise;steady-state performance},
doi={10.1109/OJSP.2020.2989031},
ISSN={2644-1322},
month={},}
@ARTICLE{7091934,
author={Thomos, Nikolaos and Kurdoglu, Eymen and Frossard, Pascal and van der Schaar, Mihaela},
journal={IEEE Transactions on Multimedia},
title={Adaptive Prioritized Random Linear Coding and Scheduling for Layered Data Delivery From Multiple Servers},
year={2015},
volume={17},
number={6},
pages={893-906},
abstract={In this paper, we deal with the problem of jointly determining the optimal coding strategy and the scheduling decisions when receivers obtain layered data from multiple servers. The layered data is encoded by means of prioritized random linear coding (PRLC) in order to be resilient to channel loss while respecting the unequal levels of importance in the data, and data blocks are transmitted simultaneously in order to reduce decoding delays and improve the delivery performance. We formulate the optimal coding and scheduling decisions problem in our novel framework with the help of Markov decision processes (MDP), which are effective tools for modeling adapting streaming systems. Reinforcement learning approaches are then proposed to derive reduced computational complexity solutions to the adaptive coding and scheduling problems. The novel reinforcement learning approaches and the MDP solution are examined in an illustrative example for scalable video transmission . Our methods offer large performance gains over competing methods that deliver the data blocks sequentially. The experimental evaluation also shows that our novel algorithms offer continuous playback and guarantee small quality variations which is not the case for baseline solutions. Finally, our work highlights the advantages of reinforcement learning algorithms to forecast the temporal evolution of data demands and to decide the optimal coding and scheduling decisions .},
keywords={Receivers;Servers;Encoding;Decoding;Delays;Streaming media;Scheduling;Layered data;Markov decision processes (MDP);prioritized random linear codes (PRLC);Q-learning;rateless codes;virtual experience},
doi={10.1109/TMM.2015.2425228},
ISSN={1941-0077},
month={June},}
@INPROCEEDINGS{5569966,
author={Fortuna, R. and Leonardi, E. and Mellia, M. and Meo, M. and Traverso, S.},
booktitle={2010 IEEE Tenth International Conference on Peer-to-Peer Computing (P2P)},
title={QoE in Pull Based P2P-TV Systems: Overlay Topology Design Tradeoffs},
year={2010},
volume={},
number={},
pages={1-10},
abstract={This paper presents a systematic performance analysis of pull P2P video streaming systems for live applications, providing guidelines for the design of the overlay topology and the chunk scheduling algorithm. The contribution of the paper is threefold: (1) we propose a realistic simulative model of the system that represents the effects of access bandwidth heterogeneity, latencies, peculiar characteristics of the video, while still guaranteeing good scalability properties; (2) we propose a new latency/bandwidth-aware overlay topology design strategy that improves application layer performance while reducing the underlying transport network stress; (3) we investigate the impact of chunk scheduling algorithms that explicitly exploit properties of encoded video. Results show that our proposal jointly improves the actual Quality of Experience of users and reduces the cost the transport network has to support.},
keywords={Bandwidth;Streaming media;Topology;Peer to peer computing;Delay;Network topology;Scheduling algorithm},
doi={10.1109/P2P.2010.5569966},
ISSN={2161-3567},
month={Aug},}
@INPROCEEDINGS{5161036,
author={Schneider, Scott and Andrade, Henrique and Gedik, Bugra and Biem, Alain and Wu, Kun-Lung},
booktitle={2009 IEEE International Symposium on Parallel & Distributed Processing},
title={Elastic scaling of data parallel operators in stream processing},
year={2009},
volume={},
number={},
pages={1-12},
abstract={We describe an approach to elastically scale the performance of a data analytics operator that is part of a streaming application. Our techniques focus on dynamically adjusting the amount of computation an operator can carry out in response to changes in incoming workload and the availability of processing cycles. We show that our elastic approach is beneficial in light of the dynamic aspects of streaming workloads and stream processing environments. Addressing another recent trend, we show the importance of our approach as a means to providing computational elasticity in multicore processor-based environments such that operators can automatically find their best operating point. Finally, we present experiments driven by synthetic workloads, showing the space where the optimizing efforts are most beneficial and a radioastronomy imaging application, where we observe substantial improvements in its performance-critical section.},
keywords={Data analysis;Availability;Streaming media;Intelligent sensors;Runtime;Computer science;Performance analysis;Application software;Elasticity;Multicore processing},
doi={10.1109/IPDPS.2009.5161036},
ISSN={1530-2075},
month={May},}
@INPROCEEDINGS{9499550,
author={Mostafaei, Habib and Afridi, Shafi and Abawajy, Jemal H.},
booktitle={2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)},
title={SNR: Network-aware Geo-Distributed Stream Analytics},
year={2021},
volume={},
number={},
pages={820-827},
abstract={Emerging applications such as those running on the Internet of Things (IoT) devices produce constant data streams that need to be processed in real-time. Distributed stream processing systems (DSPs), with geographically distributed cluster networks interconnected via wide area network (WAN) links, have recently gained interest in handling these applications. How-ever, these applications have stringent requirements such as low-latency and high bandwidth that must be guaranteed to ensure the quality of service (QoS). These application requirements raise fundamental DSPs resource management and scheduling challenge. In this paper, we formulate the problem of placement of worker nodes on a geo-distributed DSPs cluster network as a multi-criteria decision-making problem and propose an additive weighting-based approach to solve it. The proposed solution finds the trade-off among different network parameters and allows executing the tasks according to the desired performance metrics. We evaluated the proposed approach using the Yahoo! streaming benchmark on a testbed and compare it against mechanisms deployed in Apache Spark, Apache Storm, and Apache Flink. The results of the evaluation show that our approach improves the performance of Spark up to 2.2x-7.2x, Storm up to 1.2x-3.4x, and Flink up to 1.4x-3.3x compared to other approaches, which makes our approach useful for use in practical environments.},
keywords={Wide area networks;Additives;Storms;Bandwidth;Quality of service;Benchmark testing;Topology;IoT;worker node placement;Geo-distributed analytics;Stream processing;Simple Additive Weighting},
doi={10.1109/CCGrid51090.2021.00100},
ISSN={},
month={May},}
@ARTICLE{4802361,
author={Liang, Chao and Guo, Yang and Liu, Yong},
journal={IEEE Transactions on Multimedia},
title={Investigating the Scheduling Sensitivity of P2P Video Streaming: An Experimental Study},
year={2009},
volume={11},
number={3},
pages={348-360},
abstract={Peer-to-peer (P2P) technology has recently been employed to deliver large scale video multicast services on the Internet. Considerable efforts have been made by both academia and industry on P2P streaming design. While academia mostly focus on exploring design space to approach the theoretical performance bounds, our recent measurement study on several commercial P2P streaming systems indicates that they are able to deliver good user quality of experience with seemingly simple designs. One intriguing question remains: how elaborate should a good P2P video streaming design be? Towards answering this question, we developed and implemented several representative P2P streaming designs, ranging from theoretically proved optimal designs to straightforward ldquonaiverdquo designs. Through an extensive comparison study on PlanetLab, we unveil several key factors contributing to the successes of simple P2P streaming designs, including system resource index, server capacity and chunk scheduling rule, peer download buffering and peering degree. We also identify regions where naive designs are inadequate and more elaborate designs can improve things considerably. Our study not only brings us better understandings and more insights into the operation of existing systems, it also sheds lights on the design of future systems that can achieve a good balance between the performance and the complexity.},
keywords={Streaming media;Job shop scheduling;Space exploration;Internet;Web server;Space technology;Large-scale systems;Network servers;Unicast;Delay;Peer-to-peer networks;scheduling;system design;video streaming},
doi={10.1109/TMM.2009.2012909},
ISSN={1941-0077},
month={April},}
@INPROCEEDINGS{6008898,
author={Mazur, Edward and Li, Boduo and Diao, Yanlei and Shenoy, Prashant},
booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum},
title={Towards Scalable One-Pass Analytics Using MapReduce},
year={2011},
volume={},
number={},
pages={1102-1111},
abstract={An integral part of many data-intensive applications is the need to collect and analyze enormous datasets efficiently. Concurrent with such application needs is the increasing adoption of MapReduce as a programming model for processing large datasets using a cluster of machines. Current MapReduce systems, however, require the data set to be loaded into the cluster before running analytical queries, and thereby incur high delays to start query processing. Furthermore, existing systems are geared towards batch processing. In this paper, we seek to answer a fundamental question: what architectural changes are necessary to bring the benefits of the MapReduce computation model to incremental, one-pass analytics, i.e., to support stream processing and online aggregation? To answer this question, we first conduct a detailed empirical performance study of current MapReduce implementations including Hadoop and MapReduce Online using a variety of workloads. By doing so, we identify several drawbacks of existing systems for one-pass analytics. Based on the insights from our study, we conclude by listing key design requirements and arguing for architectural changes of MapReduce systems to overcome their current limitations and fully embrace incremental one-pass analytics and showing promising preliminary results.},
keywords={Sorting;Computational modeling;Benchmark testing;Load modeling;Parallel processing;Fault tolerance;Fault tolerant systems},
doi={10.1109/IPDPS.2011.251},
ISSN={1530-2075},
month={May},}
@INPROCEEDINGS{874652,
author={Pechanek, G.G. and Vassiliadis, S.},
booktitle={Proceedings of the 26th Euromicro Conference. EUROMICRO 2000. Informatics: Inventing the Future},
title={The ManArray/sup TM/ embedded processor architecture},
year={2000},
volume={1},
number={},
pages={348-355 vol.1},
abstract={The BOPS(R) ManArray/sup TM/ architecture is presented as a scalable DAP platform for the embedded processor domain. In this domain, ManArray-based processors use a single architecture definition, that supports multiple configurations of processing elements (PEs) from low end single PE to large arrays of PEs, and single tool set. The ManArray (selectable) parallelism architecture mixes control oriented operations, VLIWs, packed data operations, and distributed array processing in a cohesive, independently selectable manner. In addition, scalable conditional execution and single-cycle communications across a high connectivity, low cost network are integrated in the architecture. This allows another level of selectivity that enhances the application of the parallel resources that enhances the application of the parallel resources to high performance algorithms. Coupled with the array DSP is a scalable DMA engine that runs in the background and provides programmer-selectable data-distribution patterns and a high-bandwidth data-streaming interface to system peripherals and global memory. This paper introduces the embedded scalable ManArray architecture and a number of benchmarks. For example, a standard ASIC flow DSP/coprocessor core, the BOPS2040, can process a distributed 256-point complex FFT in 425 cycles and an 8/spl times/8 2D IDCT that meets IEEE standards in 34 cycles.},
keywords={Computer architecture;Costs;Coprocessors;Digital signal processing;Decoding;USA Councils;Embedded computing;Communication system control;Array signal processing;Signal processing algorithms},
doi={10.1109/EURMIC.2000.874652},
ISSN={1089-6503},
month={Sep.},}
@ARTICLE{9300187,
author={Dubuc, Timothée and Stahl, Frederic and Roesch, Etienne B.},
journal={IEEE Access},
title={Mapping the Big Data Landscape: Technologies, Platforms and Paradigms for Real-Time Analytics of Data Streams},
year={2021},
volume={9},
number={},
pages={15351-15374},
abstract={The `Big Data' of yesterday is the `data' of today. As technology progresses, new challenges arise and new solutions are developed. Due to the emergence of Internet of Things applications within the last decade, the field of Data Mining has been faced with the challenge of processing and analysing data streams in real-time, and under high data throughput conditions. This is often referred to as the Velocity aspect of Big Data. Whereas there are numerous reviews on Data Stream Mining techniques and applications, there is very little work surveying Data Stream processing paradigms and associated technologies, from data collection through to pre-processing and feature processing, from the perspective of the user, not that of the service provider. In this article, we evaluate a particular type of solution, which focuses on streaming data, and processing pipelines that permit online analysis of data streams that cannot be stored as-is on the computing platform. We review foundational computational concepts such as distributed computation, fault-tolerant computing, and computational paradigms/architectures. We then review the available technological solutions, and applications that pertain to data stream mining as case studies of these theoretical concepts. We conclude with a discussion of the field of data stream processing/analytics, future directions and research challenges.},
keywords={Big Data;Business;Benchmark testing;Tools;Hardware;Task analysis;Measurement;Big data applications;Internet of Things (IoT);edge computing;distributed computing;pipeline processing},
doi={10.1109/ACCESS.2020.3046132},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8605759,
author={Weißbach, Manuel},
booktitle={2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC Companion)},
title={Live Traffic Data Analysis Using Stream Processing},
year={2018},
volume={},
number={},
pages={65-70},
abstract={The increasing digitalization in the traffic infrastructure offers a great potential to optimize traffic flows, to save costs, and to improve the CO2 balance. Achieving this requires the use of scalable, high-performance software environments that process live traffic data with minimal latency. However, there are no standard solutions that work out of the box. Instead, technology stacks of complex components must be assembled, configured, and deployed from a large and heterogeneous set of available building blocks. Since there are no guidelines on which particular software to use in which configuration for specific use cases, it is extremely difficult to build such complex architectures from scratch. Nevertheless, many application areas, including traffic data analysis, have domain-specific requirements, which makes it possible to close these gaps on the basis of further research. Following this idea, we analyze how typical applications of traffic data analysis can be implemented using stream processing technologies in order to find reusable solutions that can be used as blueprints for the design of applications with similar requirements. Therefore, a number of typical use cases will be analyzed, implemented and benchmarked on the basis of various stream processing architectures. This way, specific levers are to be found to systematically increase the performance. Our first results show significant performance differences between different software solutions and architectures.},
keywords={Computer architecture;Sparks;Data analysis;Software;Storms;Benchmark testing;Engines;benchmarking;live traffic analysis;streaming analytics;big data;mobile crowdsensing;stream processing},
doi={10.1109/UCC-Companion.2018.00036},
ISSN={},
month={Dec},}
@ARTICLE{7921687,
author={Baccarelli, Enzo and Naranjo, Paola G. Vinueza and Scarpiniti, Michele and Shojafar, Mohammad and Abawajy, Jemal H.},
journal={IEEE Access},
title={Fog of Everything: Energy-Efficient Networked Computing Architectures, Research Challenges, and a Case Study},
year={2017},
volume={5},
number={},
pages={9882-9910},
abstract={Fog computing (FC) and Internet of Everything (IoE) are two emerging technological paradigms that, to date, have been considered standing-alone. However, because of their complementary features, we expect that their integration can foster a number of computing and network-intensive pervasive applications under the incoming realm of the future Internet. Motivated by this consideration, the goal of this position paper is fivefold. First, we review the technological attributes and platforms proposed in the current literature for the standing-alone FC and IoE paradigms. Second, by leveraging some use cases as illustrative examples, we point out that the integration of the FC and IoE paradigms may give rise to opportunities for new applications in the realms of the IoE, Smart City, Industry 4.0, and Big Data Streaming, while introducing new open issues. Third, we propose a novel technological paradigm, the Fog of Everything (FoE) paradigm, that integrates FC and IoE and then we detail the main building blocks and services of the corresponding technological platform and protocol stack. Fourth, as a proof-of-concept, we present the simulated energy-delay performance of a small-scale FoE prototype, namely, the V-FoE prototype. Afterward, we compare the obtained performance with the corresponding one of a benchmark technological platform, e.g., the V-D2D one. It exploits only device-to-device links to establish inter-thing “ad hoc” communication. Last, we point out the position of the proposed FoE paradigm over a spectrum of seemingly related recent research projects.},
keywords={Cloud computing;Big Data;Edge computing;Biological system modeling;Ecosystems;Smart cities;Fog of IoE;virtualized networked computing platforms for IoE;context-aware networking-plus-computing distributed resource management;Internet of Energy;Smart City;Industry 4.0;Big Data Streaming;future Internet},
doi={10.1109/ACCESS.2017.2702013},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{4401052,
author={Bhattacharyya, Supratik and Madeira, Andre and Muthukrishnan, S. and Ye, Tao},
booktitle={2007 IEEE 23rd International Conference on Data Engineering Workshop},
title={How to scalably and accurately skip past streams},
year={2007},
volume={},
number={},
pages={654-663},
abstract={Data stream methods look at each new item of the stream, perform a small number of operations while keeping a small amount of memory, and still perform much-needed analyses. However, in many situations, the update speed per item is extremely critical and not every item can be extensively examined. In practice, this has been addressed by only examining every Nth item from the input; decreasing the input rate by a fraction 1/N. but resulting in loss of guarantees on the accuracy of the post-hoc analyses. In this paper, we present a technique of skipping past streams and looking at only a fraction of the input. Unlike traditional methods, our skipping is performed in a principled manner based on the "norm" of the stream seen. Using this technique on top of well-known sketches, we show several-fold improvement in the update time for processing streams with a given guaranteed accuracy, for a number of stream processing problems including data summarization, heavy hitters detection and self-join size estimation. We present experimental results of our methods over synthetic data and integrate our methods into Sprint's Continuous Monitoring (CMON) system for live network traffic analyses. Furthermore, aiming at future scalable stream processing systems and going beyond state-of-art packet header analyses, we show how the packet contents can be analyzed at streaming speeds, a more challenging task because each packet content can result in many updates.},
keywords={Performance analysis;Monitoring;Telecommunication traffic;IP networks;Face detection;State estimation;Fault diagnosis;Spine;Web and internet services;Inspection},
doi={10.1109/ICDEW.2007.4401052},
ISSN={},
month={April},}
@ARTICLE{8304764,
author={Ouyang, Peng and Yin, Shouyi and Liu, Leibo and Zhang, Youguang and Zhao, Weisheng and Wei, Shaojun},
journal={IEEE Transactions on Circuits and Systems I: Regular Papers},
title={A Fast and Power-Efficient Hardware Architecture for Visual Feature Detection in Affine-SIFT},
year={2018},
volume={65},
number={10},
pages={3362-3375},
abstract={Visual feature detection has been widely used in many computer vision applications, with increasing concern on feature robustness, processing speed, and power efficiency. In comparison with popular feature detection algorithms, affine-SIFT achieves the strongest robustness on the image illumination, image rotation, and image scale transformation, but exhibits extreme high computation complexity. To improve its computing efficiency, this work first proposes three hardware optimization methods to address three main performance bottlenecks. The first method is the reverse affine-based pipelined computing with optimized memory accessing. The second method is about stream processing with full parallel Gaussian pyramid. The third method is the rotation invariant binary pattern based feature vector generation. Then by incorporating these three optimization methods, this paper designs a high-efficient pipelined and parallel hardware architecture with optimized parallel memory accessing. Postlayout simulations using TSMC 65-nm 1P9M low power process show that this work achieves a processing speed of 97 fps at 1080p (1000 feature points per frame on average) under 200 MHz, with power consumption at 300 mW. In comparison, its computing efficiency (1005.6K pixels/s at 1 MHz) and power efficiency (670.5K pixels/s at 1 mW) are higher than state-of-the-art works and it is more promising for broad vision applications especially the embedded vision and mobile vision applications.},
keywords={Feature detection;Parallel architectures;Feature extraction;Optimization;Power demand;Computational complexity;Parallel architecture;binary pattern;affine computing;memory optimization},
doi={10.1109/TCSI.2018.2806447},
ISSN={1558-0806},
month={Oct},}
@INPROCEEDINGS{7516111,
author={Buddhika, Thilina and Pallickara, Shrideep},
booktitle={2016 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
title={NEPTUNE: Real Time Stream Processing for Internet of Things and Sensing Environments},
year={2016},
volume={},
number={},
pages={1143-1152},
abstract={Improvements in miniaturization and networking capabilities of sensors have contributed to the proliferation of Internet of Things (IoT) and continuous sensing environments. Data streams generated in such settings must keep pace with generation rates and be processed in real time. Challenges in accomplishing this include: high data arrival rates, buffer overflows, context-switches, and object creation overheads. We propose a holistic framework that addresses the CPU, memory, network, and kernel issues involved in stream processing. Our prototype, Neptune, builds on our Granules cloud runtime. The framework maximizes bandwidth utilization in the presence of small messages via the use of buffering and dynamic compactions of packets based on payload entropy. Our use of thread-pools and batched processing reduces context switches and improves effective CPU utilizations. NEPTUNE alleviates memory pressure that can lead to swapping, page faults, and thrashing through efficient reuse of objects. To cope with buffer overflows we rely on flow control and throttling the preceding stages of a processing pipeline. Our benchmarks demonstrate the suitability of the Neptune and we contrast our performance with Apache Storm, the dominant stream-processing framework developed by Twitter. At a single node, we are able to achieve a processing rate of ~2 million stream packets per-second. In a distributed setup, we achieved a rate of ~100 million packets per-second.},
keywords={Internet of things;Message systems;Throughput;Program processors;Real-time systems;Sensors;Bandwidth;Distributed stream processing;Internet-of-Things;High-throughput data processing},
doi={10.1109/IPDPS.2016.43},
ISSN={1530-2075},
month={May},}
@INPROCEEDINGS{7778638,
author={Hoseiny Farahabady, M. Reza and Dehghani Samani, Hamid R. and Wang, Yidan and Zomaya, Albert Y. and Tari, Zahir},
booktitle={2016 IEEE 15th International Symposium on Network Computing and Applications (NCA)},
title={A QoS-aware controller for Apache Storm},
year={2016},
volume={},
number={},
pages={334-342},
abstract={Apache Storm has recently emerged as an attractive fault-tolerant open-source distributed data processing platform that has been chosen by many industry leaders to develop real-time applications for processing a huge amount of data in a scalable manner. A key aspect to achieve the best performance in this system lies on the design of an efficient scheduler for component execution, called topology, on the available computing resources. In response to workload fluctuations, we propose an advanced scheduler for Apache Storm that provides improved performance with highly dynamic behavior. While enforcing the required Quality-of-Service (QoS) of individual data streams, the controller allocates computing resources based on decisions that consider the future states of non-controllable disturbance parameters, e.g. arriving rate of tuples or resource utilization in each worker node. The performance evaluation is carried out by comparing the proposed solution with two well-known alternatives, namely the Storm's default scheduler and the best-effort approach (i.e. the heuristic that is based on the first-fit decreasing approximation algorithm). Experimental results clearly show that the proposed controller increases the overall resource utilization by 31% on average compared to the two others solutions, without significant negative impact on the QoS enforcement level.},
keywords={Quality of service;Storms;Topology;Measurement;Resource management;Data processing;Throughput;Streaming Data Processing;Apache Storm;Model Predictive Control;Resource Allocation/Scheduling},
doi={10.1109/NCA.2016.7778638},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7577354,
author={Kritikakis, Charalabos and Chrysos, Grigorios and Dollas, Apostolos and Pnevmatikatos, Dionisios N.},
booktitle={2016 26th International Conference on Field Programmable Logic and Applications (FPL)},
title={An FPGA-based high-throughput stream join architecture},
year={2016},
volume={},
number={},
pages={1-4},
abstract={Stream join is a fundamental operation that combines information from different high-speed and high-volume data streams. This paper presents an FPGA-based architecture that maps the most performance-efficient stream join algorithm, i.e. ScaleJoin, to reconfigurable logic. The system was fully implemented on a Convey HC-2ex hybrid computer and the experimental performance evaluation shows that the proposed system outperforms by up to one order of magnitude the corresponding fully optimized parallel software-based solution running on a high-end 48-core multiprocessor platform. The proposed architecture can be used as a generic template for mapping stream processing algorithms to reconfigurable logic, taking into consideration real-world challenges.},
keywords={Field programmable gate arrays;stream processing;ScaleJoin;join operator;FPGA architecture},
doi={10.1109/FPL.2016.7577354},
ISSN={1946-1488},
month={Aug},}
@INPROCEEDINGS{5502540,
author={Chang, L. and Pan, J.},
booktitle={2010 IEEE International Conference on Communications},
title={On the System Parameters of Peer-to-Peer Video Streaming with Network Coding},
year={2010},
volume={},
number={},
pages={1-5},
abstract={Random linear network coding has been recently proved as a feasible solution to large-scale, peer-to-peer video dissemination over the Internet. In this paper, we use a simple analytical model to characterize and verify the efficiency of network coding in peer-to-peer video streaming systems. Several system parameters such as block size, server capacity, and peer aggressiveness are investigated with their influence on the system performance under flash crowd scenarios. Both our theoretical analysis and simulation results demonstrate that network coding can perform very close to the idealized scheduling algorithm for peer-to-peer video streaming.},
keywords={Peer to peer computing;Streaming media;Network coding;Analytical models;Large-scale systems;IP networks;Network servers;Web server;System performance;Performance analysis},
doi={10.1109/ICC.2010.5502540},
ISSN={1938-1883},
month={May},}
@INPROCEEDINGS{5488439,
author={Li, Runzhi and Qishi Wu and Yunyue Lin and Xukang Lu and Wang, Zongmin},
booktitle={2010 IEEE Network Operations and Management Symposium - NOMS 2010},
title={On topology construction in layered P2P live streaming networks},
year={2010},
volume={},
number={},
pages={599-606},
abstract={Peer-to-peer (P2P) overlay networks provide a highly effective and scalable solution to live media streaming systems that require the collective use of massively distributed network resources. A P2P media streaming architecture is typically built completely or partially upon a tree-structured network topology and the process of tree construction has a significant impact on the overall system performance. We build network cost models and formulate a specific type of topology construction problem, Maximum Average Bandwidth Spanning Tree (MABST), which aims at optimizing the system's average stream rate. We prove that MABST is NP-complete by reducing from Hamiltonian Path problem and propose an efficient heuristic algorithm. The performance superiority of the proposed algorithm is justified by experimental results using a live media streaming system deployed in real networks and is also illustrated by an extensive set of simulations on simulated networks of various sizes in comparison with other methods based on a degree constraint or a greedy strategy.},
keywords={Network topology;Streaming media;Bandwidth;Delay;System performance;Jitter;Measurement;Quality of service;Tree data structures;Buffer storage;P2P;NP-complete;spanning tree},
doi={10.1109/NOMS.2010.5488439},
ISSN={2374-9709},
month={April},}
@INPROCEEDINGS{7944930,
author={Jambi, Sahar and Anderson, Kenneth M.},
booktitle={2017 IEEE Third International Conference on Big Data Computing Service and Applications (BigDataService)},
title={Engineering Scalable Distributed Services for Real-Time Big Data Analytics},
year={2017},
volume={},
number={},
pages={131-140},
abstract={There is high demand for tools that analyze large sets of streaming data in both industrial and academic settings. While existing work has examined a wide range of issues, we focus on query support. In particular, we focus on providing analysts flexibility with respect to the types of queries they can make on large data sets in real time as well as over historical data. We have designed and implemented a lightweight service-based framework-EPIC Real-Time-that manages a set of queries that can be applied to user-initiated data analysis events (such as studying tweets generated during a disaster). Our prototype combines stream processing and batch processing techniques inspired by the Lambda Architecture. We investigate a core set of query types that can answer a wide range of queries asked by analysts who study crisis events. In this paper, we present a prototype implementation of EPIC Real-Time which makes use of event-driven and reactive programming techniques. We also present a performance evaluation on how efficiently the real-time and batch-oriented queries perform, how well these queries meet the needs of our analysts, and provide insight into how EPIC Real-Time performs along a number of dimensions including performance, usability, scalability, and reliability.},
keywords={Real-time systems;Big Data;Computer architecture;Twitter;Batch production systems;Software;Tools;social media analysis;lambda architecture;query support;crisis informatics},
doi={10.1109/BigDataService.2017.22},
ISSN={},
month={April},}
@INPROCEEDINGS{9464011,
author={Cermak, Milan and Celeda, Pavel},
booktitle={2021 IFIP/IEEE International Symposium on Integrated Network Management (IM)},
title={Stream-Based IP Flow Analysis},
year={2021},
volume={},
number={},
pages={736-741},
abstract={As the complexity of Internet services, transmission speed, and data volume increases, current IP flow monitoring and analysis approaches cease to be sufficient, especially within high-speed and large-scale networks. Although IP flows consist only of selected network traffic features, their processing faces high computational demands, analysis delays, and large storage requirements. To address these challenges, we propose to improve the IP flow monitoring workflow by stream-based collection and analysis of IP flows utilizing a distributed data stream processing. This approach requires changing the paradigm of IP flow data monitoring and analysis, which is the main goal of our research. We analyze distributed stream processing systems, for which we design a novel performance benchmark to determine their suitability for stream-based processing of IP flow data. We define a stream-based workflow of IP flow collection and analysis based on the benchmark results, which we also implement as a publicly available and open-source framework Stream4Flow. Furthermore, we propose new analytical methods that leverage the stream-based IP flow data processing approach and extend network monitoring and threat detection capabilities.},
keywords={Web and internet services;Distributed databases;Telecommunication traffic;Benchmark testing;Real-time systems;Delays;IP networks;Stream Processing;IP Flow;Stream4Flow},
doi={},
ISSN={1573-0077},
month={May},}
@INPROCEEDINGS{8778344,
author={Renart, Eduard Gibert and Balouek-Thomert, Daniel and Parashar, Manish},
booktitle={2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
title={An Edge-Based Framework for Enabling Data-Driven Pipelines for IoT Systems},
year={2019},
volume={},
number={},
pages={885-894},
abstract={Due to the proliferation of the Internet of Things (IoT) paradigm, the number of devices connected to the Internet is growing. These devices are generating unprecedented amounts of data at the edges of the infrastructure. Although the generated data provides great potential, identifying and processing relevant data points hidden in streams of unimportant data, and doing this in near real time, remains a significant challenge. Existing stream processing platforms require the data to be transported to the cloud for processing, resulting in latencies that can prevent timely decision making or may reduce the amount of data processed. To tackle this problem, we designed an IoT Edge Framework, called R-Pulsar, that extends cloud capabilities to local devices and provides a programming model for deciding what, when, and where data get collected and processed. In this paper, we discuss motivating use cases and the architectural design of R-Pulsar. We have deployed and tested R-Pulsar on embedded devices (Raspberry Pi and Android phone) and present an experimental evaluation that demonstrates that R-Pulsar can enable timely data analytics by effectively leveraging edge and cloud resources.},
keywords={Cloud computing;Internet of Things;Programming;Sensors;Task analysis;Cameras;Real-time systems;Edge Computing;Stream Processing;Edge analytics;Big Data},
doi={10.1109/IPDPSW.2019.00146},
ISSN={},
month={May},}
@INPROCEEDINGS{5695617,
author={Ferreira, Heitor and Duarte, Sergio and Preguiça, Nuno},
booktitle={2010 IEEE 16th International Conference on Parallel and Distributed Systems},
title={4Sensing -- Decentralized Processing for Participatory Sensing Data},
year={2010},
volume={},
number={},
pages={306-313},
abstract={Participatory Sensing is an emerging application paradigm that leverages the growing ubiquity of sensor-capable smart phones to allow communities carry out wide-area sensing tasks, as a side-effect of people's everyday lives and movements. This paper proposes a decentralized infrastructure for supporting Participatory Sensing applications. It describes an architecture and a domain specific programming language for modeling, prototyping and developing the distributed processing of participatory sensing data with the goal of allowing faster and easier development of these applications. Moreover, a case-study application is also presented as the basis for an experimental evaluation.},
keywords={Roads;Sensors;Peer to peer computing;Mobile communication;Aggregates;Pipelines;Computer architecture;Participatory Sensing;decentralized processing;data streaming;mobile computing},
doi={10.1109/ICPADS.2010.20},
ISSN={1521-9097},
month={Dec},}
@ARTICLE{9537919,
author={Jin, Leilei and Fu, Wenjie and Ling, Ming and Shi, Longxing},
journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
title={A Fast Cross-Layer Dynamic Power Estimation Method by Tracking Cycle-Accurate Activity Factors With Spark Streaming},
year={2022},
volume={30},
number={4},
pages={353-364},
abstract={The advent of autonomous power-limited systems poses a new challenge for early design space exploration. The existing architecture-level power evaluation tools lose accuracy due to ignoring features of circuit-level behaviors and influences of process, voltage, and temperature variations. Although power estimations based on SPICE or PrimeTime PX (PTPX) are accurate enough, they come at the cost of long simulation time and are available only in very late phases of design flow. In this article, a fast and accurate dynamic power evaluation method is proposed, which estimates activity factors at the circuit level. The impact of process variation at the gate level is considered through the proposed effective capacitance model. Activity factors are then estimated by the model and input vectors of the circuit. Input vectors are generated by architecture-level simulations in the form of streaming. For real-time and high-speed power evaluation, a data streaming framework is proposed for massive parallelism. The cross-layer estimation is verified based on the functional units of PULPino processor running SPEC CPU2006 benchmarks. Compared with the SPICE results using SMIC 28-nm PDK, our cycle-by-cycle dynamic power analysis shows an average error of 5.4%. Meanwhile, our approach realizes 65.2% faster than the traditional PTPX simulation and 48.8% faster compared with the state-of-art cross-level evaluation method.},
keywords={Capacitance;Logic gates;Integrated circuit modeling;Estimation;Real-time systems;Tools;Power demand;Activity factor;dynamic power;effective capacitance estimation;process variations;worse case power estimation},
doi={10.1109/TVLSI.2021.3111000},
ISSN={1557-9999},
month={April},}
@ARTICLE{8356092,
author={Gao, Lin and Tang, Ming and Pang, Haitian and Huang, Jianwei and Sun, Lifeng},
journal={IEEE Transactions on Mobile Computing},
title={Multi-User Cooperative Mobile Video Streaming: Performance Analysis and Online Mechanism Design},
year={2019},
volume={18},
number={2},
pages={376-389},
abstract={Adaptive bitrate streaming enables video users to adapt their playing bitrates to the real-time network conditions, hence achieving the desirable quality-of-experience (QoE). In a multi-user wireless scenario, however, existing single-user based bitrate adaptation methods may fail to provide the desirable QoE, due to lack of consideration of multi-user interactions (such as the multi-user interferences and network congestion). In this work, we propose a novel user cooperation framework based on user-provided networking for multi-user mobile video streaming over wireless cellular networks. The framework enables nearby mobile video users to crowdsource their cellular links and resources for cooperative video streaming. We first analyze the social welfare performance bound of the proposed cooperative streaming system by introducing a virtual time-slotted system. Then, we design a low complexity Lyapunov-based online algorithm, which can be implemented in an online and distributed manner without the complete future and global network information. Numerical results show that the proposed online algorithm achieves an average 97 percent of the theoretical maximum social welfare. We further conduct experiments with real data traces, to compare our proposed online algorithm with the existing online algorithms in the literature. Experiment results show that our algorithm outperforms the existing algorithms in terms of both the achievable bitrate (with an average gain of 20 $\sim$ 30 percent) and social welfare (with an average gain of 10 $\sim$ 50 percent).},
keywords={Streaming media;Bit rate;Quality of experience;Internet;Device-to-device communication;Smart phones;Real-time systems;Mobile video streaming;adaptive bitrate;mobile crowdsourcing;online algorithm},
doi={10.1109/TMC.2018.2834358},
ISSN={1558-0660},
month={Feb},}
@INPROCEEDINGS{7022741,
author={Ploennigs, Joern and Chen, Bei and Palmes, Paulito and Lloyd, Raymond},
booktitle={2014 IEEE International Conference on Data Mining Workshop},
title={e2-Diagnoser: A System for Monitoring, Forecasting and Diagnosing Energy Usage},
year={2014},
volume={},
number={},
pages={1231-1234},
abstract={We propose e2-Diagnoser, a real-time data mining system for the energy management of smart, sensor-equipped buildings. The main features of e2-Diagnoser are: (i) fast extraction of a large portfolio of buildings' benchmarks at multiple places, and (ii) accurate prediction of buildings' energy usage down to sub meter level to detect and diagnose abnormal energy consumptions. Fundamentally, the e2-Diagnoser system is built on a novel statistical learning algorithm using the Generalized Additive Model (GAM) to simultaneously monitor the mean and variation of the energy usage as well as identify the influencing factors such as weather conditions. Its implementation is based on stream processing platform that integrates data from various sources using semantic web technologies and provides an interactive user interface to visualize results. The platform is scalable and can be easily adapted to other applications such as smart-grid networks. Here we describe the architecture, methodology, and show the web-interface to demonstrate the main functions in the e2-Diagnoser.},
keywords={Buildings;Data mining;Energy consumption;Data models;Benchmark testing;Portfolios;Meteorology;Energy Prediction;Smart Buildings;Building Benchmark;Pattern Extraction},
doi={10.1109/ICDMW.2014.56},
ISSN={2375-9259},
month={Dec},}
@INPROCEEDINGS{8119202,
author={Steffl, Samuel and Reda, Sherief},
booktitle={2017 IEEE International Conference on Computer Design (ICCD)},
title={LACore: A Supercomputing-Like Linear Algebra Accelerator for SoC-Based Designs},
year={2017},
volume={},
number={},
pages={137-144},
abstract={Linear algebra operations are at the heart of scientific computing solvers, machine learning and artificial intelligence. In this paper, LACore, a novel, programmable accelerator architecture for general-purpose linear algebra applications, is presented. LACore enables many of the architectural features typically available in custom supercomputing machines in an accelerator form factor that can be deployed in System-On-a-Chip (SoC) based designs. LACore has several architectural features including heterogeneous data-streaming LAMemUnits, a configurable systolic datapath that supports scalar, vector and multi-stream output modes, and a decoupled architecture that overlap memory transfer and execution. To evaluate LACore, we implemented its architecture as an extension to the RISC-V ISA in the gem5 cycle-accurate simulator. The LACore ISA was implemented in gcc, and a C-programming software framework, the LACoreAPI, has been developed for high-level programming of the LACore. Using the HPCC benchmark suite, we compare our LACore architecture against three other platforms: an in-order RISC-V CPU, a superscalar x86 CPU with SSE2, and a scaled NVIDIA Fermi GPU. The LACore outperforms the superscalar x86 processor in the benchmark suite by an average of 3.43x, and outperforms the scaled Fermi GPU by an average of 12.04x, within the same or less design area.},
keywords={Graphics processing units;Linear algebra;Registers;Benchmark testing;Memory management;Instruction sets;Linear Algebra;Heterogeneous Computing;Accelerator Architectures},
doi={10.1109/ICCD.2017.29},
ISSN={1063-6404},
month={Nov},}
@INPROCEEDINGS{6187557,
author={Ravishankar, Chirag and Ananthanarayanan, Sundaram and Garg, Siddharth and Kennings, Andrew},
booktitle={Thirteenth International Symposium on Quality Electronic Design (ISQED)},
title={Analysis and evaluation of greedy thread swapping based dynamic power management for MPSoC platforms},
year={2012},
volume={},
number={},
pages={617-624},
abstract={Thread migration (TM) is a recently proposed dynamic power management technique for heterogeneous multi-processor system-on-chip (MPSoC) platforms that eliminates the area and power overheads incurred by fine-grained dynamic voltage and frequency scaling (DVFS) based power management. In this paper, we take the first step towards formally analyzing and experimentally evaluating the use of power-aware TM for parallel data streaming applications on MPSoC platforms. From an analysis perspective, we characterize the optimal mapping of threads to cores and prove the convergence properties of a complexity effective greedy thread swapping based TM algorithm to the globally optimal solution. The proposed techniques are evaluated on a 9-core FPGA based MPSoC prototype equipped with fully-functional TM and DVFS support, and running a parallelized video encoding benchmark based on the Motion Picture Experts Group (MPEG-2) standard. Our experimental results validate the proposed theoretical analysis, and show that the proposed TM algorithm provides within 8% of the DVFS performance under the same power budget, and assuming no overheads for DVFS. Assuming voltage regulator inefficiency of 80%, the proposed TM algorithm has 9% higher performance than DVFS, again under the same total power budget.},
keywords={Instruction sets;Throughput;Field programmable gate arrays;Prototypes;Heuristic algorithms;Computational modeling;Multicore processing;Power management;Thread migration;DVFS;Multi-core;FPGA},
doi={10.1109/ISQED.2012.6187557},
ISSN={1948-3295},
month={March},}
@INPROCEEDINGS{7502952,
author={Čermák, Milan and Jirsík, Tomáš and Laštovička, Martin},
booktitle={NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium},
title={Real-time analysis of NetFlow data for generating network traffic statistics using Apache Spark},
year={2016},
volume={},
number={},
pages={1019-1020},
abstract={In this paper, we present a framework for the real-time generation of network traffic statistics on Apache Spark Streaming, a modern distributed stream processing system. Our previous results showed that stream processing systems provide enough throughput to process a large volume of NetFlow data and hence they are suitable for network traffic monitoring. This paper describes the integration of Apache Spark Streaming into a current network monitoring architecture. We prove that it is possible to implement the same basic methods for NetFlow data analysis in the stream processing framework as in the traditional ones. Moreover, our stream processing implementation discovers new information which is not available when using traditional network monitoring approaches.},
keywords={Sparks;Monitoring;Data analysis;Real-time systems;Computer architecture;Probes;Benchmark testing},
doi={10.1109/NOMS.2016.7502952},
ISSN={2374-9709},
month={April},}
@ARTICLE{7160761,
author={Vaidya, Pranav S. and Lee, John Jaehwan and Pai, Vijay S. and Lee, Miyoung and Hur, Sungjin},
journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
title={Symbiote Coprocessor Unit—A Streaming Coprocessor for Data Stream Acceleration},
year={2016},
volume={24},
number={3},
pages={813-826},
abstract={This paper describes the design and the architecture of symbiote coprocessor unit (SCU)—a programmable streaming coprocessor for a heterogeneous reconfigurable logic-assisted data stream management systems (DSMSs) such as symbiote. The SCU is intended for streaming applications with real-time event and data processing that have stricter deadlines, high-bandwidth, and high-accuracy requirements. To meet these requirements, the SCU exploits unique characteristics of DSMSs, such as single-pass tuple processing, windowed operators, and inherent data level parallelism, using a single-instruction multiple-data very large instruction word (SIMD-VLIW) microarchitecture and a novel inverted distributed register file. In order to better explain the instruction set, design, and functionality of the various units in the SCU, this paper also provides a brief overview of SymQL—a procedural query language that we developed to describe the queries that can be executed on the SCU. Finally, this paper presents the performance of SCU using four queries that represent common data stream processing use-cases, one of them being similar to a query found in the Linear Road Benchmark. Using these queries on SCU simulation, we show that the SCU outperforms a software-only DSMS running on an AMD Opteron 2350 quad-core processor by 1.5–42 times.},
keywords={Program processors;Accelerators;Registers;Organizations;Coprocessors;Field programmable gate arrays;Computer architecture;Coprocessor accelerators;data stream management systems (DSMSs);heterogeneous computing;system architectures.;Coprocessor accelerators;data stream management systems (DSMSs);heterogeneous computing;system architectures},
doi={10.1109/TVLSI.2015.2432063},
ISSN={1557-9999},
month={March},}
@INPROCEEDINGS{4741191,
author={Noh, Jeonghun and Deshpande, Sachin},
booktitle={2008 Tenth IEEE International Symposium on Multimedia},
title={Pseudo-DHT: Distributed Search Algorithm for P2P Video Streaming},
year={2008},
volume={},
number={},
pages={348-355},
abstract={In this paper, we propose pseudo-DHT, an efficient resource location algorithm in peer-to-peer (P2P) streaming systems. A lookup overlay formed by participating peers provides a foundation for pseudo-DHT's register (key, value) and retrieve (key) services. Using pseudo-DHT, peers register their video contents information (key) with their network identity (value). To reduce retrieval latency, register (ldr) performs the alteration of a given key on a key collision. For retrieve (ldr), a query for a key returns a value associated with the key or a key closest to the key. We apply pseudo-DHT to P2TSS, a P2P system that provides both live and time-shifted streams. In P2TSS, a live video is divided and spread out in peers' buffers. Peers construct a chord overlay that serves as the base of pseudo-DHT. A theoretical analysis is presented to predict the search performance of P2TSS with pseudo-DHT. Extensive simulations show that our pseudo-DHT provides good scalability and low overhead, matching our analysis.},
keywords={Streaming media;Information retrieval;USA Councils;Peer to peer computing;Delay;Performance analysis;Multimedia systems;Laboratories;Analytical models;Scalability;Peer-to-peer;DHT;time-shifted stream;live video stream;distributed search},
doi={10.1109/ISM.2008.57},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9610303,
author={Kang, Peng and Lama, Palden and Khan, Samee U.},
booktitle={2021 IEEE International Conference on Cloud Engineering (IC2E)},
title={SLO-aware Virtual Rebalancing for Edge Stream Processing},
year={2021},
volume={},
number={},
pages={126-135},
abstract={The Internet of Things (IoT) has enabled an abundance of geographically distributed physical devices or “things” equipped with sensors and actuators to exchange information with the Cloud. However, this paradigm remains largely under-exploited for real-time analytic applications. The benefit of realtime data acquisition at the Edge becomes fruitless as it is not readily accessible to more powerful data analytic tools in the Cloud due to wide-area network delays. In this paper, we present VRebalance, a virtual resource orchestrator that provides an end-to-end performance guarantee for concurrent stream processing workloads at the Edge. VRebalance employs Bayesian Optimization $\mathcal{BO}$ to quickly identify near-optimal resource configurations. Experimental results with a real-time open-source IoT benchmark for Distributed Stream Processing Platforms (RIoTBench) and a representative stream processing engine (Apache Storm) demonstrate the superior performance, resource efficiency and adaptiveness of our $\mathcal{BO}$-based resource management system. VRebalance meets the performance SLO (service level objective) targets for stream processing workloads even in the presence of acute system dynamics. It decreases the SLO violation rate by at least 34% for static workloads and by 62.5% for dynamic workloads compared to a hill climbing method. Compared to Storm's default resource scaling mechanism, our method decreases the SLO violation rate by 83.7%.},
keywords={Cloud computing;Storms;System dynamics;Tools;Real-time systems;Sensors;Internet of Things;Internet of Things;Stream Processing;Bayesian Optimization;Resource Management},
doi={10.1109/IC2E52221.2021.00027},
ISSN={},
month={Oct},}
@INPROCEEDINGS{5963582,
author={Oiki, Tomoaki and Suzumura, Toyotaro},
booktitle={2011 IEEE International Conference on Communications Workshops (ICC)},
title={Tonegawa: Highly Scalable Distributed Web Server with Data Stream Processing},
year={2011},
volume={},
number={},
pages={1-5},
abstract={We developed Tonegawa, which is a distributed Web server on top of a stream processing system called System S under development by IBM Research. Tonegawa takes staged execution approach and a web request is processed over multiple stages, each of which can be processed by one multi-core node or even distributed to a cluster of nodes. We conducted the performance evaluation of Tonegawa with the use of both static contents and dynamic contents, and showed that Tonegawa on multiple nodes can be utilized in the case where large computational effort is required. In addition, we demonstrated the qualitative software productivity with regards to the implementation of a web server using such a stream-style programming, which decreases potential bugs and brings highly extensibility to the system.},
keywords={Web servers;Throughput;Load management;Computer architecture;Context;Instruction sets},
doi={10.1109/iccw.2011.5963582},
ISSN={2164-7038},
month={June},}
@INPROCEEDINGS{9150458,
author={Guo, Jia and Agrawal, Gagan},
booktitle={2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
title={Smart Streaming: A High-Throughput Fault-tolerant Online Processing System},
year={2020},
volume={},
number={},
pages={396-405},
abstract={In recent years, there has been considerable interest in developing frameworks for processing streaming data. Like the precursor commercial systems for data-intensive processing, these systems have largely not used methods popular within the HPC community (for example, MPI for communication). In this paper, we demonstrate a system for stream processing that offers a high-level API to the users (similar to MapReduce), is fault-tolerant, and is also more efficient and scalable than current solutions. Particularly, a cost-efficient MPI/OpenMP based fault-tolerant scheme is incorporated so that the system can survive node failures with only a modest degradation of performance. We evaluate both the functionality and efficiency of Smart Streaming using four common applications in machine learning and data analytics. A comparison against state-of-the-art streaming frameworks shows our system boosts the throughput of test cases by up to 10X and achieve desirable parallelism when scaled out. Additionally, the performance loss upon failures is only proportional to the share of failed resources.},
keywords={Fault tolerance;Fault tolerant systems;Sparks;Throughput;Data analysis;Real-time systems;Machine learning},
doi={10.1109/IPDPSW50202.2020.00075},
ISSN={},
month={May},}
@INPROCEEDINGS{9932034,
author={Michael, Panayiotis A. and Tsanakas, Panayiotis D. and Parker, D. S.},
booktitle={2022 IEEE/ACM 26th International Symposium on Distributed Simulation and Real Time Applications (DS-RT)},
title={Blue Danube: A Large-Scale, End-to-End Synchronous, Distributed Data Stream Processing Architecture for Time-Sensitive Applications},
year={2022},
volume={},
number={},
pages={39-48},
abstract={An extensive list of time-sensitive applications requiring ultra-low latency ranging from a few microseconds to a few milliseconds are presented in recent publications and IEEE standards. Time-sensitive applications, include industrial, critical healthcare and transportation applications as also applications for Smart Grids and the Internet of Vehicles – one of the most active research fields of Intelligent Transportation Systems of Smart Cities. In this work, we mainly set our focus on the suite of safety applications which attracts strong interest from the research community, as it aims to avoid road accidents and save lives. The IEEE Time-Sensitive Networking (TSN) set of standards specifies fundamental real-time characteristics. Nevertheless, as TSN works on Data Link layer (Layer 2 of the OSI model) the benefits of these characteristics fade away when other layers are crossed from the Application layer (Layer 7). Indicatively, recent research works report latencies on the order of tens of seconds when benchmarking Data Stream Processing and IoT platforms, and thus they are not suited for time-critical applications. Such platforms mainly use loosely coupled components with asynchronous communication. On Application layer, we propose a novel End-to-End Synchronous, Distributed Architecture for Large-Scale, High-Bandwidth, Ultra-Low Latency Data Stream Processing. Through our Big Data Stream analysis experiments (4.7 Gbit/s total average aggregated throughput, 1 Terabyte in-memory distributed database, 4 milliseconds average query latency) we have demonstrated the suitability of our architecture for time-sensitive applications such as accident avoidance for the Internet of Vehicles.},
keywords={Distributed databases;Transportation;Open systems;Big Data;Throughput;Real-time systems;Data models;synchronous;data stream processing;end-to-end synchronous;time-sensitive applications;time-critical applications;ultra-low latency;Internet-of-Things;Intelligent Transportation Systems;Internet of Vehicles;Smart Cities},
doi={10.1109/DS-RT55542.2022.9932034},
ISSN={1550-6525},
month={Sep.},}
@INPROCEEDINGS{8889581,
author={Milovanović, V. M. and Petrović, M. L.},
booktitle={2019 IEEE 31st International Conference on Microelectronics (MIEL)},
title={A Highly Parametrizable Chisel HCL Generator of Single-Path Delay Feedback FFT Processors},
year={2019},
volume={},
number={},
pages={247-250},
abstract={A configurable fast Fourier transform (FFT) engines and their inverse counterparts are indispensable in modern wireless communication and radar systems. The FFT processors are usually customized per use case. Therefore, a design generator of single-path delay feedback type of an FFT processor, that permits continuous input and output data streaming has been captured inside Chisel hardware construction language. It supports a wide range of parameter settings, like input data and twiddle factor widths, FFT sizes and number of stages, three radices, different scaling and rounding methods after each butterfly or dragonfly stage, among others, thus enabling an agile design space exploration. A comparison with commercially available FFTs which were specifically tailored for the particular FPGA platforms proves that FFT generator instances can be both performance-and resource-competitive with state of the art designs.},
keywords={Generators;Delays;Hardware;Registers;Program processors;Libraries;Field programmable gate arrays},
doi={10.1109/MIEL.2019.8889581},
ISSN={2159-1679},
month={Sep.},}
@INPROCEEDINGS{8914227,
author={Ndubuaku, Maryleen and Anjum, Ashiq and Liotta, Antonio},
booktitle={2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)},
title={Cloud-assisted Adaptive Stream Processing from Discriminative Representations},
year={2019},
volume={},
number={},
pages={164-169},
abstract={As the streaming data generated by Internet of Things (IoT) ubiquitous sensors grow in massive scale, extracting interesting information (anomalies) in real-time becomes more challenging. Traditional systems which retrospectively perform all the processing in the cloud do not capture real-time changes in the data. Similarly, real-time solutions which rely on human monitors have the tendency to miss the anomalies due to their rare nature. In recent times, several machine learning techniques have been proposed for stream processing. Approaches based on supervised or semi-supervised learning fail to adapt to changing patterns of the streaming data and the data labelling costs are huge. To address these limitations, we propose a cloud-assisted framework where an intermediary node (edge) is introduced between the end devices and the cloud to assist in stream processing. A model deployed on the edge is designed to learn in an iterative manner to discriminate between similar and dissimilar data representations, making it easier to distinguish the anomalies. In this work, we have proposed an iterative method that combines the capabilities of deep clustering and l2-normalisation to achieve better discriminative representations. Experimental results demonstrate the proposed method achieves robust performance over state-of-the-art discriminative representation algorithms and sets new benchmark accuracy on transformation invariant image dataset.},
keywords={Real-time systems;Training;Data mining;Adaptation models;Data models;Pipelines;Task analysis},
doi={10.1109/SMC.2019.8914227},
ISSN={2577-1655},
month={Oct},}
@ARTICLE{9099971,
author={KhudaBukhsh, Wasiur R. and Kar, Sounak and Alt, Bastian and Rizk, Amr and Koeppl, Heinz},
journal={IEEE Transactions on Parallel and Distributed Systems},
title={Generalized Cost-Based Job Scheduling in Very Large Heterogeneous Cluster Systems},
year={2020},
volume={31},
number={11},
pages={2594-2604},
abstract={We study job assignment in large, heterogeneous resource-sharing clusters of servers with finite buffers. This load balancing problem arises naturally in today's communication and big data systems, such as Amazon Web Services, Network Service Function Chains, and Stream Processing. Arriving jobs are dispatched to a server, following a load balancing policy that optimizes a performance criterion such as job completion time. Our contribution is a randomized Cost-Based Scheduling (CBS) policy in which the job assignment is driven by general cost functions of the server queue lengths. Beyond existing schemes, such as the Join the Shortest Queue (JSQ), the power of d or the SQ(d) and the capacity-weighted JSQ, the notion of CBS yields new application-specific policies such as hybrid locally uniform JSQ. As today's data center clusters have thousands of servers, exact analysis of CBS policies is tedious. In this article, we derive a scaling limit when the number of servers grows large, facilitating a comparison of various CBS policies with respect to their transient as well as steady state behavior. A byproduct of our derivations is the relationship between the queue filling proportions and the server buffer sizes, which cannot be obtained from infinite buffer models. Finally, we provide extensive numerical evaluations and discuss several applications including multi-stage systems.},
keywords={Scheduling;Load management;Load modeling;Cost function;Data centers;Performance evaluation;Job scheduling;performance evaluation;mean-field limit},
doi={10.1109/TPDS.2020.2997771},
ISSN={1558-2183},
month={Nov},}
@INPROCEEDINGS{4595868,
author={Liang, Chao and Guo, Yang and Liu, Yong},
booktitle={2008 The 28th International Conference on Distributed Computing Systems},
title={Is Random Scheduling Sufficient in P2P Video Streaming?},
year={2008},
volume={},
number={},
pages={53-60},
abstract={Peer-to-peer (P2P) has recently been employed to deliver large scale video multicast services on the Internet. Considerable efforts have been made by both academia and industry on P2P streaming design. While academia mostly focus on exploring design space to approach the theoretical performance bounds, our recent measurement study on several commercial P2P streaming systems indicates that they are able to deliver good user quality of experience with seemingly simple designs. One intriguing question remains: how elaborate should a good P2P video streaming design be? Towards answering this question, we developed and implemented several representative P2P streaming designs, ranging from theoretically proved optimal designs to straight forward "naive" designs. Through an extensive comparison study on PlanetLab, we unveil several key factors contributing to the successes of simple P2P streaming designs, including system resource index, sever capacity and chunk scheduling rule, peer download buffering and peering degree. We also identify regions where naive designs are inadequate and more elaborate designs can improve things considerably. Our study not only brings us better understandings and more insights into the operation of existing systems, it also sheds lights on the design of future systems that can achieve a good balance between the performance and the complexity.},
keywords={Servers;Peer to peer computing;Streaming media;Bandwidth;Indexes;Optimal scheduling;Delay;peer-to-peer;scheduling;streaming},
doi={10.1109/ICDCS.2008.103},
ISSN={1063-6927},
month={June},}
@ARTICLE{5361399,
author={Liu, Yong},
journal={IEEE/ACM Transactions on Networking},
title={Delay Bounds of Chunk-Based Peer-to-Peer Video Streaming},
year={2010},
volume={18},
number={4},
pages={1195-1206},
abstract={Peer-to-peer (P2P) systems exploit the uploading bandwidth of individual peers to distribute content at low server cost. While the P2P bandwidth sharing design is very efficient for bandwidth-sensitive applications, it imposes a fundamental performance constraint for delay-sensitive applications: The uploading bandwidth of a peer cannot be utilized to upload a piece of content until it completes the download of that content. This constraint sets up a limit on how fast a piece of content can be disseminated to all peers in a P2P system. In this paper, we theoretically study the impact of this inherent delay constraint and derive the minimum delay bounds for P2P live streaming systems. We show that the bandwidth heterogeneity among peers can be exploited to significantly improve the delay performance of all peers. We further propose a conceptual snowball streaming algorithm to approach the minimum delay bound in a dynamic P2P networking environment. Our analysis and simulation suggest that the proposed algorithm has better delay performance and more robust than static balanced multi-tree-based streaming solutions. Insights brought forth by our study can be used to guide the design of new P2P systems with shorter streaming delays.},
keywords={Delay;Peer to peer computing;Streaming media;Bandwidth;Costs;Constraint theory;Performance analysis;Algorithm design and analysis;Analytical models;Robustness;Delay bound;peer-to-peer (P2P);video streaming},
doi={10.1109/TNET.2009.2038155},
ISSN={1558-2566},
month={Aug},}
@INPROCEEDINGS{8638380,
author={Prosperi, Laurent and Costan, Alexandru and Silva, Pedro and Antoniu, Gabriel},
booktitle={2018 IEEE/ACM Workflows in Support of Large-Scale Science (WORKS)},
title={Planner: Cost-Efficient Execution Plans Placement for Uniform Stream Analytics on Edge and Cloud},
year={2018},
volume={},
number={},
pages={42-51},
abstract={Stream processing applications handle unbounded and continuous flows of data items which are generated from multiple geographically distributed sources. Two approaches are commonly used for processing: Cloud-based analytics and Edge analytics. The first one routes the whole data set to the Cloud, incurring significant costs and late results from the high latency networks that are traversed. The latter can give timely results but forces users to manually define which part of the computation should be executed on Edge and to interconnect it with the remaining part executed in the Cloud, leading to sub-optimal placements. In this paper, we introduce Planner, a middleware for uniform and transparent stream processing across Edge and Cloud. Planner automatically selects which parts of the execution graph will be executed at the Edge in order to minimize the network cost. Real-world micro-benchmarks show that Planner reduces the network usage by 40% and the makespan (end-to-end processing time) by 15% compared to state-of-the-art.},
keywords={Cloud computing;Clouds;Computational modeling;Engines;Sparks;Contracts;Distributed databases;stream-processing;Edge-analytics;hybrid-stream-processing},
doi={10.1109/WORKS.2018.00010},
ISSN={},
month={Nov},}
@INPROCEEDINGS{7827608,
author={Koehn, Thaddeus and Athanas, Peter},
booktitle={2016 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
title={Arbitrary streaming permutations with minimum memory and latency},
year={2016},
volume={},
number={},
pages={1-6},
abstract={Streaming architectures are a popular choice for data intensive application due to their high throughput requirements. When assembling components for a streaming application, it is often necessary to build translation blocks between them to match the ordering of the data elements required for the subsequent processing. This paper addresses this need by developing a technique that realizes arbitrary permutations in a streaming architecture. It is parametrized to accommodate any size data sequence and streaming width. This technique is applied to an architecture that receives continuous input at a rate of k elements per clock cycle, and after an initial start-up latency, outputs continuously at the same rate. In addition, the memory usage and latency through the memory array is minimized. This design is evaluated for permutations parametrized by size and stream width in terms of the memory elements and depths required. The class of stride permutation is considered for specific experimental evaluation. On average, this technique and architecture has only half the latency and requires half the memory of other techniques.},
keywords={Random access memory;Ports (Computers);Clocks;Pipelines;Throughput;Memory management},
doi={10.1145/2966986.2967004},
ISSN={1558-2434},
month={Nov},}
@INPROCEEDINGS{4351520,
author={Jia, Jinkang and Li, Chunxi and Chen, Changjia},
booktitle={2007 IFIP International Conference on Network and Parallel Computing Workshops (NPC 2007)},
title={Characterizing PPStream across Internet},
year={2007},
volume={},
number={},
pages={413-418},
abstract={Since the appearance of various P2P IPTV systems which timely broadcast live streaming to peers, they have attracted millions of users from all over the world. It is reported that the online audience have reached more than 1.2 million in peak time by the official website of PPStream, one of the most popular IPTV system in China. However, at the same time the popularity of these systems make the amounts of video traffic grow exponentially. In order to study the global playback performance, users ' behaviors and network characteristics as well, we developed our dedicated crawler of PPStream. Based on the measurements, we make some extensive performance evaluation on this commercially successful P2P IPTV system, and some characteristics on geographic clustering, connection stability, arrival/departure pattern, playback quality, sharing ratio and topology have been revealed. We think these findings can help other researchers model such streaming systems and system operators make further optimizations.},
keywords={Internet;IPTV;Topology;Protocols;Crawlers;Large-scale systems;Delay;TV;Switches;Bandwidth},
doi={10.1109/NPC.2007.34},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6877240,
author={Gabel, Mohse and Schuster, Assaf and Keren, Daniel},
booktitle={2014 IEEE 28th International Parallel and Distributed Processing Symposium},
title={Communication-Efficient Distributed Variance Monitoring and Outlier Detection for Multivariate Time Series},
year={2014},
volume={},
number={},
pages={37-47},
abstract={Modern scale-out services are comprised of thousands of individual machines, which must be continuously monitored for unexpected failures. One recent approach to monitoring is latent fault detection, an adaptive statistical framework for scale-out, load-balanced systems. By periodically measuring hundreds of performance metrics and looking for outlier machines, it attempts to detect subtle problems such as misconfigurations, bugs, and malfunctioning hardware, before they manifest as machine failures. Previous work on a large, real-world Web service has shown that many failures are indeed preceded by such latent faults. Latent fault detection is an offline framework with large bandwidth and processing requirements. Each machine must send all its measurements to a centralized location, which is prohibitive in some settings and requires data-parallel processing infrastructure. In this work we adapt the latent fault detector to provide an online, communication- and computation-reduced version. We utilize stream processing techniques to trade accuracy for communication and computation. We first describe a novel communication-efficient online distributed variance monitoring algorithm that provides a continuous estimate of the global variance within guaranteed approximation bounds. Using the variance monitor, we provide an online distributed outlier detection framework for non-stationary multivariate time series common in scale-out systems. The adapted framework reduces data size and central processing cost by processing the data in situ, making it usable in wider settings. Like the original framework, our adaptation admits different comparison functions, supports non-stationary data, and provides statistical guarantees on the rate of false positives. Simulations on logs from a production system show that we are able to reduce bandwidth by an order of magnitude, with below 1% error compared to the original algorithm.},
keywords={Monitoring;Vectors;Radiation detectors;Time series analysis;Fault detection;Synchronization;Detectors;distributed computing;distributed processing;data analysis;time series analysis;fault detection},
doi={10.1109/IPDPS.2014.16},
ISSN={1530-2075},
month={May},}
@INPROCEEDINGS{9012371,
author={Prasuna, T. and Pravallika, K. GOWRI and Babu, D. CHAKRADHAR and Sindhura, V.},
booktitle={2018 3rd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT)},
title={A Novel Approach for Improved Data Replication Using HDFS},
year={2018},
volume={},
number={},
pages={854-859},
abstract={HDFS (Hadoop Distributed File System) is intended to store huge dataset values with accurate file location with high reliability and data streaming to the application is done at high bandwidth. HDFS deals with high fault tolerance with the use of replication of data. Many researches have been done on fitting the data in the exact location. The problem occurred in Hadoop distributed file system is difficulty with information space for storage. It is the most complicated problem which reduce the performance of the file system. To overcome this issue the proposed system aims to have the better data replication which depends upon the access count estimation in Hadoop framework. The proposed system creates the better replicas and to solve the data locality problem with improved arrangement of data replicas and to assign the task for efficient workers to complete the Map Reduce task to obtain the better results. By comparison with the existing system, the proposed system performs the better replication and solves the data locality problem. An experiment has been performed for evaluating the proposed technique with default technique and previously used replication techniques using a benchmark. With respect to the results obtained the proposed method obtained a better throughput when compared to the previous techniques.},
keywords={Pipelines;Task analysis;Throughput;Writing;File systems;Distributed databases;Computer architecture;Hadoop;Data locality;Access Prediction},
doi={10.1109/RTEICT42901.2018.9012371},
ISSN={},
month={May},}
@INPROCEEDINGS{5735684,
author={Lu, Xukang and Wu, Qishi and Lin, Yunyue and Li, Runzhi},
booktitle={IEEE Local Computer Network Conference},
title={On a decentralized approach to tree construction in hybrid P2P networks},
year={2010},
volume={},
number={},
pages={112-119},
abstract={The client-server architecture widely adopted on the Internet is not adequate to meet the ever-increasing user loads and bandwidth demands in live streaming systems especially for multimedia content delivery. Peer-to-peer (P2P) overlay networks provide excellent system scalability and high resource utilization, which make it an attractive solution to this problem. We consider a hybrid hierarchical P2P overlay network that consists of both super and normal peers to support live streaming applications. This architecture is built upon a tree-structured network of super peers, which organize normal peers into clusters. The tree construction process has a significant impact on the overall system performance. We formulate a specific type of problem, max-minTC, to maximize the minimum node throughput in tree construction, where the system's stream rate is optimized by constructing an efficient spanning tree among super peers. We present a decentralized approach where super peers run the same algorithm in parallel to derive a tree from an identical database describing the topology of the streaming system. This approach is able to quickly converge to a new tree upon the detection of any topological changes in super peers. The performance superiority of the proposed solution is illustrated by extensive simulations on a large set of simulated networks of various sizes from small to large scales in comparison with other methods.},
keywords={Peer to peer computing;Bandwidth;Throughput;Network topology;Topology;Databases;Servers;Overlay networks;P2P;spanning tree;distributed algorithm},
doi={10.1109/LCN.2010.5735684},
ISSN={0742-1303},
month={Oct},}
@INPROCEEDINGS{4630103,
author={Repantis, Thomas and Kalogeraki, Vana},
booktitle={2008 IEEE International Conference on Dependable Systems and Networks With FTCS and DCC (DSN)},
title={Hot-spot prediction and alleviation in distributed stream processing applications},
year={2008},
volume={},
number={},
pages={346-355},
abstract={Many emerging distributed applications require the real-time processing of large amounts of data that are being updated continuously. Distributed stream processing systems offer a scalable and efficient means of in-network processing of such data streams. However, the large scale and the distributed nature of such systems, as well as the fluctuation of their load render it difficult to ensure that distributed stream processing applications meet their Quality of Service demands. We describe a decentralized framework for proactively predicting and alleviating hot-spots in distributed stream processing applications in real-time. We base our hot-spot prediction techniques on statistical forecasting methods, while for hot-spot alleviation we employ a non-disruptive component migration protocol. The experimental evaluation of our techniques, implemented in our Synergy distributed stream processing middleware over PlanetLab, using a real stream processing application operating on real streaming data, demonstrates high prediction accuracy and substantial performance benefits.},
keywords={Quality of service;Middleware;Linear regression;Mathematical model;Equations;Queueing analysis;Real time systems},
doi={10.1109/DSN.2008.4630103},
ISSN={2158-3927},
month={June},}
@INPROCEEDINGS{8079733,
author={Karakaya, Ziya and Yazici, Ali and Alayyoub, Mohammed},
booktitle={2017 International Conference on Computer and Applications (ICCA)},
title={A Comparison of Stream Processing Frameworks},
year={2017},
volume={},
number={},
pages={1-12},
abstract={This study compares the performance of Big Data Stream Processing frameworks including Apache Spark, Flink, and Storm. Also, it measures the resource usage and performance scalability of the frameworks against a varying number of cluster sizes. It has been observed that, Flink outperforms both Spark and Storm under equal constraints. However, Spark can be optimized to provide the higher throughput than Flink with the cost of higher latency.},
keywords={Big Data;Stream Processing Framework;Spark;Storm;Flink},
doi={10.1109/COMAPP.2017.8079733},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{4736167,
author={Bouillet, Eric and Dube, Parijat and George, David and Liu, Zhen and Pendarakis, Dimitrios and Zhang, Li},
booktitle={2008 Winter Simulation Conference},
title={Distributed multi-layered workload synthesis for testing stream processing systems},
year={2008},
volume={},
number={},
pages={1003-1011},
abstract={Testing and benchmarking of stream processing systems requires workload representative of real world scenarios with myriad of users, interacting through different applications over different modalities with different underlying protocols. The workload should have realistic volumetric and contextual statistics at different levels: user level, application level, packet level etc. Further realistic workload is inherently distributed in nature. We present a scalable framework for synthesis of distributed workload based on identifying different layers of workload corresponding to different time-scales. The architecture is extensible and modular, promotes reuse of libraries at different layers and offers the flexibility to add additional plug-ins at different layers without sacrificing the efficiency.},
keywords={System testing;Production facilities;Benchmark testing;Protocols;Streaming media;Temperature sensors;Traffic control;Statistical distributions;Monitoring;Encoding},
doi={10.1109/WSC.2008.4736167},
ISSN={1558-4305},
month={Dec},}
@INPROCEEDINGS{9188142,
author={Gavua, Ebenezer Komla and Kecskemeti, Gabor},
booktitle={2019 International Conference on High Performance Computing & Simulation (HPCS)},
title={A Comparative Analysis and Evaluation of MapReduce Cloud Computing Simulators},
year={2019},
volume={},
number={},
pages={692-699},
abstract={The application of MapReduce cloud computing simulators for research and development is becoming popular, due to their efficiency and ease of utilization. This ignited the development of several cloud simulators for algorithm testing and performance analysis of dynamic MapReduce environments. The selection of appropriate simulator for a specific research remains a challenge. We have designed a MapReduce classification framework to guide cloud and big data researchers towards suitable tools. We have reviewed eleven MapReduce specific simulators. Our evaluation first revealed thirty general functional requirements for more widely applicable cloud simulators. Then, we focused on specific concerns of MapReduce related simulations and filtered the general requirements down to the most relevant thirteen. Our evaluation highlighted the strengths and weakness of several MapReduce simulators. IoT-based applications, stream processing and replaying of production cluster workloads are key criteria absent from many simulators. Therefore, we identified these as gaps, that simulator developers could focus on when extending their works towards MapReduce oriented simulations. Finally, researchers simulating dynamic behaviors of Hadoop clusters should select simulators efficient in parameter tuning.},
keywords={Cloud computing;Computational modeling;Data models;Scalability;Analytical models;Task analysis;Software;cloud computing;map reduce;simulation},
doi={10.1109/HPCS48598.2019.9188142},
ISSN={},
month={July},}
@ARTICLE{1195413,
author={Plale, B. and Schwan, K.},
journal={IEEE Transactions on Parallel and Distributed Systems},
title={Dynamic querying of streaming data with the dQUOB system},
year={2003},
volume={14},
number={4},
pages={422-432},
abstract={Data streaming has established itself as a viable communication abstraction in data-intensive parallel and distributed computations, occurring in applications such as scientific visualization, performance monitoring, and large-scale data transfer. A known problem in large-scale event communication is tailoring the data received at the consumer. It is the general problem of extracting data of interest from a data source, a problem that the database community has successfully addressed with SOL queries, a time tested, user-friendly way for noncomputer scientists to access data. By leveraging the efficiency of query processing provided by relational queries, the dQUOB system provides a conceptual relational data model and SOL query access over streaming data. Queries can be used to extract data, combine streams, and create new streams. The language augments queries with an action to enable more complex data transformations such as Fourier transforms. The dQUOB system has been applied to two large-scale distributed applications: a safety critical autonomous robotics simulation and scientific software visualization for global atmospheric transport modeling. In this paper, we present the dQUOB system and the results of performance evaluation undertaken to assess its applicability in data-intensive wide-area computations, where the benefit of portable data transformation must be evaluated against the cost of continuous query evaluation.},
keywords={Large-scale systems;Data visualization;Data mining;Query processing;Software safety;Atmospheric modeling;Computer applications;Concurrent computing;Distributed computing;Monitoring},
doi={10.1109/TPDS.2003.1195413},
ISSN={1558-2183},
month={April},}
@INPROCEEDINGS{7027513,
author={Bellavista, Paolo and Corradi, Antonio and Reale, Andrea and Ticca, Nicola},
booktitle={2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
title={Priority-Based Resource Scheduling in Distributed Stream Processing Systems for Big Data Applications},
year={2014},
volume={},
number={},
pages={363-370},
abstract={Distributed Stream Processing Systems (DSPSs) are attracting increasing industrial and academic interest as flexible tools to implement scalable and cost-effective on-line analytics applications over Big Data streams. Often hosted in private/public cloud deployment environments, DSPSs offer data stream processing services that transparently exploit the distributed computing resources made available to them at runtime. Given the volume of data of interest, possible (hard/soft) real-time processing requirements, and the time-variable characteristics of input data streams, it is very important for DSPSs to use smart and innovative scheduling techniques that allocate computing resources properly and avoid static over-provisioning. In this paper, we originally investigate the suitability of exploiting application-level indications about differentiated priorities of different stream processing tasks to enable application-specific DSPS resource scheduling, e.g., Capable of re-shaping processing resources in order to dynamically follow input data peaks of prioritized tasks, with no static over-provisioning. We originally propose a general and simple technique to design and implement priority-based resource scheduling in flow-graph-based DSPSs, by allowing application developers to augment DSPS graphs with priority metadata and by introducing an extensible set of priority schemas to be automatically handled by the extended DSPS. In addition, we show the effectiveness of our approach via its implementation and integration in our Quasit DSPS and through experimental evaluation of this prototype on a real-world stream processing application of Big Data vehicular traffic analysis.},
keywords={Digital signal processing;Runtime;Data models;Processor scheduling;Big data;Scheduling;Throughput;Distributed Stream Processing;Big Data;Priority-based Resource Scheduling;Application-level and Application-specific Scheduling;Cloud Computing Optimization;Vehicular Traffic Analysis},
doi={10.1109/UCC.2014.46},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9306697,
author={HoseinyFarahabady, M. Reza and Taheri, Javid and Zomaya, Albert Y. and Tari, Zahir},
booktitle={2020 IEEE 19th International Symposium on Network Computing and Applications (NCA)},
title={A Dynamic Resource Controller for Resolving Quality of Service Issues in Modern Streaming Processing Engines},
year={2020},
volume={},
number={},
pages={1-8},
abstract={Devising an elastic resource allocation controller of data analytical applications in virtualized data-center has received a great attention recently, mainly due to the fact that even a slight performance improvement can translate to huge monetary savings in practical large-scale execution. Apache Flink is among modern streamed data processing run-times that can provide both low latency and high throughput computation in to execute processing pipelines over high-volume and high-velocity data-items under tight latency constraints. However, a yet to be answered challenge in a large-scale platform with tens of worker nodes is how to resolve the run-time violation in the quality of service (QoS) level in a multi-tenant data streaming platforms, particularly when the amount of workload generated by different users fluctuates. Studies showed that a static resource allocation algorithm (round-robin), which is used by default in Apache Flink, suffer from lack of responsiveness to sudden traffic surges happening unpredictably during the run-time. In this paper, we address the problem of resource management in a Flink platform for ensuring different QoS enforcement levels in a platform with shared computing resources. The proposed solution applies theoretical principals borrowed from close-loop control theory to design a CPU and memory adjustment mechanism with the primary goal to fulfill the different QoS levels requested by submitted applications while the resource interference is considered as the critical performance-limiting factor. The performance evaluation is carried out by comparing the proposed resource allocation mechanism with two static heuristics (round robin and class-based weighted fair queuing) in a 80-core cluster under multiple traffic patterns resembling sudden changes in the incoming workloads of low-priory streaming applications. The experimental results confirm the stability of the proposed controller to regulate the underlying platform resources to smoothly follow the target values (QoS violation rates). Particularly, the proposed solution can achieve higher efficiency compared to the other heuristics by reducing the response-time of high priority applications by 53% while maintaining the enforced QoS levels during the burst traffic periods.},
keywords={Quality of service;Data processing;Resource management;Process control;Time factors;Degradation;Surges;Apache Flink Streaming Platform;Elastic Auto-Tuning;Performance Modeling of Computer System;Quality of Services (QoS) Issues},
doi={10.1109/NCA51143.2020.9306697},
ISSN={2643-7929},
month={Nov},}
@INPROCEEDINGS{5764567,
author={Seyyedi, S. M. Y. and Akbari, B.},
booktitle={2011 International Symposium on Computer Networks and Distributed Systems (CNDS)},
title={Hybrid CDN-P2P architectures for live video streaming: Comparative study of connected and unconnected meshes},
year={2011},
volume={},
number={},
pages={175-180},
abstract={There are two main scalable methods for streaming live video over the Internet: Content Delivery Networks (CDNs) and Peer-to-Peer (P2P) networks. Though both have their own problems, P2P streaming systems challenge delivering video with constant quality and CDNs approaches require deployment of large number of servers throughout the Internet that is costly. Recently, using hybrid architectures based on both CDN and P2P networks has shown to be an efficient approach for large-scale video distribution over the Internet. This paper is compared the performance of two main hybrid CDN-P2P architectures includes: (i) CDN-P2P unconnected mesh in which independent P2P mesh networks are constructed under each CDN node, and (ii) CDN-P2P connected mesh in which CDN nodes and peers participate in construction of a single P2P mesh network. The comparison is preformed in addition, to the pure mesh-based P2P video streaming, using extensive simulation and based on different QoS metrics.},
keywords={Streaming media;Peer to peer computing;Servers;Delay;Computer architecture;Internet;Bit rate;Peer-to-Peer systems;Hybrid CDN-P2P;Video streaming},
doi={10.1109/CNDS.2011.5764567},
ISSN={},
month={Feb},}
@INPROCEEDINGS{6313696,
author={Cervino, Javier and Kalyvianaki, Evangelia and Salvachua, Joaquin and Pietzuch, Peter},
booktitle={2012 IEEE 28th International Conference on Data Engineering Workshops},
title={Adaptive Provisioning of Stream Processing Systems in the Cloud},
year={2012},
volume={},
number={},
pages={295-301},
abstract={With the advent of data-intensive applications that generate large volumes of real-time data, distributed stream processing systems (DSPS) become increasingly important in domains such as social networking and web analytics. In practice, DSPSs must handle highly variable workloads caused by unpredictable changes in stream rates. Cloud computing offers an elastic infrastructure that DSPSs can use to obtain resources on-demand, but an open problem is to decide on the correct resource allocation when deploying DSPSs in the cloud. This paper proposes an adaptive approach for provisioning virtual machines (VMs) for the use of a DSPS in the cloud. We initially perform a set of benchmarks across performance metrics such as network latency and jitter to explore the feasibility of cloud-based DSPS deployments. Based on these results, we propose an algorithm for VM provisioning for DSPSs that reacts to changes in the stream workload. Through a prototype implementation on Amazon EC2, we show that our approach can achieve low-latency stream processing when VMs are not overloaded, while adjusting resources dynamically with workload changes.},
keywords={Throughput;Engines;Digital signal processing;Cloud computing;Jitter;Benchmark testing;Delay},
doi={10.1109/ICDEW.2012.40},
ISSN={},
month={April},}
@INPROCEEDINGS{5770398,
author={Leidi, Tiziano and Heeb, Thierry and Colla, Marco and Thiran, Jean-Philippe},
booktitle={2011 Sixth International Symposium on Parallel Computing in Electrical Engineering},
title={Event-driven Scheduling for Parallel Stream Processing},
year={2011},
volume={},
number={},
pages={36-41},
abstract={To optimize real-time stream-processing applications for chip-level multi processors, several challenges have to be met. Poor scalability and poor internal data pressure may result from serial dependencies within or between the algorithms. Load imbalances introduced by the parallel-processing hardware and execution environment may also limit performance. To maximize the throughput and minimize the latency of parallel stream-processing applications, we propose an approach that complements run-time dynamic load balancing with static pre-compile partitioning. In our solution, the dynamic features are based on event-driven scheduling, while the static features benefit from profile-guided automatic optimizations. In this paper, we present some recent enhancements of DSPE, an open-source development environment, featuring model and source code generators for prototyping, refining and customizing real-time stream-processing applications. By using our approach on micro-benchmarks and sample applications, we also show that it is possible to reduce the impact of the different speed-up constrainers.},
keywords={Engines;Software;Parallel processing;Heuristic algorithms;Software algorithms;Scalability;Dynamic scheduling;stream processing;parallel processing;code generation;event-driven scheduling;profile-guided optimizations;dynamic load-balancing},
doi={10.1109/PARELEC.2011.14},
ISSN={},
month={April},}
@INPROCEEDINGS{8759314,
author={Kang, Jian and Samarasinghe, Gihan and Senanayake, Upul and Conjeti, Sailesh and Sowmya, Arcot},
booktitle={2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)},
title={Deep Learning for Volumetric Segmentation in Spatio-Temporal Data: Application to Segmentation of Prostate in DCE-MRI},
year={2019},
volume={},
number={},
pages={61-65},
abstract={Segmentation of the prostate in MR images is an essential step that underpins the success of subsequent analysis methods, such as cancer lesion detection inside the tumour and registration between different modalities. This work focuses on leveraging deep learning for analysis of longitudinal volumetric datasets, particularly for the task of segmentation, and presents proof-of-concept for segmentation of the prostate in 3D+T DCE-MRI sequences. A two-stream processing pipeline is proposed for this task, comprising a spatial stream modelled using a volumetric fully convolutional network and a temporal stream modeled using recurrent neural networks with Long-Short-term Memory (LSTM) units. The predictions of the two streams are fused using deep neural networks. The proposed method has been validated on a public benchmark dataset of 17 patients, each with 40 temporal volumes. When averaged over three experiments, a highly competitive Dice overlap score of 0.8688 and sensitivity of 0.8694 were achieved. As a spatiotemporal segmentation method, it can easily migrate to other datasets.},
keywords={Magnetic resonance imaging;Image segmentation;Deep learning;Three-dimensional displays;Bladder;Feature extraction;prostate segmentation;deep learning;LSTM},
doi={10.1109/ISBI.2019.8759314},
ISSN={1945-8452},
month={April},}
@INPROCEEDINGS{7973737,
author={Imai, Shigeru and Patterson, Stacy and Varela, Carlos A.},
booktitle={2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)},
title={Maximum Sustainable throughput Prediction for Data Stream Processing over Public Clouds},
year={2017},
volume={},
number={},
pages={504-513},
abstract={In cloud-based stream processing services, the maximum sustainable throughput (MST) is defined as the maximum throughput that a system composed of a fixed number of virtual machines (VMs) can ingest indefinitely. If the incoming data rate exceeds the system's MST, unprocessed data accumulates, eventually making the system inoperable. Thus, it is important for the service provider to keep the MST always larger than the incoming data rate by dynamically changing the number of VMs used by the system. In this paper, we identify a common data processing environment used by modern data stream processing systems, and we propose MST prediction models for this environment. We train the models using linear regression with samples obtained from a few VMs and predict MST for a larger number of VMs. To minimize the time and cost for model training, we statistically determine a set of training samples using Intel's Storm benchmarks with representative resource usage patterns. Using typical use-case benchmarks on Amazon's EC2 public cloud, our experiments show that, training with up to 8 VMs, we can predict MST for streaming applications with less than 4% average prediction error for 12 VMs, 9% for 16 VMs, and 32% for 24 VMs. Further, we evaluate our prediction models with simulation based elastic VM scheduling on a realistic workload. These simulation results show that with 10% over provisioning, our proposed models' cost efficiency is on par with the cost of an optimal scaling policy without incurring any service level agreement violations.},
keywords={Throughput;Data processing;Predictive models;Storms;Data models;Computational modeling;Cloud computing;cloud computing;performance prediction;resource management;auto-scaling},
doi={10.1109/CCGRID.2017.105},
ISSN={},
month={May},}
@INPROCEEDINGS{5421671,
author={Wen, Ke and Zhao, Li},
booktitle={2010 7th IEEE Consumer Communications and Networking Conference},
title={PartnerVoD: Improving P2P-VoD with Partnership Overlay},
year={2010},
volume={},
number={},
pages={1-5},
abstract={Recently video-on-demand (VoD) has become a popular Internet application due to its promising usage in a variety of Internet-based services. However, it remains a challenging problem to provide scalable and fluent VoD services over Internet especially when including VCR operations into VoD service. Supporting user interactivities such as random seek, rewind and fast forward is desirable while these operations surely introduce extra complexity and overhead into the VoD system. Moreover, users may probably have to wait for a long time because new data needs to be buffered and this would greatly deteriorate user experiences. In this paper, we propose an overlay-constructing method called PartnerVoD, aiming at maximizing the collaboration among peers and the utility of upload bandwidth. In PartnerVoD, peers with close playing positions become partners and stream media data to each other. In order to support fast streaming and efficient neighbor discovery, we not only takes advantage of P2P-VoD network's hierarchical characteristic in time domain but also takes locality awareness into account. Additionally, performance evaluation shows that it can help improve VCR performance at the same time.},
keywords={Streaming media;Video recording;Network servers;Web and internet services;Peer to peer computing;Collaboration;Video sharing;Communications Society;Bandwidth;Buffer storage},
doi={10.1109/CCNC.2010.5421671},
ISSN={2331-9860},
month={Jan},}
@ARTICLE{8290568,
author={Fan, Xitian and Wu, Di and Cao, Wei and Luk, Wayne and Wang, Lingli},
journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
title={Stream Processing Dual-Track CGRA for Object Inference},
year={2018},
volume={26},
number={6},
pages={1098-1111},
abstract={With the development of machine learning technology, the exploration of energy-efficient and flexible architectures for object inference algorithms is of growing interest in recent years. However, not many publications concentrate on a coarsegrained reconfigurable architecture (CGRA) for object inference algorithms. This paper provides a stream processing, dual-track programming CGRA-based approach to address the inherent computing characteristics of algorithms in object inference. Based on the proposed approach, an architecture called stream dual-track CGRA (SDT-CGRA) is presented as an implementation prototype. To evaluate the performance, the SDT-CGRA is realized in Verilog HDL and implemented in Semiconductor Manufacturing International Corporation 55-nm process, with the footprint of 5.19 mm2 at 450 MHz. Seven object inference algorithms, including convolutional neural network (CNN), k-means, principal component analysis (PCA), spatial pyramid matching (SPM), linear support vector machine (SVM), Softmax, and Joint Bayesian, are selected as benchmarks. The experimental results show that the SDT-CGRA can gain on average 343.8 times and 17.7 times higher energy efficiency for Softmax, PCA, and CNN, 621.0 times and 1261.8 times higher energy efficiency for k-means, SPM, linear-SVM, and Joint-Bayesian algorithms when compared with the Intel Xeon E5-2637 CPU and the Nvidia TitanX graphics processing unit. When compared with the state-of-the-art solutions of AlexNet on field-programmable gate array and CGRA, the proposed SDT-CGRA can achieve a 1.78 times increase in energy efficiency and a 13 times speedup, respectively.},
keywords={Computer architecture;Inference algorithms;Acceleration;Algorithm design and analysis;Kernel;Feature extraction;Signal processing algorithms;Acceleration;coarse-grained reconfigurable architecture (CGRA);deep learning;domain-specific computing;object inference},
doi={10.1109/TVLSI.2018.2797600},
ISSN={1557-9999},
month={June},}
@INPROCEEDINGS{7056925,
author={Jayati},
booktitle={2014 Conference on IT in Business, Industry and Government (CSIBIG)},
title={The Berkeley Data Analytics Stack (BDAS)},
year={2014},
volume={},
number={},
pages={1-1},
abstract={Summary form only given. The session on “The Berkeley Data Analytics Stack” shall elucidate its current components which include Spark, Shark and Mesos with emphasis on Spark and it's real-time extension called Spark-Streaming which adds stream processing capabilities to Spark. One-liners describing each of these technologies are as follows: 1) BDAS is an open source, next-generation data analytics stack under development at the UC Berkeley AMPLab. 2) Spark, a high-speed cluster computing system compatible with Hadoop that can outperform it by up to 100x thanks to its ability to perform computations in memory. 3) Shark, a port of Apache Hive onto Spark that is compatible with existing Hive warehouses and queries. Shark can answer HiveQL queries up to 100x faster than Hive without modification to the data and queries, and is also open source as part of BDAS. 4) Mesos is a cluster manager that provides efficient resource isolation and sharing across distributed applications or frameworks. It can run Hadoop, MPI, Hypertable, Spark, and other applications on a dynamically shared pool of nodes. 5) Apart, from an elaborate explanation of various facets of Spark, the session would also aim to walk through machine learning algorithm benchmarking and examples that would substantiate the concepts covered.},
keywords={Abstracts;Sparks},
doi={10.1109/CSIBIG.2014.7056925},
ISSN={},
month={March},}
@INPROCEEDINGS{1410192,
author={Hwang, J.-H. and Balazinska, M. and Rasin, A. and Cetintemel, U. and Stonebraker, M. and Zdonik, S.},
booktitle={21st International Conference on Data Engineering (ICDE'05)},
title={High-availability algorithms for distributed stream processing},
year={2005},
volume={},
number={},
pages={779-790},
abstract={Stream-processing systems are designed to support an emerging class of applications that require sophisticated and timely processing of high-volume data streams, often originating in distributed environments. Unlike traditional data-processing applications that require precise recovery for correctness, many stream-processing applications can tolerate and benefit from weaker recovery guarantees. In this paper, we study various recovery guarantees and pertinent recovery techniques that can meet the correctness and performance requirements of stream-processing applications. We discuss the design and algorithmic challenges associated with the proposed recovery techniques and describe how each can provide different guarantees with proper combinations of redundant processing, checkpointing, and remote logging. Using analysis and simulations, we quantify the cost of our recovery guarantees and examine the performance and applicability of the recovery techniques. We also analyze how the knowledge of query network properties can help decrease the cost of high availability.},
keywords={Condition monitoring;Costs;Remote monitoring;Digital signal processing;Runtime;Algorithm design and analysis;Checkpointing;Performance analysis;Analytical models;Availability},
doi={10.1109/ICDE.2005.72},
ISSN={2375-026X},
month={April},}
@INPROCEEDINGS{7490758,
author={Jiahua Fan and Haopeng Chen and Fei Hu},
booktitle={2015 4th International Conference on Computer Science and Network Technology (ICCSNT)},
title={Adaptive task scheduling in storm},
year={2015},
volume={01},
number={},
pages={309-314},
abstract={Processing of stream data attracts more and more attention of many big companies and organizations. Storm is a well-known distributed stream processing system that is often used for real-time analysis, online machine learning, continuous computing, distributed remote process call (RPC), etc. In this paper, we study the default scheduler of Storm and other implementations of customized scheduler to discover the primary factors affecting the performance of the cluster. Then, we design and implement an adaptive task scheduler by adding load tracker to monitor the runtime status of the cluster and applying static and dynamic scheduling strategies. At last, we conduct experiments to assess our work by measuring average processing time, overall throughput and stability of the cluster through network bounded and CPU bounded benchmarks. As for average processing time of topologies, the adaptive scheduler achieves about 67% and 30% improvement on cluster of heavy and light load respectively.},
keywords={Topology;Storms;Network topology;Benchmark testing;Fasteners;Adaptive scheduling;Scheduling;stream processing;distributed computing;Apache Storm;load monitoring},
doi={10.1109/ICCSNT.2015.7490758},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9101749,
author={Zhang, Shuhao and Wu, Yingjun and Zhang, Feng and He, Bingsheng},
booktitle={2020 IEEE 36th International Conference on Data Engineering (ICDE)},
title={Towards Concurrent Stateful Stream Processing on Multicore Processors},
year={2020},
volume={},
number={},
pages={1537-1548},
abstract={Recent data stream processing systems (DSPSs) can achieve excellent performance when processing large volumes of data under tight latency constraints. However, they sacrifice support for concurrent state access that eases the burden of developing stateful stream applications. Recently, some have proposed managing concurrent state access during stream processing by modeling state accesses as transactions. However, these are realized with locks involving serious contention overhead. The coarse-grained processing paradigm adopted in these proposals magnify contention issues and does not exploit modern multicore architectures to their full potential. This paper introduces TStream, a novel DSPS supporting efficient concurrent state access on multicore processors. Transactional semantics is employed like previous work, but scalability is greatly improved due to two novel designs: 1) dual-mode scheduling, which exposes more parallelism opportunities, 2) dynamic restructuring execution, which aggressively exploits the parallelism opportunities from dual-mode scheduling without centralized lock contentions. To validate our proposal, we evaluate TStream with a benchmark of four applications on a modern multicore machine. Experimental results show that 1) TStream achieves up to 4.8 times higher throughput with similar processing latency compared to the state-of-the-art and 2) unlike prior solutions, TStream is highly tolerant of varying application workloads such as key skewness and multi-partition state accesses.},
keywords={Roads;Multicore processing;Schedules;Scalability;Semantics;Parallel processing;Dynamic scheduling},
doi={10.1109/ICDE48307.2020.00136},
ISSN={2375-026X},
month={April},}
@INPROCEEDINGS{9086217,
author={Kesavan, Suraj P and Fujiwara, Takanori and Li, Jianping Kelvin and Ross, Caitlin and Mubarak, Misbah and Carothers, Christopher D. and Ross, Robert B. and Ma, Kwan-Liu},
booktitle={2020 IEEE Pacific Visualization Symposium (PacificVis)},
title={A Visual Analytics Framework for Reviewing Streaming Performance Data},
year={2020},
volume={},
number={},
pages={206-215},
abstract={Understanding and tuning the performance of extreme-scale parallel computing systems demands a streaming approach due to the computational cost of applying offline algorithms to vast amounts of performance log data. Analyzing large streaming data is challenging because the rate of receiving data and limited time to comprehend data make it difficult for the analysts to sufficiently examine the data without missing important changes or patterns. To support streaming data analysis, we introduce a visual analytic framework comprising of three modules: data management, analysis, and interactive visualization. The data management module collects various computing and communication performance metrics from the monitored system using streaming data processing techniques and feeds the data to the other two modules. The analysis module automatically identifies important changes and patterns at the required latency. In particular, we introduce a set of online and progressive analysis methods for not only controlling the computational costs but also helping analysts better follow the critical aspects of the analysis results. Finally, the interactive visualization module provides the analysts with a coherent view of the changes and patterns in the continuously captured performance data. Through a multi-faceted case study on performance analysis of parallel discrete-event simulation, we demonstrate the effectiveness of our framework for identifying bottlenecks and locating outliers.},
keywords={Analytical models;Visual analytics;Computational modeling;Data visualization;Parallel processing;Real-time systems;Computational efficiency;Human-centered computing;Visualization;Visualization application domains;Visual analytics},
doi={10.1109/PacificVis48177.2020.9280},
ISSN={2165-8773},
month={June},}
@INPROCEEDINGS{6495010,
author={Emani, Murali Krishna and Wang, Zheng and O'Boyle, Michael F. P.},
booktitle={Proceedings of the 2013 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
title={Smart, adaptive mapping of parallelism in the presence of external workload},
year={2013},
volume={},
number={},
pages={1-10},
abstract={Given the wide scale adoption of multi-cores in main stream computing, parallel programs rarely execute in isolation and have to share the platform with other applications that compete for resources. If the external workload is not considered when mapping a program, it leads to a significant drop in performance. This paper describes an automatic approach that combines compile-time knowledge of the program with dynamic runtime workload information to determine the best adaptive mapping of programs to available resources. This approach delivers increased performance for the target application without penalizing the existing workload. This approach is evaluated on NAS and SpecOMP parallel bench-mark programs across a wide range of workload scenarios. On average, our approach achieves performance gain of 1.5x over a state-of-art scheme on a 12 core machine.},
keywords={Runtime;Benchmark testing;Training data;Instruction sets;Dynamic scheduling;Training;Parallelism Mapping;Runtime adaptation;Machine Learning},
doi={10.1109/CGO.2013.6495010},
ISSN={},
month={Feb},}
@INPROCEEDINGS{1639354,
author={Li Zhang and Parashar, M.},
booktitle={Proceedings 20th IEEE International Parallel & Distributed Processing Symposium},
title={Enabling efficient and flexible coupling of parallel scientific applications},
year={2006},
volume={},
number={},
pages={10 pp.-},
abstract={Emerging scientific and engineering simulations are presenting challenging requirements for coupling between multiple physics models and associated parallel codes that execute independently and in a distributed manner. Realizing coupled simulations requires an efficient, flexible and scalable coupling framework and simple programming abstractions. This paper presents a coupling framework that addresses these requirements. The framework is based on the Seine geometry-based interaction model. It enables efficient computation of communication schedules, supports low-overheads processor-to-processor data streaming, and provides high-level abstraction for application developers. The design, CCA-based implementation, and experimental evaluation of the Seine based coupling framework are presented},
keywords={Computational modeling;Physics;Solid modeling;Processor scheduling;Nuclear and plasma sciences;Plasma simulation;Concurrent computing;Application software;Software systems;Laboratories},
doi={10.1109/IPDPS.2006.1639354},
ISSN={1530-2075},
month={April},}
@INPROCEEDINGS{8603166,
author={Tran, Geoffrey Phi and Walters, John Paul and Crago, Stephen},
booktitle={2018 IEEE/ACM 11th International Conference on Utility and Cloud Computing (UCC)},
title={Reducing Tail Latencies while Improving Resiliency to Timing Errors for Stream Processing Workloads},
year={2018},
volume={},
number={},
pages={194-203},
abstract={Stream processing is an increasingly popular model for online data processing that can be partitioned into streams of elements. It is commonly used in real-time data analytics services, such as processing Twitter tweets and Internet of Things (IoT) device feeds. Current stream processing frameworks boast high throughput and low average latency. However, users of these frameworks may desire lower tail latencies and better real-time performance for their applications. In practice, there are a number of errors that can affect the performance of stream processing applications, such as garbage collection and resource contention. For some applications, these errors may cause unacceptable violations of real-time constraints. In this paper we propose applying redundancy in the data processing pipeline to increase the resiliency of stream processing applications to timing errors. This results in better real-time performance and a reduction in tail latency. We present a methodology and apply this redundancy in a framework based on Twitter's Heron. Finally, we evaluate the effectiveness of this technique against a range of injected timing errors using benchmarks from Intel's Storm Benchmark. Our results show that redundant tuple processing can effectively reduce the tail latency, and that the number of missed deadlines can also be reduced by up to 94% in the best case. We also study the potential effects of duplication when applied at different stages in the topology. For the topologies in this paper, we further observe that duplication is most effective when computation is redundant at the first bolt. Finally, we evaluate the additional overhead that duplicating tuples brings to a stream processing topology. Our results also show that computation overhead scales slower than communication, and that the real-time performance is improved in spite of the overheads. Overall we conclude that redundancy through duplicated tuples is indeed a powerful tool for increasing the resiliency to intermittent runtime timing errors.},
keywords={Redundancy;Storms;Timing;Topology;Fault tolerant systems;Real-time systems;stream processing;fault tolerance;garbage collection;resiliency;real-time;tail latency},
doi={10.1109/UCC.2018.00028},
ISSN={},
month={Dec},}
@INPROCEEDINGS{4937793,
author={Hao Liu and Riley, George and Ingle, Rajesh},
booktitle={2008 2nd International Symposium on Advanced Networks and Telecommunication Systems},
title={Mathematical model and analysis of peer-to-peer IPTV},
year={2008},
volume={},
number={},
pages={1-3},
abstract={Peer-to-peer overlay is an attractive solution to distribute video streams over large-scale IP networks. A number of algorithms and frameworks have been proposed. But generic and theoretical analysis of P2P streaming is scarce in the literature. In this paper, we present a novel probability model, making the formal analysis and performance evaluation of P2P IPTV accessible. With the help of the proposed model, we then reveal that the efficiency of P2P streaming system is closely correlated to piece diversity.},
keywords={Mathematical model;Peer to peer computing;IPTV;Streaming media;Bandwidth;IP networks;YouTube;Costs;Stochastic systems;Computer science},
doi={10.1109/ANTS.2008.4937793},
ISSN={2153-1684},
month={Dec},}
@INPROCEEDINGS{8644799,
author={Wang, Xiao-Dong and Chen, Rung-Ching and Yan, Fei and Hendry, Hendry},
booktitle={2018 International Symposium on Computer, Consumer and Control (IS3C)},
title={K-Means Clustering with Feature Selection for Stream Data},
year={2018},
volume={},
number={},
pages={453-456},
abstract={K-means clustering is popular for its efficiency and is often chosen for analyzing large-scale data. However, it is hard to deal with high-dimensional data, which often contain lots of redundant features. In addition, in real-world applications, we usually confront with massive data streams, such as transport system and social media, which are often periodically generated in high-dimensional space. Although existing K-means extensions have achieved great success on high-dimensional data by integrating with dimension reduction methods, they are limited to off-line data. To solve these problems, we propose a streaming Kmeans clustering with feature selection. The proposed algorithm divides the traditional clustering procedure into several related multiple clustering tasks and selects the representative features by the group sparsity regularization technique. Besides, within such framework, the shared information among neighbor streams can be properly explored. Experimental results on several benchmark datasets demonstrate the effectiveness of the proposed model.},
keywords={Clustering algorithms;Feature extraction;Linear programming;Task analysis;Optimization;Breast;Dimensionality reduction;feature selection;K-means clustering;group sparsity},
doi={10.1109/IS3C.2018.00120},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7405527,
author={Cardellini, Valeria and Grassi, Vincenzo and Presti, Francesco Lo and Nardelli, Matteo},
booktitle={2015 IEEE Symposium on Computers and Communication (ISCC)},
title={On QoS-aware scheduling of data stream applications over fog computing infrastructures},
year={2015},
volume={},
number={},
pages={271-276},
abstract={Fog computing is rapidly changing the distributed computing landscape by extending the Cloud computing paradigm to include wide-spread resources located at the network edges. This diffused infrastructure is well suited for the implementation of data stream processing (DSP) applications, by possibly exploiting local computing resources. Storm is an open source, scalable, and fault-tolerant DSP system designed for locally distributed clusters. We made it suitable to operate in a geographically distributed and highly variable environment; to this end, we extended Storm with new components that allow to execute a distributed QoS-aware scheduler and give self-adaptation capabilities to the system. In this paper we provide a thorough experimental evaluation of the proposed solution using two sets of DSP applications: the former is characterized by a simple topology with different requirements; the latter comprises some well known applications (i.e., Word Count, Log Processing). The results show that the distributed QoS-aware scheduler outperforms the centralized default one, improving the application performance and enhancing the system with runtime adaptation capabilities. However, complex topologies involving many operators may cause some instability that can decrease the DSP application availability.},
keywords={Quality of service;Storms;Digital signal processing;Topology;Cloud computing;Monitoring;Fasteners},
doi={10.1109/ISCC.2015.7405527},
ISSN={},
month={July},}
@ARTICLE{7336545,
author={Liu, Weijiang and Qu, Wenyu and Gong, Jian and Li, Keqiu},
journal={IEEE Transactions on Information Forensics and Security},
title={Detection of Superpoints Using a Vector Bloom Filter},
year={2016},
volume={11},
number={3},
pages={514-527},
abstract={Internet attacks, such as distributed denial-of-service attacks and worm attacks, are increasing in severity and frequency. Identifying and mitigating realtime attacks are an important and challenging task for network administrators. An infected host can make a large number of connections to distinct destinations during a short time. Such a host is called a superpoint. Detecting superpoints can be utilized for traffic engineering and anomaly detection. This paper proposes a novel data streaming method for detecting superpoints and proves guarantees on its accuracy with low memory requirements. The superior performance of this method comes from a new data structure, called vector bloom filter (VBF), which is a variant of standard BF. The VBF consists of six hash functions, four of which take some consecutive bits from the input string as the corresponding value, respectively. The information of superpoints is obtained by using the overlapping of hash bit strings of the VBF. Theoretical analysis and experimental results show that the proposed method can detect superpoints precisely and efficiently through comparison with other existing approaches.},
keywords={IP networks;Grippers;Information filters;Arrays;Accuracy;IP flow;Superpoint;Bloom filter;Cardinality estimation;Random variable;IP flow;superpoint;bloom filter;cardinality estimation;random variable},
doi={10.1109/TIFS.2015.2503269},
ISSN={1556-6021},
month={March},}
@INPROCEEDINGS{9235069,
author={E. Venugopal, Vinu and Theobald, Martin and Chaychi, Samira and Tawakuli, Amal},
booktitle={2020 IEEE 32nd International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)},
title={AIR: A Light-Weight Yet High-Performance Dataflow Engine based on Asynchronous Iterative Routing},
year={2020},
volume={},
number={},
pages={51-58},
abstract={Distributed Stream Processing Engines (DSPEs) are currently among the most emerging topics in data management, with applications ranging from real-time event monitoring to processing complex dataflow programs and big data analytics. In this paper, we describe the architecture of our AIR engine, which is designed from scratch in C++ using the Message Passing Interface (MPI), pthreads for multithreading, and is directly deployed on top of a common HPC workload manager such as SLURM. AIR implements a light-weight, dynamic sharding protocol (referred to as "Asynchronous Iterative Routing"), which facilitates a direct and asynchronous communication among all worker nodes and thereby completely avoids any additional communication overhead with a dedicated master node. With its unique design, AIR fills the gap between the prevalent scale-out (but Java-based) architectures like Apache Spark and Flink, on one hand, and recent scale-up (and C++ based) prototypes such as StreamBox and PiCo, on the other hand. Our experiments over various benchmark settings confirm that AIR performs as good as the best scale-up SPEs on a single-node setup, while it outperforms existing scale-out DSPEs in terms of processing latency and sustainable throughput by a factor of up to 15 in a distributed setting.},
keywords={Task analysis;Throughput;Computer architecture;C++ languages;Message systems;Resource management;Java;dataflow processing engine;stream processing;high sustainable throughput;distributed stream data processing;asynchronous stream processing},
doi={10.1109/SBAC-PAD49847.2020.00018},
ISSN={2643-3001},
month={Sep.},}
@ARTICLE{7547948,
author={Zhang, Yunquan and Cao, Ting and Li, Shigang and Tian, Xinhui and Yuan, Liang and Jia, Haipeng and Vasilakos, Athanasios V.},
journal={Proceedings of the IEEE},
title={Parallel Processing Systems for Big Data: A Survey},
year={2016},
volume={104},
number={11},
pages={2114-2136},
abstract={The volume, variety, and velocity properties of big data and the valuable information it contains have motivated the investigation of many new parallel data processing systems in addition to the approaches using traditional database management systems (DBMSs). MapReduce pioneered this paradigm change and rapidly became the primary big data processing system for its simplicity, scalability, and fine-grain fault tolerance. However, compared with DBMSs, MapReduce also arouses controversy in processing efficiency, low-level abstraction, and rigid dataflow. Inspired by MapReduce, nowadays the big data systems are blooming. Some of them follow MapReduce's idea, but with more flexible models for general-purpose usage. Some absorb the advantages of DBMSs with higher abstraction. There are also specific systems for certain applications, such as machine learning and stream data processing. To explore new research opportunities and assist users in selecting suitable processing systems for specific applications, this survey paper will give a high-level overview of the existing parallel data processing systems categorized by the data input as batch processing, stream processing, graph processing, and machine learning processing and introduce representative projects in each category. As the pioneer, the original MapReduce system, as well as its active variants and extensions on dataflow, data access, parameter tuning, communication, and energy optimizations will be discussed at first. System benchmarks and open issues for big data processing will also be studied in this survey.},
keywords={Big data;Computer applications;Programming;Parallel processing;Data models;Benchmark testing;Machine learning;Structured Query Language;Big data;machine learning;MapReduce;parallel processing;SQL;survey},
doi={10.1109/JPROC.2016.2591592},
ISSN={1558-2256},
month={Nov},}
@INPROCEEDINGS{8672226,
author={Wang, Wen'an and Zhang, Chuang and Chen, Xiaojun and Li, Zhao and Ding, Hong and Wen, Xin},
booktitle={2018 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Ubiquitous Computing & Communications, Big Data & Cloud Computing, Social Computing & Networking, Sustainable Computing & Communications (ISPA/IUCC/BDCloud/SocialCom/SustainCom)},
title={An On-the-Fly Scheduling Strategy for Distributed Stream Processing Platform},
year={2018},
volume={},
number={},
pages={773-780},
abstract={Distributed stream processing can accomplish real-time processing of continuous streaming big data to obtain valuable information with high velocity. To maintain continuously stable and efficient running of stream applications, however, continuous online scheduling operations are required in the context of highly dynamic data stream. For this reason, this paper proposes the on-the-fly scheduling strategy in a distributed stream processing environment, which dynamically predicts abnormal events through double exponential smoothing and adopts traffic-aware active migration protocol to adjust the network routing structure on-the-fly to balance the inter-worker load. Moreover, an evaluation method is proposed to quantitatively analyze the various scheduling objectives. Finally, we commendably apply the scheduling strategy to a stream processing platform, which regards docker instance as basic scheduling units. Meanwhile, based on the platform and the evaluation method, we complete performance comparison experiments of the scheduling algorithm. The experimental results indicate that our algorithm has excellent performance in throughput of topology, average processing time and balance of task load, which is suitable for deployment in a distributed environment with large-scale nodes and tasks.},
keywords={Task analysis;Processor scheduling;Topology;Dynamic scheduling;Smoothing methods;Prediction algorithms;distributed stream processing;prediction algorithm;exponential smoothing;traffic-aware migration;evaluation method},
doi={10.1109/BDCloud.2018.00116},
ISSN={},
month={Dec},}
@ARTICLE{7274673,
author={Mullen, Tim R. and Kothe, Christian A. E. and Chi, Yu Mike and Ojeda, Alejandro and Kerth, Trevor and Makeig, Scott and Jung, Tzyy-Ping and Cauwenberghs, Gert},
journal={IEEE Transactions on Biomedical Engineering},
title={Real-time neuroimaging and cognitive monitoring using wearable dry EEG},
year={2015},
volume={62},
number={11},
pages={2553-2567},
abstract={Goal: We present and evaluate a wearable high-density dry-electrode EEG system and an open-source software framework for online neuroimaging and state classification. Methods: The system integrates a 64-channel dry EEG form factor with wireless data streaming for online analysis. A real-time software framework is applied, including adaptive artifact rejection, cortical source localization, multivariate effective connectivity inference, data visualization, and cognitive state classification from connectivity features using a constrained logistic regression approach (ProxConn). We evaluate the system identification methods on simulated 64-channel EEG data. Then, we evaluate system performance, using ProxConn and a benchmark ERP method, in classifying response errors in nine subjects using the dry EEG system. Results: Simulations yielded high accuracy (AUC = 0.97 ± 0.021) for real-time cortical connectivity estimation. Response error classification using cortical effective connectivity [short-time directdirected transfer function (sdDTF)] was significantly above chance with similar performance (AUC) for cLORETA (0.74 ± 0.09) and LCMV (0.72 ± 0.08) source localization. Cortical ERPbased classification was equivalent to ProxConn for cLORETA (0.74 ± 0.16) butsignificantlybetterforLCMV (0.82 ± 0.12). Conclusion: We demonstrated the feasibility for real-time cortical connectivity analysis and cognitive state classification from highdensity wearable dry EEG. Significance: This paper is the first validated application of these methods to 64-channel dry EEG. This study addresses a need for robust real-time measurement and interpretation of complex brain activity in the dynamic environment of the wearable setting. Such advances can have broad impact in research, medicine, and brain-computer interfaces. The pipelines are made freely available in the open-source SIFT and BCILAB toolboxes.},
keywords={Electroencephalography;Electrodes;Sensors;Headphones;Biomedical monitoring;Real-time systems;Wireless communication;Wearable sensors;EEG;dry-contact electrode;brain-computer interfaces;neuroimaging;connectivity analysis;adaptive systems;Adaptive systems;brain–computer interfaces (BCI);connectivity analysis;dry-contact electrode;electroencephalography (EEG);neuroimaging;wearable sensors},
doi={10.1109/TBME.2015.2481482},
ISSN={1558-2531},
month={Nov},}
@INPROCEEDINGS{7836456,
author={Mossel, Annette and Kroeter, Manuel},
booktitle={2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)},
title={Streaming and Exploration of Dynamically Changing Dense 3D Reconstructions in Immersive Virtual Reality},
year={2016},
volume={},
number={},
pages={43-48},
abstract={We introduce a novel framework that enables large-scale dense 3D scene reconstruction, data streaming over the network and immersive exploration of the reconstructed environment using virtual reality. The system is operated by two remote entities, where one entity – for instance an autonomous aerial vehicle – captures and reconstructs the environment as well as transmits the data to another entity – such as human observer – that can immersivly explore the 3D scene, decoupled from the view of the capturing entity. The performance evaluation revealed the framework’s capabilities to perform RGB-D data capturing, dense 3D reconstruction, streaming and dynamic scene updating in real time for indoor environments up to a size of 100m2, using either a state-of-the-art mobile computer or a workstation. Thereby, our work provides a foundation for enabling immersive exploration of remotely captured and incrementally reconstructed dense 3D scenes, which has not shown before and opens up new research aspects in future.},
keywords={Three-dimensional displays;Image reconstruction;Solid modeling;Surface reconstruction;Graphics processing units;Cameras;Streaming media},
doi={10.1109/ISMAR-Adjunct.2016.0035},
ISSN={},
month={Sep.},}
@ARTICLE{6775008,
author={Chakareski, Jacob},
journal={IEEE Transactions on Communications},
title={Wireless Streaming of Interactive Multi-View Video via Network Compression and Path Diversity},
year={2014},
volume={62},
number={4},
pages={1350-1357},
abstract={We formulate a system framework for network compression of interactive multi-view streaming video. The setup comprises a media server that delivers the content over two independent network paths to a client. Our system features a proxy-server located at the junction of the wired and wireless portions of each path. The proxy dynamically adapts the content data sent over the wireless links, in response to channel quality feedback from the client, such that video distortion at the client is minimized. We analyze the performance of our system and contrast its characteristics with dynamic content adaptation at the source and conventional streaming architectures, including scalable video. We numerically simulate the operation of all streaming systems under comparison and establish a close agreement between our analysis and the experimental findings. The proposed system delivers superior video quality over the reference competitors, while enabling notable transmission rate savings, at the same time.},
keywords={Wireless communication;Streaming media;Servers;Delays;Encoding;Cameras;Signal to noise ratio;Multi-view video multiple descriptions;multi-path wireless transmission;interactive immersive video streaming;network compression},
doi={10.1109/TCOMM.2014.022314.120890},
ISSN={1558-0857},
month={April},}
@INPROCEEDINGS{6831304,
author={Chakareski, Jacob},
booktitle={2013 IEEE Global Communications Conference (GLOBECOM)},
title={Wireless streaming of interactive multi-view video: Network compression meets path diversity},
year={2013},
volume={},
number={},
pages={1612-1618},
abstract={I formulate a system framework for network compression of interactive multi-view streaming video. The setup comprises a media server that delivers the content over two independent network paths to a client. My system features a proxy-server located at the junction of the wired and wireless portions of each path. The proxy dynamically adapts the content data sent over the wireless links, in response to channel quality feedback from the client, such that video distortion at the client is minimized. I analyze the performance of my system and contrast its characteristics with dynamic content adaptation at the source and conventional streaming architectures, including scalable video. I numerically simulate the operation of all streaming systems under comparison and establish a close agreement between my analysis and the experimental findings. The proposed system delivers superior video quality over the reference competitors, while enabling notable transmission rate savings, at the same time.},
keywords={Wireless communication;Delays;Signal to noise ratio;Streaming media;Servers;Encoding;Video recording},
doi={10.1109/GLOCOM.2013.6831304},
ISSN={1930-529X},
month={Dec},}
@INPROCEEDINGS{6888904,
author={Friedman, Roy and Libov, Alexander and Vigfusson, Ymir},
booktitle={2014 IEEE 34th International Conference on Distributed Computing Systems},
title={MOLStream: A Modular Rapid Development and Evaluation Framework for Live P2P Streaming},
year={2014},
volume={},
number={},
pages={278-287},
abstract={We present MOL Stream, a modular framework for rapid development and evaluation of P2P live streaming systems. MOL Stream allows P2P streaming protocols to be decomposed into basic blocks, each associated with a standard functional specification. By exposing structural commonalities between these components, MOL Stream enables specific implementations of these building blocks to be combined in order to devise, refine and evaluate new P2P live streaming protocols. Our approach offers several benefits. First, block encapsulation entails that more advanced individual components, e.g., the overlay, can seamlessly replace existing ones without affecting the rest of the system. As a case study, we show how MOL Stream can seamlessly substitute the overlay used by DONet/Coolstreaming, a popular P2P live streaming implementation, for an improved version. Second, MOL Stream facilitates the comparison between various protocols over local clusters or wide-area test beds such as Planet Lab. The combination of rapid prototyping and minimum effort valuation enables researchers and students to faster understand how various design choices at different levels impact the performance and scalability of the protocol, as shown through several examples in this paper. MOL Stream is written in Java and is freely available as an open-source project at https://sourceforge.net/projects/molstream/.},
keywords={Peer-to-peer computing;Protocols;Bandwidth;Libraries;Measurement;Java;Cost function;P2P;Live Streaming;Modular middleware;Development Framework;Evaluation Framework},
doi={10.1109/ICDCS.2014.36},
ISSN={1063-6927},
month={June},}