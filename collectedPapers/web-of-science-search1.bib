
@inproceedings{ WOS:000296057102125,
Author = {Chen, Yishuai and Zhang, Baoxian and Chen, Changjia},
Book-Group-Author = {IEEE},
Title = {Modeling and Performance Analysis of P2P Live Streaming Systems under
   Flash Crowds},
Booktitle = {2011 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS (ICC)},
Series = {IEEE International Conference on Communications},
Year = {2011},
Note = {IEEE International Conference on Communications (ICC), Kyoto, JAPAN, JUN
   05-09, 2011},
Organization = {IEEE; IEEE Commun Soc; IEICE Commun Soc; Sci Council Japan},
Abstract = {A fundamental problem that a peer-to-peer (P2P) live streaming system
   faces is how to support flash crowds effectively. A flash crowd occurs
   when a burst of join requests arrive at a system. When a flash crowd
   occurs, the sudden arrival of numerous peers may starve the upload
   capacity of a P2P system, and degrade the quality of service. By
   theoretical analysis and simulations, we find that a system has limited
   capacity to handle a flash crowd: It can recover to a new stable state
   when the size of flash crowd is small or moderate, but collapse when the
   flash crowd is excessively large. The capacity of a system is
   independent of initial state of the system while relevant to stable
   peers' departure rate, which suggests this capacity is an essential
   property of a P2P live streaming system. In addition, we prove that a
   P2P live streaming system with admission control has excellent capacity
   to handle flash crowds: It can recover from flash crowds of excessively
   large size and a startup peer's waiting time scales logarithmically with
   the size of flash crowds. Our theoretical model and simulation results
   provide a promising framework to understand the capacity of a P2P live
   streaming system for handling flash crowds.},
DOI = {10.1109/icc.2011.5962881},
ISSN = {1550-3607},
ISBN = {978-1-61284-233-2},
Unique-ID = {WOS:000296057102125},
}

@inproceedings{ WOS:000189424600006,
Author = {Tu, YC and Sun, JZ and Prabhakar, S},
Editor = {Venkatasubramanian, N},
Title = {Performance analysis of a hybrid media streaming system},
Booktitle = {MULTIMEDIA COMPUTING AND NETWORKING 2004},
Series = {Proceedings of SPIE},
Year = {2004},
Volume = {5305},
Pages = {69-82},
Note = {Conference on Multimedia Computing and Networking, San Jose, CA, JAN
   21-22, 2004},
Organization = {Soc Imaging Sci \& Technol; SPIE; ACM SIG Multimedia},
Abstract = {Recent research efforts have demonstrated the promising potential of
   building cost-effective media streaming systems on top of peer-to-peer
   (P2P) networks. A P2P media streaming architecture can reach large size
   and streaming capacity that are difficult to achieve in conventional
   server-based streaming services. Hybrid streaming systems that combine
   the use of dedicated streaming servers and P2P networks were proposed to
   build on the advantages of both paradigms. However, the dynamics of such
   systems and the impact of various factors on system behaviors are not
   totally clear. In this paper, we present an analytical framework to
   quantitatively study the features of a hybrid media streaming model.
   Based on this framework, we derive an equation to describe the capacity
   growth of a single-file streaming system. We then extend the analysis to
   multi-file scenarios by solving an optimization problem. We also show
   that the system model achieves optimal allocation of server bandwidth
   among different media objects. The unpredictable departure/failure of
   peers is a critical factor that affects performance of P2P systems. To
   model peer failures in our system, we propose the concept of peer
   lifespan. The original equation is enhanced with coefficients generated
   from the distribution of peer lifespan. Results from large-scale
   simulations support our analysis.},
ISSN = {0277-786X},
EISSN = {1996-756X},
ISBN = {0-8194-5208-4},
Unique-ID = {WOS:000189424600006},
}

@inproceedings{ WOS:000302390700022,
Author = {Kotevski, Zoran and Mitrevski, Pece},
Editor = {Gusev, M and Mitrevski, P},
Title = {A Modeling Framework for Performance Analysis of P2P Live Video
   Streaming Systems},
Booktitle = {ICT INNOVATIONS 2010},
Series = {Communications in Computer and Information Science},
Year = {2011},
Volume = {83},
Pages = {215-225},
Note = {ICT Innovations Conference 2010, Ohrid, MACEDONIA, SEP 12-15, 2010},
Organization = {Macedonian Soc Informat \& Commun Technol; UKIM, Univ Ss Cyril \&
   Methodius; UKIM, Inst Informat, Fac Nat Sci \& Math; UKIM, Fac Elect
   Engn \& Informat Technol; Asseco S E Europe; Duna Comp; Lancom Comp;
   Netcetera; Neocom},
Abstract = {Client/server media streaming systems exhibit streaming limitations when
   number of clients rises and the server can no longer sustain the upload
   load. At first, IP Multicast was proposed as an alternative solution to
   this problem but its deployment brought many practical issues in
   scalability and deployment that prevented it from wider use. Recently, a
   new promising technique emerged which is cost effective, easy to deploy
   and can support thousands of simultaneous users. It's a peer to peer
   network of logically connected clients which form an application level
   overlay network on top of the physical network. This new paradigm brings
   numerous advantages, but also a lot of open issues that need to be
   resolved. This paper exposes the fundamental characteristics of p2p live
   video streaming systems, gives a survey of p2p video streaming
   applications and presents a novel modeling framework for performance
   analysis of such systems as our main goal in future research.},
ISSN = {1865-0929},
EISSN = {1865-0937},
ISBN = {978-3-642-19324-8},
ResearcherID-Numbers = {Mitrevski, Pece/V-6000-2019
   Kotevski, Zoran/E-3704-2015},
ORCID-Numbers = {Mitrevski, Pece/0000-0002-0300-7115
   Kotevski, Zoran/0000-0002-3154-0259},
Unique-ID = {WOS:000302390700022},
}

@inproceedings{ WOS:000393364900003,
Author = {Gao, Changjun and Huo, Yusong and Su, Yujie and Wu, Jun and Ma, Yan},
Editor = {Lin, J and Wu, J and Wang, W},
Title = {SU-PEERCAST: A P2P LIVE STREAMING SYSTEM WITH SUPER-NODE BASED ON
   PEERCAST},
Booktitle = {PROCEEDINGS OF THE 2010 INTERNATIONAL CONFERENCE ON ADVANCED
   INTELLIGENCE AND AWARENESS INTERNET, AIAI2010},
Year = {2010},
Pages = {23-27},
Note = {International Conference on Advanced Intelligence and Awareness Internet
   (AIAI2010), Beijing, PEOPLES R CHINA, OCT 23-25, 2010},
Organization = {Beijing Univ Posts \& Telecommun; Minist Educ China; Nat Sci Fdn China;
   Inst Engn \& Technol; Inst Elect Informat \& Commun Engineers},
Abstract = {The amount of client a live streaming system can serve by unicast is
   limited by the bandwidth requirement. Theoretically, IP-multicast is an
   efficient solution for that situation, but it suffers from poor
   deployment. Therefore, another solution, called Application Layer
   Multicast (ALM), is being increasingly recognized as a available
   alternative. However, this solution also has certain shortcomings. In
   this paper, we firstly introduce a live streaming system--PeerCast based
   on application layer multicast, and besides that we indicate its
   existing problems under practical deployment in the large-scale network.
   Secondly, in order to improve the PeerCast system performance, we append
   a Super-Node layer, which can divide the live system into different
   domains, and re-design the play process and heartbeat detection
   mechanism for our new live system. Finally, the re-designed system
   performance evaluation is presented.},
ISBN = {978-1-84919-206-4},
Unique-ID = {WOS:000393364900003},
}

@inproceedings{ WOS:000263157700036,
Author = {Giacomazzi, Paolo and Poli, Alessandro},
Editor = {Hobbs, M and Xiang, Y and Zhou, W},
Title = {Performance analysis of peer-to-peer video streaming systems with tree
   and forest topology},
Booktitle = {PROCEEDINGS OF THE 2008 14TH IEEE INTERNATIONAL CONFERENCE ON PARALLEL
   AND DISTRIBUTED SYSTEMS},
Year = {2008},
Pages = {287-294},
Note = {14th International Conference on Parallel and Distributed Systems,
   Melbourne, AUSTRALIA, DEC 08-10, 2008},
Organization = {IEEE Comp Soc Tech Comm Parallel Proc; IEEE Comp Soc Tech Comm
   Distributed Proc; IEEE Comp Soc; IEEE},
Abstract = {Peer-to-peer networks are an increasingly popular solution for the
   distribution of media content to a large number of users, with limited
   investments for network infrastructures. The distribution of a real time
   video stream imposes strict performance requirements such as small
   playback delays and few frame losses. In this paper, we focus on
   peer-to-peer video streaming systems with tree or forest content
   distribution structure and we provide a sensitivity analysis to
   investigate the impact of three critical parameters rejoin time, average
   permanence time of peers and playback threshold - over the quality of
   the video stream received by users. The study, carried out through
   simulation, considers a general peer-to-peer video streaming reference
   model with tree/forest topology.},
DOI = {10.1109/ICPADS.2008.12},
ISBN = {978-0-7695-3434-3},
Unique-ID = {WOS:000263157700036},
}

@inproceedings{ WOS:000855078401028,
Author = {Verheijde, Jim and Karakoidas, Vassilios and Fragkoulis, Marios and
   Katsifodimos, Asterios},
Book-Group-Author = {IEEE Comp Soc},
Title = {S- QUERY: Opening the Black Box of Internal Stream Processor State},
Booktitle = {2022 IEEE 38TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE 2022)},
Series = {IEEE International Conference on Data Engineering},
Year = {2022},
Pages = {1314-1327},
Note = {38th IEEE International Conference on Data Engineering (ICDE), ELECTR
   NETWORK, MAY 09-11, 2022},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {Distributed streaming dataflow systems have evolved into scalable and
   fault-tolerant production-grade systems. Their applicability has
   departed from the mere analysis of streaming windows and complex-event
   processing, and now includes cloud applications and machine learning
   inference. Although the advancements in the state management of
   streaming systems have contributed significantly to their maturity, the
   internal state of streaming operators has been so far hidden from
   external applications. However, that internal state can be seen as a
   materialized view that can be used for analytics, monitoring, and
   debugging.
   In this paper we argue that exposing the internal state of streaming
   systems to outside applications by making it queryable, opens the road
   for novel use cases. To this end, we introduce S-QUERY: an approach and
   reference architecture where the state of stream processors can be
   queried - either live or through snapshots, achieving different
   isolation levels. We show how this new capability can be implemented in
   an existing opensource stream processor, and how queryable state can
   affect the performance of such a system. Our experimental evaluation
   suggests that the snapshot configuration adds only up to 8ms latency in
   the 99.99th percentile and negligible increase in 0-90th percentiles.},
DOI = {10.1109/ICDE53745.2022.00103},
ISSN = {1084-4627},
ISBN = {978-1-6654-0883-7},
Unique-ID = {WOS:000855078401028},
}

@article{ WOS:000756796100011,
Author = {Su, Guoxin and Liu, Li and Zhang, Minjie and Rosenblum, David S.},
Title = {Quantitative Verification for Monitoring Event-Streaming Systems},
Journal = {IEEE TRANSACTIONS ON SOFTWARE ENGINEERING},
Year = {2022},
Volume = {48},
Number = {2},
Pages = {538-550},
Month = {FEB 1},
Abstract = {High-performance data streaming technologies are increasingly adopted in
   IT companies to support the integration of heterogeneous and possibly
   distributed applications. Compared with the traditional message queuing
   middleware, a streaming platform enables the implementation of
   event-streaming systems (ESS) which include not only complex queues but
   also pipelines that transform and react to the streams of data. By
   analysing the centralised data streams, one can evaluate the
   Quality-of-Service for other systems and components that produce or
   consume those streams. We consider the exploitation of probabilistic
   model checking as a performance monitoring technique for ESS systems.
   Probabilistic model checking is a mature, powerful verification
   technique with successful application in performance analysis. However,
   an ESS system may contain quantitative parameters that are determined by
   event streams observed in a certain period of time. In this paper, we
   present a novel theoretical framework called QV4M (meaning
   ``quantitative verification for monitoring{''}) for monitoring ESS
   systems, which is based on two recent methods of probabilistic model
   checking. QV4M assumes the parameters in a probabilistic system model as
   random variables and infers the statistical significance for the
   probabilistic model checking output. We also present an empirical
   evaluation of computational time and data cost for QV4M.},
DOI = {10.1109/TSE.2020.2996033},
ISSN = {0098-5589},
EISSN = {1939-3520},
ORCID-Numbers = {Su, Guoxin/0000-0002-2087-4894
   Liu, Li/0000-0002-4776-5292},
Unique-ID = {WOS:000756796100011},
}

@article{ WOS:000382358700016,
Author = {Saleh, Bassel and Qiu, Dongyu},
Title = {Performance Analysis of Network-Coding-Based P2P Live Streaming Systems},
Journal = {IEEE-ACM TRANSACTIONS ON NETWORKING},
Year = {2016},
Volume = {24},
Number = {4},
Pages = {2140-2153},
Month = {AUG},
Abstract = {Peer-to-peer (P2P) video streaming is a scalable and cost-effective
   technology to stream video content to a large population of users and
   has attracted a lot of research for over a decade now. Recently, network
   coding has been introduced to improve the efficiency of these systems
   and to simplify the protocol design. There are already some successful
   commercial applications that utilize network coding. However, previous
   analytical studies of network-coding-based P2P streaming systems mainly
   focused on fundamental properties of the system and ignored the
   influence of the protocol details. In this study, a unique stochastic
   model is developed to reveal how segments of the video stream evolve
   over their lifetime in the buffer before they go into playback.
   Different strategies for segment selection have been studied with the
   model, and their performance has been compared. A new approximation of
   the probability of linear independence of coded blocks has been proposed
   to study the redundancy of network coding. Finally, extensive numerical
   results and simulations have been provided to validate our model. From
   these results, in-depth insights into how system parameters and segment
   selection strategies affect the performance of the system have been
   obtained.},
DOI = {10.1109/TNET.2015.2448597},
ISSN = {1063-6692},
EISSN = {1558-2566},
Unique-ID = {WOS:000382358700016},
}

@inproceedings{ WOS:000771729900009,
Author = {Lu, Pengqi and Yue, Yue and Yuan, Liang and Zhang, Yunquan},
Editor = {Lai, Y and Wang, T and Jiang, M and Xu, G and Liang, W and Castiglione, A},
Title = {AutoFlow: Hotspot-Aware, Dynamic Load Balancing for Distributed Stream
   Processing},
Booktitle = {ALGORITHMS AND ARCHITECTURES FOR PARALLEL PROCESSING, ICA3PP 2021, PT
   III},
Series = {Lecture Notes in Computer Science},
Year = {2022},
Volume = {13157},
Pages = {133-151},
Note = {21st International Conference on Algorithms and Architectures for
   Parallel Processing (ICA3PP), ELECTR NETWORK, DEC 03-05, 2021},
Organization = {Swinburne Univ Technol; Springer, Lecture Notes Comp Sci; FAAI},
Abstract = {Stream applications are widely deployed on the cloud. While modern
   distributed streaming systems like Flink and Spark Streaming can
   schedule and execute them efficiently, streaming dataflows are often
   dynamically changing, which may cause computation imbalance and
   back-pressure.
   We introduce AutoFlow, an automatic, hotspot-aware dynamic load balance
   system for streaming dataflows. It incorporates a centralized scheduler
   that monitors the load balance in the entire dataflow dynamically and
   implements state migrations correspondingly. The scheduler achieves
   these two tasks using a simple asynchronous distributed control message
   mechanism and a hotspot-diminishing algorithm. The timing mechanism
   supports implicit barriers and a highly efficient state-migration
   without global barriers or pauses to operators. It also supports a
   time-window based load-balance measurement and feeds them to the
   hotspot-diminishing algorithm without user interference. We implemented
   AutoFlow on top of Ray, an actor-based distributed execution framework.
   Our evaluation based on various streaming benchmark datasets shows that
   AutoFlow achieves good load-balance and incurs a low latency overhead in
   a highly data-skew workload.},
DOI = {10.1007/978-3-030-95391-1\_9},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-030-95391-1; 978-3-030-95390-4},
Unique-ID = {WOS:000771729900009},
}

@inproceedings{ WOS:000810735004069,
Author = {Ribezzo, Giuseppe and De Cicco, Luca and Palmisano, Vittorio and
   Mascolo, Saverio},
Book-Group-Author = {ASSOC COMP MACHINERY},
Title = {TAPAS-360 degrees: A Tool for the Design and Experimental Evaluation of
   360 degrees Video Streaming Systems},
Booktitle = {MM `20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON
   MULTIMEDIA},
Year = {2020},
Pages = {4477-4480},
Note = {28th ACM International Conference on Multimedia (MM), ELECTR NETWORK,
   OCT 12-16, 2020},
Organization = {ACM SIGMM; Assoc Comp Machinery},
Abstract = {Video streaming platforms are required to innovate their delivery
   pipeline to allow new and more immersive video content to be supported.
   In particular, Omnidirectional videos enable the user to explore a 360
   degrees scene by moving their heads using Head Mounted Display devices.
   Viewport adaptive streaming allows changing dynamically the quality of
   the video falling in the user's field of view. In this paper, we present
   TAPAS-360 degrees, an open-source tool that enables designing and
   experimenting all the components required to build omnidirectional video
   streaming systems. The tool can be used by researchers focusing on the
   design of viewport-adaptive algorithms and also to produce video streams
   to be employed for subjective and objective Quality of Experience
   evaluations.},
DOI = {10.1145/3394171.3414541},
ISBN = {978-1-4503-7988-5},
Unique-ID = {WOS:000810735004069},
}

@inproceedings{ WOS:000257132600001,
Author = {Bracciale, L. and Lo Piccolo, F. and Luzzi, D. and Salsano, S. and
   Bianchi, G. and Blefari-Melazzi, N.},
Book-Group-Author = {IEEE},
Title = {A push-based scheduling algorithm for large scale P2P live streaming},
Booktitle = {2008 4TH INTERNATIONAL TELECOMMUNICATION NETWORKING WORKSHOP ON QOS IN
   MULTISERVICE IP NETWORKS},
Year = {2008},
Pages = {1-7},
Note = {4th International Telecommunication Networking Workshop on QoS in
   Multiservice IP Networks, Venice, ITALY, FEB 13-15, 2008},
Organization = {TELECOM; CISCO; gtti; Ist Electtr Ingegner Informat Telecomun},
Abstract = {In this paper, we present a chunk scheduling algorithm for a mesh-based
   peer-to-peer live streaming system and we evaluate it by simulations
   over large-scale networks. Literature papers typically design chunk
   scheduling algorithms by considering the chunk delivery ratio as
   performance metric. We propose a push-based algorithm, which not only
   tries to maximize the chunk delivery ratio but it also takes into
   account and tries to minimize the delivery delay of chunks at the peer
   nodes. This is an important requirement, when dealing with real-time
   multimedia flows. Another important contribution of this paper is the
   design and implementation of a simulator able to evaluate the
   performance of large scale P2P networks (tens of thousands peers). The
   importance of this contribution lies in the fact that existing
   simulators and performance studies handle at most hundreds or few
   thousands of peers, while real-life P2P streaming systems aim at
   distributing contents to several hundreds of thousands, if not millions,
   of users. The performance evaluation study aims at providing a
   comprehensive view of what performance can be expected for mesh-based
   peer-to-peer streaming systems, both in terms of chunk delivery ratio
   and delay, for a large range of the number of users. The individual
   effect of a variety of system parameters, and especially number of
   partner nodes in the mesh, constrained link bandwidth, node
   heterogeneity, and network size, has been analyzed. Our results show
   that performances of the proposed push-based solution are already quite
   effective even with severely bandwidth constrained large scale networks.},
DOI = {10.1109/ITNEWS.2008.4488121},
ISBN = {978-1-4244-1844-2},
ResearcherID-Numbers = {Salsano, Stefano/B-2914-2010
   Bracciale, Lorenzo/AHH-1873-2022
   Bracciale, Lorenzo/AAG-6136-2019
   },
ORCID-Numbers = {Salsano, Stefano/0000-0003-3040-3559
   Bracciale, Lorenzo/0000-0002-6673-3157
   Bianchi, Giuseppe/0000-0001-7277-7423},
Unique-ID = {WOS:000257132600001},
}

@inproceedings{ WOS:000242373900285,
Author = {Tan, Jin and Chen, XiaoZhu},
Editor = {Wenbo, X},
Title = {Minimizing delivery cost in hybrid overlay networks for streaming media},
Booktitle = {DCABES 2006 Proceedings, Vols 1 and 2},
Year = {2006},
Pages = {1184-1187},
Note = {International Symposium on Distributed Computing and Applications to
   Business, Engineering and Science, Hangzhou, PEOPLES R CHINA, OCT 12-15,
   2006},
Abstract = {There are three key issues on streaming system in Internet: scalability,
   delivery cost and QoS. The scalability and QoS was improved by means of
   pushing the streaming objects to the client sides in a CDNs-based
   streaming system, but the cost of deploying and maintaining was very
   high. However it was difficult to provide good QoS in a P2P-based
   streaming system due to the heterogeneous peers and arbitrary network
   connection of peers. Under the hybrid architecture proposed recently,
   this paper presents a new content delivery approach with which the
   streaming media is segmented, cached on proxy in CDNs and stored on
   peers in P2P dispersedly, hence it takes less resource of peers and be
   fairer. It is shown that traffic in CDNs and workloads of edge server
   are reduced effectively, the reliability of streaming delivery in P2P is
   ensured by using this approach according to performance analysis.},
ISBN = {7-81118-023-5},
Unique-ID = {WOS:000242373900285},
}

@inproceedings{ WOS:000288888100037,
Author = {Kowalski, Greg and Hefeeda, Mohamed},
Book-Group-Author = {IEEE},
Title = {Empirical Analysis of Multi-Sender Segment Transmission Algorithms in
   Peer-to-Peer Streaming},
Booktitle = {2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009)},
Year = {2009},
Pages = {243-250},
Note = {11th IEEE International Symposium on Multimedia, San Diego, CA, DEC
   14-16, 2009},
Abstract = {We study and analyze segment transmission scheduling algorithms in
   swarm-based peer-to-peer (P2P) streaming systems. These scheduling
   algorithms are responsible for coordinating the streaming of video data
   from multiple senders to a receiver in each streaming session. Although
   scheduling algorithms directly impact the user-perceived visual quality
   in streaming sessions, they have not been rigorously analyzed in the
   literature. In this paper, we first conduct an extensive experimental
   study to evaluate various scheduling algorithms on many Planet Lab nodes
   distributed all over the world. We study three important performance
   metrics: (i) continuity index which captures the smoothness of the video
   playback, (ii) load balancing index which indicates how the load is
   spread across sending peers, and (iii) buffering delay required to
   ensure continuous playback. Our experimental analysis reveals the
   strengths and weaknesses of each scheduling algorithm, and provides
   insights for developing better ones in order to improve the overall
   performance of P2P streaming systems. Then, we propose a new scheduling
   algorithm called On-time Delivery of VBR streams (ODV). Our experiments
   show that the proposed scheduling algorithm improves the playback
   quality by increasing the continuity index, requires smaller buffering
   delays, and achieves more balanced load distribution across peers.},
DOI = {10.1109/ISM.2009.55},
ISBN = {978-1-4244-5231-6},
Unique-ID = {WOS:000288888100037},
}

@inproceedings{ WOS:000522460300023,
Author = {Venkataraman, Shivaram and Panda, Aurojit and Ousterhout, Kay and
   Armbrust, Michael and Ghodsi, Ali and Franklin, Michael J. and Recht,
   Benjamin and Stoica, Ion},
Book-Group-Author = {ACM},
Title = {Drizzle: Fast and Adaptable Stream Processing at Scale},
Booktitle = {PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS
   PRINCIPLES (SOSP `17)},
Year = {2017},
Pages = {374-389},
Note = {26th ACM Symposium on Operating Systems Principles (SOSP), Shanghai,
   PEOPLES R CHINA, OCT 28-31, 2017},
Organization = {Assoc Comp Machinery; ACM SIGOPS; USENIX; Huawei; Alibaba; Apple;
   ArXanFintech; Baidu; BOPU Asset; Facebook; Intel; Microsoft; Tencent;
   CreditEase; DiDi; Google; SmartX; VMware; Akamai; Amazon; FMA AI; IBM
   Res; Oracle; Uber; HP Enterprise},
Abstract = {Large scale streaming systems aim to provide high throughput and low
   latency. They are often used to run mission-critical applications, and
   must be available 24x7. Thus such systems need to adapt to failures and
   inherent changes in workloads, with minimal impact on latency and
   throughput. Unfortunately, existing solutions require operators to
   choose between achieving low latency during normal operation and
   incurring minimal impact during adaptation. Continuous operator
   streaming systems, such as Naiad and Flink, provide low latency during
   normal execution but incur high overheads during adaptation (e.g.,
   recovery), while micro-batch systems, such as Spark Streaming and
   FlumeJava, adapt rapidly at the cost of high latency during normal
   operations.
   Our key observation is that while streaming workloads require
   millisecond-level processing, workload and cluster properties change
   less frequently. Based on this, we develop Drizzle, a system that
   decouples the processing interval from the coordination interval used
   for fault tolerance and adaptability. Our experiments on a 128 node EC2
   cluster show that on the Yahoo Streaming Benchmark, Drizzle can achieve
   endto-end record processing latencies of less than 100ms and can get
   2-3x lower latency than Spark. Drizzle also exhibits better
   adaptability, and can recover from failures 4x faster than Flink while
   having up to 13x lower latency during recovery.},
DOI = {10.1145/3132747.3132750},
ISBN = {978-1-4503-5085-3},
Unique-ID = {WOS:000522460300023},
}

@article{ WOS:000742908500071,
Author = {Gomes, Ana Sofia and Oliveirinha, Joao and Cardoso, Pedro and Bizarro,
   Pedro},
Title = {Railgun: managing large streaming windows under MAD requirements},
Journal = {PROCEEDINGS OF THE VLDB ENDOWMENT},
Year = {2021},
Volume = {14},
Number = {12},
Pages = {3069-3082},
Month = {AUG},
Note = {47th International Conference on Very Large Data Bases (VLDB),
   Copenhagen, DENMARK, AUG 16-20, 2021},
Abstract = {Some mission critical systems, e.g., fraud detection, require accurate,
   real-time metrics over long time sliding windows on applications that
   demand high throughput and low latencies. As these applications need to
   run ``forever{''} and cope with large, spiky data loads, they further
   require to be run in a distributed setting. We are unaware of any
   streaming system that provides all those properties. Instead, existing
   systems take large simplifications, such as implementing sliding windows
   as a fixed set of overlapping windows, jeopardizing metric accuracy
   (violating regulatory rules) or latency (breaching service agreements).
   In this paper, we propose Railgun, a fault-tolerant, elastic, and
   distributed streaming system supporting real-time sliding windows for
   scenarios requiring high loads and millisecond-level latencies. We
   benchmarked an initial prototype of Railgun using real data, showing
   significant lower latency than Flink and low memory usage independent of
   window size. Further, we show that Railgun scales nearly linearly,
   respecting our msec-level latencies at high percentiles (<250ms @
   99.9\%) even under a load of 1 million events per second.},
DOI = {10.14778/3476311.3476384},
ISSN = {2150-8097},
Unique-ID = {WOS:000742908500071},
}

@article{ WOS:000353297300005,
Author = {Yan, Junhua and Tian, Chen and Sun, Jingdong and Mao, Hanzi},
Title = {Improve Distributed Client Lifecycle Control in ShadowStream},
Journal = {INTERNATIONAL JOURNAL OF WEB SERVICES RESEARCH},
Year = {2014},
Volume = {11},
Number = {4, SI},
Pages = {62-78},
Month = {OCT-DEC},
Abstract = {ShadowStream is a novel Internet live streaming system that integrates
   performance evaluation as an intrinsic capability. An essential
   component in ShadowStream is distributed lifecycle control mechanism,
   which assigns each client a virtual arrival/lifetime to create a
   particular scenario to evaluate the performance of streaming system. The
   original design focuses on utilizing stable streaming viewers in
   physical world to guarantee the accuracy of ShadowStream, which, on the
   other hand, significantly limits the scale of the experiment. The
   authors' research develops a novel distributed client lifecycle control
   to get rid of restrictions caused by the limited number of stable
   viewers in live-testing streaming networks. The core idea of their
   research is to match the desired experimental scenario with real
   viewers' behavior in physical world. The result demonstrates that with
   the authors' methodology, the scale of experiments can be doubled.},
DOI = {10.4018/IJWSR.2014100105},
ISSN = {1545-7362},
EISSN = {1546-5004},
Unique-ID = {WOS:000353297300005},
}

@inproceedings{ WOS:000299395900096,
Author = {Keong, Chee Yik and Hoong, Poo Kuan and Ting, Choo-Yee},
Book-Group-Author = {IEEE},
Title = {Efficient Hybrid Push-Pull Based P2P Media Streaming System},
Booktitle = {2011 IEEE 17TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED
   SYSTEMS (ICPADS)},
Series = {International Conference on Parallel and Distributed Systems -
   Proceedings},
Year = {2011},
Pages = {735-740},
Note = {17th IEEE International Conference on Parallel and Distributed Systems
   (ICPADS), Tainan, TAIWAN, DEC 07-09, 2011},
Organization = {IEEE; IEEE Comp Soc; Natl Cheng Kung Univ; Natl Sci Council; Minist
   Educ; Acad Sinica; Natl Ctr High Performance Comp; Inst Informat Ind;
   Ind Tech Res Inst; Taiwan Assoc Cloud Comp; Comp Soc Republ China; Intel
   Corp; Tainan City Govt; IEEE Comp Soc Tech Comm Parallel Proc (TCPP)},
Abstract = {Peer-to-Peer (P2P) communication is a popular protocol that has
   significant impacted and also changed the way for files being
   distributed over the large networks. Variants of P2P protocols are also
   applied for other media distribution such as audio and video streaming.
   The P2P protocol is widely adapted by researchers as a method to handle
   larger group of users. Coolstreaming, the first large scale P2P
   streaming experiment till today, applied a mesh-based streaming system
   which has slowly evolved from a pure pull system to a hybrid push-pull
   system. In this paper, we present our proposed push-pull scheduling for
   P2P streaming that can heuristically select the most optimal frame to be
   pushed based on the rules that we designed. Our proposed solution
   incorporates the fast content distribution characteristic of both Push
   and Pull approaches. For performance evaluation, we compare our
   scheduling algorithm with the pure pull Coolstreaming scheduling and
   Random push-pull scheduling where both scheduling serve as a benchmark
   in three main criteria -end-to-end delay, frame miss-ratio and frame
   redundancy. Simulation results showed that our proposed heuristic
   push-pull overall outperformed the other scheduling schemes, where our
   proposed scheduling algorithm demonstrates as a better solution towards
   reducing mesh delay in P2P streaming.},
DOI = {10.1109/ICPADS.2011.55},
ISSN = {1521-9097},
ISBN = {978-0-7695-4576-9},
ResearcherID-Numbers = {Poo, Kuan Hoong/B-5981-2012},
ORCID-Numbers = {Poo, Kuan Hoong/0000-0002-1154-1799},
Unique-ID = {WOS:000299395900096},
}

@inproceedings{ WOS:000299260700070,
Author = {Sutinen, Tiia and Rivas, Helena},
Book-Group-Author = {IEEE},
Title = {Cross-layer Assisted Network Interface Selection for Multi-interface
   Video Streaming},
Booktitle = {2011 20TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATIONS AND
   NETWORKS (ICCCN)},
Series = {IEEE International Conference on Computer Communications and Networks},
Year = {2011},
Note = {20th International Conference on Computer Communications and Networks
   (ICCCN), HI, JUL 31-AUG 04, 2011},
Organization = {IEEE; IEEE Commun Soc; U. S. Nat Sci Fdn (NSF); QUALCOMM; Microsoft Res;
   Eic},
Abstract = {Multi-homing is expected to be an important enabler of the future
   Internet. Already today, terminal devices are equipped with multiple
   network interfaces and able to use them simultaneously. In the future,
   mobile multimedia services such as video streaming can maximize the user
   experienced quality by utilizing the available network resources,
   concurrently. However, intelligent decision-making as well as dynamic
   mapping of traffic to network interfaces are required for optimal
   operation. In this paper, we propose a dynamic cross-layer communication
   assisted network interface selection solution for a multi-interface
   streaming system designed for scalable video streams. We also present a
   prototype implementation and verify its operation in an experimental
   evaluation.},
ISSN = {1095-2055},
ISBN = {978-1-4577-0638-7},
Unique-ID = {WOS:000299260700070},
}

@article{ WOS:000339877700008,
Author = {Kotevski, Zoran and Mitrevski, Pece},
Title = {Hybrid fluid modeling approach for performance analysis of P2P live
   video streaming systems},
Journal = {PEER-TO-PEER NETWORKING AND APPLICATIONS},
Year = {2014},
Volume = {7},
Number = {4, SI},
Pages = {410-426},
Month = {DEC},
Abstract = {In this paper a hybrid modeling approach with different modeling
   formalisms and solution methods is employed in order to analyze the
   performance of peer to peer live video streaming systems. We conjointly
   use queuing networks and Fluid Stochastic Petri Nets, developing several
   performance models to analyze the behavior of rather complex systems.
   The models account for: network topology, peer churn, scalability, peer
   average group size, peer upload bandwidth heterogeneity and video
   buffering, while introducing several features unconsidered in previous
   performance models, such as: admission control for lower contributing
   peers, control traffic overhead and internet traffic packet loss. Our
   analytical and simulation results disclose the optimum number of peers
   in a neighborhood, the minimum required server upload bandwidth, the
   optimal buffer size and the influence of control traffic overhead. The
   analysis reveals the existence of a performance switch-point (i.e.
   threshold) up to which system scaling is beneficial, whereas performance
   steeply decreases thereafter. Several degrees of degraded service are
   introduced to explore performance with arbitrary percentage of lost
   video frames and provide support for protocols that use scalable video
   coding techniques. We also find that implementation of admission control
   does not improve performance and may discourage new peers if waiting
   times for joining the system increase.},
DOI = {10.1007/s12083-013-0205-7},
ISSN = {1936-6442},
EISSN = {1936-6450},
ResearcherID-Numbers = {Kotevski, Zoran/E-3704-2015
   Mitrevski, Pece/V-6000-2019},
ORCID-Numbers = {Kotevski, Zoran/0000-0002-3154-0259
   Mitrevski, Pece/0000-0002-0300-7115},
Unique-ID = {WOS:000339877700008},
}

@article{ WOS:000256264900007,
Author = {Hsu, Cheng-Hsin and Hefeeda, Mohamed},
Title = {On the accuracy and complexity of rate-distortion models for
   fine-grained scalable video sequences},
Journal = {ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS},
Year = {2008},
Volume = {4},
Number = {2},
Abstract = {Rate-distortion ( R-D) models are functions that describe the
   relationship between the bitrate and expected level of distortion in the
   reconstructed video stream. R-D models enable optimization of the
   received video quality in different network conditions. Several R-D
   models have been proposed for the increasingly popular fine-grained
   scalable video sequences. However, the models' relative performance has
   not been thoroughly analyzed. Moreover, the time complexity of each
   model is not known, nor is the range of bitrates in which the model
   produces valid results. This lack of quantitative performance analysis
   makes it difficult to select the model that best suits a target
   streaming system. In this article, we classify, analyze, and rigorously
   evaluate all R-D models proposed for FGS coders in the literature. We
   classify R-D models into three categories: analytic, empirical, and
   semi-analytic. We describe the characteristics of each category. We
   analyze the R-D models by following their mathematical derivations,
   scrutinizing the assumptions made, and explaining when the assumptions
   fail and why. In addition, we implement all R-D models, a total of
   eight, and evaluate them using a diverse set of video sequences. In our
   evaluation, we consider various source characteristics, diverse channel
   conditions, different encoding/decoding parameters, different frame
   types, and several performance metrics including accuracy, range of
   applicability, and time complexity of each model. We also present clear
   systematic ways ( pseudo codes) for constructing various R-D models from
   a given video sequence. Based on our experimental results, we present a
   justified list of recommendations on selecting the best R-D models for
   video-on-demand, video conferencing, real-time, and peer-to-peer
   streaming systems.},
DOI = {10.1145/1352012.1352019},
Article-Number = {15},
ISSN = {1551-6857},
EISSN = {1551-6865},
Unique-ID = {WOS:000256264900007},
}

@inproceedings{ WOS:000475888000074,
Author = {Hanif, Muhammad and Yoon, Hyeongdeok and Lee, Choonhwa},
Book-Group-Author = {IEEE Comp Soc},
Title = {Benchmarking Tool for Modern Distributed Stream Processing Engines},
Booktitle = {33RD INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2019)},
Year = {2019},
Pages = {393-395},
Note = {33rd International Conference on Information Networking (ICOIN), Kuala
   Lumpur, MALAYSIA, JAN 09-11, 2019},
Organization = {IEEE; IEEE Comp Soc; Korean Inst Informat Scientists \& Engineers,
   Informat Networking Soc},
Abstract = {There is an upsurge in the usage and adaptation of streaming
   applications in the recent years by both industry and academia. At the
   core of these applications is streaming data processing engines that
   perform resource management and allocation in order to support
   continuous track of queries over distributed data streams. Several
   stream processing engines exists to handle these distributed streaming
   applications. In this paper, we present different challenges of the
   stream processing systems, in particular to stateful operators and
   implement Linear Road benchmark to examine the characteristic and
   performance metrics of the streaming system, in particular Apache Flink.
   Furthermore, we examine that Apache Flink can be used as a core for an
   efficient Linear Road application implementation for distributed
   environments without breaching the SLA requirements of the application.},
ISBN = {978-1-5386-8350-7},
Unique-ID = {WOS:000475888000074},
}

@inproceedings{ WOS:000410667100113,
Author = {Mao, Hanzi and Tian, Chen and Sun, Jingdong and Yan, Junhua and Wu,
   Weimin and Huang, Benxiong},
Editor = {Apduhan, BO and Zheng, Y and Nakamoto, Y and Thulasiraman, P and Ning, H and Sun, Y},
Title = {ShadowVoD: Performance Evaluation as a Capability in Production P2P-CDN
   Hybrid VoD Networks},
Booktitle = {2014 IEEE 11TH INTL CONF ON UBIQUITOUS INTELLIGENCE AND COMPUTING AND
   2014 IEEE 11TH INTL CONF ON AUTONOMIC AND TRUSTED COMPUTING AND 2014
   IEEE 14TH INTL CONF ON SCALABLE COMPUTING AND COMMUNICATIONS AND ITS
   ASSOCIATED WORKSHOPS},
Year = {2014},
Pages = {771-776},
Note = {IEEE Int Conf on Ubiquitous Intelligence and Computing (UIC) / 11th IEEE
   Int Conf on Autonomic and Trusted Computing (ATC) / 14th IEEE Int Conf
   on Scalable Computing and Communications (ScalCom), Denpasar, INDONESIA,
   DEC 09-12, 2014},
Organization = {Inst Elect \& Elect Engineers; IEEE Comp Soc; IEEE Tech Comm Scalable
   Comp; Northwestern Polytechn Univ; STIKOM Bali; StFX Univ; Kyushu Sangyo
   Univ},
Abstract = {Video-on-Demand (VoD) services have achieved great success recently.
   Most such streaming systems are P2P-CDN hybrid systems. To ensure
   reliable performance, the most efficient way is to subject those VoD
   streaming networks to large-scale, realistic performance evaluations.
   Our previous ShadowStream system is a production Internet live streaming
   network with performance evaluation as a built-in capability. In this
   paper, we extend the same idea into the VoD services. There exists
   significant difference between live and VoD, hence ShadowStream cannot
   be directly used in VoD context. Firstly, clients in P2P-VoD service are
   not synchronized in viewing progress; secondly, in VoD there exists
   interactive operations (e.g., pause and drag); thirdly, the different
   playpoints of users also bring difficulty to replacing departed real
   clients. In this paper, we solve all above mentioned challenges. We
   implement ShadowVoD and demonstrate its benefits through extensive
   evaluations.},
DOI = {10.1109/UIC-ATC-ScalCom.2014.77},
ISBN = {978-1-4799-7646-1},
Unique-ID = {WOS:000410667100113},
}

@inproceedings{ WOS:000228692600024,
Author = {Huang, J and Feng, WC and Walpole, J and Jouve, W},
Editor = {Chandra, S and Venkatasubramanian, N},
Title = {An experimental analysis of DCT-based approaches for fine-grain
   multi-resolution video},
Booktitle = {Multimedia Computing and Networking 2005},
Series = {PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)},
Year = {2005},
Volume = {5680},
Pages = {241-252},
Note = {Conference on Multimedia Computing and Networking 2005, San Jose, CA,
   JAN 19-20, 2005},
Organization = {Soc Imaging Sci \& Technol; SPIE},
Abstract = {This paper presents the architectural trade-offs to support fine-grain
   multi-resolution video over a wide range of resolutions. In the future,
   video streaming systems will have to support video adaptation over an
   extremely large range of display requirements (e.g. 90x60 to 1920x1080).
   While several techniques have been proposed for multi-resolution video
   adaptation, which is also known as spatial scalability, they have
   focused mainly on limited spatial resolutions. In this paper, we examine
   the ability of current techniques to support wide-range spatial
   scalability. Based upon experiments with real video, we propose an
   architecture that can support wide-range adaptation more effectively.
   Our results indicate that multiple encodings with limited spatial
   adaptation from each encoding provides the best trade-off between
   efficient coding and the ability to adapt the stream to various
   resolutions.},
DOI = {10.1117/12.592317},
ISSN = {0277-786X},
ISBN = {0-8194-5653-5},
Unique-ID = {WOS:000228692600024},
}

@inproceedings{ WOS:000272028600032,
Author = {Liu, Hao and Riley, George and Ingle, Rajesh},
Book-Group-Author = {IEEE},
Title = {Mathematical Model and Analysis of Peer-to-peer IPTV},
Booktitle = {ANTS: 2008 2ND INTERNATIONAL SYMPOSIUM ON ADVANCED NETWORKS AND
   TELECOMMUNICATION SYSTEMS},
Series = {International Symposium on Advanced Networks and Telecommunication
   Systems},
Year = {2008},
Pages = {94+},
Note = {2nd International Symposium on Advanced Networks and Telecommunication
   Systems, Indian Inst Technol, Bombay, INDIA, DEC 15-17, 2008},
Organization = {IEEE},
Abstract = {Peer-to-peer overlay is an attractive solution to distribute video
   streams over large-scale IP networks. A number of algorithms and
   frameworks have been proposed. But generic and theoretical analysis of
   P2P streaming is scarce in the literature. In this paper, we present a
   novel probability model, making the formal analysis and performance
   evaluation of P2P IPTV accessible. With the help of the proposed model,
   we then reveal that the efficiency of P2P streaming system is closely
   correlated to piece diversity.},
ISSN = {2153-1676},
ISBN = {978-1-4244-3600-2},
ResearcherID-Numbers = {Ingle, Rajesh/AAO-3769-2021},
ORCID-Numbers = {Ingle, Rajesh/0000-0001-5678-5191},
Unique-ID = {WOS:000272028600032},
}

@inproceedings{ WOS:000351597600014,
Author = {Stapenhurst, Robert and Lu, Jinyun and Agrafiotis, Dimitris},
Book-Group-Author = {IEEE},
Title = {PERFORMANCE EVALUATION OF OBJECTIVE VIDEO QUALITY METRICS ON MIXED
   SPATIOTEMPORAL RESOLUTION CONTENT},
Booktitle = {2013 20TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP 2013)},
Series = {IEEE International Conference on Image Processing ICIP},
Year = {2013},
Pages = {64-68},
Note = {20th IEEE International Conference on Image Processing (ICIP),
   Melbourne, AUSTRALIA, SEP 15-18, 2013},
Organization = {Inst Elect \& Elect Engineers; IEEE Signal Proc Soc},
Abstract = {In this paper we present a study of objective video quality metric
   performance on test sequences which have undergone spatiotemporal
   resolution scaling prior to and after compression. The bit rates and
   resolutions tested have been chosen to typify consumer `home theatre'
   wireless streaming scenarios. The aim of the study is to identify a
   suitable video quality metric for use in a video streaming system that
   meets changing bandwidth constraints through adaptation of
   spatiotemporal resolution in addition to quantisation parameters. We
   first collect subjective quality scores and then assess correlation of
   objective metrics with this data. Of the metrics tested, we conclude
   that MOVIE is the most capable of accurate subjective score prediction
   under changing spatiotemporal resolution conditions.},
ISSN = {1522-4880},
ISBN = {978-1-4799-2341-0},
Unique-ID = {WOS:000351597600014},
}

@inproceedings{ WOS:000494256300026,
Author = {Mahmood, Ahmed R. and Daghistani, Anas and Aly, Ahmed M. and Tang,
   Mingjie and Basalamah, Saleh and Prabhakar, Sunil and Aref, Walid G.},
Editor = {BanaeiKashani, F and Hoel, E and Guting, RH and Tamassia, R and Xiong, L},
Title = {Adaptive Processing of Spatial-Keyword Data Over a Distributed Streaming
   Cluster},
Booktitle = {26TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC
   INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2018)},
Year = {2018},
Pages = {219-228},
Note = {26th ACM-SIGSPATIAL International Conference on Advances in Geographic
   Information Systems (ACM SIGSPATIAL GIS), Seattle, WA, NOV 06-09, 2018},
Organization = {Assoc Comp Machinery Special Interest Grp Spatial Informat; Assoc Comp
   Machinery; HERE; Amazon; Apple; Esri; Lyft; Uber; Oracle; Microsoft;
   IBM; Google},
Abstract = {The widespread use of GPS-enabled smartphones along with the popularity
   of micro-blogging and social networking applications, e.g., Twitter and
   Facebook, has resulted in the generation of huge streams of geo-tagged
   textual data. Many applications require realtime processing of these
   streams. For example, location-based adtargeting systems enable
   advertisers to register millions of ads to millions of users based on
   the users' location and textual proile. Existing streaming systems are
   either centralized or are not spatial-keyword aware, and hence these
   systems cannot eiciently support the processing of rapidly arriving
   spatial-keyword data streams. In this paper, we introduce a two-layered
   indexing scheme for the distributed processing of spatial-keyword data
   streams. We realize this indexing scheme in Tornado, a distributed
   spatial-keyword streaming system. The irst layer, termed the routing
   layer, is used to fairly distribute the workload, and furthermore,
   co-locate the data objects and the corresponding queries at the same
   processing units. The routing layer uses the Augmented-Grid, a novel
   structure that is equipped with an eicient search algorithm for
   distributing the data objects and queries. The second layer, termed the
   evaluation layer, resides within each processing unit to reduce the
   processing overhead. The two-layered index adapts to changes in the
   workload by applying a cost formula that continuously represents the
   processing overhead at each processing unit. Extensive experimental
   evaluation using real Twitter data indicates that Tornado achieves high
   scalability and more than 2x improvement over the baseline approach in
   terms of the overall system throughput.},
DOI = {10.1145/3274895.3274932},
ISBN = {978-1-4503-5889-7},
ResearcherID-Numbers = {Aref, Walid/D-4403-2019
   Daghistani, Anas/ABD-4518-2021
   },
ORCID-Numbers = {Aref, Walid/0000-0001-8169-7775
   Daghistani, Anas/0000-0002-4895-4714
   Basalamah, Saleh/0000-0002-2276-8307},
Unique-ID = {WOS:000494256300026},
}

@inproceedings{ WOS:000236978802062,
Author = {Kang, S and Ku, KI and Shim, JM and Hur, SJ and Ju, SH and Choi, W},
Book-Group-Author = {ICACT},
Title = {Performance evaluation of software streaming server architecture for
   massive users},
Booktitle = {8TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS
   1-3: TOWARD THE ERA OF UBIQUITOUS NETWORKS AND SOCIETIES},
Year = {2006},
Pages = {U1736-U1741},
Note = {8th International Conference on Advanced Communication Technology,
   Minist Informat \& Commun, Phoenix Pk, SOUTH KOREA, FEB 20-22, 2006},
Organization = {Natl Computerizat Agcy; Elect \& Telecommun Res Inst; IEEE Commun Soc;
   IEEE Reg 10; IEEE Daejeon Sect; Open Stand \& Internet Assoc; Korean
   Inst Commun \& Sci; IEEK Commun Soc},
Abstract = {In this paper, we propose the streaming server architecture for massive
   users and verify it by a small scale simulation with virtual users.
   Software streaming is one of the ASP solution that allows the execution
   of stream-enabled software, even while the transmission of the program
   may still be in progress.
   In this paper, we analyze workload characteristics of the software
   stream, and extract four requirements that software streaming system
   have to satisfy. Based on these requirements, we design the software
   streaming server architecture. The verification of the designed server
   is performed by virtual user simulation. The result tells us the
   capacity of each server and helps us to calculate the scale of the
   system for massive users.},
ISBN = {89-5519-129-4},
Unique-ID = {WOS:000236978802062},
}

@inproceedings{ WOS:000080978400002,
Author = {Zhao, W and Tripathi, SK},
Book-Group-Author = {ASSOC COMP MACHINERY
   ASSOC COMP MACHINERY
   ASSOC COMP MACHINERY
   ASSOC COMP MACHINERY},
Title = {Bandwidth-efficient continuous media streaming through optimal
   multiplexing},
Booktitle = {PERFORMANCE EVALUATION REVIEW, SPECIAL ISSUE, VOL 27 NO 1, JUNE 1999:
   ACM SIGMETRICS `99, PROCEEDINGS - INTERNATIONAL CONFERENCE ON
   MEASUREMENT AND MODELING OF COMPUTER SYSTEMS},
Year = {1999},
Pages = {13-22},
Note = {International Conference on Measurement and Modeling of Computer Systems
   (ACM SIGMETRICS 99), Held in Conjunction with ACM Federated Computing
   Research Conference 99, ATLANTA, GA, MAY 01-04, 1999},
Organization = {Assoc Comp Machinery, SIGMETRICS},
Abstract = {Maximizing bandwidth efficiency in distributed continuous media
   streaming systems is the key in delivering cost-effective multimedia
   services to distributed and heterogeneous receivers. We introduce a
   technique based on stream multiplexing to achieve the highest possible
   bandwidth efficiency, while preserving stringent and deterministic
   quality of service guarantees. The technique accomplishes the optimal
   multiplexing (i.e. resulting in the lowest possible bandwidth
   allocation) by exploiting both the temporal and the spatial structures
   among a group of continuous media streams. We present a family of
   optimal multiplexing schedules. The adverse per-stream effects of
   optimal multiplexing are studied and a technique based on transmission
   rearrangement is proposed to mitigates these effects, without
   sacrificing the achieved multiplexing optimality. The results presented
   in the paper provide some fundamental criteria and limits in the design
   and evaluation of resource allocation, admission control and stream
   scheduling policies for bandwidth efficient continuous media streaming.},
DOI = {10.1145/301453.301476},
ISBN = {1-58113-083-X},
Unique-ID = {WOS:000080978400002},
}

@inproceedings{ WOS:000392812600175,
Author = {Seyfabad, Mehdi Seydali and Akbari, Behzad},
Book-Group-Author = {IEEE},
Title = {CAC-Live: Centralized Assisted Cloud P2P Live Streaming},
Booktitle = {2014 22ND IRANIAN CONFERENCE ON ELECTRICAL ENGINEERING (ICEE)},
Series = {Iranian Conference on Electrical Engineering},
Year = {2014},
Pages = {908-913},
Note = {22nd Iranian Conference on Electrical Engineering (ICEE), Shahid
   Beheshti Univ, Tehran, IRAN, MAY 20-22, 2014},
Abstract = {Peer-to-Peer (P2P) live video streaming over the Internet is a
   developing technology that recently has gained more attention. The use
   of P2P network with leveraging of local resources of peers, increases
   scalability and reduces costs. One of the limitations of P2P live video
   streaming systems is the lack of adequate resources such as available
   upload bandwidth, both at video source and inside P2P overlay network
   that lead to reduce the quality of service (QoS) experienced by the
   users. One solution for this problem is to employ additional on-demand
   resources such as virtual machines (VM) that are rented from a cloud
   provider to increase the amount of total available bandwidth. In this
   paper, we propose an architecture for improving the QoS of the peers by
   using virtual machines (VMs) dynamically are rented from cloud
   providers. Estimation of required VMs is performed through a
   central-based method and the number of VMs is calculated periodically.
   Our simulation based performance evaluation shows the efficiency of the
   proposed method.},
ISSN = {2164-7054},
ISBN = {978-1-4799-4409-5},
Unique-ID = {WOS:000392812600175},
}

@inproceedings{ WOS:000744421000035,
Author = {Ivanov, Todor and Taaffe, Jason},
Book-Group-Author = {ACM},
Title = {Exploratory Analysis of Spark Structured Streaming},
Booktitle = {COMPANION OF THE 2018 ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE
   ENGINEERING (ICPE `18)},
Year = {2018},
Pages = {141-146},
Note = {9th ACM/SPEC International Conference on Performance Engineering (ICPE),
   Berlin, GERMANY, APR 09-13, 2018},
Organization = {Assoc Comp Machinery; SPEC; ACM SIGMETRICS; ACM SIGSOFT},
Abstract = {In the Big Data era, stream processing has become a common requirement
   for many data-intensive applications. This has lead to many advances in
   the development and adaption of large scale streaming systems. Spark and
   Flink have become a popular choice for many developers as they combine
   both batch and streaming capabilities in a single system. However,
   introducing the Spark Structured Streaming in version 2.0 opened up
   completely new features for SparkSQL, which are alternatively only
   available in Apache Calcite.
   This work focuses on the new Spark Structured Streaming and analyses it
   by diving into its internal functionalities. With the help of a
   micro-benchmark consisting of streaming queries, we perform initial
   experiments evaluating the technology. Our results show that Spark
   Structured Streaming is able to run multiple queries successfully in
   parallel on data with changing velocity and volume sizes.},
DOI = {10.1145/3185768.3186360},
ISBN = {978-1-4503-5629-9},
Unique-ID = {WOS:000744421000035},
}

@inproceedings{ WOS:000286907800020,
Author = {Karki, Rabin and Seenivasan, Thangam and Claypool, Mark and Kinicki,
   Robert},
Book-Group-Author = {ACM},
Title = {Performance Analysis of Home Streaming Video Using Orb},
Booktitle = {NOSSDAV 2010: PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON NETWORK
   AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO},
Year = {2010},
Pages = {111-116},
Note = {20th ACM Workshop on Network and Operating System Support for Digital
   Audio and Video, Amsterdam, NETHERLANDS, JUN 02-04, 2010},
Organization = {ACM SIGMM},
Abstract = {A new paradigm in video streaming is emerging, that of personal video
   servers in the home streaming video to remote clients on the Internet.
   The potential impact of such technologies demands careful study to
   assess performance and impact. This project studies one such personal
   video streaming system called Orb in a closed network environment,
   allowing us to control network bandwidths. Our performance evaluation
   focuses on Orb's method of bandwidth estimation, video performance and
   bitrates, and resource usage during transcoding. Analysis shows Orb uses
   simplistic, but effective, methods of determining available bandwidth,
   dynamic temporal and spatial scaling, and significant CPU cycles when
   transcoding. The results should be useful for subsequent comparison with
   other home streaming technologies and capacity planning for network
   providers.},
ISBN = {978-1-4503-0043-8},
ResearcherID-Numbers = {Claypool, Mark/ABC-5316-2020},
Unique-ID = {WOS:000286907800020},
}

@article{ WOS:000292619600003,
Author = {Nagaoka, Takeshi and Ito, Akihiko and Okano, Kozo and Kusumoto, Shinji},
Title = {QoS Analysis of Real-Time Distributed Systems Based on Hybrid Analysis
   of Probabilistic Model Checking Technique and Simulation},
Journal = {IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS},
Year = {2011},
Volume = {E94D},
Number = {5},
Pages = {958-966},
Month = {MAY},
Abstract = {For the Internet, system developers often have to estimate the QoS by
   simulation techniques or mathematical analysis. Probabilistic model
   checking can evaluate performance, dependability and stability of
   information processing systems with random behaviors. We apply a hybrid
   analysis approach onto real-time distributed systems. In the hybrid
   analysis approach, we perform stepwise analysis using probabilistic
   models of target systems in different abstract levels. First, we create
   a probabilistic model with detailed behavior of the system (called
   detailed model), and apply simulation on the detailed model. Next, based
   on the simulation results, we create a probabilistic model in an
   abstract level (called simplified model). Then, we verify qualitative
   properties using the probabilistic model checking techniques. This
   prevents from state-explosion. We evaluate the validity of our approach
   by comparing to simulation results of NS-2 using a case study of a video
   data streaming system. The experiments show that the result of the
   proposed approach is very close to that of NS-2 simulation. The result
   encourages the approach is useful for the performance analysis on
   various domain.},
DOI = {10.1587/transinf.E94.D.958},
ISSN = {1745-1361},
Unique-ID = {WOS:000292619600003},
}

@article{ WOS:000577281400001,
Author = {Ojo, Oluwafolake E. and Oluwatope, Ayodeji O. and Ajadi, Suraju O.},
Title = {A reliable peer-to-peer streaming protocol in low-capacity networks},
Journal = {PEER-TO-PEER NETWORKING AND APPLICATIONS},
Year = {2021},
Volume = {14},
Number = {2},
Pages = {559-584},
Month = {MAR},
Abstract = {The recent global demand for video streaming applications has paved the
   way for peer-to-peer streaming system (P2PSS). Strategic scheduling
   scheme and dynamic overlay topology are essential to maintain quality of
   service (QoS) and quality of experience (QoE) in P2PSS. The concept of
   P2PSS was tailored towards relying on active peers' bandwidth to achieve
   cheap and scalable means of distribution over the Internet, such that
   peers with highest bandwidth serve as backbones for others. However,
   selecting backbone peers in low-capacity network environment is
   challenging due to insufficient bandwidth and poor infrastructure,
   thereby resulting in poor QoS and unpleasant user's QoE. In this paper,
   we conducted a survey on users' experiences with live video in selected
   locations in Nigeria. We designed an adaptive P2P streaming protocol and
   performed a packet-level simulation in Network Simulator 3(NS-3).
   Diverse simulation scenarios were set up to evaluate the proposed
   streaming protocol. Trace files data were analysed to measure end-to-end
   delay, start-up delay, and throughput. Furthermore, the proposed
   streaming protocol was benchmarked against selected existing schemes.
   The evaluation results revealed a 7.4\% and 28\% reduction in start-up
   and in end-to-end delays and 9\% increase in throughput.},
DOI = {10.1007/s12083-020-01002-4},
EarlyAccessDate = {OCT 2020},
ISSN = {1936-6442},
EISSN = {1936-6450},
ResearcherID-Numbers = {Oluwatope, Ayodeji Oludola/AHC-8966-2022
   },
ORCID-Numbers = {Oluwatope, Ayodeji Oludola/0000-0003-0180-5241
   Ojo, Oluwafolake/0000-0002-1051-756X},
Unique-ID = {WOS:000577281400001},
}

@inproceedings{ WOS:000260249100039,
Author = {Picconi, Fabio and Massoulie, Laurent},
Editor = {Kellerer, W and Singhal, SK and Steinmetz, R},
Book-Author = {Wehrle, K},
Title = {Is there a future for mesh-based live video streaming?},
Booktitle = {P2P'08: EIGHTH INTERNATIONAL CONFERENCE ON PEER-TO-PEER COMPUTING,
   PROCEEDINGS},
Series = {IEEE International Conference on Peer-to-Peer Computing},
Year = {2008},
Pages = {289-298},
Note = {8th International Conference on Peer-to-Peer Computing, Aachen Univ,
   Aachen, GERMANY, SEP 08-11, 2008},
Organization = {IEEE Commun Soc; Microsoft; Distributed Syst; RWTH Aachen Univ; Nokia;
   UMIC; Google; IEEE Comp Soc},
Abstract = {Peer-to-peer live streaming systems allow a bandwidth-constrained source
   to broadcast a video feed to a large number of users. In addition, a
   design with high link utilization can achieve high stream rates,
   supporting high-quality video. Until now; only tree-based designs have
   been shown to achieve close-to-optimal rates in real-life conditions,
   leaving the question open as to the attainable efficiency of completely
   unstructured mesh-based approaches.
   In this paper we answer that question by showing that a
   carefully-designed mesh-based system can achieve close-to-optimal stream
   rates. Specifically, we implement and evaluate a design based on a
   mesh-based algorithm called DP/LU. Contrary to tree-based designs, DP/LU
   uses an unstructured overlay, which is easier to construct and is highly
   resistant to churn. In addition, we introduce mechanisms for overlay
   rewiring and source scheduling that lead to significant performance
   improvements.
   Our experimental evaluation shows that our design achieves 95\% of the
   maximum achievable stream rate in a static environment, and 90\% under
   high churn. This demonstrates that mesh-based designs are an excellent
   choice for scalable and robust high-quality peer-to-peer live streaming.},
DOI = {10.1109/P2P.2008.18},
ISSN = {2161-3567},
ISBN = {978-0-7695-3318-6},
Unique-ID = {WOS:000260249100039},
}

@article{ WOS:000411247600009,
Author = {Al-Zubaidy, Hussein and Fodor, Viktoria and Dan, Gyorgy and Flierl,
   Markus},
Title = {Reliable Video Streaming With Strict Playout Deadline in Multihop
   Wireless Networks},
Journal = {IEEE TRANSACTIONS ON MULTIMEDIA},
Year = {2017},
Volume = {19},
Number = {10},
Pages = {2238-2251},
Month = {OCT},
Abstract = {Motivated by emerging vision-based intelligent services, we consider the
   problem of rate adaptation for high-quality and low-delay visual
   information delivery over wireless networks using scalable video coding.
   Rate adaptation in this setting is inherently challenging due to the
   interplay between the variability of the wireless channels, the queuing
   at the network nodes, and the frame-based decoding and playback of the
   video content at the receiver at very short time scales. To address the
   problem, we propose a low-complexity model-based rate adaptation
   algorithm for scalable video streaming systems, building on a novel
   performance model based on stochastic network calculus. We validate the
   analytic model using extensive simulations. We show that it allows fast
   near-optimal rate adaptation for fixed transmission paths, as well as
   cross-layer optimized routing and video rate adaptation in mesh
   networks, with less than 10\% quality degradation compared to the best
   achievable performance.},
DOI = {10.1109/TMM.2017.2742399},
ISSN = {1520-9210},
EISSN = {1941-0077},
ResearcherID-Numbers = {Dan, György/H-8604-2012
   },
ORCID-Numbers = {Dan, György/0000-0002-4876-0223
   /0000-0002-0150-2489
   Flierl, Markus/0000-0002-7807-5681},
Unique-ID = {WOS:000411247600009},
}

@inproceedings{ WOS:000380453600046,
Author = {Rattanaopas, Kritwara and Tandayya, Pichaya},
Book-Group-Author = {IEEE},
Title = {Performance Analysis of a Multi-Tier Video on Demand Service on
   Virtualization Platforms},
Booktitle = {2015 INTERNATIONAL COMPUTER SCIENCE AND ENGINEERING CONFERENCE (ICSEC)},
Year = {2015},
Pages = {245-250},
Note = {International Computer Science and Engineering Conference (ICSEC),
   Chiang Mai, THAILAND, NOV 23-26, 2015},
Organization = {IEEE Thailand Sect; IEEE Xplore Digital Lib; ARCCIT; Maejo Univ; Chiang
   Mai Univ; INEX; NETBRIGHT; Hewlett Packard Enterprise; CISCO; ECTI
   Assoc; IBM},
Abstract = {Cloud computing technology, especially virtualization is employed in
   many data centers nowadays. The key concept of virtualization concerns
   elastic or scalable infrastructure. This concept can be implemented by
   exploiting multi-tier web applications and hypervisors which are virtual
   machine management software. Xen hypervisor has presented its Version
   4.4 in 2014. In this paper, we present the performance analysis
   comparison between Xen para-virtualization and KVM full virtualization
   on the case study of open source video streaming called Cumulusclips, a
   YouTube-like system. This investigation involves real workload mp4 video
   streaming on 200 clients' browser, running 3 experiments, including
   large video files (similar to 3 GB), small video files (similar to 120
   MB) and random-size video files (the ratio of large and small video
   files is 25\%/75\%). The requests size results show that Xen
   para-virtualization can serve all requests better than KVM full
   virtualization and use less resource. Xen's performance is dropped when
   CPU usage is 100\% in Experiment 1 (large files). In Experiments 2
   (small files) and 3 (random-size files), Xen's CPU usage is under 10\%,
   but KVM's CPU usage is over 50\%. The requests size results of Xen and
   KVM are equal in Experiment 2, but Xen has the maximum throughput about
   a half (51\%) of KVM's. Therefore, we can conclude that Xen
   paravirtualization has better performance than KVM full virtualization
   on multi-tier video streaming system.},
ISBN = {978-1-4673-7825-3},
ResearcherID-Numbers = {Tandayya, Pichaya/AAH-6051-2021
   Tandayya, Pichaya/AAI-8436-2020
   Tandayya, Pichaya/AAW-4415-2020},
ORCID-Numbers = {Tandayya, Pichaya/0000-0001-9454-8146},
Unique-ID = {WOS:000380453600046},
}

@article{ WOS:000251109900009,
Author = {Purandare, Darshan and Guha, Ratan},
Title = {An alliance based peering scheme for P2P live media streaming},
Journal = {IEEE TRANSACTIONS ON MULTIMEDIA},
Year = {2007},
Volume = {9},
Number = {8},
Pages = {1633-1644},
Month = {DEC},
Abstract = {While recent measurement studies ha, le shown the effectiveness of P2P
   network in media streaming, there have been questions raised about the
   Quality of Service (QoS), reliability of streaming services and sub
   optimal uplink utilization in particular. P2P streaming systems are
   inherently less reliable because of churn, internet dynamics, node
   heterogeneity and randomness in the swarm. We present a new model for
   P2P media streaming based on clustering of peers, called alliances. We
   show that alliance formation is a loosely coupled and an effective way
   to organize the peers. We show that our model maps to a
   ``small-world{''} network, which form efficient overlay structures and
   are robust to network perturbations such as churn. We present a
   comparative simulation based study of our model with CoolStreaming/DONet
   and present a quantitative performance evaluation. Simulation results
   are promising and show that our model scales well under varying
   workloads and conditions, delivers near optimal levels of QoS, and for
   most cases, performs at par or even better than CoolStreaming/DONet.},
DOI = {10.1109/TMM.2007.907453},
ISSN = {1520-9210},
EISSN = {1941-0077},
Unique-ID = {WOS:000251109900009},
}

@article{ WOS:000222679300006,
Author = {Zhou, XB and Xu, CZ},
Title = {Harmonic proportional bandwidth allocation and scheduling for service
   differentiation on streaming servers},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2004},
Volume = {15},
Number = {9},
Pages = {835-848},
Month = {SEP},
Abstract = {To provide ubiquitous access to the proliferating rich media on the
   Internet, scalable streaming servers must be able to provide
   differentiated services to various client requests. Recent advances of
   transcoding technology make network-I/O bandwidth usages at the server
   communication ports controllable by request schedulers on the fly. In
   this article, we propose a transcoding-enabled bandwidth allocation
   scheme for service differentiation on streaming servers. It aims to
   deliver high bit rate streams to high priority request classes without
   overcompromising low priority request classes. We investigate the
   problem of providing differentiated streaming services at application
   level in two aspects: stream bandwidth allocation and request
   scheduling. We formulate the bandwidth allocation problem as an
   optimization of a harmonic utility function of the stream quality
   factors and derive the optimal streaming bit rates for requests of
   different classes under various server load conditions. We prove that
   the optimal allocation, referred to as harmonic proportional allocation,
   not only maximizes the system utility function, but also guarantees
   proportional fair sharing between classes with different prespecified
   differentiation weights. We evaluate the allocation scheme, in
   combination with two popular request scheduling approaches, via
   extensive simulations and compare it with an absolute differentiation
   strategy and a proportional-share strategy tailored from relative
   differentiation in networking. Simulation results show that the harmonic
   proportional allocation scheme can meet the objective of relative
   differentiation in both short and long timescales and greatly enhance
   the service availability and maintain low queueing delay when the
   streaming system is highly loaded.},
DOI = {10.1109/TPDS.2004.43},
ISSN = {1045-9219},
EISSN = {1558-2183},
ResearcherID-Numbers = {XU, CHENGZHONG/AAX-1707-2020},
ORCID-Numbers = {XU, CHENGZHONG/0000-0001-9480-0356},
Unique-ID = {WOS:000222679300006},
}

@inproceedings{ WOS:000454692400029,
Author = {Javed, M. Haseeb and Lu, Xiaoyi and Panda, Dhabaleswar K.},
Book-Group-Author = {IEEE},
Title = {Cutting the Tail: Designing High Performance Message Brokers to Reduce
   Tail Latencies in Stream Processing},
Booktitle = {2018 IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPUTING (CLUSTER)},
Series = {IEEE International Conference on Cluster Computing},
Year = {2018},
Pages = {223-233},
Note = {IEEE International Conference on Cluster Computing (CLUSTER), Belfast,
   NORTH IRELAND, SEP 10-13, 2018},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {Over the last decade, organizations have become heavily reliant on
   providing near-instantaneous insights to the end user based on vast
   amounts of data collected from various sources in real-time. In order to
   accomplish this task, a stream processing pipeline is constructed, which
   in its most basic form, consists of a Stream Processing Engine (SPE) and
   a Message Broker (MB). The SPE is responsible for performing actual
   computations on the data and providing insights from it. MB, on the
   other hand, acts as an intermediate queue to which data is written by
   ephemeral sources and then fetched by the SPE to perform computations
   on. Due to the inherent real-time nature of such a pipeline, low latency
   is a highly desirable feature for them. Thus, several existing research
   works in the community focus on improving latency and throughput of the
   streaming pipeline. However, there is a dearth of studies optimizing the
   tail latencies of such pipelines. Moreover, the root cause of this high
   tail latency is still vague. In this paper, we propose a model-based
   approach to analyze in-depth the reasons behind high tail latency in
   streaming systems such as Apache Kafka. Having found the MB to be a
   major contributor of messages with high tail latencies in a streaming
   pipeline, we design and implement an RDMA-enhanced high-performance MB,
   called Frieda, with the higher goal of accelerating any arbitrary stream
   processing pipeline regardless of the SPE used. Our experiments show a
   reduction of up to 98\% in 99.9th percentile latency for microbenchmarks
   and up to 31\% for full-fledged stream processing pipeline constructed
   using Yahoo! Streaming Benchmark.},
DOI = {10.1109/CLUSTER.2018.00040},
ISSN = {1552-5244},
ISBN = {978-1-5386-8319-4},
Unique-ID = {WOS:000454692400029},
}

@inproceedings{ WOS:000380558700008,
Author = {Lu, Ruirui and Wu, Gang and Xie, Bin and Hu, Jingtong},
Book-Group-Author = {IEEE},
Title = {StreamBench: Towards Benchmarking Modern Distributed Stream Computing
   Frameworks},
Booktitle = {2014 IEEE/ACM 7TH INTERNATIONAL CONFERENCE ON UTILITY AND CLOUD
   COMPUTING (UCC)},
Series = {International Conference on Utility and Cloud Computing},
Year = {2014},
Pages = {69-78},
Note = {IEEE/ACM 7th International Conference on Utility and Cloud Computing
   (UCC), London, UNITED KINGDOM, DEC 08-11, 2014},
Organization = {IEEE; IEEE Comp Soc; ACM; TCSC IEEE; Sigarch},
Abstract = {While big data is becoming ubiquitous, interest in handling data stream
   at scale is also gaining popularity, which leads to the sprout of many
   distributed stream computing systems. However, complexity of stream
   computing and diversity of workloads expose great challenges to
   benchmark these systems. Due to lack of standard criteria, evaluations
   and comparisons of these systems tend to be difficult. This paper takes
   an early step towards benchmarking modern distributed stream computing
   frameworks. After identifying the challenges and requirements in the
   field, we raise our benchmark definition StreamBench regarding the
   requirements. StreamBench proposes a message system functioning as a
   mediator between stream data generation and consumption. It also covers
   7 benchmark programs that intend to address typical stream computing
   scenarios and core operations. Not only does it care about performance
   of systems under different data scales, but also takes fault tolerance
   ability and durability into account, which drives to incorporate four
   workload suites targeting at these various aspects of systems. Finally,
   we illustrate the feasibility of StreamBench by applying it to two
   popular frameworks, Apache Storm and Apache Spark Streaming. We draw
   comparisons from various perspectives between the two platforms with
   workload suites of StreamBench. In addition, we also demonstrate
   performance improvement of Storm's latest version with the benchmark.},
ISSN = {2373-6860},
ISBN = {978-1-4799-7881-6},
ORCID-Numbers = {Hu, Jingtong/0000-0003-4029-4034},
Unique-ID = {WOS:000380558700008},
}

@inproceedings{ WOS:000492836500161,
Author = {Karimov, Jeyhun and Rabl, Tilmann and Katsifodimos, Asterios and
   Samarev, Roman and Heiskanen, Henri and Markl, Volker},
Book-Group-Author = {IEEE},
Title = {Benchmarking Distributed Stream Data Processing Systems},
Booktitle = {2018 IEEE 34TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE)},
Series = {IEEE International Conference on Data Engineering},
Year = {2018},
Pages = {1507-1518},
Note = {34th IEEE International Conference on Data Engineering Workshops
   (ICDEW), Paris, FRANCE, APR 16-19, 2018},
Organization = {IEEE; IEEE Comp Soc; U S Natl Sci Fdn},
Abstract = {The need for scalable and efficient stream analysis has led to the
   development of many open-source streaming data processing systems
   (SDPSs) with highly diverging capabilities and performance
   characteristics. While first initiatives try to compare the systems for
   simple workloads, there is a clear gap of detailed analyses of the
   systems' performance characteristics. In this paper, we propose a
   framework for benchmarking distributed stream processing engines. We use
   our suite to evaluate the performance of three widely used SDPSs in
   detail, namely Apache Storm, Apache Spark, and Apache Flink. Our
   evaluation focuses in particular on measuring the throughput and latency
   of windowed operations, which are the basic type of operations in stream
   analytics. For this benchmark, we design workloads based on real-life,
   industrial use-cases inspired by the online gaming industry. The
   contribution of our work is threefold. First, we give a definition of
   latency and throughput for stateful operators. Second, we carefully
   separate the system under test and driver, in order to correctly
   represent the open world model of typical stream processing deployments
   and can, therefore, measure system performance under realistic
   conditions. Third, we build the first benchmarking framework to define
   and test the sustainable performance of streaming systems. Our detailed
   evaluation highlights the individual characteristics and use-cases of
   each system.},
DOI = {10.1109/ICDE.2018.00169},
ISSN = {1084-4627},
ISBN = {978-1-5386-5520-7},
ResearcherID-Numbers = {Markl, Volker/AAX-1862-2020},
Unique-ID = {WOS:000492836500161},
}

@article{ WOS:000327393900029,
Author = {Chen, Yishuai and Zhang, Baoxian and Liu, Yong and Zhu, Wei},
Title = {Measurement and Modeling of Video Watching Time in a Large-Scale
   Internet Video-on-Demand System},
Journal = {IEEE TRANSACTIONS ON MULTIMEDIA},
Year = {2013},
Volume = {15},
Number = {8},
Pages = {2087-2098},
Month = {DEC},
Abstract = {Video watching time is a crucial measure for studying user watching
   behavior in online Internet video-on-demand (VoD) systems. It is
   important for system planning, user engagement understanding, and system
   quality evaluation. However, due to the limited access of user data in
   large-scale streaming systems, a systematic measurement, analysis, and
   modeling of video watching time is still missing. In this paper, we
   measure PPLive, one of the most popular commercial Internet VoD systems
   in China, over a three week period. We collect accurate user watching
   data of more than 100 million streaming sessions of more than 100
   thousand distinct videos. Based on the measurement data, we characterize
   the distribution of watching time of different types of videos and
   reveal a number of interesting characteristics regarding the relation
   between video watching time and various video-related features
   (including video type, duration, and popularity). We further build a
   suite of mathematical models for characterizing these relationships.
   Extensive performance evaluation shows the high accuracy of these models
   as compared with commonly used data-mining based models. Our measurement
   and modeling results bring forth important insights for simulation,
   design, deployment, and evaluation of Internet VoD systems.},
DOI = {10.1109/TMM.2013.2280123},
ISSN = {1520-9210},
EISSN = {1941-0077},
Unique-ID = {WOS:000327393900029},
}

@inproceedings{ WOS:000390023100051,
Author = {Gudumasu, Srinivas and Hamza, Ahmed and Asbun, Eduardo and He, Yong and
   Ye, Yan},
Editor = {Tescher, AG},
Title = {Layer-based Buffer Aware Rate Adaptation Design for SHVC Video Streaming},
Booktitle = {APPLICATIONS OF DIGITAL IMAGE PROCESSING XXXIX},
Series = {Proceedings of SPIE},
Year = {2016},
Volume = {9971},
Note = {Conference on Applications of Digital Image Processing XXXIX, San Diego,
   CA, AUG 29-SEP 01, 2016},
Organization = {SPIE},
Abstract = {This paper proposes a layer based buffer aware rate adaptation design
   which is able to avoid abrupt video quality fluctuation, reduce
   re-buffering latency and improve bandwidth utilization when compared to
   a conventional simulcast based adaptive streaming system. The proposed
   adaptation design schedules DASH segment requests based on the estimated
   bandwidth, dependencies among video layers and layer buffer fullness.
   Scalable HEVC video coding is the latest state-of-art video coding
   technique that can alleviate various issues caused by simulcast based
   adaptive video streaming. With scalable coded video streams, the video
   is encoded once into a number of layers representing different qualities
   and/or resolutions: a base layer (BL) and one or more enhancement layers
   (EL), each incrementally enhancing the quality of the lower layers. Such
   layer based coding structure allows fine granularity rate adaptation for
   the video streaming applications.
   Two video streaming use cases are presented in this paper. The first use
   case is to stream HD SHVC video over a wireless network where available
   bandwidth varies, and the performance comparison between proposed
   layer-based streaming approach and conventional simulcast streaming
   approach is provided. The second use case is to stream 4K/UHD SHVC video
   over a hybrid access network that consists of a 5G millimeter wave
   high-speed wireless link and a conventional wired or WiFi network. The
   simulation results verify that the proposed layer based rate adaptation
   approach is able to utilize the bandwidth more efficiently. As a result,
   a more consistent viewing experience with higher quality video content
   and minimal video quality fluctuations can be presented to the user.},
DOI = {10.1117/12.2235795},
Article-Number = {99711M},
ISSN = {0277-786X},
ISBN = {978-1-5106-0333-2; 978-1-5106-0334-9},
ORCID-Numbers = {Ye, Yan/0000-0002-7278-0822},
Unique-ID = {WOS:000390023100051},
}

@inproceedings{ WOS:000390194300039,
Author = {Algemili, Usamah},
Editor = {Qiu, MK},
Title = {Investigation of Reconfigurable FPGA Design for Processing Big Data
   Streams},
Booktitle = {2016 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD
   (BIGDATASECURITY), IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND
   SMART COMPUTING (HPSC), AND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT
   DATA AND SECURITY (IDS)},
Year = {2016},
Pages = {226-233},
Note = {2nd IEEE International Conference on High Performance and Smart
   Computing (IEEE HPSC), New York, NY, APR 08-10, 2016},
Organization = {IEEE; IEEE Comp Soc; IEEE TCSC; PACE Univ; Columbia Univ; N Amer Chinese
   Talents Assoc; Longxian High Tech; Stony Brook Univ; IEEE Big Data Secur
   HPSC IDS Comm; Shanghai Jiao Tong Univ; IEEE Transact Cloud Comp; IEEE
   Transact Comp},
Abstract = {Big Data situation has placed a tremendous pressure on the existing
   computational models. The challenges of Big Data call for a new approach
   to solve both software and hardware problems. Streaming applications is
   a form of on-demand software distribution. In streaming scenarios, only
   essential portions of an application's code need to be installed on the
   system, while the receiver performs the main operations. The necessary
   code and files are delivered over the network as, and when, they are
   required.
   The hardware architecture plays an important role in improving the
   efficiency of a streaming system. The variance of hardware performance
   on different HW architectures is quite interesting. Previous work
   confirms that the CPUs, GPUs, and FPGAs are performing differently on
   specific applications. The previous efforts of hardware benchmarking
   show that GPUs outperformed the other platforms in terms of execution
   time. CPUs outperformed in overall execution combined with transfer
   time. FPGAs outperformed for fixed algorithms using streaming {[}1].
   Hence, this paper evaluates the performance of streaming applications on
   a pipelined FPGA design. In the context of real-time processing, it
   elects one of the Big Data streaming problems that gets a candidate for
   majority element on-the-fly; that is Moore's Voting Algorithm. The
   performance analysis of Moore's algorithm on FPGA highlights a
   noticeable improvement by using a pipelining architecture.},
DOI = {10.1109/BigDataSecurity-HPSC-IDS.2016.75},
ISBN = {978-1-5090-2403-2},
Unique-ID = {WOS:000390194300039},
}

@article{ WOS:000456138500010,
Author = {Gao, Lin and Tang, Ming and Pang, Haitian and Huang, Jianwei and Sun,
   Lifeng},
Title = {Multi-User Cooperative Mobile Video Streaming: Performance Analysis and
   Online Mechanism Design},
Journal = {IEEE TRANSACTIONS ON MOBILE COMPUTING},
Year = {2019},
Volume = {18},
Number = {2},
Pages = {376-389},
Month = {FEB 1},
Abstract = {Adaptive bitrate streaming enables video users to adapt their playing
   bitrates to the real-time network conditions, hence achieving the
   desirable quality-of-experience (QoE). In a multi-user wireless
   scenario, however, existing single-user based bitrate adaptation methods
   may fail to provide the desirable QoE, due to lack of consideration of
   multi-user interactions (such as the multi-user interferences and
   network congestion). In this work, we propose a novel user cooperation
   framework based on user-provided networking for multi-user mobile video
   streaming over wireless cellular networks. The framework enables nearby
   mobile video users to crowdsource their cellular links and resources for
   cooperative video streaming. We first analyze the social welfare
   performance bound of the proposed cooperative streaming system by
   introducing a virtual time-slotted system. Then, we design a low
   complexity Lyapunov-based online algorithm, which can be implemented in
   an online and distributed manner without the complete future and global
   network information. Numerical results show that the proposed online
   algorithm achieves an average 97 percent of the theoretical maximum
   social welfare. We further conduct experiments with real data traces, to
   compare our proposed online algorithm with the existing online
   algorithms in the literature. Experiment results show that our algorithm
   outperforms the existing algorithms in terms of both the achievable
   bitrate (with an average gain of 20 similar to 30 percent) and social
   welfare (with an average gain of 10 similar to 50 percent).},
DOI = {10.1109/TMC.2018.2834358},
ISSN = {1536-1233},
EISSN = {1558-0660},
ResearcherID-Numbers = {Tang, Ming/AER-2583-2022
   Huang, Jianwei/C-1303-2008
   GAO, Lin/N-8286-2015},
ORCID-Numbers = {Huang, Jianwei/0000-0001-6631-1096
   },
Unique-ID = {WOS:000456138500010},
}

@article{ WOS:000354527500011,
Author = {Thomos, Nikolaos and Kurdoglu, Eymen and Frossard, Pascal and van der
   Schaar, Mihaela},
Title = {Adaptive Prioritized Random Linear Coding and Scheduling for Layered
   Data Delivery From Multiple Servers},
Journal = {IEEE TRANSACTIONS ON MULTIMEDIA},
Year = {2015},
Volume = {17},
Number = {6},
Pages = {893-906},
Month = {JUN},
Abstract = {In this paper, we deal with the problem of jointly determining the
   optimal coding strategy and the scheduling decisions when receivers
   obtain layered data from multiple servers. The layered data is encoded
   by means of prioritized random linear coding (PRLC) in order to be
   resilient to channel loss while respecting the unequal levels of
   importance in the data, and data blocks are transmitted simultaneously
   in order to reduce decoding delays and improve the delivery performance.
   We formulate the optimal coding and scheduling decisions problem in our
   novel framework with the help of Markov decision processes (MDP), which
   are effective tools for modeling adapting streaming systems.
   Reinforcement learning approaches are then proposed to derive reduced
   computational complexity solutions to the adaptive coding and scheduling
   problems. The novel reinforcement learning approaches and the MDP
   solution are examined in an illustrative example for scalable video
   transmission. Our methods offer large performance gains over competing
   methods that deliver the data blocks sequentially. The experimental
   evaluation also shows that our novel algorithms offer continuous
   playback and guarantee small quality variations which is not the case
   for baseline solutions. Finally, our work highlights the advantages of
   reinforcement learning algorithms to forecast the temporal evolution of
   data demands and to decide the optimal coding and scheduling decisions.},
DOI = {10.1109/TMM.2015.2425228},
ISSN = {1520-9210},
EISSN = {1941-0077},
ResearcherID-Numbers = {Frossard, Pascal/AAF-2268-2019
   Thomos, Nikolaos/AAU-2328-2020
   },
ORCID-Numbers = {van der schaar, Mihaela/0000-0003-3933-6049
   Thomos, Nikolaos/0000-0001-7266-2642},
Unique-ID = {WOS:000354527500011},
}

@inproceedings{ WOS:000570730200051,
Author = {Kolev, Boyan and Akbarinia, Reza and Jimenez-Peris, Ricardo and
   Levchenko, Oleksandra and Masseglia, Florent and Patino, Marta and
   Valduriez, Patrick},
Editor = {Hammoudi, S and Quix, C and Bernardino, J},
Title = {Pipelined Implementation of a Parallel Streaming Method for Time Series
   Correlation Discovery on Sliding Windows},
Booktitle = {PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON DATA SCIENCE,
   TECHNOLOGY AND APPLICATIONS (DATA)},
Year = {2019},
Pages = {431-436},
Note = {8th International Conference on Data Science, Technology and
   Applications (DATA), Prague, CZECH REPUBLIC, JUL 26-28, 2019},
Abstract = {This paper addresses the problem of continuously finding highly
   correlated pairs of time series over the most recent time window. The
   solution builds upon the ParCorr parallel method for online correlation
   discovery and is designed to run continuously on top of the UPM-CEP data
   streaming engine through efficient streaming operators. The
   implementation takes advantage of the flexible API of the streaming
   engine that provides low level primitives for developing custom
   operators. Thus, each operator is implemented to process incoming tuples
   on-the-fly and hence emit resulting tuples as early as possible. This
   guarantees a real pipelined flow of data that allows for outputting
   early results, as the experimental evaluation shows.},
DOI = {10.5220/0008191304310436},
ISBN = {978-989-758-377-3},
ResearcherID-Numbers = {Patiño-Martinez, Marta/ABE-6826-2020
   },
ORCID-Numbers = {PATINO MARTINEZ, MARTA/0000-0003-2997-3722
   Patino Martinez, Marta/0000-0001-6947-4974},
Unique-ID = {WOS:000570730200051},
}

@inproceedings{ WOS:000369860500090,
Author = {Lee, Suk Kyu and Kim, Hyunsoon and Lee, Woonghee and Kim, Hwantae and
   Jung, Jongtack and Kim, Hwangnam},
Book-Group-Author = {IEEE},
Title = {ReMA: Real-Time 3D Video Streaming System for Mobile Devices},
Booktitle = {2014 IEEE INTERNATIONAL PERFORMANCE COMPUTING AND COMMUNICATIONS
   CONFERENCE (IPCCC)},
Series = {IEEE International Performance Computing and Communications Conference
   (IPCCC)},
Year = {2014},
Note = {33rd IEEE International Performance, Computing, and Communications
   Conference (IPCCC), Austin, TX, DEC 05-07, 2014},
Organization = {IEEE; IEEE Comp Soc Tech Comm Simulat; IEEE Comp Soc Tech Comm Comp
   Commun; IEEE Central Texas Sect; IEEE Comp Soc},
Abstract = {User's multimedia interaction is facing a paradigm shift from 2D to 3D
   videos. Nonetheless, it is still difficult to watch 3D videos with a
   mobile device. With current technological barrier in wireless
   networking, it is hardly imagined that the timely transmission for a 3D
   video streaming could be feasible with the mobile device. In this paper,
   we propose ReMA, a novel 3D video distribution system based on a
   lightweight compression, a link-adaptive transmission scheme, and a
   network-side assistance for processing capability. ReMA consists of a 3D
   data transmitter, a receiver, and an infrastructure for generating and
   distributing 3D videos. We implemented the proposed system in a real
   test-bed and conducted a thorough empirical evaluation study. Based on
   the empirical results, the proposed system presents a great promise in
   streaming 3D video in real-time to the mobile device.},
ISSN = {1097-2641},
ISBN = {978-1-4799-7575-4},
ResearcherID-Numbers = {Lee, Woonghee/AAW-8903-2021},
ORCID-Numbers = {Lee, Woonghee/0000-0003-0856-6415},
Unique-ID = {WOS:000369860500090},
}

@inproceedings{ WOS:000851014500012,
Author = {Yang, Shinhyung and Jeong, Yonguk and Hong, ChangWan and Jun, Hyunje and
   Burgstaller, Bernd},
Editor = {Heras, DB and Bouge, L and Mencagli, G and Jeannot, E and Sakellariou, R and Badia, RM and Barbosa, JG and Ricci, L and Scott, SL and Lankes, S and Weidendorfer, J},
Title = {Scalability and State: A Critical Assessment of Throughput Obtainable on
   Big Data Streaming Frameworks for Applications With and Without State
   Information},
Booktitle = {EURO-PAR 2017: PARALLEL PROCESSING WORKSHOPS},
Series = {Lecture Notes in Computer Science},
Year = {2018},
Volume = {10659},
Pages = {141-152},
Note = {23rd International Conference on Parallel and Distributed Computing
   (Euro-Par), Santiago de Compostela, SPAIN, AUG 28-SEP 01, 2017},
Organization = {Univ Santiago Compostela, Centro Investigac Tecnoloxias Informac},
Abstract = {Emerging Big Data streaming applications are facing unbounded (infinite)
   data sets at a scale of millions of events per second. The information
   captured in a single event, e.g., GPS position information of mobile
   phone users, loses value (perishes) over time and requires sub-second
   latency responses. Conventional Cloud-based batch-processing platforms
   are inadequate to meet these constraints.
   Existing streaming engines exhibit low throughput and are thus equally
   ill-suited for emerging Big Data streaming applications. To validate
   this claim, we evaluated the Yahoo streaming benchmark and our own
   real-time trend detector on three state-of-the-art streaming engines:
   Apache Storm, Apache Flink and Spark Streaming. We adapted the Kieker
   dynamic profiling framework to gather accurate profiling information on
   the throughput and CPU utilization exhibited by the two benchmarks on
   the Google Compute Engine.
   To estimate the performance overhead incurred by current streaming
   engines, we re-implemented our Java-based trend detector as a
   multi-threaded, shared-memory application in C++. The achieved
   throughput of 3 2 million events per second on a stand-alone 2 CPU (44
   cores) Intel Xeon E5-2699 v4 server is 44 times higher than the maximum
   throughput achieved with the Apache Storm version of the trend detector
   deployed on 30 virtual machines (nodes) in the Cloud. Our experiment
   suggests vertical scaling as a viable alternative to horizontal scaling,
   especially if shared state has to be maintained in a streaming
   application. For reproducibility, we have open-sourced our framework
   configurations on GitHub{[}1].},
DOI = {10.1007/978-3-319-75178-8\_12},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-75178-8; 978-3-319-75177-1},
ORCID-Numbers = {Yang, Shinhyung/0000-0002-8997-9942},
Unique-ID = {WOS:000851014500012},
}

@inproceedings{ WOS:000458738400019,
Author = {Memeti, Suejb and Pllana, Sabri},
Editor = {Pop, F and Negru, C and GonzalezVelez, H and Rak, J},
Title = {HSTREAM: A directive-based language extension for heterogeneous stream
   computing},
Booktitle = {2018 21ST IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND
   ENGINEERING (CSE 2018)},
Series = {IEEE International Conference on Computational Science and Engineering},
Year = {2018},
Pages = {138-145},
Note = {21st IEEE International Conference on Computational Science and
   Engineering (CSE), Univ Politehnica Bucharest, Bucharest, ROMANIA, OCT
   29-31, 2018},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {Big data streaming applications require utilization of heterogeneous
   parallel computing systems, which may comprise multiple multi-core CPUs
   and many-core accelerating devices such as NVIDIA GPUs and Intel Xeon
   Phis. Programming such systems require advanced knowledge of several
   hardware architectures and device-specific programming models, including
   OpenMP and CUDA. In this paper, we present HSTREAM, a compiler
   directive-based language extension to support programming stream
   computing applications for heterogeneous parallel computing systems.
   HSTREAM source-to-source compiler aims to increase the programming
   productivity by enabling programmers to annotate the parallel regions
   for heterogeneous execution and generate target specific code. The
   HSTREAM runtime automatically distributes the workload across CPUs and
   accelerating devices. We demonstrate the usefulness of HSTREAM language
   extension with various applications from the STREAM benchmark.
   Experimental evaluation results show that HSTREAM can keep the same
   programming simplicity as OpenMP, and the generated code can deliver
   performance beyond what CPUs-only and GPUs-only executions can deliver.},
DOI = {10.1109/CSE.2018.00026},
ISSN = {1949-0828},
ISBN = {978-1-5386-7649-3},
ORCID-Numbers = {Memeti, Suejb/0000-0003-1608-3181},
Unique-ID = {WOS:000458738400019},
}

@article{ WOS:000402022500012,
Author = {Nagasu, Kohei and Sano, Kentaro and Kono, Fumiya and Nakasato, Naohito},
Title = {FPGA-based tsunami simulation: Performance comparison with GPUs, and
   roofline model for scalability analysis},
Journal = {JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING},
Year = {2017},
Volume = {106},
Pages = {153-169},
Month = {AUG},
Abstract = {MOST (Method Of Splitting Tsunami) is widely used to solve shallow water
   equations (SWEs) for simulation of tsunami. This paper presents
   high-performance and power-efficient computation of MOST for practical
   tsunami simulation with FPGA. The custom hardware for simulation is
   based on a stream computing architecture for deeply pipelining to
   increase performance with a limited bandwidth. We design a stream
   processing element (SPE) of computing kernels combined with stencil
   buffers. We also introduce an SPE array architecture with spatial and
   temporal parallelism to further exploit available hardware resources by
   implementing multiple SPEs with parallel internal pipelines. Our
   prototype implementation with Arria 10 FPGA demonstrates that the
   FPGA-based design performs numerically stable tsunami simulation with
   real ocean-depth data in single precision by introducing
   non-dimensionalization. We explore the design space of SPE arrays, and
   find that the design of six cascaded SPEs with a single pipeline
   achieves the sustained performance of 383 GFlops and the performance per
   power of 8.41 GFlops/W with a stream bandwidth of only 7.2 GB/s. These
   numbers are 8.6 and 17.2 times higher than those of NVidia Tesla K20c
   GPU, and 1.7 and 7.1 times higher than those of AMD Radeon R9 280X GPU,
   respectively, for the same tsunami simulation in single precision.
   Moreover, we proposed a roofline model for stream computing with the SPE
   array in order to investigate factors of performance degradation and
   possible performance improvement for given FPGAs. With the model, we
   estimate that an upcoming Stratix 10 GX2800 FPGA can achieve the
   sustained performance of 8.7.TFlops at most with our SPE array
   architecture for tsunami simulation. (C) 2016 Elsevier Inc. All rights
   reserved.},
DOI = {10.1016/j.jpdc.2016.12.015},
ISSN = {0743-7315},
EISSN = {1096-0848},
Unique-ID = {WOS:000402022500012},
}

@inproceedings{ WOS:000841861700013,
Author = {Liu, Tao and Yang, Zhihong and Sun, Yuzhong},
Book-Group-Author = {IEEE},
Title = {Docker Container Networking Based Apache Storm and Flink Benchmark Test},
Booktitle = {2021 22ND ASIA-PACIFIC NETWORK OPERATIONS AND MANAGEMENT SYMPOSIUM
   (APNOMS)},
Series = {Asia-Pacific Network Operations and Management Symposium-APNOMS},
Year = {2021},
Pages = {49-52},
Note = {22nd Asia-Pacific Network Operations and Management Symposium (APNOMS),
   ELECTR NETWORK, SEP 08-10, 2021},
Abstract = {Many distributed stream computing engines have emerged to handle big
   data, and they can be deployed in cloud environments consisting of
   native networks or container networks. Most of the benchmark research on
   stream computing engines are carried out under the native network, and
   the research on the impact on container network on stream computing
   engines is currently inadequate. However, the use of container network
   will inevitably lead to performance degradation, which is the
   disadvantage of all virtual networks. In this work, we build Apache
   Storm and Apache Flink, which are Streaming Computation Engines in
   container network and native network environments and conduct
   performance measurements through experiments processing textual data to
   verify how much performance decreases in container network. Experiments
   show that the throughput in a container network environment is 1\%-5\%
   lower and CPU utilization is 11\%-18\% lower than in a local network
   environment.},
ISSN = {2576-8565},
EISSN = {2576-8557},
ISBN = {978-4-88552-332-8},
Unique-ID = {WOS:000841861700013},
}

@inproceedings{ WOS:000405512400075,
Author = {Xie, Bin and Sun, Guanyi and Ma, Guo},
Editor = {Xu, B},
Title = {Docker Based Overlay Network Performance Evaluation in Large Scale
   Streaming System},
Booktitle = {PROCEEDINGS OF 2016 IEEE ADVANCED INFORMATION MANAGEMENT, COMMUNICATES,
   ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IMCEC 2016)},
Year = {2016},
Pages = {366-369},
Note = {IEEE Advanced Information Management, Communicates, Electronic and
   Automation Control Conference (IMCEC), Xian, PEOPLES R CHINA, OCT 03-05,
   2016},
Organization = {IEEE; IEEE Beijing Sect; Global Union Acad Sci \& Technol; Chongqing
   Global Union Acad Sci \& Technol; Xian Peihua Univ},
Abstract = {Docker, the most popular container technique today, has accepted by more
   and more people and companies. It achieves agility and controls for
   Development and IT Operations teams to build, ship, and run any app,
   anywhere. Taking Docker's advantages, enterprises are able to leverage
   big data analytics more efficiently. In this paper, we use two network
   modes in Docker when building one Spark based streaming application. To
   get better achievement we design one experimental system to investigate
   performance between host and overlay network mode from different
   aspects. Through our working, we find host mode is faster overlay mode
   around 8\%. At the same time, the overlay mode is more stable. We
   introduce coefficient of variation to see the difference of transfer
   latency among every package and overlay mode is better than host mode
   more than 50\%. Therefore, overlay network mode is more suitable for the
   business with high quality requirement of network jitter like video
   conference. On the other hand, when need to get higher transfer latency,
   host mode is better choice.},
ISBN = {978-1-4673-9613-4},
Unique-ID = {WOS:000405512400075},
}

@inproceedings{ WOS:000390604100037,
Author = {Smirnov, Pavel A. and Nasonov, Denis},
Editor = {Boukhanovsky, A and Bubak, M and Balakhontceva, M},
Title = {Quality-based workload scaling for real-time streaming systems},
Booktitle = {5TH INTERNATIONAL YOUNG SCIENTIST CONFERENCE ON COMPUTATIONAL SCIENCE,
   YSC 2016},
Series = {Procedia Computer Science},
Year = {2016},
Volume = {101},
Pages = {323-332},
Note = {5th International Young Scientist Conference on Computational Science
   (YSC), Krakow, POLAND, OCT 26-28, 2016},
Abstract = {In this paper we propose an idea to scale workload via elastic quality
   of solution provided by the particular streaming applications. The
   contribution of this paper consists of quality-based workload scaling
   model, implementation details for quality assessment mechanism
   implemented at the top of Apache Storm and experimental evaluation of
   the proposed model on a synthetic and real-world (medical) examples.},
DOI = {10.1016/j.procs.2016.11.038},
ISSN = {1877-0509},
ResearcherID-Numbers = {Nasonov, Denis/B-8171-2014
   Smirnov, Alexey/AAB-2521-2020},
ORCID-Numbers = {Smirnov, Alexey/0000-0001-5361-8232},
Unique-ID = {WOS:000390604100037},
}

@article{ WOS:000443244400010,
Author = {Alsmirat, Mohammad A. and Sarhan, Nabil J.},
Title = {Cross-layer optimization for many-to-one wireless video streaming
   systems},
Journal = {MULTIMEDIA TOOLS AND APPLICATIONS},
Year = {2018},
Volume = {77},
Number = {19},
Pages = {24789-24811},
Month = {OCT},
Abstract = {This paper develops a cross-layer optimization solution for video
   streaming from multiple sources to a central proxy station over a
   wireless network. The proposed solution manages the application rates
   and transmission opportunities of various video sources based on the
   dynamic network conditions in such a way that minimizes the overall
   video distortion. The solution includes a new online approach for
   estimating the effective network airtime and a new video
   bitrate-distortion model. We demonstrate the effectiveness of the
   proposed solution through extensive experiments. The results show that
   the proposed solution substantially enhances the perceptual video
   quality while reducing the power consumed by the video sources and that
   the solution is highly adaptable to the existence of interfering network
   traffic.},
DOI = {10.1007/s11042-018-5698-x},
ISSN = {1380-7501},
EISSN = {1573-7721},
ORCID-Numbers = {Sarhan, Nabil/0000-0002-0527-5666},
Unique-ID = {WOS:000443244400010},
}

@inproceedings{ WOS:000458430500061,
Author = {Shah, Syed Saddam Hussain and Said, Naina and Nayab, Aysha and Khan,
   Waleed and Shinwari, Zaryab Ali and Jawad, M. and Minallah, Nasru},
Book-Group-Author = {IEEE},
Title = {Performance Comparison of Chunk and Peer Scheduling Algorithms of
   Peer-to-Peer Streaming Systems},
Booktitle = {2018 INTERNATIONAL CONFERENCE ON FRONTIERS OF INFORMATION TECHNOLOGY
   (FIT 2018)},
Series = {International Conference on Frontiers of Information Technology},
Year = {2018},
Pages = {361-366},
Note = {16th International Conference on Frontiers of Information Technology
   (FIT), COMSTECH, Islamabad, PAKISTAN, DEC 17-19, 2018},
Organization = {IEEE Comp Soc; IEEE Islamabad Chapter; IEEE Ind Elect Soc; COMSATS Univ
   Islamabad},
Abstract = {With increasing popularity of Peer to Peer systems for video streaming,
   it is important that the expectations of the users regarding the quality
   of such systems are being met. In a P2P system, the media stream is
   divided into small data units known as chunks. Each peer in a Peer to
   Peer (P2P) system has to take two important decisions at a given time.
   First, which chunks are to be shared and second with which peer. This
   paper compares the performance of different combinations of chunk/peer
   schedulers in terms of chunk diffusion delay, average chunk distribution
   delay and max chunk distribution delay. By doing so, the best possible
   combination of the two schedulers for the given experimental setup is
   explored. The results obtained under the specified experimental setup
   show that when chunk scheduling algorithm Deadline Based Chunk Scheduler
   (DLc) is combined with different peer scheduling algorithms, the best
   results are obtained by its combination with Chunk Earliest Free Pair
   Scheduler (CEFp). For a constant peer scheduler CEFp combined with
   different chunk schedulers, the best results are obtained by combining
   it with Latest Blind Chunk Scheduler (LBc). Finally, with varying
   neighborhood size, the best results are obtained by the combination of
   DLC and Chunk Almost Free Peer Scheduler (CAFp).},
DOI = {10.1109/FIT.2018.00070},
ISSN = {2334-3141},
ISBN = {978-1-5386-9355-1},
Unique-ID = {WOS:000458430500061},
}

@inproceedings{ WOS:000316564100148,
Author = {Hazra, J. and Reddi, Ravi Kiran and Das, Kaushik and Seetharam, Deva P.
   and Sinha, A. K.},
Book-Group-Author = {IEEE},
Title = {Power Grid Transient Stability Prediction Using Wide Area Synchrophasor
   Measurements},
Booktitle = {2012 3RD IEEE PES INNOVATIVE SMART GRID TECHNOLOGIES EUROPE (ISGT
   EUROPE)},
Series = {IEEE PES Innovative Smart Grid Technologies Conference Europe},
Year = {2012},
Note = {3rd IEEE PES International Conference and Exhibition on Innovative Smart
   Grid Technologies Europe (ISGT Europe), Tech Univ Berlin, Berlin,
   GERMANY, OCT 14-17, 2012},
Organization = {IEEE PES Power \& Energy Soc; Tech Univ Berlin, SENSE Lab; IEEE},
Abstract = {Electric power systems are prone to various kinds of transient
   disturbances which exist only for a fraction of second and often trigger
   cascading failures. Hence it is important to detect and prevent them
   from spreading in time. Conventionally these events are prevented by
   deploying costly special protection systems (SPS). Unfortunately, in
   many cases SPSs mis-operate as they could not predict the stability well
   ahead and are designed to operate based on past experiences and
   extensive off-line simulations. This paper proposes an online transient
   stability prediction scheme based on live synchrophasor data. The
   novelty of the proposed method is that it accurately predicts the
   transient stability based on only few (10 to 12) sample fault data
   without solving computationally extensive electromechanical dynamics.
   Synchrophasor data from geographically distributed Phasor Measurement
   Units (PMUs) are collected, synchronized, aggregated (if required) and
   analyzed on a stream computing platform to predict the trajectories of
   the generators which are then used to predict the transient stability of
   the grid. Performance of the proposed scheme is evaluated on the
   benchmark systems and evaluation results are presented in this paper.},
DOI = {10.1109/ISGTEurope.2012.6465752},
ISSN = {2165-4816},
ISBN = {978-1-4673-2595-0; 978-1-4673-2596-7},
ResearcherID-Numbers = {Das, Kaushik/Q-1265-2016},
ORCID-Numbers = {Das, Kaushik/0000-0002-6501-7896},
Unique-ID = {WOS:000316564100148},
}

@article{ WOS:000552737900159,
Author = {Akanbi, Adeyinka and Masinde, Muthoni},
Title = {A Distributed Stream Processing Middleware Framework for Real-Time
   Analysis of Heterogeneous Data on Big Data Platform: Case of
   Environmental Monitoring},
Journal = {SENSORS},
Year = {2020},
Volume = {20},
Number = {11},
Month = {JUN},
Abstract = {In recent years, the application and wide adoption of Internet of Things
   (IoT)-based technologies have increased the proliferation of monitoring
   systems, which has consequently exponentially increased the amounts of
   heterogeneous data generated. Processing and analysing the massive
   amount of data produced is cumbersome and gradually moving from
   classical `batch' processing-extract, transform, load (ETL) technique to
   real-time processing. For instance, in environmental monitoring and
   management domain, time-series data and historical dataset are crucial
   for prediction models. However, the environmental monitoring domain
   still utilises legacy systems, which complicates the real-time analysis
   of the essential data, integration with big data platforms and reliance
   on batch processing. Herein, as a solution, a distributed stream
   processing middleware framework for real-time analysis of heterogeneous
   environmental monitoring and management data is presented and tested on
   a cluster using open source technologies in a big data environment. The
   system ingests datasets from legacy systems and sensor data from
   heterogeneous automated weather systems irrespective of the data types
   to Apache Kafka topics using Kafka Connect APIs for processing by the
   Kafka streaming processing engine. The stream processing engine executes
   the predictive numerical models and algorithms represented in event
   processing (EP) languages for real-time analysis of the data streams. To
   prove the feasibility of the proposed framework, we implemented the
   system using a case study scenario of drought prediction and forecasting
   based on the Effective Drought Index (EDI) model. Firstly, we transform
   the predictive model into a form that could be executed by the streaming
   engine for real-time computing. Secondly, the model is applied to the
   ingested data streams and datasets to predict drought through persistent
   querying of the infinite streams to detect anomalies. As a conclusion of
   this study, a performance evaluation of the distributed stream
   processing middleware infrastructure is calculated to determine the
   real-time effectiveness of the framework.},
DOI = {10.3390/s20113166},
Article-Number = {3166},
EISSN = {1424-8220},
ResearcherID-Numbers = {Masinde, Muthoni/P-7374-2015
   Akanbi, Adeyinka/M-3563-2013},
ORCID-Numbers = {Masinde, Muthoni/0000-0002-8914-0055
   Akanbi, Adeyinka/0000-0002-8796-0674},
Unique-ID = {WOS:000552737900159},
}

@inproceedings{ WOS:000318700200033,
Author = {Emani, Murali Krishna and Wang, Zheng and O'Boyle, Michael F. P.},
Book-Group-Author = {IEEE},
Title = {Smart, Adaptive Mapping of Parallelism in the Presence of External
   Workload},
Booktitle = {PROCEEDINGS OF THE 2013 IEEE/ACM INTERNATIONAL SYMPOSIUM ON CODE
   GENERATION AND OPTIMIZATION (CGO)},
Series = {International Symposium on Code Generation and Optimization},
Year = {2013},
Pages = {347-356},
Note = {11th IEEE/ACM International Symposium on Code Generation and
   Optimization (CGO), Shenzhen, PEOPLES R CHINA, FEB 23-27, 2013},
Organization = {IEEE; Assoc Comp Machinery (ACM); ACM SIGMICRO; ACM SIGPLAN; IEEE Comp
   Soc Tc-uARCH; Natl Sci Fdn (NSF); Google; Chinese Acad Sci (CAS);
   Huawei; Intel; Natl Nat Sci Fdn China (NSFC); Chinese Acad Sci (CAS),
   Inst Comp Technol (ICT); CAS, ICT, State Key Lab Comp Architecture;
   Sugon; Facebook; Microsoft; Loongson Tech; Oracle; IBM Res; PARATERA;
   IEEE Comp Soc},
Abstract = {Given the wide scale adoption of multi-cores in main stream computing,
   parallel programs rarely execute in isolation and have to share the
   platform with other applications that compete for resources. If the
   external workload is not considered when mapping a program, it leads to
   a significant drop in performance. This paper describes an automatic
   approach that combines compile-time knowledge of the program with
   dynamic runtime workload information to determine the best adaptive
   mapping of programs to available resources. This approach delivers
   increased performance for the target application without penalizing the
   existing workload. This approach is evaluated on NAS and SpecOMP
   parallel benchmark programs across a wide range of workload scenarios.
   On average, our approach achieves performance gain of 1.5x over a
   state-of-art scheme on a 12 core machine.},
ISSN = {2164-2397},
ISBN = {978-1-4673-5525-4; 978-1-4673-5524-7},
ResearcherID-Numbers = {Wang, Zheng/AAP-8818-2020},
ORCID-Numbers = {Wang, Zheng/0000-0001-6157-0662},
Unique-ID = {WOS:000318700200033},
}

@article{ WOS:000283808600021,
Author = {Li, Yongkun and Lui, John C. S.},
Title = {Stochastic analysis of a randomized detection algorithm for pollution
   attack in P2P live streaming systems},
Journal = {PERFORMANCE EVALUATION},
Year = {2010},
Volume = {67},
Number = {11, SI},
Pages = {1273-1288},
Month = {NOV},
Note = {Conference on Performance Evaluation 2010, Namur, BELGIUM, NOV 17-19,
   2010},
Abstract = {Pollution attack is known to have a disastrous effect on existing P2P
   infrastructures it can reduce the number of legitimate P2P users by as
   much as 85\% and it generates abundant bogus data which may deplete the
   communication bandwidth We propose a distributed defense and detection
   mechanism to resolve pollution attacks The mechanism is composed of a
   set of randomized and fully distributed algorithms that can be executed
   by any legitimate peer We present the analytical framework to quantify
   (a) the probability of false negative (b) the probability of false
   positive, and (c) the distribution of time needed for detection In our
   detection algorithm and analysis we consider the case of (1) single
   attacker within the neighborhood (2) multiple attackers within the
   neighborhood Furthermore we show how to `optimize the system parameters
   so as to quickly discover and eliminate malicious peers from the system
   (C) 2010 Elsevier B V All rights reserved},
DOI = {10.1016/j.peva.2010.08.005},
ISSN = {0166-5316},
EISSN = {1872-745X},
Unique-ID = {WOS:000283808600021},
}

@article{ WOS:000374011400007,
Author = {Maamar, Haifa Raja and Boukerche, Azzedine and Petriu, Emil},
Title = {A performance evaluation of mobility management and multihop supplying
   partner strategies for 3D streaming systems over thin mobile devices},
Journal = {CONCURRENCY AND COMPUTATION-PRACTICE \& EXPERIENCE},
Year = {2016},
Volume = {28},
Number = {6, SI},
Pages = {1769-1795},
Month = {APR 25},
Abstract = {The recent advances in technology and mobile computing led to the rapid
   growth of networked 3D streaming applications. The emerging services can
   involve augmented reality, virtual environment walkthrough, multiplayer
   gaming just to mention a few. Because of the limited network bandwidth
   of the client-server approach, research works are now turning toward
   mobile ad hoc networks-based streaming, where the resources of each peer
   are used during the streaming service. Peer-to-peer technologies are
   considering the solution to adapt for scalable applications. Yet,
   supplying partner selection and 3D data delivery are still significant
   challenges to face because of the dynamic wireless environment that
   causes link breakages, high packet loss, an adverse impact on the
   quality of the 3D media, and a low user satisfaction. In this paper, we
   propose a supplying partner selection technique coupled with a content
   delivery technique for peer-to-peer 3D streaming over thin mobile
   devices. Our proposed protocol, which we refer to as MULTIPLY, considers
   multihop suppliers in order to alleviate the load on the server and uses
   the signal strength measurement to analyze the wireless link when
   sending back the 3D data. Given the high dynamicity of the network due
   to the mobility of the users, the streaming can be greatly affected. We
   therefore study the impact of the mobility on MULTIPLY. The performance
   evaluation of our protocol obtained using an extensive set of simulation
   experiments is then reported. Copyright (C) 2013 John Wiley \& Sons,
   Ltd.},
DOI = {10.1002/cpe.3106},
ISSN = {1532-0626},
EISSN = {1532-0634},
Unique-ID = {WOS:000374011400007},
}

@inproceedings{ WOS:000455947000333,
Author = {Suzumura, Toyotaro and Nishii, Shunsuke and Ganse, Masaru},
Book-Group-Author = {Assoc Comp Machinery},
Title = {Towards Large-Scale Graph Stream Processing Platform},
Booktitle = {WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON
   WORLD WIDE WEB},
Year = {2014},
Pages = {1321-1326},
Note = {23rd International Conference on World Wide Web (WWW), Seoul, SOUTH
   KOREA, APR 07-11, 2014},
Organization = {Assoc Comp Machinery; IW3C2; ACM SIGWEB; NAVER; Google; Microsoft; SK
   Planet; Facebook; Yahoo! Labs; Daum; European Patent Off; LG Elect;
   Baidu; Kaggle; Samsung; Korea Tourism Org; Korean Federat Sci \& Technol
   Soc; Seoul Metropolitan Govt; Korea Inst Informat Scientists \&
   Engineers; Int World Wide Web Conf Steering Comm; Korea Adv Inst Sci \&
   Technol; Korean Agcy Technol \& Stand},
Abstract = {In recent years, real-time data mining for large-scale time evolving
   graphs is becoming a hot research topic. Most of the prior arts target
   relatively static graphs and also process them in store-and-process
   batch processing model. In this paper we propose a method of applying
   on-the-fly and incremental graph stream computing model to such dynamic
   graph analysis. To process large-scale graph streams on a cluster of
   nodes dynamically in a scalable fashion, we propose an incremental
   large-scale graph processing model called ``Incremental GIM-V
   (Generalized Iterative Matrix-Vector Multiplication){''}. We also design
   and implement UNICORN, a system that adopts the proposed incremental
   processing model on top of IBM InfoSphere Streams. Our performance
   evaluation demonstrates that our method achieves up to 48\% speedup on
   PageRank with Scale 16 Log-normal Graph (vertexes=65,536,
   edges=8,364,525) with 4 nodes, 3023\% speedup on Random walk with
   Restart with Kronecker Graph with Scale 18 (vertexes=262,144,
   edges=8,388,608) with 4 nodes against original GIM-V.},
DOI = {10.1145/2567948.2580051},
ISBN = {978-1-4503-2745-9},
Unique-ID = {WOS:000455947000333},
}

@article{ WOS:000599134900001,
Author = {Kolajo, Taiwo and Daramola, Olawande and Adebiyi, Ayodele},
Title = {Big data stream analysis: a systematic literature review},
Journal = {JOURNAL OF BIG DATA},
Year = {2019},
Volume = {6},
Number = {1},
Month = {JUN 6},
Abstract = {Recently, big data streams have become ubiquitous due to the fact that a
   number of applications generate a huge amount of data at a great
   velocity. This made it difficult for existing data mining tools,
   technologies, methods, and techniques to be applied directly on big data
   streams due to the inherent dynamic characteristics of big data. In this
   paper, a systematic review of big data streams analysis which employed a
   rigorous and methodical approach to look at the trends of big data
   stream tools and technologies as well as methods and techniques employed
   in analysing big data streams. It provides a global view of big data
   stream tools and technologies and its comparisons. Three major
   databases, Scopus, ScienceDirect and EBSCO, which indexes journals and
   conferences that are promoted by entities such as IEEE, ACM,
   SpringerLink, and Elsevier were explored as data sources. Out of the
   initial 2295 papers that resulted from the first search string, 47
   papers were found to be relevant to our research questions after
   implementing the inclusion and exclusion criteria. The study found that
   scalability, privacy and load balancing issues as well as empirical
   analysis of big data streams and technologies are still open for further
   research efforts. We also found that although, significant research
   efforts have been directed to real-time analysis of big data stream not
   much attention has been given to the preprocessing stage of big data
   streams. Only a few big data streaming tools and technologies can do all
   of the batch, streaming, and iterative jobs; there seems to be no big
   data tool and technology that offers all the key features required for
   now and standard benchmark dataset for big data streaming analytics has
   not been widely adopted. In conclusion, it was recommended that research
   efforts should be geared towards developing scalable frameworks and
   algorithms that will accommodate data stream computing mode, effective
   resource allocation strategy and parallelization issues to cope with the
   ever-growing size and complexity of data.},
DOI = {10.1186/s40537-019-0210-7},
Article-Number = {47},
EISSN = {2196-1115},
ResearcherID-Numbers = {Daramola, Olawande/AAO-6312-2020
   Adebiyi, Ayodele/ACA-3720-2022
   Kolajo, Taiwo/AAA-4508-2022
   Daramola, Olawande/AAD-1266-2019
   },
ORCID-Numbers = {Daramola, Olawande/0000-0001-6340-078X
   Daramola, Olawande/0000-0001-6340-078X
   Kolajo, Taiwo/0000-0001-6780-2495
   Adebiyi, Ayodele/0000-0002-3114-6315},
Unique-ID = {WOS:000599134900001},
}

@inproceedings{ WOS:000502364100057,
Author = {Yan, Hongbin and Sun, Dawei and Gao, Shang and Zhou, Zhangbing},
Editor = {Romdhani, I and Shu, L and Takahiro, H and Zhou, Z and Gordon, T and Zeng, D},
Title = {Performance Analysis of Storm in a Real-World Big Data Stream Computing
   Environment},
Booktitle = {COLLABORATIVE COMPUTING: NETWORKING, APPLICATIONS AND WORKSHARING,
   COLLABORATECOM 2017},
Series = {Lecture Notes of the Institute for Computer Sciences Social Informatics
   and Telecommunications Engineering},
Year = {2018},
Volume = {252},
Pages = {624-634},
Note = {13th European-Alliance-for-Innovation (EAI) International Conference on
   Collaborative Computing - Networking, Applications and Worksharing
   (CollaborateCom), Edinburgh, SCOTLAND, DEC 11-13, 2017},
Organization = {European Alliance for Innovat},
Abstract = {As an important distributed real-time computation system, Storm has been
   widely used in a number of applications such as online machine learning,
   continuous computation, distributed RPC, and more. Storm is designed to
   process massive data streams in real time. However, there have been few
   studies conducted to evaluate the performance characteristics clusters
   in Storm. In this paper, we analyze the performance of a Storm cluster
   mainly from two aspects, hardware configuration and parallelism setting.
   Key factors that affect the throughput and latency of the Storm cluster
   are identified, and the performance of Storm's fault-tolerant mechanism
   is evaluated, which help users use the computation system more
   efficiently.},
DOI = {10.1007/978-3-030-00916-8\_57},
ISSN = {1867-8211},
EISSN = {1867-822X},
ISBN = {978-3-030-00916-8; 978-3-030-00915-1},
Unique-ID = {WOS:000502364100057},
}

@article{ WOS:000326501400004,
Author = {Tang, Yuzhe and Gedik, Bugra},
Title = {Autopipelining for Data Stream Processing},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2013},
Volume = {24},
Number = {12},
Pages = {2344-2354},
Month = {DEC},
Abstract = {Stream processing applications use online analytics to ingest high-rate
   data sources, process them on-the-fly, and generate live results in a
   timely manner. The data flow graph representation of these applications
   facilitates the specification of stream computing tasks with ease, and
   also lends itself to possible runtime exploitation of parallelization on
   multicore processors. While the data flow graphs naturally contain a
   rich set of parallelization opportunities, exploiting them is
   challenging due to the combinatorial number of possible configurations.
   Furthermore, the best configuration is dynamic in nature; it can differ
   across multiple runs of the application, and even during different
   phases of the same run. In this paper, we propose an autopipelining
   solution that can take advantage of multicore processors to improve
   throughput of streaming applications, in an effective and transparent
   way. The solution is effective in the sense that it provides good
   utilization of resources by dynamically finding and exploiting sources
   of pipeline parallelism in streaming applications. It is transparent in
   the sense that it does not require any hints from the application
   developers. As a part of our solution, we describe a light-weight
   runtime profiling scheme to learn resource usage of operators comprising
   the application, an optimization algorithm to locate best places in the
   data flow graph to explore additional parallelism, and an adaptive
   control scheme to find the right level of parallelism. We have
   implemented our solution in an industrial-strength stream processing
   system. Our experimental evaluation based on microbenchmarks, synthetic
   workloads, as well as real-world applications confirms that our design
   is effective in optimizing the throughput of stream processing
   applications without requiring any changes to the application code.},
DOI = {10.1109/TPDS.2012.333},
ISSN = {1045-9219},
EISSN = {1558-2183},
ResearcherID-Numbers = {Gedik, Buğra/F-7842-2014},
Unique-ID = {WOS:000326501400004},
}

@inproceedings{ WOS:000377348700005,
Author = {Zhao, Yong and Zhang, Ying and Yao, Yiting and Li, Youfu and Liu, Peng},
Book-Author = {Xu, B},
Title = {Cocktail: A Hybrid System Combining Hadoop and Storm},
Booktitle = {2015 IEEE ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION
   CONTROL CONFERENCE (IAEAC)},
Year = {2015},
Pages = {20-25},
Note = {IEEE Advanced Information Technology, Electronic and Automation Control
   Conference (IAEAC), Chongqing, PEOPLES R CHINA, DEC 19-20, 2015},
Organization = {IEEE; IEEE Beijing Sect; Global Union Acad Sci \& Technol; Chongqing
   Global Union Acad Sci \& Technol},
Abstract = {Hadoop and Storm are playing a significant role in Cloud Computing and
   either of them has its own applicable area. Cocktail is a new hybrid
   system that combines Hadoop and Storm into one single system, leveraging
   the functions of two computing frameworks. The design and implementation
   of Cocktail includes a SQL-like query language making the implementation
   of details transparent for users, an intelligent framework selector
   based on cost model to choose appropriate framework automatically, and
   an efficient resource scheduling and task execution framework. Cocktail
   has a wide range of application scenarios from batch processing to
   stream computing, using Storm to process real-time data and Hadoop to
   process large-scale data. We compare the performance, throughput and
   scalability of Cocktail with SummingBird to demonstrate the
   practicability and capability. According to benchmark, for small-scale
   data, the performance of Cocktail is close to Summingbird based on Storm
   and 20\%similar to 40\% faster than Summingbird based on Hadoop. And for
   large-scale data, Cocktail's throughput is 40\% higher than
   Summingbird's throughout based on Storm.},
ISBN = {978-1-4799-1980-2},
ResearcherID-Numbers = {Yao, Yiting/AAA-5765-2021},
Unique-ID = {WOS:000377348700005},
}

@article{ WOS:000297212300011,
Author = {Wang, Feng and Yang, Can-Qun and Du, Yun-Fei and Chen, Juan and Yi,
   Hui-Zhan and Xu, Wei-Xia},
Title = {Optimizing Linpack Benchmark on GPU-Accelerated Petascale Supercomputer},
Journal = {JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY},
Year = {2011},
Volume = {26},
Number = {5},
Pages = {854-865},
Month = {SEP},
Abstract = {In this paper we present the programming of the Unpack benchmark on
   TianHe-1 system, the first petascale supercomputer system of China, and
   the largest GPU-accelerated heterogeneous system ever attempted before.
   A hybrid programming model consisting of MPI, OpenMP and streaming
   computing is described to explore the task parallel, thread parallel and
   data parallel of the Unpack. We explain how we optimized the load
   distribution across the CPUs and GPUs using the two-level adaptive
   method and describe the implementation in details. To overcome the
   low-bandwidth between the CPU and GPU communication, we present a
   software pipelining technique to hide the communication overhead.
   Combined with other traditional optimizations, the Unpack we developed
   achieved 196.7 GFLOPS on a single compute element of TianHe-1. This
   result is 70.1\% of the peak compute capability, 3.3 times faster than
   the result by using the vendor's library. On the full configuration of
   TianHe-1 our optimizations resulted in a Unpack performance of 0.563
   PFLOPS, which made TianHe-1 the 5th fastest supercomputer on the Top500
   list in November, 2009.},
DOI = {10.1007/s11390-011-0184-1},
ISSN = {1000-9000},
EISSN = {1860-4749},
Unique-ID = {WOS:000297212300011},
}

@article{ WOS:000296543000013,
Author = {Bioglio, V. and Gaeta, R. and Grangetto, M. and Sereno, M. and Spoto, S.},
Title = {A game theory framework for ISP streaming traffic management},
Journal = {PERFORMANCE EVALUATION},
Year = {2011},
Volume = {68},
Number = {11, SI},
Pages = {1162-1174},
Month = {NOV},
Abstract = {The overlay/underlay topology mismatch affects the performance of
   existing P2P platforms that can generate large volumes of unnecessary
   inter-ISP network traffic. Although recent works have shown the benefits
   of network awareness P2P solutions, no studies have focused on the
   investigation of the ISP behavior and their cooperative/non-cooperative
   attitudes.
   This paper proposes a game theoretic framework to help the design of
   techniques promoting the ISP cooperation in P2P streaming platforms and
   decreasing unnecessary inter-domain streaming traffic.
   We first analyze some simple scenarios to discuss the existence of Nash
   equilibria, the Pareto optimality, and a fairness criterion to refine
   the equilibrium points. Moreover, we apply ideas from Evolutionary Game
   Theory to design a distributed schemata that the ISPs can use to reach
   ``socially acceptable{''} equilibrium points in a large ISP population.
   Furthermore, we develop a discrete event simulation to evaluate the
   effectiveness of the Evolutionary Game Theory framework. The study
   presented in the paper shows that the proposed strategies can
   effectively stimulate ISP cooperation aiming at the minimization of
   inter-ISP traffic and help to provide reliable P2P streaming service.
   (C) 2011 Elsevier B.V. All rights reserved.},
DOI = {10.1016/j.peva.2011.07.007},
ISSN = {0166-5316},
EISSN = {1872-745X},
ResearcherID-Numbers = {Sereno, Matteo/E-3906-2010
   Grangetto, Marco/D-1222-2010
   Gaeta, Rossano/C-6256-2011},
ORCID-Numbers = {Sereno, Matteo/0000-0002-5339-3456
   Grangetto, Marco/0000-0002-2709-7864
   Gaeta, Rossano/0000-0002-6521-403X},
Unique-ID = {WOS:000296543000013},
}

@article{ WOS:000497520700005,
Author = {Hoffmann, Moritz and Lattuada, Andrea and McSherry, Frank and Kalavri,
   Vasiliki and Liagouris, John and Roscoe, Timothy},
Title = {Megaphone: Latency-conscious state migration for distributed streaming
   dataflows},
Journal = {PROCEEDINGS OF THE VLDB ENDOWMENT},
Year = {2019},
Volume = {12},
Number = {9},
Pages = {1002-1015},
Month = {MAY},
Abstract = {We design and implement Megaphone, a data migration mechanism for
   stateful distributed dataflow engines with latency objectives. When
   compared to existing migration mechanisms, Megaphone has the following
   differentiating characteristics: (i) migrations can be subdivided to a
   configurable granularity to avoid latency spikes, and (ii) migrations
   can be prepared ahead of time to avoid runtime coordination. Megaphone
   is implemented as a library on an unmodified timely dataflow
   implementation, and provides an operator interface compatible with its
   existing APIs. We evaluate Megaphone on established benchmarks with
   varying amounts of state and observe that compared to naive approaches
   Megaphone reduces service latencies during reconfiguration by orders of
   magnitude without significantly increasing steady-state overhead.},
DOI = {10.14778/3329772.3329777},
ISSN = {2150-8097},
ORCID-Numbers = {/0000-0001-8219-4862},
Unique-ID = {WOS:000497520700005},
}

@inproceedings{ WOS:000450160400035,
Author = {van Dongen, Giselle and Steurtewagen, Bram and Van den Poel, Dirk},
Book-Group-Author = {IEEE},
Title = {Latency Measurement of Fine-Grained Operations in Benchmarking
   Distributed Stream Processing Frameworks},
Booktitle = {2018 IEEE INTERNATIONAL CONGRESS ON BIG DATA (IEEE BIGDATA CONGRESS)},
Series = {IEEE International Congress on Big Data},
Year = {2018},
Pages = {247-250},
Note = {IEEE International Congress on Big Data (IEEE BigData) Part of the IEEE
   World Congress on Services, San Francisco, CA, JUL 02-07, 2018},
Organization = {IEEE; IEEE Comp Soc; CCF, TCSC},
Abstract = {This paper describes a benchmark for stream processing frameworks
   allowing accurate latency benchmarking of fine-grained individual stages
   of a processing pipeline. By determining the latency of distinct common
   operations in the processing flow instead of the end-to-end latency, we
   can form guidelines for efficient processing pipeline design.
   Additionally, we address the issue of defining time in distributed
   systems by capturing time on one machine and defining the baseline
   latency. We validate our benchmark for Apache Flink using a processing
   pipeline comprising common stream processing operations. Our results
   show that joins are the most time consuming operation in our processing
   pipeline. The latency incurred by adding a join operation is 4.5 times
   higher than for a parsing operation, and the latency gradually becomes
   more dispersed after adding additional stages.},
DOI = {10.1109/BigDataCongress.2018.00043},
ISSN = {2379-7703},
ISBN = {978-1-5386-7232-7},
ResearcherID-Numbers = {Van den Poel, Dirk/AAN-1891-2021
   },
ORCID-Numbers = {Van den Poel, Dirk/0000-0002-8676-8103
   van Dongen, Giselle/0000-0003-1605-724X
   Steurtewagen, Bram/0000-0002-2206-2371},
Unique-ID = {WOS:000450160400035},
}

@inproceedings{ WOS:000747673800129,
Author = {Silvestre, Pedro F. and Fragkoulis, Marios and Spinellis, Diomidis and
   Katsifodimos, Asterios},
Book-Group-Author = {ASSOC COMP MACHINERY},
Title = {Clonos: Consistent Causal Recovery for Highly-Available Streaming
   Dataflows},
Booktitle = {SIGMOD `21: PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON
   MANAGEMENT OF DATA},
Series = {International Conference on Management of Data},
Year = {2021},
Pages = {1637-1650},
Note = {ACM SIGMOD International Conference on Management of Data (SIGMOD),
   ELECTR NETWORK, JUN 20-25, 2021},
Organization = {ACM SIGMOD; Assoc Comp Machinery},
Abstract = {Stream processing lies in the backbone of modern businesses, being
   employed for mission critical applications such as real-time fraud
   detection, car-trip fare calculations, traffic management, and stock
   trading. Large-scale applications are executed by scale-out stream
   processing systems on thousands of long-lived operators, which are
   subject to failures. Recovering from failures fast and consistently are
   both top priorities, yet they are only partly satisfied by existing
   fault tolerance methods due to the strong assumptions these make. In
   particular, prior solutions fail to address consistency in the presence
   of nondeterminism, such as calls to external services, asynchronous
   timers and processing-time windows.
   This paper describes Clonos, a fault tolerance approach that achieves
   fast, local operator recovery with exactly-once guarantees and high
   availability by instantly switching to passive standby operators. Clonos
   enforces causally consistent recovery, including output deduplication,
   by tracking nondeterminism within the system through causal logging. To
   implement Clonos we re-engineered many of the internal subsystems of a
   state of the art stream processor. We evaluate Clonos' overhead and
   recovery on the Nexmark benchmark against Apache Flink. Clonos achieves
   instant recovery with negligible overhead and, unlike previous work,
   does not make assumptions on the deterministic nature of operators.},
DOI = {10.1145/3448016.3457320},
ISSN = {0730-8078},
ISBN = {978-1-4503-8343-1},
ResearcherID-Numbers = {Spinellis, Diomidis/E-3600-2010},
ORCID-Numbers = {Spinellis, Diomidis/0000-0003-4231-1897},
Unique-ID = {WOS:000747673800129},
}

@article{ WOS:000364043400071,
Author = {Satyanarayan, Arvind and Russell, Ryan and Hoffswell, Jane and Heer,
   Jeffrey},
Title = {Reactive Vega: A Streaming Dataflow Architecture for Declarative
   Interactive Visualization},
Journal = {IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS},
Year = {2016},
Volume = {22},
Number = {1},
Pages = {659-668},
Month = {JAN},
Note = {10th IEEE Conference on Visual Analytics Science and Technology (VAST) /
   IEEE VIS Conference, Chicago, IL, OCT 25-30, 2015},
Organization = {IEEE; IEEE Comp Soc; IEEE Visualizat \& Graph Tech Comm; InfoVis; SciVis},
Abstract = {We present Reactive Vega. a system architecture that provides the first
   robust and comprehensive treatment of declarative visual and interaction
   design for data visualization. Starting from a single declarative
   specification. Reactive Vega constructs a dataflow graph in which input
   data, scene graph elements, and interaction events are all treated as
   first-class streaming data sources. To support expressive interactive
   visualizations that may involve time-varying scalar, relational. or
   hierarchical data, Reactive Vegas dataflow graph can dynamically
   re-write itself at runtime by extending or pruning branches in a
   data-driven fashion. We discuss both compile- and run-time optimizations
   applied within Reactive Vega, and share the results of benchmark studies
   that indicate superior interactive performance to both D3 and the
   original, non-reactive Vega system.},
DOI = {10.1109/TVCG.2015.2467091},
ISSN = {1077-2626},
EISSN = {1941-0506},
ORCID-Numbers = {Hoffswell, Jane/0000-0002-9871-4575},
Unique-ID = {WOS:000364043400071},
}

@incollection{ WOS:000266063000001,
Author = {Kitchen, Christine A. and Guest, Martyn F.},
Editor = {Zelkowitz, MV},
Title = {The UK HPC Integration Market: Commodity-Based Clusters},
Booktitle = {ADVANCES IN COMPUTERS, VOL 75: COMPUTER PERFORMANCE ISSUES},
Series = {Advances in Computers},
Year = {2009},
Volume = {75},
Pages = {1-111},
Abstract = {This chapter considers the ubiquitous position of commodity clusters in
   providing HPC capabilities to the scientific community, and the many
   issues faced by organizations when deciding how best to procure,
   maintain, and maximize the usage of such a resource. With a focus on
   developments within the UK, we provide an overview of the current
   high-performance computing (HPC) landscape from both the customer and
   supplier perspective. Historically HPC provision in the UK has been
   focused on one or two leading-edge national facilities that have helped
   the UK to develop and maintain an internationally competitive position
   in research using HPC. This HPC dynamic has, however, changed
   dramatically in the period 2005-2008 with the major injection of funding
   into University HPC sector through the Science Research Investment Fund
   (SRIF). This sector is now the major provider of HPC resources to the UK
   research base, with the capability of the sector increased 100-fold.
   Our primary focus lies on the role of HPC Integrators in supplying
   resources into this sector, and the challenges faced by the HPC service
   providers themselves in sustaining and growing these activities. The
   host sites through partnership with the selected integrator aim to
   maximize this entire process, from procurement through system
   installation and subsequent lifetime of the service. We ask whether
   those integrators based primarily in the UK have the ability to provide
   the necessary level of expertise required in all phases of the process,
   from procurement to ongoing support of the resource throughout its
   lifecycle.
   We consider how current HPC technology roadmaps might impinge on the
   role of integrators in responding to the undoubted challenges that lie
   ahead. Crucial issues when considering potential integrator involvement
   include both size of the hardware solution, that is, number of cores,
   number of nodes, and the ongoing robustness of open-source software
   solutions that might be deployed on these platforms. Informed by
   developments over the past 24 months associated with the deployment of
   systems funded under SRIF, we provide an in-depth analysis of the
   current status and capability of a number of the leading RPC Integrators
   within the UK. Our primary attention is given to the three major
   companies who now supply the academic community and hence are well known
   to us-Streamline Computing, ClusterVision, and OCF. Seven other
   integrators are also considered, albeit with less rigor. Consideration
   is also given to several of the Tier-1 suppliers of clusters.
   In reviewing the status of commodity-based systems in scientific and
   technical computing, systems representative of those supported by the
   integrators, we consider how an organization might best decide on the
   optimum technology to deploy against its intended workload. We outline
   our cluster performance evaluation work that uses a variety of synthetic
   and application-based floating-point metrics to inform this question.
   Our analysis relies on performance measurements of application
   independent tests (microbenchmarks) and a suite of scientific
   applications that are in active use on many large-scale systems. The
   microbenchmarks we used provide information on the performance
   characteristics of the hardware, specifically memory bandwidth and
   latency, and intercore/interprocessor communication performance. These
   measurements have been extensively used to provide insight into
   application performance, with the scientific applications used being
   taken from existing workloads within the SRIF HPC sector, representing
   various scientific domains and program structures-molecular dynamics,
   computational engineering, and materials simulation to name a few.
   The chapter concludes with a 10-point summary of important
   considerations when procuring HPC clusters, particularly those in the
   mid-to-high-end range.},
DOI = {10.1016/S0065-2458(08)00801-2},
ISSN = {0065-2458},
ISBN = {978-0-12-374810-2},
ResearcherID-Numbers = {novacescu, florica/B-4503-2011},
ORCID-Numbers = {novacescu, florica/0000-0001-5561-4956},
Unique-ID = {WOS:000266063000001},
}

@inproceedings{ WOS:000386327700092,
Author = {Qian, Shilei and Wu, Gang and Huang, Jie and Das, Tathagata},
Book-Group-Author = {IEEE},
Title = {Benchmarking Modern Distributed Streaming Platforms},
Booktitle = {PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY
   (ICIT)},
Year = {2016},
Pages = {592-598},
Note = {IEEE International Conference on Industrial Technology (ICET), Taipei,
   TAIWAN, MAR 14-17, 2016},
Organization = {Inst Elect \& Elect Engineers; IEEE Ind Elect Soc; Natl Taiwan Univ, Int
   Ctr Excellence Intelligent Robot \& Automat Res},
Abstract = {The prevalence of big data technology has generated increasing demands
   in large-scale streaming data processing. However, for certain tasks it
   is still challenging to appropriately select a platform due to the
   diversity of choices and the complexity of configurations. This paper
   focuses on benchmarking some principal streaming platforms. We achieve
   our goals on StreamBench, a streaming benchmark tool based on which we
   introduce proper modifications and extensions. We then accomplish
   performance comparisons among different big data platforms, including
   Apache Spark, Apache Storm and Apache Samza. In terms of performance
   criteria, we consider both computational capability and fault-tolerance
   ability. Finally, we give a summary on some key knobs for performance
   tuning as well as on hardware utilization.},
ISBN = {978-1-4673-8075-1},
Unique-ID = {WOS:000386327700092},
}

@article{ WOS:000668447500006,
Author = {De Stefani, Lorenzo and Terolli, Erisa and Upfal, Eli},
Title = {Tiered Sampling: An Efficient Method for Counting Sparse Motifs in
   Massive Graph Streams},
Journal = {ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA},
Year = {2021},
Volume = {15},
Number = {5},
Month = {JUN},
Abstract = {We introduce TIERED SAMPLING, a novel technique for estimating the count
   of sparse motifs in massive graphs whose edges are observed in a stream.
   Our technique requires only a single pass on the data and uses a memory
   of fixed size M, which can be magnitudes smaller than the number of
   edges.
   Our methods address the challenging task of counting sparse
   motifs-sub-graph patterns-that have a low probability of appearing in a
   sample of M edges in the graph, which is the maximum amount of data
   available to the algorithms in each step. To obtain an unbiased and low
   variance estimate of the count, we partition the available memory into
   tiers (layers) of reservoir samples. While the base layer is a standard
   reservoir sample of edges, other layers are reservoir samples of
   sub-structures of the desired motif. By storing more frequent
   sub-structures of the motif, we increase the probability of detecting an
   occurrence of the sparse motif we are counting, thus decreasing the
   variance and error of the estimate.
   While we focus on the designing and analysis of algorithms for counting
   4-cliques, we present a method which allows generalizing TIERED SAMPLING
   to obtain high-quality estimates for the number of occurrence of any
   sub-graph of interest, while reducing the analysis effort due to
   specific properties of the pattern of interest.
   We present a complete analytical analysis and extensive experimental
   evaluation of our proposed method using both synthetic and real-world
   data. Our results demonstrate the advantage of our method in obtaining
   high-quality approximations for the number of 4 and 5-cliques for large
   graphs using a very limited amount of memory, significantly
   outperforming the single edge sample approach for counting sparse motifs
   in large scale graphs.},
DOI = {10.1145/3441299},
Article-Number = {79},
ISSN = {1556-4681},
EISSN = {1556-472X},
Unique-ID = {WOS:000668447500006},
}

@inproceedings{ WOS:000393284200075,
Author = {Wang, Guyue and Wada, Koichi and Yamagiwa, Shinichi},
Book-Group-Author = {IEEE},
Title = {Performance Evaluation of Parallelizing Algorithm using Spanning Tree
   for Stream-based Computing},
Booktitle = {2016 FOURTH INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING (CANDAR)},
Series = {International Symposium on Computing and Networking},
Year = {2016},
Pages = {497-503},
Note = {4th International Symposium on Computing and Networking (CANDAR),
   Hiroshima, JAPAN, NOV 22-25, 2016},
Organization = {EIC; IPS; IEICE Tech Comm Comp Syst; IPSJ Special Interest Grp Syst
   Architecture},
Abstract = {This paper proposes a detailed performance evaluation of an algorithm
   using spanning tree that automatically exploits the parallelism and
   determines an execution order of multiple kernel programs in distributed
   environment.
   In stream-based computing, efficient parallel execution requires careful
   scheduling of the invocation of the kernel programs. By mapping a kernel
   to a node and an I/O stream between kernels to an edge, the entire
   stream process can be treated as a spanning tree. The spanning tree,
   which allows feedback and feedforward edges, is effective for expressing
   dependencies that exist among kernels. In spanning tree, the nodes at
   the same depth do not have edges between them, and thus can be executed
   in parallel in the case parent nodes have been already executed. The
   series of the nodes can be executed in a pipelined manner. Thus, the
   proposed algorithm can extract both spatial and temporal parallelism.
   To evaluate the effectiveness of the proposed algorithm, two
   applications have been developed and parallelized based on the proposed
   algorithm. The results show that the parallel execution using four nodes
   of a GPU cluster obtained 3.5 times speedup in 2D-FFT and 3.0 times
   speedup in LU decomposition, compared to the sequential execution.},
DOI = {10.1109/CANDAR.2016.62},
ISSN = {2379-1888},
ISBN = {978-1-5090-2655-5},
Unique-ID = {WOS:000393284200075},
}

@inproceedings{ WOS:000695282900002,
Author = {Volnes, Espen and Plagemann, Thomas and Goebel, Vera and Kristiansen,
   Stein},
Editor = {Nambiar, R and Poess, M},
Title = {EXPOSE: Experimental Performance Evaluation of Stream Processing Engines
   Made Easy},
Booktitle = {PERFORMANCE EVALUATION AND BENCHMARKING (TPCTC 2020)},
Series = {Lecture Notes in Computer Science},
Year = {2021},
Volume = {12752},
Pages = {18-34},
Note = {12th TPC Technology Conference on Performance Evaluation and
   Benchmarking (TPCTC), ELECTR NETWORK, AUG 31, 2020},
Organization = {Transact Proc Performance Council},
Abstract = {Experimental performance evaluation of stream processing engines (SPE)
   can be a great challenge. Aiming to make fair comparisons of different
   SPEs raises this bar even higher. One important reason for this
   challenge is the fact that these systems often use concepts that require
   expert knowledge for each SPE. To address this issue, we present Expose,
   a distributed performance evaluation framework for SPEs that enables a
   user through a declarative approach to specify experiments and conduct
   them on multiple SPEs in a fair way and with low effort. Experimenters
   with few technical skills can define and execute distributed experiments
   that can easily be replicated. We demonstrate Expose by defining a set
   of experiments based on the existing NEXMark benchmark and conduct a
   performance evaluation of Flink, Beam with the Flink runner, Siddhi,
   T-Rex, and Esper, on powerful and resource-constrained hardware.},
DOI = {10.1007/978-3-030-84924-5\_2},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-030-84924-5; 978-3-030-84923-8},
Unique-ID = {WOS:000695282900002},
}

@inproceedings{ WOS:000850448600075,
Author = {Katragadda, Satya and Gottumukkala, Raju and Venna, Siva and Lipari,
   Nicholas and Gaikwad, Shailendra and Pusala, Murali and Chen, Jian and
   Borst, Christoph W. and Raghavan, Vijay and Bayoumi, Magdy},
Book-Group-Author = {ASSOC COMP MACHINERY},
Title = {VAStream: A Visual Analytics System for Fast Data Streams},
Booktitle = {PEARC `19: PROCEEDINGS OF THE PRACTICE AND EXPERIENCE IN ADVANCED
   RESEARCH COMPUTING ON RISE OF THE MACHINES (LEARNING)},
Year = {2019},
Note = {Conference on Practice and Experience in Advanced Research Computing on
   Rise of the Machines (learning) (PEARC), Chicago, IL, JUL 28-AUG 01,
   2019},
Organization = {Assoc Comp Machinery; ACM SIGAPP},
Abstract = {Processing high-volume, high-velocity data streams is an important big
   data problem in many sciences, engineering, and technology domains.
   There are many open-source distributed stream processing and cloud
   platforms that offer low-latency stream processing at scale, but the
   visualization and user-interaction components of these systems are
   limited to visualizing the outcome of stream processing results. Visual
   analysis represents a new form of analysis where the user has more
   control and interactive capabilities either to dynamically change the
   visualization, analytics or data management processes. VAStream provides
   an environment for big data stream processing along with interactive
   visualization capabilities. The system environment consists of hardware
   and software modules to optimize streaming data workflow (that includes
   data ingest, pre-processing, analytics, visualization, and collaboration
   components). The system environment is evaluated for two realtime
   streaming applications. The real-time event detection using social media
   streams uses text data arriving from sources such as Twitter to detect
   emerging events of interest. The real-time river sensor network analysis
   project uses unsupervised classification methods to classify sensor
   network streams arriving from the US river network to detect water
   quality problems. We discuss implementation details and provide
   performance comparison results of various individual stream processing
   operations for both stream processing applications.},
DOI = {10.1145/3332186.3332256},
ISBN = {978-1-4503-7227-5},
Unique-ID = {WOS:000850448600075},
}

@inproceedings{ WOS:000717040500027,
Author = {Ma, Kun and Yu, Ziqiang and Ji, Ke and Yang, Bo},
Editor = {Ibrahim, S and Choo, KKR and Yan, Z and Pedrycz, W},
Title = {Sream-Based Live Probabilistic Topic Computing and Matching},
Booktitle = {ALGORITHMS AND ARCHITECTURES FOR PARALLEL PROCESSING, ICA3PP 2017},
Series = {Lecture Notes in Computer Science},
Year = {2017},
Volume = {10393},
Pages = {397-406},
Note = {17th International Conference on Algorithms and Architectures for
   Parallel Processing (ICA3PP), Helsinki, FINLAND, AUG 21-23, 2017},
Abstract = {Public opinion monitoring refers to real-time first story detection
   (FSD) on a particular Internet news event. It play an important part in
   finding news propagation tendency. Current opinion monitoring methods
   are related to text matching. However, it has some limitations such as
   latent and hidden topic discovery and incorrect relevance ranking of
   matching results on large-scale data. In this paper, we propose one
   improved solution to live public opinion monitoring: stream-based live
   probabilistic topic computing and matching. Our method attempts to
   address the disadvantages such as semantic matching and low efficiency
   on timely big data. Topic real-time computing with stream processing
   paradigm and topic matching with query-time document and field boosting
   are proposed to make substantial improvements. Finally, our experimental
   evaluation on topic computing and matching using crawled historical
   Netease news records shows the high effectiveness and efficiency of the
   proposed approach.},
DOI = {10.1007/978-3-319-65482-9\_27},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-65482-9; 978-3-319-65481-2},
Unique-ID = {WOS:000717040500027},
}

@inproceedings{ WOS:000374173700009,
Author = {Nalepa, Filip and Batko, Michal and Zezula, Pavel},
Editor = {Kofron, J and Vojnar, T},
Title = {Performance Analysis of Distributed Stream Processing Applications
   Through Colored Petri Nets},
Booktitle = {MATHEMATICAL AND ENGINEERING METHODS IN COMPUTER SCIENCE, MEMICS 2015},
Series = {Lecture Notes in Computer Science},
Year = {2016},
Volume = {9548},
Pages = {93-106},
Note = {10th International Doctoral Workshop on Mathematical and Engineering
   Methods in Computer Science (MEMICS), Telc, CZECH REPUBLIC, OCT 23-25,
   2015},
Abstract = {Nowadays, a lot of data are produced every second and they need to be
   processed immediately. Processing such unbounded streams of data is
   often run in a distributed environment in order to achieve high
   throughput. The challenge is the ability to predict the
   performance-related characteristics of such applications. Knowledge of
   these properties is essential for decisions about the amount of needed
   computational resources, how the computations should be spread in the
   distributed environment, etc.
   In this paper, we present performance analysis of distributed stream
   processing applications using Colored Petri Nets (CPNs). We extend our
   previously proposed model with processing strategies which are used to
   specify performance effects when multiple tasks are placed on the same
   resource. We also show a detailed conversion of the whole proposed model
   to the CPNs. The conversion is validated through simulations of the CPNs
   which are compared to real streaming applications.},
DOI = {10.1007/978-3-319-29817-7\_9},
ISSN = {0302-9743},
ISBN = {978-3-319-29817-7; 978-3-319-29816-0},
Unique-ID = {WOS:000374173700009},
}

@article{ WOS:000412299700008,
Author = {Shukla, Anshu and Chaturvedi, Shilpa and Simmhan, Yogesh},
Title = {RIoTBench: An IoT benchmark for distributed stream processing systems},
Journal = {CONCURRENCY AND COMPUTATION-PRACTICE \& EXPERIENCE},
Year = {2017},
Volume = {29},
Number = {21},
Month = {NOV 10},
Abstract = {The Internet of Things (IoT) is an emerging technology paradigm where
   millions of sensors and actuators help monitor and manage physical,
   environmental, and human systems in real time. The inherent closed-loop
   responsiveness and decision making of IoT applications make them ideal
   candidates for using low latency and scalable stream processing
   platforms. Distributed stream processing systems (DSPS) hosted in cloud
   data centers are becoming the vital engine for real-time data processing
   and analytics in any IoT software architecture. But the efficacy and
   performance of contemporary DSPS have not been rigorously studied for
   IoT applications and data streams. Here, we propose RIoTBench, a
   real-time IoT benchmark suite, along with performance metrics, to
   evaluate DSPS for streaming IoT applications. The benchmark includes 27
   common IoT tasks classified across various functional categories and
   implemented as modular microbenchmarks. Further, we define four IoT
   application benchmarks composed from these tasks based on common
   patterns of data preprocessing, statistical summarization, and
   predictive analytics that are intrinsic to the closed-loop IoT
   decision-making life cycle. These are coupled with four stream workloads
   sourced from real IoT observations on smart cities and smart health,
   with peak streams rates that range from 500 to 10000messages/second from
   up to 3million sensors. We validate the RIoTBench suite for the popular
   Apache Storm DSPS on the Microsoft Azure public cloud and present
   empirical observations. This suite can be used by DSPS researchers for
   performance analysis and resource scheduling, by IoT practitioners to
   evaluate DSPS platforms, and even reused within IoT solutions.},
DOI = {10.1002/cpe.4257},
Article-Number = {e4257},
ISSN = {1532-0626},
EISSN = {1532-0634},
ORCID-Numbers = {Simmhan, Yogesh/0000-0003-4140-7774},
Unique-ID = {WOS:000412299700008},
}

@inproceedings{ WOS:000271224100012,
Author = {Ma, Anguo and Cai, Jing and Cheng, Yu and Ni, Xiaoqiang and Tang, Yuxing
   and Xing, Zuocheng},
Editor = {Dou, Y and Gruber, R and Joller, JM},
Title = {Performance Optimization Strategies of High Performance Computing on GPU},
Booktitle = {ADVANCED PARALLEL PROCESSING TECHNOLOGIES, PROCEEDINGS},
Series = {Lecture Notes in Computer Science},
Year = {2009},
Volume = {5737},
Pages = {150-164},
Note = {8th International Symposium on Advanced Parallel Processing
   Technologies, Rapperswil, SWITZERLAND, AUG 24-25, 2009},
Abstract = {Recently GPU is widely utilized in scientific computing and engineering
   applications, owing primarily to the evolution of GPU architecture.
   Firstly, we analyze some key performance characters of GPU in detail,
   and the relationships among GPU architecture programming model and
   memory hierarchy. Secondly, we present three performance optimization
   strategies. Prefetching, Streamlining, and Task Division. Adequate
   experiments have been done to abstract the relationships among different
   factors and efficiency. Finally, we map the HPL benchmark to testify our
   strategies and achieve certain speedup.},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-642-03643-9},
Unique-ID = {WOS:000271224100012},
}

@inproceedings{ WOS:000523190300044,
Author = {Mamouras, Konstantinos and Stanford, Caleb and Alur, Rajeev and Ives,
   Zachary G. and Tannen, Val},
Editor = {McKinley, KS and Fisher, K},
Title = {Data-Trace Types for Distributed Stream Processing Systems},
Booktitle = {PROCEEDINGS OF THE 40TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE
   DESIGN AND IMPLEMENTATION (PLDI `19)},
Year = {2019},
Pages = {670-685},
Note = {40th ACM SIGPLAN Conference on Programming Language Design and
   Implementation (PLDI) part of ACM's Federated Computing Research
   Conference (FCRC), Phoenix, AZ, JUN 22-26, 2019},
Organization = {Assoc Comp Machinery; ACM SIGPLAN},
Abstract = {Distributed architectures for efficient processing of streaming data are
   increasingly critical to modern information processing systems. The goal
   of this paper is to develop type-based programming abstractions that
   facilitate correct and efficient deployment of a logical specification
   of the desired computation on such architectures. In the proposed model,
   each communication link has an associated type specifying tagged data
   items along with a dependency relation over tags that captures the
   logical partial ordering constraints over data items. The semantics of a
   (distributed) stream processing system is then a function from input
   data traces to output data traces, where a data trace is an equivalence
   class of sequences of data items induced by the dependency relation.
   This data-trace transduction model generalizes both acyclic synchronous
   data-flow and relational query processors, and can specify computations
   over data streams with a rich variety of partial ordering and
   synchronization characteristics. We then describe a set of programming
   templates for data-trace transductions: abstractions corresponding to
   common stream processing tasks. Our system automatically maps these
   high-level programs to a given topology on the distributed
   implementation platform Apache Storm while preserving the semantics. Our
   experimental evaluation shows that (1) while automatic parallelization
   deployed by existing systems may not preserve semantics, particularly
   when the computation is sensitive to the ordering of data items, our
   programming abstractions allow a natural specification of the query that
   contains a mix of ordering constraints while guaranteeing correct
   deployment, and (2) the throughput of the automatically compiled
   distributed code is comparable to that of hand-crafted distributed
   implementations.},
DOI = {10.1145/3314221.3314580},
ISBN = {978-1-4503-6712-7},
ORCID-Numbers = {Stanford, Caleb/0000-0002-8428-7736},
Unique-ID = {WOS:000523190300044},
}

@inproceedings{ WOS:000418398000007,
Author = {Shukla, Anshu and Simmhan, Yogesh},
Editor = {Nambiar, R and Poess, M},
Title = {Benchmarking Distributed Stream Processing Platforms for IoT
   Applications},
Booktitle = {PERFORMANCE EVALUATION AND BENCHMARKING: TRADITIONAL - BIG DATA -
   INTERNET OF THINGS, TPCTC 2016},
Series = {Lecture Notes in Computer Science},
Year = {2017},
Volume = {10080},
Pages = {90-106},
Note = {8th TPC Technology Conference on Performance Evaluation and Benchmarking
   (TPCTC), New Delhi, INDIA, SEP 05-09, 2016},
Organization = {Transact Proc Performance Council},
Abstract = {Internet of Things (IoT) is a technology paradigm where millions of
   sensors monitor, and help inform or manage, physical, environmental and
   human systems in real-time. The inherent closed-loop responsiveness and
   decision making of IoT applications makes them ideal candidates for
   using low latency and scalable stream processing platforms. Distributed
   Stream Processing Systems (DSPS) are becoming essential components of
   any IoT stack, but the efficacy and performance of contemporary DSPS
   have not been rigorously studied for IoT data streams and applications.
   Here, we develop a benchmark suite and performance metrics to evaluate
   DSPS for streaming IoT applications. The benchmark includes 13 common
   IoT tasks classified across functional categories and forming
   micro-benchmarks, and two IoT applications for statistical summarization
   and predictive analytics that leverage various dataflow patterns of
   DSPS. These are coupled with stream workloads from real IoT observations
   on smart cities. We validate the benchmark for the popular Apache Storm
   DSPS, and present the results.},
DOI = {10.1007/978-3-319-54334-5\_7},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-54334-5; 978-3-319-54333-8},
ORCID-Numbers = {Simmhan, Yogesh/0000-0003-4140-7774},
Unique-ID = {WOS:000418398000007},
}

@inproceedings{ WOS:000851014500005,
Author = {del Rio Astorga, David and Dolz, Manuel F. and Fernandez, Javier and
   Daniel Garcia, J.},
Editor = {Heras, DB and Bouge, L and Mencagli, G and Jeannot, E and Sakellariou, R and Badia, RM and Barbosa, JG and Ricci, L and Scott, SL and Lankes, S and Weidendorfer, J},
Title = {Supporting Advanced Patterns in GRPPI, a Generic Parallel Pattern
   Interface},
Booktitle = {EURO-PAR 2017: PARALLEL PROCESSING WORKSHOPS},
Series = {Lecture Notes in Computer Science},
Year = {2018},
Volume = {10659},
Pages = {55-67},
Note = {23rd International Conference on Parallel and Distributed Computing
   (Euro-Par), Santiago de Compostela, SPAIN, AUG 28-SEP 01, 2017},
Organization = {Univ Santiago Compostela, Centro Investigac Tecnoloxias Informac},
Abstract = {The emergence of generic interfaces, encapsulating algorithmic aspects
   in pattern-based constructions, has greatly alleviated the development
   of data-intensive and stream-processing applications. In this paper, we
   complement the basic patterns supported by GRPPI, a C++ General and
   Reusable Parallel Pattern Interface of the state-of-the-art, with the
   advanced parallel patterns Pool, Windowed-Farm, and Stream-Iterator.
   This collection of advanced patterns is basically oriented to some
   domain-specific applications, ranging from the evolutionary to the
   real-time computing areas, where compositions of basic patterns are not
   capable of fully mimicking algorithmic behavior of their original
   sequential codes. The experimental evaluation of the advanced patterns
   on a set of domain-specific use-cases, using different back-ends (C++
   Threads, OpenMP and Intel TBB) and pattern-specific parameters, reports
   remarkable performance gains. We also demonstrate the benefits of the
   GRPPI pattern interface from the usability and flexibility points of
   view.},
DOI = {10.1007/978-3-319-75178-8\_5},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-75178-8; 978-3-319-75177-1},
ResearcherID-Numbers = {Garcia Sanchez, Jose Daniel/I-3899-2014
   Dolz, Manuel F./ABF-6232-2020},
ORCID-Numbers = {Garcia Sanchez, Jose Daniel/0000-0002-1873-9706
   Dolz, Manuel F./0000-0001-9466-3398},
Unique-ID = {WOS:000851014500005},
}

@article{ WOS:000683972700001,
Author = {Van Dongen, Giselle and van den Poel, Dirk},
Title = {Influencing Factors in the Scalability of Distributed Stream Processing
   Jobs},
Journal = {IEEE ACCESS},
Year = {2021},
Volume = {9},
Pages = {109413-109431},
Abstract = {More and more use cases require fast, accurate, and reliable processing
   of large volumes of data. To do this, a distributed stream processing
   framework is needed which can distribute the load over several machines.
   In this work, we study and benchmark the scalability of stream
   processing jobs in four popular frameworks: Flink, Kafka Streams, Spark
   Streaming, and Structured Streaming. Besides that, we determine the
   factors that influence the performance and efficiency of scaling
   processing jobs with distinct characteristics. We evaluate horizontal,
   as well as vertical scalability. Our results show how the scaling
   efficiency is impacted by many factors including the initial cluster
   layout and direction of scaling, the pipeline design, the framework
   design, resource allocation, and data characteristics. Finally, we give
   some recommendations on how practitioners should undertake to scale
   their clusters.},
DOI = {10.1109/ACCESS.2021.3102645},
ISSN = {2169-3536},
ORCID-Numbers = {van Dongen, Giselle/0000-0003-1605-724X
   Van den Poel, Dirk/0000-0002-8676-8103},
Unique-ID = {WOS:000683972700001},
}

@inproceedings{ WOS:000467843200102,
Author = {Wang, Wen'an and Zhang, Chuang and Chen, Xiaojun and Li, Zhao and Ding,
   Hong and Wen, Xin},
Editor = {Chen, JJ and Yang, LT},
Title = {An On-the-fly Scheduling Strategy for Distributed Stream Processing
   Platform},
Booktitle = {2018 IEEE INT CONF ON PARALLEL \& DISTRIBUTED PROCESSING WITH
   APPLICATIONS, UBIQUITOUS COMPUTING \& COMMUNICATIONS, BIG DATA \& CLOUD
   COMPUTING, SOCIAL COMPUTING \& NETWORKING, SUSTAINABLE COMPUTING \&
   COMMUNICATIONS},
Series = {IEEE International Symposium on Parallel and Distributed Processing with
   Applications},
Year = {2018},
Pages = {773-780},
Note = {16th IEEE ISPA / 17th IEEE IUCC / 8th IEEE BDCloud / 11th IEEE SocialCom
   / 8th IEEE SustainCom, Melbourne, AUSTRALIA, DEC 11-13, 2018},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {Distributed stream processing can accomplish real-time processing of
   continuous streaming big data to obtain valuable information with high
   velocity. To maintain continuously stable and efficient running of
   stream applications, however, continuous online scheduling operations
   are required in the context of highly dynamic data stream. For this
   reason, this paper proposes the on-the-fly scheduling strategy in a
   distributed stream processing environment, which dynamically predicts
   abnormal events through double exponential smoothing and adopts
   trafficaware active migration protocol to adjust the network routing
   structure on-the-fly to balance the inter-worker load. Moreover, an
   evaluation method is proposed to quantitatively analyze the various
   scheduling objectives. Finally, we commendably apply the scheduling
   strategy to a stream processing platform, which regards docker instance
   as basic scheduling units. Meanwhile, based on the platform and the
   evaluation method, we complete performance comparison experiments of the
   scheduling algorithm. The experimental results indicate that our
   algorithm has excellent performance in throughput of topology, average
   processing time and balance of task load, which is suitable for
   deployment in a distributed environment with large-scale nodes and
   tasks.},
DOI = {10.1109/BDCloud.2018.00116},
ISSN = {2158-9178},
ISBN = {978-1-7281-1141-4},
Unique-ID = {WOS:000467843200102},
}

@article{ WOS:000689665100012,
Author = {Henning, Soeren and Hasselbring, Wilhelm},
Title = {Theodolite: Scalability Benchmarking of Distributed Stream Processing
   Engines in Microservice Architectures},
Journal = {BIG DATA RESEARCH},
Year = {2021},
Volume = {25},
Month = {JUL 15},
Abstract = {Distributed stream processing engines are designed with a focus on
   scalability to process big data volumes in a continuous manner. We
   present the Theodolite method for benchmarking the scalability of
   distributed stream processing engines. Core of this method is the
   definition of use cases that microservices implementing stream
   processing have to fulfill. For each use case, our method identifies
   relevant workload dimensions that might affect the scalability of a use
   case. We propose to design one benchmark per use case and relevant
   workload dimension.
   We present a general benchmarking framework, which can be applied to
   execute the individual benchmarks for a given use case and workload
   dimension. Our framework executes an implementation of the use case's
   dataflow architecture for different workloads of the given dimension and
   various numbers of processing instances. This way, it identifies how
   resources demand evolves with increasing workloads. Within the scope of
   this paper, we present 4 identified use cases, derived from processing
   Industrial Internet of Things data, and 7 corresponding workload
   dimensions. We provide implementations of 4 benchmarks with Kafka
   Streams and Apache Flink as well as an implementation of our
   benchmarking framework to execute scalability benchmarks in cloud
   environments. We use both for evaluating the Theodolite method and for
   benchmarking Kafka Streams' and Flink's scalability for different
   deployment options. (C) 2021 Elsevier Inc. All rights reserved.},
DOI = {10.1016/j.bdr.2021.100209},
EarlyAccessDate = {FEB 2021},
Article-Number = {100209},
ISSN = {2214-5796},
ORCID-Numbers = {Henning, Soren/0000-0001-6912-2549},
Unique-ID = {WOS:000689665100012},
}

@article{ WOS:000476763200007,
Author = {Nardelli, Matteo and Cardellini, Valeria and Grassi, Vincenzo and Lo
   Presti, Francesco},
Title = {Efficient Operator Placement for Distributed Data Stream Processing
   Applications},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2019},
Volume = {30},
Number = {8},
Pages = {1753-1767},
Month = {AUG},
Abstract = {In the last few years, a large number of real-time analytics
   applications rely on the Data Stream Processing (DSP) so to extract, in
   a timely manner, valuable information from distributed sources.
   Moreover, to efficiently handle the increasing amount of data, recent
   trends exploit the emerging presence of edge/Fog computing resources so
   to decentralize the execution of DSP applications. Since determining the
   Optimal DSP Placement (for short, ODP) is an NP-hard problem, we need
   efficient heuristics that can identify a good application placement on
   the computing infrastructure in a feasible amount of time, even for
   large problem instances. In this paper, we present several DSP placement
   heuristics that consider the heterogeneity of computing and network
   resources; we divide them in two main groups: model-based and
   model-free. The former employ different strategies for efficiently
   solving the ODP model. The latter implement, for the problem at hand,
   some of the well-known meta-heuristics, namely greedy first-fit, local
   search, and tabu search. By leveraging on ODP, we conduct a thorough
   experimental evaluation, aimed to assess the heuristics' efficiency and
   efficacy under different configurations of infrastructure size,
   application topology, and optimization objectives.},
DOI = {10.1109/TPDS.2019.2896115},
ISSN = {1045-9219},
EISSN = {1558-2183},
ResearcherID-Numbers = {Nardelli, Matteo/K-7215-2016
   Cardellini, Valeria/F-8409-2012
   },
ORCID-Numbers = {Nardelli, Matteo/0000-0002-9519-9387
   Cardellini, Valeria/0000-0002-6870-7083
   LO PRESTI, Francesco/0000-0002-7461-6276},
Unique-ID = {WOS:000476763200007},
}

@article{ WOS:000265248100010,
Author = {Liu, Zhen and Tang, Ao and Xia, Cathy H. and Zhang, Li},
Title = {A decentralized control mechanism for stream processing networks},
Journal = {ANNALS OF OPERATIONS RESEARCH},
Year = {2009},
Volume = {170},
Number = {1, SI},
Pages = {161-182},
Month = {SEP},
Note = {Workshop on Stochastic Performance Models for Resource Allocation in
   Communication Systems (StoPeRA), Amsterdam, NETHERLANDS, NOV 08-10, 2006},
Organization = {EuroNGI},
Abstract = {Data streaming applications are becoming more and more common due to the
   rapid development in emerging areas such as sensor networks, multimedia
   streaming, and on-line data mining, etc. These applications are often
   running in a decentralized, distributed environment. The requirements
   for processing large volumes of streaming data at real time have posed
   many great design challenges. One of the critical issues is to optimize
   the ongoing resource consumption of multiple, distributed, cooperating
   processing units. In this paper, we consider a generic model for the
   general stream data processing systems. We address the resource
   allocation problem for a collection of processing units so as to
   maximize the weighted sum of the throughput of different streams. Each
   processing unit may require multiple input data streams simultaneously
   and produce one or many valuable output streams. We develop
   decentralized control mechanisms that maximize the overall system
   throughput in such data stream processing networks. Performance analysis
   on the optimality and complexity of these mechanisms are also provided.},
DOI = {10.1007/s10479-008-0434-y},
ISSN = {0254-5330},
EISSN = {1572-9338},
ResearcherID-Numbers = {Xia, Cathy H/AAX-4667-2021},
Unique-ID = {WOS:000265248100010},
}

@inproceedings{ WOS:000615960500011,
Author = {Weissbach, Manuel and Hilbert, Hannes and Springer, Thomas},
Editor = {Ferguson, D and Helfert, M and Pahl, C},
Title = {Performance Analysis of Continuous Binary Data Processing using
   Distributed Databases within Stream Processing Environments},
Booktitle = {PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND
   SERVICES SCIENCE (CLOSER)},
Year = {2020},
Pages = {138-149},
Note = {10th International Conference on Cloud Computing and Services Science
   (CLOSER), Prague, CZECH REPUBLIC, MAY 07-09, 2020},
Abstract = {Big data applications must process increasingly large amounts of data
   within ever shorter time. Often a stream processing engine (SPE) is used
   to process incoming data with minimal latency. While these engines are
   designed to process data quickly, they are not made to persist and
   manage it. Thus, databases are still integrated into streaming
   architectures, which often becomes a performance bottleneck. To overcome
   this issue and achieve maximum performance, all system components used
   must be examined in terms of their throughput and latency, and how well
   they interact with each other. Several authors have already analyzed the
   performance of popular distributed database systems. While doing so, we
   focus on the interaction between the SPEs and the databases, as we
   assume that stream processing leads to changes in the access patterns to
   the databases. Moreover, our main focus is on the efficient storing and
   loading of binary data objects rather than typed data, since in our use
   cases the actual data analysis is not to be performed by the database,
   but by the SPE. We've benchmarked common databases within streaming
   environments to determine which software combination is best suited for
   these requirements. Our results show that the database performance
   differs significantly depending on the access pattern used and that
   different software combinations lead to substantial performance
   differences. Depending on the access pattern, Cassandra, MongoDB and
   PostgreSQL achieved the best throughputs, which were mostly the highest
   when Apache Flink was used.},
DOI = {10.5220/0009413301380149},
ISBN = {978-989-758-424-4},
Unique-ID = {WOS:000615960500011},
}

@inproceedings{ WOS:000458816000019,
Author = {Chao, Mengyuan and Yang, Chen and Zeng, Yukun and Stoleru, Radu},
Book-Group-Author = {IEEE},
Title = {F-MStorm: Feedback-based Online Distributed Mobile Stream Processing},
Booktitle = {2018 THIRD IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC)},
Year = {2018},
Pages = {273-285},
Note = {3rd IEEE/ACM Symposium on Edge Computing (SEC), Bellevue, WA, OCT 25-27,
   2018},
Organization = {IEEE; ACM; IEEE Comp Soc; NSF; Microsoft; Akamai;
   EdgeComputingConsortium; Huawei; IBM; AMD; Baidu; DENSO; TOYOTA
   InfoTech; VMWare},
Abstract = {A distributed mobile stream processing system allows mobile devices to
   process stream data that exceeds any single device's computation
   capability without the help of infrastructure. It is paramount to have
   such a system in many critical application scenarios, such as military
   operations and disaster response, yet an efficient online mobile stream
   processing system is still missing. In this paper, we make the key
   observation that the unique characteristics of mobile stream processing
   call for a feedback-based system design, which is in sharp contrast with
   the static configuration and scheduling of the current mobile stream
   processing system, ``MStorm{''} {[}1]. At first, we demonstrate the
   inefficiencies of MStorm through several real-world experiments. Then,
   we propose F-MStorm, a feedback-based online distributed mobile stream
   processing system, which adopts the feedback-based approach in the
   configuration, scheduling and execution levels of system design. We
   implement F-MStorm on Android phones and evaluate its performance
   through benchmark applications. We show that it achieves up to 3x lower
   response time, 10\% higher throughput and consumes 23\% less
   communication energy than the state-of-the-art systems.},
DOI = {10.1109/SEC.2018.00027},
ISBN = {978-1-5386-9445-9},
ResearcherID-Numbers = {Zeng, Yukun/AAA-9908-2020
   Chao, Mengyuan/AAH-1545-2020},
ORCID-Numbers = {Chao, Mengyuan/0000-0002-1516-0280},
Unique-ID = {WOS:000458816000019},
}

@inproceedings{ WOS:000529303200005,
Author = {Nardelli, Matteo and Russo, Gabriele Russo and Cardellini, Valeria and
   Lo Presti, Francesco},
Editor = {Mencagli, G and Heras, DB},
Title = {A Multi-level Elasticity Framework for Distributed Data Stream
   Processing},
Booktitle = {EURO-PAR 2018: PARALLEL PROCESSING WORKSHOPS},
Series = {Lecture Notes in Computer Science},
Year = {2019},
Volume = {11339},
Pages = {53-64},
Note = {International European Conference on Parallel and Distributed Computing
   (Euro-Par), Turin, ITALY, AUG 27-28, 2018},
Abstract = {Data Stream Processing (DSP) applications should be capable to
   efficiently process high-velocity continuous data streams by elastically
   scaling the parallelism degree of their operators so to deal with high
   variability in the workload. Moreover, to efficiently use computing
   resources, modern DSP frameworks should seamlessly support
   infrastructure elasticity, which allows to exploit resources available
   on-demand in geo-distributed Cloud and Fog systems. In this paper we
   propose E2DF, a framework to autonomously control the multi-level
   elasticity of DSP applications and the underlying computing
   infrastructure. E2DF revolves around a hierarchical approach, with two
   control layers that work at different granularity and time scale. At the
   lower level, fully decentralized Operator and Region managers control
   the reconfiguration of distributed DSP operators and resources. At the
   higher level, centralized managers oversee the overall application and
   infrastructure adaptation. We have integrated the proposed solution into
   Apache Storm, relying on a previous extension we developed, and
   conducted an experimental evaluation. It shows that, even with simple
   control policies, E2DF can improve resource utilization without
   application performance degradation.},
DOI = {10.1007/978-3-030-10549-5\_5},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-030-10549-5; 978-3-030-10548-8},
ResearcherID-Numbers = {Cardellini, Valeria/F-8409-2012
   Nardelli, Matteo/K-7215-2016
   },
ORCID-Numbers = {Cardellini, Valeria/0000-0002-6870-7083
   Nardelli, Matteo/0000-0002-9519-9387
   Russo Russo, Gabriele/0000-0001-8233-4570},
Unique-ID = {WOS:000529303200005},
}

@article{ WOS:000284423900011,
Author = {Jang, Byunghyun and Schaa, Dana and Mistry, Perhaad and Kaeli, David},
Title = {Exploiting Memory Access Patterns to Improve Memory Performance in
   Data-Parallel Architectures},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2011},
Volume = {22},
Number = {1},
Pages = {105-118},
Month = {JAN},
Abstract = {The introduction of General-Purpose computation on GPUs (GPGPUs) has
   changed the landscape for the future of parallel computing. At the core
   of this phenomenon are massively multithreaded, data-parallel
   architectures possessing impressive acceleration ratings, offering
   low-cost supercomputing together with attractive power budgets. Even
   given the numerous benefits provided by GPGPUs, there remain a number of
   barriers that delay wider adoption of these architectures. One major
   issue is the heterogeneous and distributed nature of the memory
   subsystem commonly found on data-parallel architectures. Application
   acceleration is highly dependent on being able to utilize the memory
   subsystem effectively so that all execution units remain busy. In this
   paper, we present techniques for enhancing the memory efficiency of
   applications on data-parallel architectures, based on the analysis and
   characterization of memory access patterns in loop bodies; we target
   vectorization via data transformation to benefit vector-based
   architectures (e. g., AMD GPUs) and algorithmic memory selection for
   scalar-based architectures (e. g., NVIDIA GPUs). We demonstrate the
   effectiveness of our proposed methods with kernels from a wide range of
   benchmark suites. For the benchmark kernels studied, we achieve
   consistent and significant performance improvements (up to 11.4 x and
   13.5 x over baseline GPU implementations on each platform, respectively)
   by applying our proposed methodology.},
DOI = {10.1109/TPDS.2010.107},
ISSN = {1045-9219},
EISSN = {1558-2183},
ORCID-Numbers = {Kaeli, David/0000-0002-5692-0151},
Unique-ID = {WOS:000284423900011},
}

@article{ WOS:000432903500009,
Author = {Shukla, Anshu and Simmhan, Yogesh},
Title = {Model-driven scheduling for distributed stream processing systems},
Journal = {JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING},
Year = {2018},
Volume = {117},
Pages = {98-114},
Month = {JUL},
Abstract = {Distributed Stream Processing Systems (DSPS) are ``Fast Data{''}
   platforms that allow streaming applications to be composed and executed
   with low latency on commodity clusters and Clouds. Such applications are
   composed as a Directed Acyclic Graph (DAG) of tasks, with data parallel
   execution using concurrent task threads on distributed resource slots.
   Scheduling such DAGs for DSPS has two parts-allocation of threads and
   resources for a DAG, and mapping threads to resources. Existing
   schedulers often address just one of these, make the assumption that
   performance linearly scales, or use ad hoc empirical tuning at runtime.
   Instead, we propose model-driven techniques for both mapping and
   allocation that rely on low-overhead a priori performance modeling of
   tasks. Our scheduling algorithms are able to offer predictable and low
   resource needs that is suitable for elastic pay-as-you-go Cloud
   resources, support a high input rate through high VM utilization, and
   can be combined with other mapping approaches as well. These are
   validated for micro and application benchmarks, and compared with
   contemporary schedulers, for the Apache Storm DSPS. (C) 2018 Elsevier
   Inc. All rights reserved.},
DOI = {10.1016/j.jpdc.2018.02.003},
ISSN = {0743-7315},
EISSN = {1096-0848},
ORCID-Numbers = {Simmhan, Yogesh/0000-0003-4140-7774},
Unique-ID = {WOS:000432903500009},
}

@inproceedings{ WOS:000454741700097,
Author = {Tri Minh Truong and Harwood, Aaron and Sinnott, Richard O. and Chen,
   Shiping},
Book-Group-Author = {IEEE},
Title = {Performance Analysis of Large-scale Distributed Stream Processing
   Systems on the Cloud},
Booktitle = {PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING
   (CLOUD)},
Year = {2018},
Pages = {754-761},
Note = {11th IEEE International Conference on Cloud Computing (CLOUD) Part of
   the IEEE World Congress on Services, San Francisco, CA, JUL 02-07, 2018},
Organization = {IEEE; IEEE Comp Soc; TCSC},
Abstract = {Real-time data processing is often a necessity as it can provide
   insights that have less value if discovered off-line or after the fact.
   However, large-scale stream processing systems are non-trivial to build
   and deploy. While there are many frameworks that allow users to create
   large-scale distributed systems, there remains many challenges in
   understanding the performance, cost of deployment and considerations and
   impact of potential (partial) outages on real-time systems performance.
   Our work considers the performance of Cloud-based stream processing
   systems in terms of back-pressure and expected utilization. The
   performance of an exemplar stream application is explored using
   different Cloud-based virtual machine resources and where the scale of
   deployment and cost benefits are taken into consideration in relation to
   the overall performance.
   To achieve this, we develop an algorithm based on queueing theory to
   predict the throughput and latency of stream data processing while
   supporting system stability. Our methodology for making fundamental
   measurements is applicable to mainstream stream processing frameworks
   such as Apache Storm and Heron. The method is especially suitable for
   large-scale distributed stream processing where jobs can run for
   extended time periods. We benchmark the performance of the system on the
   national research cloud of Australia (Nectar), and present a performance
   analysis based on estimating the overall effective utilization.},
DOI = {10.1109/CLOUD.2018.00103},
ISBN = {978-1-5386-7235-8},
ResearcherID-Numbers = {Chen, Shiping/B-7492-2011
   Chen, Shiping/Q-8611-2019},
ORCID-Numbers = {Chen, Shiping/0000-0002-4603-0024
   Chen, Shiping/0000-0002-4603-0024},
Unique-ID = {WOS:000454741700097},
}

@inproceedings{ WOS:000289663200041,
Author = {Wu, Chentao and He, Xubin and Wan, Shenggang and Cao, Qiang and Xie,
   Changsheng},
Book-Group-Author = {IEEE},
Title = {Hotspot Prediction and Cache in Distributed Stream-processing Storage
   Systems},
Booktitle = {2009 IEEE 28TH INTERNATIONAL PERFORMANCE COMPUTING AND COMMUNICATIONS
   CONFERENCE (IPCC 2009)},
Series = {IEEE International Performance Computing and Communications Conference
   (IPCCC)},
Year = {2009},
Pages = {331+},
Note = {28th IEEE International Performance Computing and Communications
   Conference, Scottsdale, AZ, DEC 14-16, 2009},
Organization = {IEEE Comp Soc},
Abstract = {Storage performance is critical in today's distributed stream-processing
   systems. One approach to improve the performance is to use hotspot
   attribute in object-based storage systems. This paper discusses hotspot
   classification and identification, and then presents an Object Hotspot
   Prediction Model (OHPM) to dynamically predict hotspots. Based on this
   model, we discuss an efficient hotspot caching strategy to improve the
   performance. To demonstrate the effectiveness of our proposed approach,
   we have developed a prototype of Hotspot Attribute-managed Storage
   System (HASS) by extending Object-based Storage Device (OSD) file system
   and iSCSI protocols. Experimental results show that the HASS improves
   the throughput by up to 62\% and reduces the disk I/O by as much as 25\%
   in our VoD tests by integrating our object hotspot prediction and cache
   approaches.},
DOI = {10.1109/PCCC.2009.5403810},
ISSN = {1097-2641},
ISBN = {978-1-4244-5737-3},
Unique-ID = {WOS:000289663200041},
}

@article{ WOS:000445150900005,
Author = {Laska, Marius and Herle, Stefan and Klamma, Ralf and Blankenbach, Joerg},
Title = {A Scalable Architecture for Real-Time Stream Processing of
   Spatiotemporal IoT Stream Data-Performance Analysis on the Example of
   Map Matching},
Journal = {ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION},
Year = {2018},
Volume = {7},
Number = {7},
Month = {JUL},
Abstract = {Scalable real-time processing of large amounts of data has become a
   research topic of particular importance due to the continuously rising
   amount of data that is generated by devices equipped with sensing
   components. While existing approaches allow for fault-tolerant and
   scalable stream processing, we present a pipeline architecture that
   consists of well-known open source tools to specifically integrate
   spatiotemporal internet of things (IoT) data streams. In a case study,
   we utilize the architecture to tackle the online map matching problem, a
   pre-processing step for trajectory mining algorithms. Given the rising
   amount of vehicle location data that is generated on a daily basis,
   existing map matching algorithms have to be implemented in a distributed
   manner to be executable in a stream processing framework that provides
   scalability. We demonstrate how to implement state-of-the-art map
   matching algorithms in our distributed stream processing pipeline and
   analyze measured latencies.},
DOI = {10.3390/ijgi7070238},
Article-Number = {238},
EISSN = {2220-9964},
ResearcherID-Numbers = {Herlé, Stefan/AAE-4772-2019
   Blankenbach, Joerg/ABA-7798-2021
   Klamma, Ralf/K-5908-2016
   },
ORCID-Numbers = {Herlé, Stefan/0000-0001-7995-8593
   Klamma, Ralf/0000-0002-2296-3401
   Blankenbach, Jorg/0000-0002-5700-8818},
Unique-ID = {WOS:000445150900005},
}

@article{ WOS:000249805400019,
Author = {Feng, Hanhua and Liu, Zhen and Xia, Cathy H. and Zhang, Li},
Title = {Load shedding and distributed resource control of stream processing
   networks},
Journal = {PERFORMANCE EVALUATION},
Year = {2007},
Volume = {64},
Number = {9-12},
Pages = {1102-1120},
Month = {OCT},
Note = {26th International Symposium on Computer Performance, Modeling,
   Measurements, and Evaluation, Cologne, GERMANY, OCT 02-05, 2007},
Abstract = {Recent advances in networking and information technology boost the
   development of new and advanced services offered over communication
   systems that integrate a widely heterogeneous mix of applications and
   computer devices. Without careful traffic control and resource
   management, the implied dramatic increase in the demand for networking
   resources and remote application services may lead to substantial
   degradation of the Quality of Service as experienced by the end users.
   In this paper, we consider the problem of joint admission control and
   dynamic resource allocation in a stream processing network so as to
   optimize the overall system utility. With a primal-dual-based
   optimization approach, we show that the resource allocation problem and
   the admission control problem can be decomposed. We then present a
   distributed algorithm which incorporates a push-and-pull-based admission
   control mechanism, and a pressure-based c mu rule for resource
   allocation. We show that the algorithm guarantees the stability of the
   network and converges to the optimal solution. Various numerical
   experiments are then presented to demonstrate the quality of the
   solution and the speed of convergence. (c) 2007 Published by Elsevier
   B.V.},
DOI = {10.1016/j.peva.2007.06.023},
ISSN = {0166-5316},
EISSN = {1872-745X},
ResearcherID-Numbers = {Xia, Cathy H/AAX-4667-2021},
Unique-ID = {WOS:000249805400019},
}

@inproceedings{ WOS:000667971400154,
Author = {Harwood, Aaron and Read, Maria Rodriguez and Amarasinghe, Gayashan
   Niroshana},
Book-Group-Author = {IEEE Comp Soc},
Title = {Dragon: A Lightweight, High Performance Distributed Stream Processing
   Engine},
Booktitle = {2020 IEEE 40TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS
   (ICDCS)},
Series = {IEEE International Conference on Distributed Computing Systems},
Year = {2020},
Pages = {1344-1351},
Note = {40th IEEE International Conference on Distributed Computing Systems
   (ICDCS), ELECTR NETWORK, NOV 29-DEC 01, 2020},
Organization = {IEEE; IEEE Comp Soc; Nanyang Technol Univ; Natl Univ Singapore; Conflux},
Abstract = {The performance of a distributed stream processing engine is
   traditionally considered in terms of fundamental measurements of latency
   and throughput. Recently, Apache Storm has demonstrated sub-millisecond
   latencies for inter-component tuple transmission, though it does so
   through aggressive throttling that leads to strict throughput
   limitations in order to keep tuple queues near empty. On the other hand,
   Apache Heron has excellent throughput characteristics, especially when
   operating near unstable conditions, but its inter-component latencies
   typically start around 10 milliseconds. Both of these systems require
   roughly 650MB of installation space. We have developed Dragon, loosely
   based on the same API as Storm and Heron, that is both lightweight,
   requiring just 7.5MB of installation space, and competitive in
   performance to Storm and Heron. In this paper we show experiments with
   all three systems using the Word Count benchmark. Dragon achieves
   throughput characteristics near to that of Heron and inter-component
   latencies less than 10ms under high load. In particular, Dragon's
   maximum latency is significantly less that Storm's maximum latency under
   high load. Finally Dragon managed to remain stable at higher effective
   throughput than Heron. We believe Dragon is a good ``allrounder{''}
   solution and is particularly suitable for Edge computing applications,
   given its small installation footprint.},
DOI = {10.1109/ICDCS47774.2020.00177},
ISSN = {1063-6927},
ISBN = {978-1-7281-7002-2},
ORCID-Numbers = {Amarasinghe, Gayashan/0000-0001-8238-413X},
Unique-ID = {WOS:000667971400154},
}

@article{ WOS:000573783500002,
Author = {Vikash and Mishra, Lalita and Varma, Shirshu},
Title = {Performance evaluation of real-time stream processing systems for
   Internet of Things applications},
Journal = {FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE},
Year = {2020},
Volume = {113},
Pages = {207-217},
Month = {DEC},
Abstract = {In the current scenario, IoT is an ideal and novel technology, which
   fulfills the needs of most of the commercial, non-commercial,
   government, and private organizations by its real-time supportive nature
   and characteristics. However, real-time processing itself a very
   critical research topic. But, most of the IoT applications are empowered
   by real-time data processing. Thus, it become a vital part of IoT.
   In this work, we proposed a four-layer infrastructure for IoT along with
   stream processing. Further, we use stream processing techniques along
   with IoT infrastructure for applications and analyze the performance of
   stream processing techniques for IoT applications. Also, we compare and
   find the five most suitable distributed stream processing systems for
   IoT, based on its performance and characteristics. We use two benchmark
   applications to evaluate the performance of distributed stream
   processing systems against response time, throughput, jitter, and
   scalability. Based on that, we suggest the adapted solution for IoT
   applications.
   We evaluate the performance with peak stream rates from 100k to 1M along
   with the various frequencies of benchmark applications. Further, on the
   basis of results, we conclude that Apache NiFi is the most suitable
   solution for IoT applications. (C) 2020 Elsevier B.V. All rights
   reserved.},
DOI = {10.1016/j.future.2020.07.012},
ISSN = {0167-739X},
EISSN = {1872-7115},
ResearcherID-Numbers = {.., vikash/H-5985-2017},
ORCID-Numbers = {.., vikash/0000-0001-6454-9519},
Unique-ID = {WOS:000573783500002},
}

@article{ WOS:000510315300016,
Author = {Kahveci, Basri and Gedik, Bugra},
Title = {Joker: Elastic stream processing with organic adaptation},
Journal = {JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING},
Year = {2020},
Volume = {137},
Pages = {205-223},
Month = {MAR},
Abstract = {This paper addresses the problem of auto-parallelization of streaming
   applications. We propose an online parallelization optimization
   algorithm that adjusts the degree of pipeline and data parallelism in a
   joint manner. We define an operator development API and a flexible
   parallel execution model to form a basis for the optimization algorithm.
   The operator interface unifies the development of different types of
   operators and makes operator properties visible in order to enable safe
   optimizations. The parallel execution model splits a data flow graph
   into regions. A region contains the longest sequence of compatible
   operators that are amenable to data parallelism as a whole and can be
   further parallelized with pipeline parallelism. We also develop a stream
   processing run-time, named Joker, to scale the execution of streaming
   applications in a safe, transparent, dynamic, and automatic manner. This
   ability is called organic adaptation. Joker implements the runtime
   machinery to execute a data flow graph with any parallelization
   configuration and most importantly change this configuration at run-time
   with low cost in the presence of partitioned stateful operators, in a
   way that is transparent to the application developers. Joker
   continuously monitors the run-time performance, and runs the
   optimization algorithm to resolve bottlenecks and scale the application
   by adjusting the degree of pipeline and data parallelism. The
   experimental evaluation based on micro-benchmarks and real-world
   applications showcase that our solution accomplishes elasticity by
   finding an effective parallelization configuration. (C) 2019 Elsevier
   Inc. All rights reserved.},
DOI = {10.1016/j.jpdc.2019.10.012},
ISSN = {0743-7315},
EISSN = {1096-0848},
Unique-ID = {WOS:000510315300016},
}

@inproceedings{ WOS:000380558700039,
Author = {Bellavista, Paolo and Corradi, Antonio and Reale, Andrea and Ticca,
   Nicola},
Book-Group-Author = {IEEE},
Title = {Priority-based Resource Scheduling in Distributed Stream Processing
   Systems for Big Data Applications},
Booktitle = {2014 IEEE/ACM 7TH INTERNATIONAL CONFERENCE ON UTILITY AND CLOUD
   COMPUTING (UCC)},
Series = {International Conference on Utility and Cloud Computing},
Year = {2014},
Pages = {363-370},
Note = {IEEE/ACM 7th International Conference on Utility and Cloud Computing
   (UCC), London, UNITED KINGDOM, DEC 08-11, 2014},
Organization = {IEEE; IEEE Comp Soc; ACM; TCSC IEEE; Sigarch},
Abstract = {Distributed Stream Processing Systems (DSPSs) are attracting increasing
   industrial and academic interest as flexible tools to implement scalable
   and cost-effective on-line analytics applications over Big Data streams.
   Often hosted in private/public cloud deployment environments, DSPSs
   offer datastream processing services that transparently exploit the
   distributed computing resources made available to them at runtime. Given
   the volume of data of interest, possible (hard/soft) real-time
   processing requirements, and the time-variable characteristics of input
   datastreams, it is very important for DSPSs to use smart and innovative
   scheduling techniques that allocate computing resources properly and
   avoid static over-provisioning. In this paper, we originally investigate
   the suitability of exploiting application-level indications about
   differentiated priorities of different stream processing tasks to enable
   application-specific DSPS resource scheduling, e.g., capable of
   re-shaping processing resources in order to dynamically follow input
   data peaks of prioritized tasks, with no static over-provisioning. We
   originally propose a general and simple technique to design and
   implement priority-based resource scheduling in flow-graph-based DSPSs,
   by allowing application developers to augment DSPS graphs with priority
   metadata and by introducing an extensible set of priority schemas to be
   automatically handled by the extended DSPS. In addition, we show the
   effectiveness of our approach via its implementation and integration in
   our Quasit DSPS and through experimental evaluation of this prototype on
   a real-world stream processing application of Big Data vehicular traffic
   analysis.},
ISSN = {2373-6860},
ISBN = {978-1-4799-7881-6},
ResearcherID-Numbers = {Corradi, Antonio/L-7480-2015
   Foschini, Luca/H-6876-2015
   Bellavista, Paolo/H-7256-2014},
ORCID-Numbers = {Corradi, Antonio/0000-0002-5107-1023
   Foschini, Luca/0000-0001-9062-3647
   Bellavista, Paolo/0000-0003-0992-7948},
Unique-ID = {WOS:000380558700039},
}

@article{ WOS:000619394400009,
Author = {Sornalakshmi, K. and Vadivu, G.},
Title = {Dynamic Auto Reconfiguration of Operator Placement in Wireless
   Distributed Stream Processing Systems},
Journal = {WIRELESS PERSONAL COMMUNICATIONS},
Abstract = {The data is generated at significant speed and volume by devices in
   real-time. The data generation and the growth of fog and edge computing
   infrastructure have led to the noteworthy development of the
   corresponding distributed stream processing systems (DSPS). A DSPS
   application has Quality of Service (QoS) restrictions in terms of
   resource cost and time. The physical resources are distributed and
   heterogeneous. The resource-constrained scheduling problem has
   considerable implications on the performance of the system and QoS
   violations. The static deployment of applications in fog or edge
   scenario has to be monitored continuously for runtime issues, and
   actions have to be taken accordingly. In this paper, we propose an
   adaptation capability with reinforcement learning techniques to an
   existing stream processing framework scheduler. This functionality
   enables the scheduler to make decisions on its own when the system model
   or knowledge of the environment is not known upfront. The reinforcement
   learning methods adapt to the system when the system model for different
   states is not available. We consider applications whose workload cannot
   be characterized or predicted. In such applications, predictions of
   input load are not helpful for online scheduling. The Q-Learning based
   online scheduler learns to make dynamic scaling decisions at runtime
   when there is performance degradation. We validated the proposed
   approach with real-time and benchmark applications on a DSPS cluster. We
   obtained an average of 6\% reduction in the response time and a 15\%
   increase in the throughput when the Q Learning module is employed in the
   scheduler.},
DOI = {10.1007/s11277-021-08264-y},
EarlyAccessDate = {FEB 2021},
ISSN = {0929-6212},
EISSN = {1572-834X},
ResearcherID-Numbers = {Krishnan, Sornalakshmi/ADG-8811-2022
   G, Vadivu/ABE-6555-2021
   },
ORCID-Numbers = {, Vadivu/0000-0003-2982-4145},
Unique-ID = {WOS:000619394400009},
}

@inproceedings{ WOS:000851014500011,
Author = {Walulya, Ivan and Nikolakopoulos, Yiannis and Gulisano, Vincenzo and
   Papatriantafilou, Marina and Tsigas, Philippas},
Editor = {Heras, DB and Bouge, L and Mencagli, G and Jeannot, E and Sakellariou, R and Badia, RM and Barbosa, JG and Ricci, L and Scott, SL and Lankes, S and Weidendorfer, J},
Title = {Viper: Communication-Layer Determinism and Scaling in Low-Latency Stream
   Processing},
Booktitle = {EURO-PAR 2017: PARALLEL PROCESSING WORKSHOPS},
Series = {Lecture Notes in Computer Science},
Year = {2018},
Volume = {10659},
Pages = {129-140},
Note = {23rd International Conference on Parallel and Distributed Computing
   (Euro-Par), Santiago de Compostela, SPAIN, AUG 28-SEP 01, 2017},
Organization = {Univ Santiago Compostela, Centro Investigac Tecnoloxias Informac},
Abstract = {Stream Processing Engines (SPEs) process continuous streams of data and
   produce up-to-date results in a real-time fashion, typically through
   one-at-a-time tuple analysis. When looking into the vital SPE processing
   properties required from applications, determinism has a strong position
   besides scalability in throughput and low processing latency. SPEs scale
   in throughput and latency by relying on shared-nothing parallelism,
   deploying multiple copies of each operator to which tuples are
   distributed based on the semantics of the operator. The coordination of
   the asynchronous analysis of parallel operators required to enforce
   determinism is then carried out by additional dedicated sorting
   operators. In this work we shift such costly coordination to the
   communication layer of the SPE. Specifically, we extend earlier work on
   shared-memory implementations of deterministic operators and provide a
   communication module (Viper) which can be integrated in the SPE
   communication layer. Using Apache Storm and the Linear Road benchmark,
   we show the benefits that can be achieved by our approach in terms of
   throughput and energy efficiency of SPEs implementing one-at-a-time
   analysis.},
DOI = {10.1007/978-3-319-75178-8\_11},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-75178-8; 978-3-319-75177-1},
ORCID-Numbers = {Papatriantafilou, Marina/0000-0001-9094-8871
   Tsigas, Philippas/0000-0001-9635-9154
   /0000-0002-2136-9179},
Unique-ID = {WOS:000851014500011},
}

@article{ WOS:000699024100011,
Author = {Wang, Xiaotong and Zhang, Chunxi and Fang, Junhua and Zhang, Rong and
   Qian, Weining and Zhou, Aoying},
Title = {A comprehensive study on fault tolerance in stream processing systems},
Journal = {FRONTIERS OF COMPUTER SCIENCE},
Year = {2022},
Volume = {16},
Number = {2},
Month = {APR},
Abstract = {Stream processing has emerged as a useful technology for applications
   which require continuous and low latency computation on infinite
   streaming data. Since stream processing systems (SPSs) usually require
   distributed deployment on clusters of servers in face of large-scale of
   data, it is especially common to meet with failures of processing nodes
   or communication networks, but should be handled seriously considering
   service quality. A failed system may produce wrong results or become
   unavailable, resulting in a decline in user experience or even
   significant financial loss. Hence, a large amount of fault tolerance
   approaches have been proposed for SPSs. These approaches often have
   their own priorities on specific performance concerns, e.g., runtime
   overhead and recovery efficiency. Nevertheless, there is a lack of a
   systematic overview and classification of the state-of-the-art fault
   tolerance approaches in SPSs, which will become an obstacle for the
   development of SPSs. Therefore, we investigate the existing achievements
   and develop a taxonomy of the fault tolerance in SPSs. Furthermore, we
   propose an evaluation framework tailored for fault tolerance,
   demonstrate the experimental results on two representative open-sourced
   SPSs and exposit the possible disadvantages in current designs. Finally,
   we specify future research directions in this domain.},
DOI = {10.1007/s11704-020-0248-x},
Article-Number = {162603},
ISSN = {2095-2228},
EISSN = {2095-2236},
Unique-ID = {WOS:000699024100011},
}

@inproceedings{ WOS:000629154600013,
Author = {Fernandez Munoz, Javier and Dolz, Manuel F. and del Rio Astorga, David
   and Prieto Cepeda, Javier and Daniel Garcia, J.},
Book-Group-Author = {Assoc Comp Machinery},
Title = {Supporting MPI-distributed stream parallel patterns in GRPPI},
Booktitle = {EUROMPI 2018: PROCEEDINGS OF THE 25TH EUROPEAN MPI USERS' GROUP MEETING},
Year = {2018},
Note = {25th European MPI Users' Group Meeting (EuroMPI), Barcelona, SPAIN, SEP
   23-26, 2018},
Organization = {Intel; hoComputer; ACM SIGHPC},
Abstract = {In the recent years, the large volumes of stream data and the near
   real-time requirements of data streaming applications have exacerbated
   the need for new scalable algorithms and programming interfaces for
   distributed and shared-memory platforms. To contribute in this
   direction, this paper presents a new distributed MPI back end for GrPPI,
   a C++ high-level generic interface of data-intensive and stream
   processing parallel patterns. This back end, as a new execution policy,
   supports the distributed and hybrid (distributed and shared-memory)
   parallel execution of the Pipeline and Farm patterns, where the hybrid
   mode combines the MPI policy with a GrPPI shared-memory one. A detailed
   analysis of the GrPPI MPI execution policy reports considerable benefits
   from the programmability, flexibility and readability points of view.
   The experimental evaluation on a streaming application with different
   distributed and shared-memory scenarios reports considerable performance
   gains with respect to the sequential versions at the expense of
   negligible GrPPI overheads.},
DOI = {10.1145/3236367.3236380},
ISBN = {978-1-4503-6492-8},
ResearcherID-Numbers = {Sánchez, José Daniel García/AAB-6490-2019},
ORCID-Numbers = {Sánchez, José Daniel García/0000-0002-1873-9706},
Unique-ID = {WOS:000629154600013},
}

@inproceedings{ WOS:000450718900028,
Author = {Wang, Yidan and Tari, Zahir and HoseinyFarahabady, M. Reza and Zomaya,
   Albert Y.},
Book-Group-Author = {IEEE},
Title = {Model-based Scheduling for Stream Processing Systems},
Booktitle = {2017 19TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING
   AND COMMUNICATIONS (HPCC) / 2017 15TH IEEE INTERNATIONAL CONFERENCE ON
   SMART CITY (SMARTCITY) / 2017 3RD IEEE INTERNATIONAL CONFERENCE ON DATA
   SCIENCE AND SYSTEMS (DSS)},
Year = {2017},
Pages = {215-222},
Note = {19th IEEE International Conference on High Performance Computing and
   Communications (HPCC) / 15th IEEE International Conference on Smart City
   (SmartCity) / 3rd IEEE International Conference on Data Science and
   Systems (DSS), Bangkok, THAILAND, DEC 18-20, 2017},
Organization = {IEEE; IEEE Comp Soc; IEEE Tech Comm Scalable Comp; Prov Elect Author},
Abstract = {Stream processing is emerging to react to the changing business
   situations of real-time processing. The main aim of this paradigm is to
   deal with the huge volume of data in the format of information flows
   originating from distributed devices. This consequently poses challenges
   to the scheduling problem in cloud data centers regarding the
   time-varying velocity of data ingesting and processing. In response to
   the uncertainties and complexities of streaming data, we propose a
   model-based scheduling scheme for stream processing systems, capturing
   the system behavior and providing an optimal allocation strategy to
   adapt to the changing work conditions. The proposed scheduling policy is
   implemented in Apache Storm, and micro-benchmarks with various shapes
   (e.g line, star, and diamond) were used in the evaluation. A topology
   that tracks trending topics on Twitter is also used, where the input is
   feeding with tweets in realtime. Experimental results show that the
   proposed solution can perform estimations that are well aligned with the
   system performance. The proposed scheduling policy achieves an improved
   performance with regards throughput and latency under varying ingesting
   rates.},
DOI = {10.1109/HPCC-SmartCity-DSS.2017.28},
ISBN = {978-1-5386-2588-0},
ResearcherID-Numbers = {Zomaya, Albert Y./G-9697-2017
   },
ORCID-Numbers = {Zomaya, Albert Y./0000-0002-3090-1059
   Tari, Zahir/0000-0002-1235-9673},
Unique-ID = {WOS:000450718900028},
}

@article{ WOS:000652196300001,
Author = {Sarathchandra, Madushi and Karandana, Chulani and Heenatigala, Winma and
   Dayarathna, Miyuru and Jayasena, Sanath},
Title = {Resource aware scheduler for distributed stream processing in cloud
   native environments},
Journal = {CONCURRENCY AND COMPUTATION-PRACTICE \& EXPERIENCE},
Year = {2021},
Volume = {33},
Number = {20},
Month = {OCT 25},
Abstract = {Recently distributed stream processors are increasingly being deployed
   in cloud computing infrastructures. In this article, we study
   performance characteristics of distributed stream processing
   applications in Google Compute Engine which is based on Kubernetes. We
   identify performance gaps in terms of throughput which appear in such
   environments when using a round robin (RR) scheduling algorithm. As a
   solution, we propose resource aware stream processing scheduler called
   resource aware scheduler for stream processing applications in cloud
   native environments (RaspaCN). We implement RaspaCN's job scheduler
   using two-step process. First, we use machine learning to identify the
   optimal number of worker nodes. Second, we use RR and multiple Knapsack
   algorithms to produce performance optimal stream processing job
   schedules. With three application benchmarks called HTTP Log Processor,
   Nexmark, and Email Processor representing real world stream processing
   scenarios we evaluate the performance benefits obtained via RaspaCN's
   scheduling algorithm. RaspaCN could produce percentage increase of
   average throughput values by at least 37\%, 38\%, and 10\%,
   respectively, for HTTP Log Processor, Nexmark, and Email Processor
   benchmarks for fixed input data rates. Furthermore, we conduct
   experiments with varying input data rates as well and show 7\% improved
   average throughput for HTTP Log Processor. These experiments show the
   effectiveness of our proposed stream processor job scheduler for
   producing improved performance.},
DOI = {10.1002/cpe.6373},
EarlyAccessDate = {MAY 2021},
Article-Number = {e6373},
ISSN = {1532-0626},
EISSN = {1532-0634},
ResearcherID-Numbers = {Jayasena, Sanath/GXV-8641-2022},
Unique-ID = {WOS:000652196300001},
}

@article{ WOS:000429540400002,
Author = {Cardellini, Valeria and Lo Presti, Francesco and Nardelli, Matteo and
   Russo, Gabriele Russo},
Title = {Optimal operator deployment and replication for elastic distributed data
   stream processing},
Journal = {CONCURRENCY AND COMPUTATION-PRACTICE \& EXPERIENCE},
Year = {2018},
Volume = {30},
Number = {9, SI},
Month = {MAY 10},
Abstract = {Processing data in a timely manner, data stream processing (DSP)
   applications are receiving an increasing interest for building new
   pervasive services. Due to the unpredictability of data sources, these
   applications often operate in dynamic environments; therefore, they
   require the ability to elastically scale in response to workload
   variations. In this paper, we deal with a key problem for the effective
   runtime management of a DSP application in geo-distributed environments:
   We investigate the placement and replication decisions while considering
   the application and resource heterogeneity and the migration overhead,
   so to select the optimal adaptation strategy that can minimize migration
   costs while satisfying the application quality of service (QoS)
   requirements. We present elastic DSP replication and placement (EDRP), a
   unified framework for the QoS-aware initial deployment and runtime
   elasticity management of DSP applications. In EDRP, the deployment and
   runtime decisions are driven by the solution of a suitable integer
   linear programming problem, whose objective function captures the
   relative importance between QoS goals and reconfiguration costs. We also
   present the implementation of EDRP and the related mechanisms on Apache
   Storm. We conduct a thorough experimental evaluation, both numerical and
   prototype-based, that shows the benefits achieved by EDRP on the
   application performance.},
DOI = {10.1002/cpe.4334},
Article-Number = {e4334},
ISSN = {1532-0626},
EISSN = {1532-0634},
ResearcherID-Numbers = {Cardellini, Valeria/F-8409-2012
   Nardelli, Matteo/K-7215-2016
   },
ORCID-Numbers = {Cardellini, Valeria/0000-0002-6870-7083
   Nardelli, Matteo/0000-0002-9519-9387
   Russo Russo, Gabriele/0000-0001-8233-4570
   LO PRESTI, Francesco/0000-0002-7461-6276},
Unique-ID = {WOS:000429540400002},
}

@article{ WOS:000603721100001,
Author = {Bordin, Maycon Viana and Griebler, Dalvan and Mencagli, Gabriele and
   Geyer, Claudio F. R. and Fernandes, Luiz Gustavo L.},
Title = {DSPBench: A Suite of Benchmark Applications for Distributed Data Stream
   Processing Systems},
Journal = {IEEE ACCESS},
Year = {2020},
Volume = {8},
Pages = {222900-222917},
Abstract = {Systems enabling the continuous processing of large data streams have
   recently attracted the attention of the scientific community and
   industrial stakeholders. Data Stream Processing Systems (DSPSs) are
   complex and powerful frameworks able to ease the development of
   streaming applications in distributed computing environments like
   clusters and clouds. Several systems of this kind have been released and
   currently maintained as open source projects, like Apache Storm and
   Spark Streaming. Some benchmark applications have often been used by the
   scientific community to test and evaluate new techniques to improve the
   performance and usability of DSPSs. However, the existing benchmark
   suites lack of representative workloads coming from the wide set of
   application domains that can leverage the benefits offered by the stream
   processing paradigm in terms of near real-time performance. The goal of
   this article is to present a new benchmark suite composed of 15
   applications coming from areas like Finance, Telecommunications, Sensor
   Networks, Social Networks and others. This article describes in detail
   the nature of these applications, their full workload characterization
   in terms of selectivity, processing cost, input size and overall memory
   occupation. In addition, it exemplifies the usefulness of our benchmark
   suite to compare real DSPSs by selecting Apache Storm and Spark
   Streaming for this analysis.},
DOI = {10.1109/ACCESS.2020.3043948},
ISSN = {2169-3536},
ResearcherID-Numbers = {Griebler, Dalvan/C-2041-2017
   Fernandes, Luiz Gustavo L./N-1988-2018
   },
ORCID-Numbers = {Griebler, Dalvan/0000-0002-4690-3964
   Fernandes, Luiz Gustavo L./0000-0002-7506-3685
   Mencagli, Gabriele/0000-0002-6263-7723
   Resin Geyer, Claudio Fernando/0000-0002-8602-2336},
Unique-ID = {WOS:000603721100001},
}

@inproceedings{ WOS:000263223000039,
Author = {Repantis, Thomas and Kalogeraki, Vana},
Book-Group-Author = {IEEE},
Title = {Hot-Spot Prediction and Alleviation in Distributed Stream Processing
   Applications},
Booktitle = {2008 IEEE INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS \& NETWORKS
   WITH FTCS \& DCC},
Series = {International Conference on Dependable Systems and Networks},
Year = {2008},
Pages = {346-355},
Note = {IEEE International Conference on Dependable Systems and Networks with
   FTCS and DCC, Anchorage, AK, JUN 24-27, 2008},
Organization = {IEEE},
Abstract = {Many emerging distributed applications require the real-time processing
   of large amounts of data that are being updated continuously.
   Distributed stream processing systems offer a scalable and efficient
   means of in-network processing of such data streams. However the large
   scale and the distributed nature of such systems, as well as the
   fluctuation of their load render it difficult to ensure that distributed
   stream processing applications meet their Quality of Service demands. We
   describe a decentralized framework for proactively predicting and
   alleviating hot-spots in distributed stream processing applications in
   real-time. We base our hot-spot prediction techniques on statistical
   forecasting methods, while for hot-spot alleviation we employ a
   non-disruptive component migration protocol. The experimental evaluation
   of our techniques, implemented in our Synergy distributed stream
   processing middleware over PlanetLab, using a real stream processing
   application operating on real streaming data, demonstrates high
   prediction accuracy and substantial Performance benefits.},
DOI = {10.1109/DSN.2008.4630103},
ISSN = {1530-0889},
ISBN = {978-1-4244-2397-2},
ResearcherID-Numbers = {Kalogeraki, Vana/ABI-1469-2020},
ORCID-Numbers = {Kalogeraki, Vana/0000-0002-6421-9947},
Unique-ID = {WOS:000263223000039},
}

@inproceedings{ WOS:000612200600236,
Author = {Wang, Lening and Zhang, Yutong and Chen, Xiaoyu and Jin, Ran},
Book-Group-Author = {IEEE},
Title = {Online Computation Performance Analysis for Distributed Machine Learning
   Pipelines in Fog Manufacturing},
Booktitle = {2020 IEEE 16TH INTERNATIONAL CONFERENCE ON AUTOMATION SCIENCE AND
   ENGINEERING (CASE)},
Series = {IEEE International Conference on Automation Science and Engineering},
Year = {2020},
Pages = {1628-1633},
Note = {16th IEEE International Conference on Automation Science and Engineering
   (CASE), ELECTR NETWORK, AUG 20-21, 2020},
Organization = {IEEE},
Abstract = {Smart manufacturing enables real-time data streaming from interconnected
   manufacturing processes to improve manufacturing quality, throughput,
   flexibility, and cost reduction via computation services. In these
   computation services, machine learning pipelines integrate various types
   of computation method options to match the contextualized, ondemand
   computation needs for the maximum prediction accuracy or the best model
   structure interpretation. On the other hand, there is a pressing need to
   integrate Fog computing in manufacturing, which will reduce
   communication time latency and dependency on connections, improve
   responsiveness and reliability of the computation services, and maintain
   data privacy. However, there is a knowledge gap in using machine
   learning pipelines in Fog manufacturing. Existing offloading strategies
   are not effective, due to the lack of accurate prediction model for the
   performance of computation services before the execution of those
   heterogeneous computation tasks. In this paper, machine learning
   pipelines are implemented in Fog manufacturing. The computation
   performance of each sub-step of pipelines is predicted and analyzed via
   linear regression models and random forest regression models. A Fog
   manufacturing testbed is adopted to validate the performance of the
   employed models. The results show that the models can adequately predict
   the performance of computation services, which can be further integrated
   into Fog manufacturing to better support offloading strategies for
   machine learning pipelines.},
ISSN = {2161-8070},
ISBN = {978-1-7281-6904-0},
Unique-ID = {WOS:000612200600236},
}

@article{ WOS:000744172000004,
Author = {Farrokh, Mohammadreza and Hadian, Hamid and Sharifi, Mohsen and Jafari,
   Ali},
Title = {SP-ant: An ant colony optimization based operator scheduler for high
   performance distributed stream processing on heterogeneous clusters},
Journal = {EXPERT SYSTEMS WITH APPLICATIONS},
Year = {2022},
Volume = {191},
Month = {APR 1},
Abstract = {A key feature of distributed stream processing (DSP) systems is the
   scheduling of operators on clustered computers. In scheduling, the
   assignment plan of operators to nodes of the cluster, requirements of
   operators, and the computational power of each worker node must be
   considered with the goal of finding a tradeoff between the communication
   latency of operators and the utilization of worker nodes to minimize the
   overall system response time. To reach this goal is quite challenging,
   especially in heterogeneous clusters, because there are no accurate
   estimations about the loads of worker nodes at run time. To address this
   challenge, we propose a novel stream processing scheduling using ant
   colony algorithm (SP-Ant). SP-Ant finds the best operator assignment
   plan considering the inter-node communication latencies of operators by
   initially collocating highly communicative operators on the same worker
   nodes using the bin-packing algorithm and iteratively (re-)scheduling
   only the less communicative operators using the exploration and
   exploitation phases of the evolutionary ant colony optimization (ACO)
   algorithm in order to reduce its convergence time. SP-Ant is implemented
   on the standard Apache Storm. Using several standard benchmark
   topologies of Storm, it is shown that SP-Ant outperforms the R-Storm and
   Storm default schedulers by at least 50\% in reducing the response time.},
DOI = {10.1016/j.eswa.2021.116322},
EarlyAccessDate = {DEC 2021},
Article-Number = {116322},
ISSN = {0957-4174},
EISSN = {1873-6793},
ResearcherID-Numbers = {Sharifi, Mohsen/S-9531-2018
   Hadian, Hamid/GMX-0483-2022},
ORCID-Numbers = {Sharifi, Mohsen/0000-0003-4992-2500
   },
Unique-ID = {WOS:000744172000004},
}

@inproceedings{ WOS:000401963300050,
Author = {Lopez, Martin Andreoni and Lobato, Antonio Gonzalez Pastana and Duarte,
   Otto Carlos M. B.},
Book-Group-Author = {IEEE},
Title = {A Performance comparison Open-Source Stream Processing Platforms},
Booktitle = {2016 IEEE GLOBAL COMMUNICATIONS CONFERENCE (GLOBECOM)},
Series = {IEEE Global Communications Conference},
Year = {2016},
Note = {59th Annual IEEE Global Communications Conference (IEEE GLOBECOM),
   Washington, DC, DEC 04-08, 2016},
Organization = {IEEE; Natl Instruments; AT \& T; Huawei; Intel; Qualcomm; Nokia;
   Samsung; Keysight Technologies; Rohde \& Schwarz},
Abstract = {Distributed stream processing platforms are a new class of real-time
   monitoring systems that analyze and extract knowledge from large
   continuous streams of data. These type of systems are crucial for
   providing high throughput and low latency required by Big Data or
   Internet of Things monitoring applications. This paper describes and
   analyzes three main open-source distributed stream-processing platforms:
   Storm, Flink, and Spark Streaming. We analyze the system architectures
   and we compare their main features. We carry out two experiments
   concerning threats detection on network traffic to evaluate the
   throughput efficiency and the resilience to node failures. Results show
   that the performance of native stream processing systems, Storm and
   Flink, is up to 15 times higher than the micro-batch processing system,
   Spark Streaming. However, Spark Streaming is robust to node failures and
   provides recovery without losses.},
ISSN = {2334-0983},
ISBN = {978-1-5090-1328-9},
ResearcherID-Numbers = {Duarte, Otto Carlos M B/C-5828-2013},
ORCID-Numbers = {Duarte, Otto Carlos M B/0000-0002-6642-4100},
Unique-ID = {WOS:000401963300050},
}

@article{ WOS:000444360400028,
Author = {Walulya, Ivan and Palyvos-Giannas, Dimitris and Nikolakopoulos, Yiannis
   and Gulisano, Vincenzo and Papatriantafilou, Marina and Tsigas,
   Philippas},
Title = {Viper: A module for communication-layer determinism and scaling in
   low-latency stream processing},
Journal = {FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE},
Year = {2018},
Volume = {88},
Pages = {297-308},
Month = {NOV},
Abstract = {Stream Processing Engines (SPEs) process continuous streams of data and
   produce results in a real-time fashion, typically through one-at-a-time
   tuple analysis. In Fog architectures, the limited resources of the edge
   devices, enabling close-to-the-source scalable analysis, demand for
   computationally- and energy-efficient SPEs. When looking into the vital
   SPE processing properties required from applications, determinism, which
   ensures consistent results independently of the way the analysis is
   parallelized, has a strong position besides scalability in throughput
   and low processing latency. SPEs scale in throughput and latency by
   relying on shared-nothing parallelism, deploying multiple copies of each
   operator to which tuples are distributed based on its semantics. The
   coordination of the asynchronous analysis of parallel operators required
   to enforce determinism is then carried out by additional dedicated
   sorting operators. To prevent this costly coordination from becoming a
   bottleneck, we introduce the Viper communication module, which can be
   integrated in the SPE communication layer and boost the coordination of
   the parallel threads analyzing the data. Using Apache Storm and data
   extracted from the Linear Road benchmark and a real-world smart grid
   system, we show benefits in the throughput, latency and energy
   efficiency coming from the utilization of the Viper module. (C) 2018
   Elsevier B.V. All rights reserved.},
DOI = {10.1016/j.future.2018.05.067},
ISSN = {0167-739X},
EISSN = {1872-7115},
ResearcherID-Numbers = {Gulisano, Vincenzo/AAV-3888-2020
   },
ORCID-Numbers = {/0000-0002-2136-9179},
Unique-ID = {WOS:000444360400028},
}

@article{ WOS:000470941700003,
Author = {Lopez-Gomez, Javier and Fernandez Munoz, Javier and del Rio Astorga,
   David and Dolz, Manuel F. and Daniel Garcia, J.},
Title = {Exploring stream parallel patterns in distributed MPI environments},
Journal = {PARALLEL COMPUTING},
Year = {2019},
Volume = {84},
Pages = {24-36},
Month = {MAY},
Abstract = {In recent years, the large volumes of stream data and the near real-time
   requirements of data streaming applications have exacerbated the need
   for new scalable algorithms and programming interfaces for distributed
   and shared-memory platforms. To contribute in this direction, this paper
   presents a new distributed MPI back end for GRPPI, a C++ high-level
   generic interface of data-intensive and stream processing parallel
   patterns. This back end, as a new execution policy, supports distributed
   and hybrid (distributed+shared-memory) parallel executions of the
   Pipeline and Farm patterns, where the hybrid mode combines the MPI
   policy with a GRPPI shared-memory one. These patterns internally
   leverage distributed queues, which can be configured to use two-sided or
   one-sided MPI primitives to communicate items among nodes. A detailed
   analysis of the GOP! MPI execution policy reports considerable benefits
   from the programmability, flexibility and readability points of view.
   The experimental evaluation of two different streaming applications with
   different distributed and shared-memory scenarios reports considerable
   performance gains with respect to the sequential versions at the expense
   of negligible GRPPI overheads. (C) 2019 Elsevier B.V. All rights
   reserved.},
DOI = {10.1016/j.parco.2019.03.004},
ISSN = {0167-8191},
EISSN = {1872-7336},
ResearcherID-Numbers = {Dolz, Manuel F./ABF-6232-2020
   Sánchez, José Daniel García/AAB-6490-2019
   Sánchez, José Daniel García/I-3899-2014},
ORCID-Numbers = {Dolz, Manuel F./0000-0001-9466-3398
   Sánchez, José Daniel García/0000-0002-1873-9706
   Sánchez, José Daniel García/0000-0002-1873-9706},
Unique-ID = {WOS:000470941700003},
}

@article{ WOS:000522921000003,
Author = {van Dongen, Giselle and Van den Poel, Dirk},
Title = {Evaluation of Stream Processing Frameworks},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2020},
Volume = {31},
Number = {8},
Pages = {1845-1858},
Month = {AUG 1},
Abstract = {The increasing need for real-time insights in data sparked the
   development of multiple stream processing frameworks. Several
   benchmarking studies were conducted in an effort to form guidelines for
   identifying the most appropriate framework for a use case. In this
   article, we extend this research and present the results gathered. In
   addition to Spark Streaming and Flink, we also include the emerging
   frameworks Structured Streaming and Kafka Streams. We define four
   workloads with custom parameter tuning. Each of these is optimized for a
   certain metric or for measuring performance under specific scenarios
   such as bursty workloads. We analyze the relationship between latency,
   throughput, and resource consumption and we measure the performance
   impact of adding different common operations to the pipeline. To ensure
   correct latency measurements, we use a single Kafka broker. Our results
   show that the latency disadvantages of using a micro-batch system are
   most apparent for stateless operations. With more complex pipelines,
   customized implementations can give event-driven frameworks a large
   latency advantage. Due to its micro-batch architecture, Structured
   Streaming can handle very high throughput at the cost of high latency.
   Under tight latency SLAs, Flink sustains the highest throughput.
   Additionally, Flink shows the least performance degradation when
   confronted with periodic bursts of data. When a burst of data needs to
   be processed right after startup, however, micro-batch systems catch up
   faster while event-driven systems output the first events sooner.},
DOI = {10.1109/TPDS.2020.2978480},
ISSN = {1045-9219},
EISSN = {1558-2183},
ResearcherID-Numbers = {Van den Poel, Dirk/AAN-1891-2021
   },
ORCID-Numbers = {Van den Poel, Dirk/0000-0002-8676-8103
   van Dongen, Giselle/0000-0003-1605-724X},
Unique-ID = {WOS:000522921000003},
}

@article{ WOS:000547567000001,
Author = {Tantalaki, Nicoleta and Souravlas, Stavros and Roumeliotis, Manos and
   Katsavounis, Stefanos},
Title = {Pipeline-Based Linear Scheduling of Big Data Streams in the Cloud},
Journal = {IEEE ACCESS},
Year = {2020},
Volume = {8},
Pages = {117182-117202},
Abstract = {Nowadays, there is an accelerating need to efficiently and timely handle
   large amounts of data that arrives continuously. Streams of big data led
   to the emergence of several Distributed Stream Processing Systems (DSPS)
   that assign processing tasks to the available resources (dynamically or
   not) and route streaming data between them. Efficient scheduling of
   processing tasks can reduce application latencies and eliminate network
   congestions. However, the available DSPSs' in-built scheduling
   techniques are far from optimal. In this work, we extend our previous
   work, where we proposed a linear scheme for the task allocation and
   scheduling problem. Our scheme takes advantage of pipelines to handle
   efficiently applications, where there is need for heavy communication
   (all-to-all) between tasks assigned to pairs of components. In this
   work, we prove that our scheme is periodic, we provide a communication
   refinement algorithm and a mechanism to handle many-to-one assignments
   efficiently. For concreteness, our work is illustrated based on Apache
   Storm semantics. The performance evaluation depicts that our algorithm
   achieves load balance and constraints the required buffer space. For
   throughput testing, we compared our work to the default Storm scheduler,
   as well as to R-Storm. Our scheme was found to outperform both the other
   strategies and achieved an average of 25\%-40\% improvement compared to
   Storm's default scheduler under different scenarios, mainly as a result
   of reduced buffering (approximate to 45\% less memory). Compared to
   R-storm, the results indicate an average of 35\%-45\% improvement.},
DOI = {10.1109/ACCESS.2020.3004612},
ISSN = {2169-3536},
ResearcherID-Numbers = {Katsavounis, Stefanos/R-8204-2019
   },
ORCID-Numbers = {Katsavounis, Stefanos/0000-0001-8988-2457},
Unique-ID = {WOS:000547567000001},
}

@inproceedings{ WOS:000432067200002,
Author = {Zacheilas, Nikos and Kalogeraki, Vana},
Editor = {Chen, LY and Reiser, HP},
Title = {DIsCO: DynamIc Data COmpression in Distributed Stream Processing Systems},
Booktitle = {DISTRIBUTED APPLICATIONS AND INTEROPERABLE SYSTEMS, DAIS 2017},
Series = {Lecture Notes in Computer Science},
Year = {2017},
Volume = {10320},
Pages = {19-33},
Note = {17th IFIP WG 6.1 International Conference on Distributed Applications
   and Interoperable Systems (DAIS) Held as Part of the 12th International
   Federated Conference on Distributed Computing Techniques (DisCoTec),
   Neuchatel, SWITZERLAND, JUN 19-22, 2017},
Organization = {Int Federat Informat Proc WG 6 1; Univ Neuchatel, Inst Comp Sci},
Abstract = {Supporting high throughput in Distributed Stream Processing Systems
   (DSPSs) has been an important goal in recent years. Current works either
   focus on automatically increasing the system resources whenever the
   current setup is inadequate or apply load shedding techniques discarding
   some of the incoming data. However, both approaches have significant
   shortcomings as they require on the fly application reconfiguration
   where the application needs to be stopped and re-uploaded in the cluster
   with the new configurations, and can lead to significant information
   loss. One approach that has not yet been considered for improving the
   throughput of DSPSs is exploiting compression algorithms to minimize the
   communication overhead between components especially in cases where we
   have large-sized data like live CCTV camera reports. This work is the
   first that provides a novel framework, built on top of Apache Storm,
   which enables dynamic compression of incoming streaming data. Our
   approach uses a profiling algorithm to automatically determine the
   compression algorithm that should be applied and supports both lossless
   and lossy compression techniques. Furthermore, we propose a novel
   algorithm for determining when profiling should be applied. Finally, our
   detailed experimental evaluation with commonly used stream processing
   applications, indicates a clear improvement on the applications'
   throughput when our proposed techniques are applied.},
DOI = {10.1007/978-3-319-59665-5\_2},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-59665-5; 978-3-319-59664-8},
ResearcherID-Numbers = {Kalogeraki, Vana/ABI-1469-2020},
ORCID-Numbers = {Kalogeraki, Vana/0000-0002-6421-9947},
Unique-ID = {WOS:000432067200002},
}

@inproceedings{ WOS:000241591300010,
Author = {Tang, Ao and Liu, Zhen and Xia, Cathy and Zhang, Li},
Editor = {Gerndt, M and Kranzlmuller, D},
Title = {Distributed resource allocation for stream data processing},
Booktitle = {HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, PROCEEDINGS},
Series = {Lecture Notes in Computer Science},
Year = {2006},
Volume = {4208},
Pages = {91-100},
Note = {2nd International Conference on High Performance Computing and
   Communications (HPCC 2006), Munich, GERMANY, SEP 13-15, 2006},
Organization = {HP; Intel; Megware; ParTec; Transtec},
Abstract = {Data streaming applications are becoming more and more common due to the
   rapid development in the areas such as sensor networks, multimedia
   streaming, and on-line data mining, etc. These applications are often
   running in a decentralized, distributed environment. The requirements
   for processing large volumes of streaming data at real time have posed
   many great design challenges. It is critical to optimize the ongoing
   resource consumption of multiple, distributed, cooperating, processing
   units. In this paper, we consider a generic model for the general stream
   data processing systems. We address the resource allocation problem for
   a collection of processing units so as to maximize the weighted sum of
   the throughput of different streams. Each processing unit may require
   multiple input data streams simultaneously and produce one or many
   valuable output streams. Data streams flow through such a system after
   processing at multiple processing units. Based on this framework, we
   develop distributed algorithms for finding the best resource allocation
   schemes in such data stream processing networks. Performance analysis on
   the optimality and complexity of these algorithms are also provided.},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {3-540-39368-4},
ResearcherID-Numbers = {Xia, Cathy H/AAX-4667-2021},
Unique-ID = {WOS:000241591300010},
}

@article{ WOS:000674058200001,
Author = {van Dongen, Giselle and Van den Poel, Dirk},
Title = {A Performance Analysis of Fault Recovery in Stream Processing Frameworks},
Journal = {IEEE ACCESS},
Year = {2021},
Volume = {9},
Pages = {93745-93763},
Abstract = {Distributed stream processing frameworks have gained widespread adoption
   in the last decade because they abstract away the complexity of parallel
   processing. One of their key features is built-in fault tolerance. In
   this work, we dive deeper into the implementation, performance, and
   efficiency of this critical feature for four state-of-the-art
   frameworks. We include the established Spark Streaming and Flink
   frameworks and the more novel Spark Structured Streaming and Kafka
   Streams frameworks. We test the behavior under different types of faults
   and settings: master failure with and without high-availability setups,
   driver failures for Spark frameworks, worker failure with or without
   exactly-once semantics, application and task failures. We highlight
   differences in behavior during these failures on several aspects, e.g.,
   whether there is an outage, downtime, recovery time, data loss,
   duplicate processing, accuracy, and the cost and behavior of different
   message delivery guarantees. Our results highlight the impact of
   framework design on the speed of fault recovery and explain how
   different use cases may benefit from different approaches. Due to their
   task-based scheduling approach, the Spark frameworks can recover within
   30 seconds and in most cases without necessitating an application
   restart. Kafka Streams has only a few seconds of downtime, but is slower
   at catching up on delays. Finally, Flink can offer end-to-end
   exactly-once semantics at a low cost but requires job restarts for most
   failures leading to high recovery times of around 50 seconds.},
DOI = {10.1109/ACCESS.2021.3093208},
ISSN = {2169-3536},
ORCID-Numbers = {Van den Poel, Dirk/0000-0002-8676-8103
   van Dongen, Giselle/0000-0003-1605-724X},
Unique-ID = {WOS:000674058200001},
}

@article{ WOS:000720503200003,
Author = {Xu, Jinlai and Palanisamy, Balaji and Wang, Qingyang and Ludwig, Heiko
   and Gopisetty, Sandeep},
Title = {Amnis: Optimized stream processing for edge computing},
Journal = {JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING},
Year = {2022},
Volume = {160},
Pages = {49-64},
Month = {FEB},
Abstract = {The proliferation of Internet-of-Things (IoT) devices is rapidly
   increasing the demands for efficient processing of low latency stream
   data generated close to the edge of the network. Edge computing-based
   stream processing techniques that carefully consider the heterogeneity
   of the computational and network resources available in the
   infrastructure provide significant benefits in optimizing the throughput
   and end-to-end latency of the data streams. In this paper, we propose a
   novel stream query processing framework called Amnis that optimizes the
   performance of the stream processing applications through a careful
   allocation of computational and network resources available at the edge.
   The Amnis approach differentiates itself through its consideration of
   data locality and resource constraints during physical plan generation
   and operator placement for the stream queries. Additionally, Amnis
   considers the coflow dependencies to optimize the network resource
   allocation through an application-level rate control mechanism. We
   implement a prototype of Amnis in Apache Storm. Our performance
   evaluation carried out in a real testbed shows that the proposed
   techniques achieve as much as 200X improvement on the end-to-end latency
   and 10X improvement on the overall throughput compared to the default
   resource aware scheduler in Storm. Keywords: Stream processing Edge
   computing Data locality Operator placement Coflow (C) 2021 Elsevier Inc.
   All rights reserved.},
DOI = {10.1016/j.jpdc.2021.10.001},
EarlyAccessDate = {NOV 2021},
ISSN = {0743-7315},
EISSN = {1096-0848},
Unique-ID = {WOS:000720503200003},
}

@article{ WOS:000409457000007,
Author = {Dayarathna, Miyuru and Li, Yuanlong and Wen, Yonggang and Fan, Rui},
Title = {Energy consumption analysis of data stream processing: a benchmarking
   approach},
Journal = {SOFTWARE-PRACTICE \& EXPERIENCE},
Year = {2017},
Volume = {47},
Number = {10},
Pages = {1443-1462},
Month = {OCT},
Abstract = {Energy efficiency of data analysis systems has become a very important
   issue in recent times because of the increasing costs of data center
   operations. Although distributed streaming workloads have increasingly
   been present in modern data centers, energy-efficient scheduling of such
   applications remains as a significant challenge. In this paper, we
   conduct an energy consumption analysis of data stream processing systems
   in order to identify their energy consumption patterns. We follow stream
   system benchmarking approach to solve this issue. Specifically, we
   implement Linear Road benchmark on six stream processing environments
   (S4, Storm, ActiveMQ, Esper, Kafka, and Spark Streaming) and
   characterize these systems' performance on a real-world data center. We
   study the energy consumption characteristics of each system with varying
   number of roads as well as with different types of component layouts. We
   also use a microbenchmark to capture raw energy consumption
   characteristics. We observed that S4, Esper, and Spark Streaming
   environments had highest average energy consumption efficiencies
   compared with the other systems. Using a neural networkbased technique
   with the power/performance information gathered from our experiments, we
   developed a model for the power consumption behavior of a streaming
   environment. We observed that energy-efficient execution of streaming
   application cannot be specifically attributed to the system CPU usage.
   We observed that communication between compute nodes with moderate tuple
   sizes and scheduling plans with balanced system overhead produces better
   power consumption behaviors in the context of data stream processing
   systems. Copyright (c) 2016 John Wiley \& Sons, Ltd.},
DOI = {10.1002/spe.2458},
ISSN = {0038-0644},
EISSN = {1097-024X},
ResearcherID-Numbers = {Wen, Yonggang/P-9406-2017
   Wen, Yonggang/B-8848-2011},
ORCID-Numbers = {Wen, Yonggang/0000-0002-2751-5114
   },
Unique-ID = {WOS:000409457000007},
}

@inproceedings{ WOS:000760304200014,
Author = {Kang, Peng and Lama, Palden and Khan, Samee U.},
Book-Group-Author = {IEEE Comp Soc},
Title = {SLO-aware Virtual Rebalancing for Edge Stream Processing},
Booktitle = {2021 IEEE INTERNATIONAL CONFERENCE ON CLOUD ENGINEERING, IC2E 2021},
Series = {International Conference on Cloud Engineering},
Year = {2021},
Pages = {126-135},
Note = {9th IEEE International Conference on Cloud Engineering (IC2E), San
   Francisco, CA, OCT 04-08, 2021},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {The Internet of Things (IoT) has enabled an abundance of geographically
   distributed physical devices or ``things{''} equipped with sensors and
   actuators to exchange information with the Cloud. However, this paradigm
   remains largely under-exploited for real-time analytic applications. The
   benefit of realtime data acquisition at the Edge becomes fruitless as it
   is not readily accessible to more powerful data analytic tools in the
   Cloud due to wide-area network delays. In this paper, we present
   VRebalance, a virtual resource orchestrator that provides an end-to-end
   performance guarantee for concurrent stream processing workloads at the
   Edge. VRebalance employs Bayesian Optimization BO to quickly identify
   near-optimal resource configurations. Experimental results with a
   real-time open-source IoT benchmark for Distributed Stream Processing
   Platforms (RIoTBench) and a representative stream processing engine
   (Apache Storm) demonstrate the superior performance, resource efficiency
   and adaptiveness of our BO-based resource management system. VRebalance
   meets the performance SLO (service level objective) targets for stream
   processing workloads even in the presence of acute system dynamics. It
   decreases the SLO violation rate by at least 34\% for static workloads
   and by 62.5\% for dynamic workloads compared to a hill climbing method.
   Compared to Storm's default resource scaling mechanism, our method
   decreases the SLO violation rate by 83.7\%.},
DOI = {10.1109/IC2E52221.2021.00027},
ISSN = {2373-3845},
ISBN = {978-1-6654-4970-0},
Unique-ID = {WOS:000760304200014},
}

@article{ WOS:000612106900018,
Author = {Eskandari, Leila and Mair, Jason and Huang, Zhiyi and Eyers, David},
Title = {I-Scheduler: Iterative scheduling for distributed stream processing
   systems},
Journal = {FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE},
Year = {2021},
Volume = {117},
Pages = {219-233},
Month = {APR},
Abstract = {Task allocation in Data Stream Processing Systems (DSPSs) has a
   significant impact on performance metrics such as data processing
   latency and system throughput. An application processed by DSPSs can be
   represented as a Directed Acyclic Graph (DAG), where each vertex
   represents a task and the edges show the dataflow between the tasks.
   Task allocation can be defined as the assignment of the vertices in the
   DAG to the physical compute nodes such that the data movement between
   the nodes is minimised. Finding an optimal task placement for DSPSs is
   NP-hard. Thus, approximate scheduling approaches are required to improve
   the performance of DSPSs. In this paper, we propose a heuristic
   scheduling algorithm which reliably and efficiently finds highly
   communicating tasks by exploiting graph partitioning algorithms and a
   mathematical optimisation software package. We evaluate the
   communication cost of our method using three micro-benchmarks, showing
   that we can achieve results that are close to optimal. We further
   compare our scheduler with two popular existing schedulers, R-Storm and
   Aniello et al.'s `Online scheduler' using two real-world applications.
   Our experimental results show that our proposed scheduler outperforms
   R-Storm, increasing throughput by up to 30\%, and improves on the Online
   scheduler by 20\%-86\% as a result of finding a more efficient
   schedule.(1) (C) 2020 Published by Elsevier B.V.},
DOI = {10.1016/j.future.2020.11.011},
ISSN = {0167-739X},
EISSN = {1872-7115},
ORCID-Numbers = {Huang, Zhiyi/0000-0001-8561-2556},
Unique-ID = {WOS:000612106900018},
}

@inproceedings{ WOS:000289456400003,
Author = {De Pauw, Wim and Letia, Mihai and Gedik, Bugra and Andrade, Henrique and
   Frenkiel, Andy and Pfeifer, Michael and Sow, Daby},
Editor = {Barringer, H and Falcone, Y and Finkbeiner, B and Havelund, K and Lee, I and Pace, G and Rosu, G and Sokolsky, O and Tillmann, N},
Title = {Visual Debugging for Stream Processing Applications},
Booktitle = {RUNTIME VERIFICATION},
Series = {Lecture Notes in Computer Science},
Year = {2010},
Volume = {6418},
Pages = {18-35},
Note = {1st International Conference on Runtime Verification, St Julians, MALTA,
   NOV 01-04, 2010},
Organization = {Int Federat Comp Logic; ARTIST Network Excellence Embedded Syst Design;
   Microsft Res; Univ Illinois},
Abstract = {Stream processing is a new computing paradigm that enables continuous
   and fast analysis of massive volumes of streaming data. Debugging
   streaming applications is not trivial, since they are typically
   distributed across multiple nodes and handle large amounts of data.
   Traditional debugging techniques like breakpoints often rely on a
   stop-the-world approach, which may be useful for debugging single node
   applications, but insufficient for streaming applications. We propose a
   new visual and analytic environment to support debugging, performance
   analysis, and troubleshooting for stream processing applications. Our
   environment provides several visualization methods to study,
   characterize, and summarize the flow of tuples between stream processing
   operators. The user can interactively indicate points in the streaming
   application from where tuples will be traced and visualized as they flow
   through different operators, without stopping the application. To
   substantiate our discussion, we also discuss several of these features
   in the context of a financial engineering application.},
ISSN = {0302-9743},
ISBN = {978-3-642-16611-2},
ResearcherID-Numbers = {Gedik, Buğra/F-7842-2014},
Unique-ID = {WOS:000289456400003},
}

@inproceedings{ WOS:000473399100004,
Author = {Bilal, Muhammad and Alsibyani, Hassan and Canini, Marco},
Book-Group-Author = {Assoc Comp Machinery},
Title = {Mitigating Network Side Channel Leakage for Stream Processing Systems in
   Trusted Execution Environments},
Booktitle = {DEBS'18: PROCEEDINGS OF THE 12TH ACM INTERNATIONAL CONFERENCE ON
   DISTRIBUTED AND EVENT-BASED SYSTEMS},
Year = {2018},
Pages = {16-27},
Note = {12th ACM International Conference on Distributed and Event-Based Systems
   (DEBS), Univ Waikato, Hamilton, NEW ZEALAND, JUN 25-29, 2018},
Organization = {ACM SIGMOD; ACM SIGSOFT},
Abstract = {A crucial concern regarding cloud computing is the confidentiality of
   sensitive data being processed in the cloud. Trusted Execution
   Environments (TEEs), such as Intel Software Guard eXtensions (SGX),
   allow applications to run securely on an untrusted platform. However,
   using TEEs alone for stream processing is not enough to ensure privacy
   as network communication patterns may leak information about the data.
   This paper introduces two techniques - anycast and multicast - for
   mitigating leakage at inter-stage communications in streaming
   applications according to a user-selected mitigation level. These
   techniques aim to achieve network data obliviousness, i.e.,
   communication patterns should not depend on the data. We implement these
   techniques in an SGX-based stream processing system. We evaluate the
   latency and throughput overheads, and the data obliviousness using three
   benchmark applications. The results show that anycast scales better with
   input load and mitigation level, and provides better data obliviousness
   than multicast.},
DOI = {10.1145/3210284.3210286},
ISBN = {978-1-4503-5782-1},
ResearcherID-Numbers = {Canini, Marco/AAE-3229-2022
   },
ORCID-Numbers = {Canini, Marco/0000-0002-5051-4283
   Alsibyani, Hassan/0000-0002-2717-6052},
Unique-ID = {WOS:000473399100004},
}

@article{ WOS:000485736800013,
Author = {Marangozova-Martin, Vania and de Palma, Noel and El Rheddane, Ahmed},
Title = {Multi-Level Elasticity for Data Stream Processing},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2019},
Volume = {30},
Number = {10},
Pages = {2326-2337},
Month = {OCT},
Abstract = {This paper investigates reactive elasticity in stream processing
   environments where the performance goal is to analyze large amounts of
   data with low latency and minimum resources. Working in the context of
   Apache Storm, we propose an elastic management strategy which modulates
   the parallelism degree of applications' components while explicitly
   addressing the hierarchy of execution containers (virtual machines,
   processes and threads). We show that provisioning the wrong kind of
   container may lead to performance degradation and propose a solution
   that provisions the least expensive container (with minimum resources)
   to increase performance. We describe our monitoring metrics and show how
   we take into account the specifics of an execution environment. We
   provide an experimental evaluation with real-world applications which
   validates the applicability of our approach.},
DOI = {10.1109/TPDS.2019.2907950},
ISSN = {1045-9219},
EISSN = {1558-2183},
Unique-ID = {WOS:000485736800013},
}

@article{ WOS:000825548100001,
Author = {Matteussi, Kassiano J. and dos Anjos, Julio C. S. and Leithardt, Valderi
   R. Q. and Geyer, Claudio F. R.},
Title = {Performance Evaluation Analysis of Spark Streaming Backpressure for
   Data-Intensive Pipelines},
Journal = {SENSORS},
Year = {2022},
Volume = {22},
Number = {13},
Month = {JUL},
Abstract = {A significant rise in the adoption of streaming applications has changed
   the decision-making processes in the last decade. This movement has led
   to the emergence of several Big Data technologies for in-memory
   processing, such as the systems Apache Storm, Spark, Heron, Samza,
   Flink, and others. Spark Streaming, a widespread open-source
   implementation, processes data-intensive applications that often require
   large amounts of memory. However, Spark Unified Memory Manager cannot
   properly manage sudden or intensive data surges and their related
   in-memory caching needs, resulting in performance and throughput
   degradation, high latency, a large number of garbage collection
   operations, out-of-memory issues, and data loss. This work presents a
   comprehensive performance evaluation of Spark Streaming backpressure to
   investigate the hypothesis that it could support data-intensive
   pipelines under specific pressure requirements. The results reveal that
   backpressure is suitable only for small and medium pipelines for
   stateless and stateful applications. Furthermore, it points out the
   Spark Streaming limitations that lead to in-memory-based issues for
   data-intensive pipelines and stateful applications. In addition, the
   work indicates potential solutions.},
DOI = {10.3390/s22134756},
Article-Number = {4756},
EISSN = {1424-8220},
ResearcherID-Numbers = {Leithardt, Valderi Reis Quietinho/B-1247-2019
   Anjos, Julio/I-4821-2017},
ORCID-Numbers = {Leithardt, Valderi Reis Quietinho/0000-0003-0446-9271
   Matteussi, Kassiano Jose/0000-0002-9131-6849
   Anjos, Julio/0000-0003-3623-2762},
Unique-ID = {WOS:000825548100001},
}

@inproceedings{ WOS:000361532100068,
Author = {Coluccio, Roberto and Ghidini, Giacomo and Reale, Andrea and Levine,
   David and Bellavista, Paolo and Emmons, Stephen P. and Smith, Jeffrey O.},
Book-Group-Author = {IEEE},
Title = {Online Stream Processing of Machine-to-Machine Communications Traffic: A
   Platform Comparison},
Booktitle = {2014 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC)},
Year = {2014},
Note = {IEEE Symposium on Computers and Communication (ISCC), Funchal, PORTUGAL,
   JUN 23-26, 2014},
Organization = {IEEE},
Abstract = {In a machine-to-machine (M2M) communications system, the deployed
   devices relay data from on-board sensors to a back-end application over
   a wireless network. Since the cellular network provides very good
   coverage (especially in inhabited areas) and is relatively inexpensive,
   commercial M2M applications often prefer it to other technologies such
   as WiFi or satellite links. Unfortunately, having been originally
   designed with human users in mind, the cellular network provides little
   support to monitor millions of unattended devices. For this reason, it
   is extremely important to monitor the underlying signalling traffic to
   detect misbehaving devices or network problems. In the cellular network
   used by M2M communications systems, the network elements communicate
   using the Signalling System \#7 (SS7), and a real-life system can
   generate tens of millions of SS7 messages per hour. This paper reports
   the results of our practical investigation on the possibility to use
   distributed stream processing systems (DSPSs) to perform real-time
   analysis of SS7 traffic in a commercial M2M communications system
   consisting of hundreds of thousands of devices. Through a thorough
   experimental evaluation based on the analysis of real-world SS7 traces,
   we present and compare the implementations of a DSPS-based data analysis
   application on top of either the well-known Storm DSPS or the Quasit
   middleware. The results show that, by using DSPS services, we are able
   to largely meet the real-time processing requirements of our use-case
   scenario.},
ResearcherID-Numbers = {Bellavista, Paolo/H-7256-2014},
ORCID-Numbers = {Bellavista, Paolo/0000-0003-0992-7948},
Unique-ID = {WOS:000361532100068},
}

@article{ WOS:000476541700005,
Author = {Fang, Hong and Zhao, Bo and Zhang, Xiao-Wang and Yang, Xuan-Xing},
Title = {A United Framework for Large-Scale Resource Description Framework Stream
   Processing},
Journal = {JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY},
Year = {2019},
Volume = {34},
Number = {4},
Pages = {762-774},
Month = {JUL},
Abstract = {Resource description framework (RDF) stream is useful to model
   spatio-temporal data. In this paper, we propose a framework for
   large-scale RDF stream processing, LRSP, to process general continuous
   queries over large-scale RDF streams. Firstly, we propose a
   formalization (named CT-SPARQL) to represent the general continuous
   queries in a unified, unambiguous way. Secondly, based on our
   formalization we propose LRSP to process continuous queries in a common
   white-box way by separating RDF stream processing, query parsing, and
   query execution. Finally, we implement and evaluate LRSP with those
   popular continuous query engines on some benchmark datasets and
   real-world datasets. Due to the architecture of LRSP, many efficient
   query engines (including centralized and distributed engines) for RDF
   can be directly employed to process continuous queries. The experimental
   results show that LRSP has a higher performance, specially, in
   processing large-scale real-world data.},
DOI = {10.1007/s11390-019-1941-9},
ISSN = {1000-9000},
EISSN = {1860-4749},
ORCID-Numbers = {Zhang, Xiaowang/0000-0002-3931-3886},
Unique-ID = {WOS:000476541700005},
}

@inproceedings{ WOS:000426912900107,
Author = {Runsewe, Olubisi and Samaan, Nancy},
Book-Group-Author = {IEEE},
Title = {Cloud Resource Scaling for Big Data Streaming Applications Using A
   Layered Multi-dimensional Hidden Markov Model},
Booktitle = {2017 17TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND GRID
   COMPUTING (CCGRID)},
Series = {IEEE-ACM International Symposium on Cluster Cloud and Grid Computing},
Year = {2017},
Pages = {848-857},
Note = {17th IEEE/ACM International Symposium on Cluster, Cloud and Grid
   Computing (CCGRID), Madrid, SPAIN, MAY 14-17, 2017},
Organization = {IEEE; Assoc Comp Machinery; IEEE Comp Soc; Mellanox Technologies; Univ
   Carlos III Madrid; ARCOS; IEEE TCSC},
Abstract = {Recent advancements in technology have led to a deluge of data that
   require real-time analysis with strict latency constraints. A major
   challenge, however, is determining the amount of resources required by
   big data stream processing applications in response to heterogeneous
   data sources, streaming events, unpredictable data volume and velocity
   changes. Over-provisioning of resources for peak loads can be wasteful
   while under-provisioning can have a huge impact on the performance of
   the streaming applications. The majority of research efforts on resource
   scaling in the cloud are investigated from the cloud provider's
   perspective, they focus on web applications and do not consider multiple
   resource bottlenecks. We aim at analyzing the resource scaling problem
   from a big data streaming application provider's point of view such that
   efficient scaling decisions can be made for future resource utilization.
   This paper proposes a Layered Multi-dimensional Hidden Markov Model
   (LMD-HMM) for facilitating the management of resource auto-scaling for
   big data streaming applications in the cloud. Our detailed experimental
   evaluation shows that LMD-HMM performs best with an accuracy of 98\%,
   outperforming the single-layer hidden markov model.},
DOI = {10.1109/CCGRID.2017.147},
ISSN = {2376-4414},
ISBN = {978-1-5090-6611-7},
ResearcherID-Numbers = {Runsewe, Olubisi/Z-2983-2019},
ORCID-Numbers = {Runsewe, Olubisi/0000-0002-5043-0581},
Unique-ID = {WOS:000426912900107},
}

@inproceedings{ WOS:000584318800010,
Author = {Shahverdi, Elkhan and Awad, Ahmed and Sakr, Sherif},
Book-Group-Author = {IEEE},
Title = {Big Stream Processing Systems: An Experimental Evaluation},
Booktitle = {2019 IEEE 35TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING WORKSHOPS
   (ICDEW 2019)},
Series = {IEEE International Conference on Data Engineering Workshop},
Year = {2019},
Pages = {53-60},
Note = {IEEE 35th International Conference on Data Engineering (ICDE), Macau,
   PEOPLES R CHINA, APR 08-11, 2019},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {As the world gets more instrumented and connected, we are witnessing a
   flood of digital data generated from various hardware (e.g., sensors) or
   software in the format of flowing streams of data. Real-time processing
   for such massive amounts of streaming data is a crucial requirement in
   several application domains including financial markets, surveillance
   systems, manufacturing, smart cities, and scalable monitoring
   infrastructure. In the last few years, several big stream processing
   engines have been introduced to tackle this challenge. In this article,
   we present an extensive experimental study of five popular systems in
   this domain, namely, Apache Storm, Apache Rink, Apache Spark, Kafka
   Streams and Hazelcast Jet. We report and analyze the performance
   characteristics of these systems. In addition, we report a set of
   insights and important lessons that we have learned from conducting our
   experiments.},
DOI = {10.1109/ICDEW.2019.00-35},
ISSN = {1943-2895},
ISBN = {978-1-7281-0890-2},
ResearcherID-Numbers = {Awad, Ahmed/C-8350-2018},
ORCID-Numbers = {Awad, Ahmed/0000-0003-1879-1026},
Unique-ID = {WOS:000584318800010},
}

@inproceedings{ WOS:000389830100137,
Author = {Cermak, Milan and Tovarnak, Daniel and Lastovicka, Martin and Celeda,
   Pavel},
Editor = {Badonnel, SO and Ulema, M and Cavdar, C and Granville, LZ and DosSantos, CRP},
Title = {A Performance Benchmark for NetFlow Data Analysis on Distributed Stream
   Processing Systems},
Booktitle = {NOMS 2016 - 2016 IEEE/IFIP NETWORK OPERATIONS AND MANAGEMENT SYMPOSIUM},
Series = {IEEE IFIP Network Operations and Management Symposium},
Year = {2016},
Pages = {919-924},
Note = {IEEE/IFIP Network Operations and Management Symposium (NOMS), Istanbul,
   TURKEY, APR 25-29, 2016},
Organization = {IEEE; IFIP; IEEE Big Data; Cisco; Argela; Avaya; Nokia; ITU ARI
   Teknokent; NETAS; IBM; Super Cloud Comp Ctr; IEEE Commun Soc},
Abstract = {Modern distributed stream processing systems can potentially be applied
   to real time network flow processing. However, differences in
   performance make some systems more suitable than others for being
   applied to this domain. We propose a novel performance benchmark, which
   is based on common security analysis algorithms of NetFlow data to
   determine the suitability of distributed stream processing systems.
   Three of the most used distributed stream processing systems are
   benchmarked and the results are compared with NetFlow data processing
   challenges and requirements. The benchmark results show that each system
   reached a sufficient data processing speed using a basic deployment
   scenario with little to no configuration tuning. Our benchmark, unlike
   any other, enables the performance of small structured messages to be
   processed on any stream processing system.},
ISSN = {1542-1201},
ISBN = {978-1-5090-0223-8},
ResearcherID-Numbers = {Cermak, Milan/AAJ-9385-2020
   Lastovicka, Martin/AAG-4876-2021
   Laštovička, Martin/AAJ-8944-2020
   Celeda, Pavel/L-6634-2013
   },
ORCID-Numbers = {Cermak, Milan/0000-0002-0212-6593
   Laštovička, Martin/0000-0002-6604-6947
   Celeda, Pavel/0000-0002-3338-2856
   Tovarnak, Daniel/0000-0002-7206-5167},
Unique-ID = {WOS:000389830100137},
}

@inproceedings{ WOS:000456877300015,
Author = {Van, Chan Le and Gao, Feng and Ali, Muhammad Intizar},
Editor = {Blomqvist, E and Maynard, D and Gangemi, A and Hoekstra, R and Hitzler, P and Hartig, O},
Title = {Optimizing the Performance of Concurrent RDF Stream Processing Queries},
Booktitle = {SEMANTIC WEB ( ESWC 2017), PT I},
Series = {Lecture Notes in Computer Science},
Year = {2017},
Volume = {10249},
Pages = {238-253},
Note = {14th International Semantic Web Conference (ESWC), Portoroz, SLOVENIA,
   MAY 28-JUN 01, 2017},
Abstract = {With the growing popularity of Internet of Things (IoT) and sensing
   technologies, a large number of data streams are being generated at a
   very rapid pace. To explore the potentials of the integration of IoT and
   semantic technologies, a few RDF Stream Processing (RSP) query engines
   are made available which are capable of processing, analyzing and
   reasoning over semantic data streams in real-time. This way, RSP
   mitigates data interoperability issues and promotes knowledge discovery
   and smart decision making for time-sensitive applications. However, a
   major hurdle in the wide adoption of RSP systems is their query
   performance. Particularly, the ability of RSP engines to handle a large
   number of concurrent queries is very limited which refrains large scale
   stream processing applications (e.g. smart city applications) to adopt
   RSP. In this paper, we propose a shared-join based approach to improve
   the performance of an RSP engine for concurrent queries. We also
   leverage query federation mechanisms to allow distributed query
   processing over multiple RSP engine instances in order to gain
   performance for concurrent and distributed queries. We apply load
   balancing strategies to distribute queries and further optimize the
   concurrent query performance. We provide a proof of concept
   implementation by extending CQELS RSP engine and evaluate our approach
   using existing benchmark datasets for RSP. We also compare the
   performance of our proposed approach with the state of the art
   implementation of CQELS RSP engine.},
DOI = {10.1007/978-3-319-58068-5\_15},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-58068-5; 978-3-319-58067-8},
ORCID-Numbers = {Ali, Muhammad Intizar/0000-0002-0674-2131},
Unique-ID = {WOS:000456877300015},
}

@article{ WOS:000278701700006,
Author = {Zinn, Daniel and Bowers, Shawn and Koehler, Sven and Ludaescher, Bertram},
Title = {Parallelizing XML data-streaming workflows via MapReduce},
Journal = {JOURNAL OF COMPUTER AND SYSTEM SCIENCES},
Year = {2010},
Volume = {76},
Number = {6, SI},
Pages = {447-463},
Month = {SEP},
Note = {3rd International Workshop on Workflow Management and Applications in
   Grid Environments (WaGe2008), Kunming, PEOPLES R CHINA, MAY 25, 2008},
Abstract = {In prior work it has been shown that the design of scientific workflows
   can benefit from a collection-oriented modeling paradigm which views
   scientific workflows as pipelines of XML stream processors. In this
   paper, we present approaches for exploiting data parallelism in XML
   processing pipelines through novel compilation strategies to the
   MapReduce framework Pipelines in our approach consist of sequences of
   processing steps that receive XML-structured data and produce, often
   through calls to ``black-box{''} (scientific) functions, modified (i.e..
   updated) XML structures. Our main contributions are (i) the development
   of a set of strategies for compiling scientific workflows, modeled as
   XML processing pipelines, into parallel MapReduce networks, and (ii) a
   discussion of their advantages and trade-offs, based on a thorough
   experimental evaluation of the various translation strategies. Our
   evaluation uses the Hadoop MapReduce system as an implementation
   platform. Our results show that execution times of XML workflow
   pipelines can be significantly reduced using our compilation strategies.
   These efficiency gains, together with the benefits of MapReduce (e.g.,
   fault tolerance) make our approach ideal for executing large-scale,
   compute-intensive XML-based Scientific workflows (C) 2009 Elsevier Inc.
   All rights reserved},
DOI = {10.1016/j.jcss.2009.11.006},
ISSN = {0022-0000},
EISSN = {1090-2724},
Unique-ID = {WOS:000278701700006},
}

@article{ WOS:000417667400003,
Author = {Fernandez-Rodriguez, Jorge Y. and Alvarez-Garcia, Juan A. and Arias
   Fisteus, Jesus and Luaces, Miguel R. and Corcoba Magana, Victor},
Title = {Benchmarking real-time vehicle data streaming models for a smart city},
Journal = {INFORMATION SYSTEMS},
Year = {2017},
Volume = {72},
Pages = {62-76},
Month = {DEC},
Abstract = {The information systems of smart cities offer project developers,
   institutions, industry and experts the possibility to handle massive
   incoming data from diverse information sources in order to produce new
   information services for citizens. Much of this information has to be
   processed as it arrives because a real-time response is often needed.
   Stream processing architectures solve this kind of problems, but
   sometimes it is not easy to benchmark the load capacity or the
   efficiency of a proposed architecture. This work presents a real case
   project in which an infrastructure was needed for gathering information
   from drivers in a big city, analyzing that information and sending
   real-time recommendations to improve driving efficiency and safety on
   roads. The challenge was to support the real-time recommendation service
   in a city with thousands of simultaneous drivers at the lowest possible
   cost. In addition, in order to estimate the ability of an infrastructure
   to handle load, a simulator that emulates the data produced by a given
   amount of simultaneous drivers was also developed. Experiments with the
   simulator show how recent stream processing platforms like Apache Kafka
   could replace custom-made streaming servers in a smart city to achieve a
   higher scalability and faster responses, together with cost reduction.
   (C) 2017 Elsevier Ltd. All rights reserved.},
DOI = {10.1016/j.is.2017.09.002},
ISSN = {0306-4379},
EISSN = {1873-6076},
ResearcherID-Numbers = {Luaces, Miguel Rodríguez/A-6434-2011
   Alvarez, Juan/GSD-7155-2022
   García, Juan Antonio Álvarez/A-6223-2008
   Magaña, Víctor Corcoba/AAZ-2273-2020
   Arias Fisteus, Jesus/H-6230-2012},
ORCID-Numbers = {Luaces, Miguel Rodríguez/0000-0003-0549-2000
   García, Juan Antonio Álvarez/0000-0002-4106-6044
   Magaña, Víctor Corcoba/0000-0001-6804-7428
   Arias Fisteus, Jesus/0000-0002-4381-2071},
Unique-ID = {WOS:000417667400003},
}

@article{ WOS:000638398900001,
Author = {Zhang, Feng and Zhang, Chenyang and Yang, Lin and Zhang, Shuhao and He,
   Bingsheng and Lu, Wei and Du, Xiaoyong},
Title = {Fine-Grained Multi-Query Stream Processing on Integrated Architectures},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2021},
Volume = {32},
Number = {9},
Pages = {2303-2320},
Month = {SEPT 1},
Abstract = {Exploring the sharing opportunities among multiple stream queries is
   crucial for high-performance stream processing. Modern stream processing
   necessitates accelerating multiple queries by utilizing heterogeneous
   coprocessors, such as GPUs, and this has shown to be an effective
   method. Emerging CPU-GPU integrated architectures 6integrate CPU and GPU
   on the same chip and eliminate PCI-e bandwidth bottleneck. Such a novel
   architecture provides new opportunities for improving multi-query
   performance in stream processing but has not been fully explored by
   existing systems. We introduce a stream processing engine, called
   FineStream, for efficient multi-query window-based stream processing on
   CPU-GPU integrated architectures. FineStream's key contribution is a
   novel fine-grained workload scheduling mechanism between CPU and GPU to
   take advantage of both architectures. Particularly, FineStream is able
   to efficiently handle multiple queries in both static and dynamic
   streams. Our experimental results show that 1) on integrated
   architectures, FineStream achieves an average 52 percent throughput
   improvement and 36 percent lower latency over the state-of-the-art
   stream processing engine; 2) compared to the coarse-grained strategy of
   applying different devices for multiple queries, FineStream achieves 32
   percent throughput improvement; 3) compared to the stream processing
   engine on the discrete architecture, FineStream on the integrated
   architecture achieves 10.4x price-throughput ratio, 1.8x energy
   efficiency, and can enjoy lower latency benefits.},
DOI = {10.1109/TPDS.2021.3066407},
ISSN = {1045-9219},
EISSN = {1558-2183},
ResearcherID-Numbers = {Zhang, Feng/X-6906-2019
   },
ORCID-Numbers = {zhang, shuhao/0000-0002-9927-6925
   LU, WEI/0000-0001-6769-2695
   Zhang, Feng/0000-0003-1983-7321
   Zhang, Chenyang/0000-0002-7627-6359},
Unique-ID = {WOS:000638398900001},
}

@inproceedings{ WOS:000554828700057,
Author = {Silva, Pedro and Costan, Alexandru and Antoniu, Gabriel},
Editor = {Baru, C and Huan, J and Khan, L and Hu, XH and Ak, R and Tian, Y and Barga, R and Zaniolo, C and Lee, K and Ye, YF},
Title = {Investigating Edge vs. Cloud Computing Trade-offs for Stream Processing},
Booktitle = {2019 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)},
Series = {IEEE International Conference on Big Data},
Year = {2019},
Pages = {469-474},
Note = {IEEE International Conference on Big Data (Big Data), Los Angeles, CA,
   DEC 09-12, 2019},
Organization = {IEEE Comp Soc; IEEE; Baidu; Very; Ankura},
Abstract = {The recent spectacular rise of the Internet of Things and the associated
   augmentation of the data deluge motivated the emergence of Edge
   computing as a means to distribute processing from centralized Clouds
   towards decentralized processing units close to the data sources. This
   led to new challenges in ways to distribute processing across
   Cloud-based, Edge-based or hybrid Cloud/Edge-based infrastructures. In
   particular, a major question is: how much can one improve (or degrade)
   the performance of an application by performing computation closer to
   the data sources rather than in the Cloud? This paper proposes a
   methodology to understand such performance trade-offs and illustrates it
   through experimental evaluation with two real-life stream processing
   use-cases executed on fully-Cloud and hybrid Cloud-Edge testbeds using
   state-of-the-art processing engines for each environment. We derive a
   set of take-aways for the community, highlighting the limitations of
   each environment, the scenarios that could benefit from hybrid
   Edge-Cloud deployments, what relevant parameters impact performance and
   how.},
ISSN = {2639-1589},
ISBN = {978-1-7281-0858-2},
ResearcherID-Numbers = {Costan, Alexandru/AAC-1776-2020},
ORCID-Numbers = {Costan, Alexandru/0000-0003-3111-6308},
Unique-ID = {WOS:000554828700057},
}

@inproceedings{ WOS:000274496200118,
Author = {Bouillet, Eric and Dube, Parijat and George, David and Liu, Zhen and
   Pendarakis, Dimitrios and Zhang, Li},
Book-Group-Author = {IEEE},
Title = {Distributed Multi-Layered Workload Synthesis for Testing Stream
   Processing Systems},
Booktitle = {2008 WINTER SIMULATION CONFERENCE, VOLS 1-5},
Year = {2008},
Pages = {1003-1011},
Note = {2008 Winter Simulation Conference, Miami, FL, DEC 07-10, 2008},
Organization = {Amer Stat Assoc; ACM SIGSIM; IEEE Syst, Man \& Cybernet Soc; Inst Ind
   Engineers; INFORMS, Simulat Soc; NIST; Soc Modeling \& Simulat Int},
Abstract = {Testing and benchmarking of stream processing systems requires workload
   representative of real world scenarios with myriad of users, interacting
   through different applications over different modalities with different
   underlying protocols. The workload should have realistic volumetric and
   contextual statistics at different levels: user level, application
   level, packet level etc. Further realistic workload is inherently
   distributed in nature. We present a scalable framework for synthesis of
   distributed workload based on identifying different layers of workload
   corresponding to different time-scales. The architecture is extensible
   and modular, promotes reuse of libraries at different layers and offers
   the flexibility to add additional plug-ins at different layers without
   sacrificing the efficiency.},
DOI = {10.1109/WSC.2008.4736167},
ISBN = {978-1-4244-2707-9},
Unique-ID = {WOS:000274496200118},
}

@article{ WOS:000437997500014,
Author = {Cardellini, Valeria and Lo Presti, Francesco and Nardelli, Matteo and
   Russo, Gabriele Russo},
Title = {Decentralized self-adaptation for elastic Data Stream Processing},
Journal = {FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE},
Year = {2018},
Volume = {87},
Pages = {171-185},
Month = {OCT},
Abstract = {Data Stream Processing (DSP) applications are widely used to develop new
   pervasive services, which require to seamlessly process huge amounts of
   data in a near real-time fashion. To keep up with the high volume of
   daily produced data, these applications need to dynamically scale their
   execution on multiple computing nodes, so to process the incoming data
   flow in parallel. In this paper, we present a hierarchical distributed
   architecture for the autonomous control of elastic DSP applications. It
   consists of a two-layered hierarchical solution, where a centralized
   per-application component coordinates the run-time adaptation of
   subordinated distributed components, which, in turn, locally control the
   adaptation of single DSP operators. Thanks to its features, the proposed
   solution can efficiently run in large-scale Fog computing environments.
   Exploiting this framework, we design several distributed self-adaptation
   policies, including a popular threshold-based approach and two
   reinforcement learning solutions. We integrate the hierarchical
   architecture and the devised self-adaptation policies in Apache Storm, a
   popular open-source DSP framework. Relying on the DEBS 2015 Grand
   Challenge as a benchmark application, we show the benefits of the
   presented self-adaptation policies, and discuss the strengths of
   reinforcement learning based approaches, which autonomously learn from
   experience how to optimize the application performance. (C) 2018
   Elsevier B.V. All rights reserved.},
DOI = {10.1016/j.future.2018.05.025},
ISSN = {0167-739X},
EISSN = {1872-7115},
ResearcherID-Numbers = {Cardellini, Valeria/F-8409-2012
   Nardelli, Matteo/K-7215-2016
   },
ORCID-Numbers = {Cardellini, Valeria/0000-0002-6870-7083
   Nardelli, Matteo/0000-0002-9519-9387
   Russo Russo, Gabriele/0000-0001-8233-4570},
Unique-ID = {WOS:000437997500014},
}

@inproceedings{ WOS:000706974800003,
Author = {Chakraborty, Rudraneel and Majumdar, Shikharesh},
Book-Group-Author = {ASSOC COMP MACHINERY},
Title = {Priority Based Resource Scheduling Techniques for a Resource Constrained
   Stream Processing System},
Booktitle = {BDCAT'17: PROCEEDINGS OF THE FOURTH IEEE/ACM INTERNATIONAL CONFERENCE ON
   BIG DATA COMPUTING, APPLICATIONS AND TECHNOLOGIES},
Year = {2017},
Pages = {21-31},
Note = {10th International Conference on Utility and Cloud Computing (UCC) / 4th
   International Conference on Big Data Computing, Applications and
   Technologies (BDCAT), Austin, TX, DEC 05-08, 2017},
Organization = {Assoc Comp Machinery; IEEE Comp Soc; IEEE TCSC; ACM SIGARCH; IEEE},
Abstract = {A multitenant Storm cluster runs multiple stream processing applications
   and uses the default Isolation Scheduler to schedule them. Isolation
   Scheduler assigns resources to topologies based on static resource
   configuration and does not provide any means for prioritizing topologies
   based on their varying business requirements. Thus, performance
   degradation, even complete starvation of topologies with high priority
   is possible when the cluster is resource constrained and comprises an
   inadequate number of resources. Two priority based resource scheduling
   techniques are proposed to overcome these problems. A performance
   analysis based on prototyping and measurements demonstrates the
   effectiveness of the proposed techniques.},
DOI = {10.1145/3148055.3148066},
ISBN = {978-1-4503-5549-0},
Unique-ID = {WOS:000706974800003},
}

@inproceedings{ WOS:000458731400020,
Author = {Tran, Geoffrey Phi C. and Walters, John Paul and Crago, Stephen P.},
Editor = {Sill, A and Spillner, J},
Title = {Reducing Tail Latencies While Improving Resiliency to Timing Errors for
   Stream Processing Workloads},
Booktitle = {2018 IEEE/ACM 11TH INTERNATIONAL CONFERENCE ON UTILITY AND CLOUD
   COMPUTING (UCC)},
Series = {International Conference on Utility and Cloud Computing},
Year = {2018},
Pages = {194-203},
Note = {11th IEEE/ACM International Conference on Utility and Cloud Computing
   (UCC-Companion) / 5th IEEE/ACM International Conference on Big Data
   Computing, Applications and Technologies (BDCAT), Zurich, SWITZERLAND,
   DEC 17-20, 2018},
Organization = {IEEE; ACM; IEEE Comp Soc},
Abstract = {Stream processing is an increasingly popular model for online data
   processing that can be partitioned into streams of elements. It is
   commonly used in real-time data analytics services, such as processing
   Twitter tweets and Internet of Things (IoT) device feeds. Current stream
   processing frameworks boast high throughput and low average latency.
   However, users of these frameworks may desire lower tail latencies and
   better real-time performance for their applications. In practice, there
   are a number of errors that can affect the performance of stream
   processing applications, such as garbage collection and resource
   contention. For some applications, these errors may cause unacceptable
   violations of real-time constraints.
   In this paper we propose applying redundancy in the data processing
   pipeline to increase the resiliency of stream processing applications to
   timing errors. This results in better realtime performance and a
   reduction in tail latency. We present a methodology and apply this
   redundancy in a framework based on Twitter's Heron. Finally, we evaluate
   the effectiveness of this technique against a range of injected timing
   errors using benchmarks from Intel's Storm Benchmark. Our results show
   that redundant tuple processing can effectively reduce the tail latency,
   and that the number of missed deadlines can also be reduced by up to
   94\% in the best case. We also study the potential effects of
   duplication when applied at different stages in the topology. For the
   topologies in this paper, we further observe that duplication is most
   effective when computation is redundant at the first bolt. Finally, we
   evaluate the additional overhead that duplicating tuples brings to a
   stream processing topology. Our results also show that computation
   overhead scales slower than communication, and that the real-time
   performance is improved in spite of the overheads. Overall we conclude
   that redundancy through duplicated tuples is indeed a powerful tool for
   increasing the resiliency to intermittent runtime timing errors.},
DOI = {10.1109/UCC.2018.00028},
ISSN = {2373-6860},
ISBN = {978-1-5386-5504-7},
ORCID-Numbers = {Walters, John Paul/0000-0001-5281-6237},
Unique-ID = {WOS:000458731400020},
}

@inproceedings{ WOS:000501731200041,
Author = {Tran, Geoffrey Phi C. and Walters, John Paul and Crago, Stephen P.},
Book-Group-Author = {IEEE},
Title = {Reducing Tail Latencies While Improving Resiliency to Timing Errors for
   Stream Processing Workloads},
Booktitle = {2018 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (IEEE SCC 2018)},
Series = {Proceedings of the IEEE International Conference on Services Computing
   SCC},
Year = {2018},
Pages = {278-281},
Note = {IEEE International Conference on Services Computing (IEEE SCC) Part of
   the IEEE World Congress on Services, San Francisco, CA, JUL 02-07, 2018},
Organization = {IEEE; IEEE Comp Soc; CCF, TCSC},
Abstract = {Stream processing is an increasingly popular model for online data
   processing that can be partitioned into streams of elements. It is
   commonly used in data analytics services, such as processing Twitter
   tweets. Current stream processing frameworks boast high throughput and
   low average latency. However, lower tail latencies and better real-time
   performance are desirable to stream processing users. In practice, there
   are issues that can affect the performance of these applications and
   cause unacceptable violations of real-time constraints. Some examples of
   these issues are garbage collection pauses and resource contention.
   In this paper, we propose applying redundancy in the data processing
   pipeline to increase the resiliency of stream processing applications to
   timing errors. This results in better real-time performance and a
   reduction in tail latency. We present a methodology and apply this
   redundancy in a framework based on Twitter's Heron. Then, we then
   evaluate the effectiveness of this technique against a range of injected
   timing errors using benchmarks from Intel's Storm Benchmark.
   Furthermore, we also study the potential effects of duplication when
   applied at different stages in the topology. Finally, we evaluate the
   additional overhead that duplicating tuples brings to a stream
   processing topology. Our results show that redundant tuple processing
   can effectively reduce the tail latency by up to 63\% and that the
   number of missed deadlines can also be reduced by up to 94\% in the best
   case. Overall we conclude that redundancy through duplicated tuples is
   indeed a powerful tool for increasing the resiliency to intermittent
   runtime timing errors.},
DOI = {10.1109/SCC.2018.00048},
ISSN = {2474-8137},
EISSN = {2474-2473},
ISBN = {978-1-5386-7250-1},
Unique-ID = {WOS:000501731200041},
}

@article{ WOS:000504322400010,
Author = {Fang, Junhua and Chao, Pingfu and Zhang, Rong and Zhou, Xiaofang},
Title = {Integrating workload balancing and fault tolerance in distributed stream
   processing system},
Journal = {WORLD WIDE WEB-INTERNET AND WEB INFORMATION SYSTEMS},
Year = {2019},
Volume = {22},
Number = {6, SI},
Pages = {2471-2496},
Month = {NOV},
Abstract = {Distributed Stream Processing Engine (DSPE) is designed for processing
   continuous streams so as to achieve the real-time performance with low
   latency guaranteed. To satisfy such requirement, the availability and
   efficiency are the main concern of the DSPE system, which can be
   achieved by a proper design of the fault tolerance module and the
   workload balancing module, respectively. However, the inherent
   characteristics of data streams, including persistence, dynamic and
   unpredictability, pose great challenges in satisfying both properties.
   As far as we know, most of the state-of-the-art DSPE systems take either
   fault tolerance or workload balancing as its single optimization goal,
   which in turn receives a higher resource overhead or longer recovery
   time. In this paper, we combine the fault tolerance and workload
   balancing mechanisms in the DSPE to reduce the overall resource
   consumption while keeping the system interactive, high-throughput,
   scalable and highly available. Based on our data-level replication
   strategy, our method can handle the dynamic data skewness and node
   failure scenario: during the distribution fluctuation of the incoming
   stream, we rebalance the workload by selectively inactivate the data in
   high-load nodes and activate their replicas on low-load nodes to
   minimize the migration overhead within the stateful operator; when a
   fault occurs in the process, the system activates the replicas of the
   data affected to ensure the correctness while keeping the workload
   balanced. Extensive experiments on various join workloads on both
   benchmark data and real data show our superior performance compared with
   baseline systems.},
DOI = {10.1007/s11280-018-0656-0},
ISSN = {1386-145X},
EISSN = {1573-1413},
ResearcherID-Numbers = {Chao, Pingfu/AAB-4129-2021
   Zhou, Xiaofang/C-6169-2013},
ORCID-Numbers = {Chao, Pingfu/0000-0002-4892-9041
   Zhou, Xiaofang/0000-0001-6343-1455},
Unique-ID = {WOS:000504322400010},
}

@inproceedings{ WOS:000483955100020,
Author = {Wang, Yidan and Tari, Zahir and Huang, Xiaoran and Zomaya, Albert Y.},
Book-Group-Author = {Assoc Comp Machinery},
Title = {A Network-aware and Partition-based Resource Management Scheme for Data
   Stream Processing},
Booktitle = {PROCEEDINGS OF THE 48TH INTERNATIONAL CONFERENCE ON PARALLEL PROCESSING
   (ICPP 2019)},
Series = {Proceedings of the International Conference on Parallel Processing},
Year = {2019},
Note = {48th International Conference on Parallel Processing (ICPP), Univ
   Tsukuba, Ctr Computat Sci, Kyoto, JAPAN, AUG 05-08, 2019},
Organization = {Data Direct Network; NEC; AMD; Intel; Mellanox; Cray; Arm; Fujitsu;
   Marvell; Pacific Teck; Supermicro; Computat Sci KK; Intelligent Light;
   NVIDIA; ParaTools; Western Digital},
Abstract = {With the increasing demand for data-driven decision making, there is an
   urgent need for processing geographically distributed data streams in
   real-time. The existing scheduling and resource management schemes
   efficiently optimize stream processing performance with the awareness of
   resource, quality-of-service, and network traffic. However, the
   correlation between network delay and inter-operator communication
   pattern is not well-understood. In this study, we propose a
   network-aware and partition-based resource management scheme to deal
   with the ever-changing network condition and data communication in
   stream processing. The proposed approach applies operator fusion by
   considering the computational demand of individual operators and the
   inter-operator communication patterns. It maps the fused operators to
   the clustered hosts with the weighted shortest processing time
   heuristic. Meanwhile, we established a 3-dimensional coordinate system
   for prompt reflection of the network condition, real-time traffic, and
   resource availability. We evaluated the proposed approach against two
   benchmarks, and the results demonstrate the efficiency in throughput and
   resource utilization. We also conducted a case study and implemented a
   prototype system supported by the proposed approach that aims to utilize
   the stream processing paradigm for pedestrian behavior analysis. The
   prototype application estimates walking time for a given path according
   to the real crowd traffic. The promising evaluation results of
   processing performance further illustrate the efficiency of the proposed
   approach.},
DOI = {10.1145/3337821.3337870},
ISSN = {0190-3918},
ISBN = {978-1-4503-6295-5},
ResearcherID-Numbers = {Zomaya, Albert Y./G-9697-2017},
ORCID-Numbers = {Zomaya, Albert Y./0000-0002-3090-1059},
Unique-ID = {WOS:000483955100020},
}

@inproceedings{ WOS:000458720100019,
Author = {Weissbach, Manuel},
Editor = {Sill, A and Spillner, J},
Title = {Live Traffic Data Analysis Using Stream Processing},
Booktitle = {2018 IEEE/ACM INTERNATIONAL CONFERENCE ON UTILITY AND CLOUD COMPUTING
   COMPANION (UCC COMPANION)},
Series = {International Conference on Utility and Cloud Computing},
Year = {2018},
Pages = {65-70},
Note = {11th IEEE/ACM International Conference on Utility and Cloud Computing
   (UCC-Companion) / 5th IEEE/ACM International Conference on Big Data
   Computing, Applications and Technologies (BDCAT), Zurich, SWITZERLAND,
   DEC 17-20, 2018},
Organization = {IEEE; ACM; IEEE Comp Soc},
Abstract = {The increasing digitalization in the traffic infrastructure offers a
   great potential to optimize traffic flows, to save costs, and to improve
   the CO2 balance. Achieving this requires the use of scalable,
   high-performance software environments that process live traffic data
   with minimal latency. However, there are no standard solutions that work
   out of the box. Instead, technology stacks of complex components must be
   assembled, configured, and deployed from a large and heterogeneous set
   of available building blocks. Since there are no guidelines on which
   particular software to use in which configuration for specific use
   cases, it is extremely difficult to build such complex architectures
   from scratch. Nevertheless, many application areas, including traffic
   data analysis, have domain-specific requirements, which makes it
   possible to close these gaps on the basis of further research. Following
   this idea, we analyze how typical applications of traffic data analysis
   can be implemented using stream processing technologies in order to find
   reusable solutions that can be used as blueprints for the design of
   applications with similar requirements. Therefore, a number of typical
   use cases will be analyzed, implemented and benchmarked on the basis of
   various stream processing architectures. This way, specific levers are
   to be found to systematically increase the performance. Our first
   results show significant performance differences between different
   software solutions and architectures.},
DOI = {10.1109/UCC-Companion.2018.00036},
ISSN = {2373-6860},
ISBN = {978-1-7281-0359-4},
Unique-ID = {WOS:000458720100019},
}

@inproceedings{ WOS:000565234200129,
Author = {Hesse, Guenter and Matthies, Christoph and Glass, Kelvin and Huegle,
   Johannes and Uflacker, Matthias},
Book-Group-Author = {IEEE Comp Soc},
Title = {Quantitative Impact Evaluation of an Abstraction Layer for Data Stream
   Processing Systems},
Booktitle = {2019 39TH IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS
   (ICDCS 2019)},
Series = {IEEE International Conference on Distributed Computing Systems},
Year = {2019},
Pages = {1381-1392},
Note = {39th IEEE International Conference on Distributed Computing Systems
   (ICDCS), Richardson, TX, JUL 07-09, 2019},
Organization = {IEEE; IEEE Comp Soc; Univ Texas Dallas, Dept Comp Sci},
Abstract = {With the demand to process ever-growing data volumes, a variety of new
   data stream processing frameworks have been developed. Moving an
   implementation from one such system to another, e.g., for performance
   reasons, requires adapting existing applications to new interfaces.
   Apache Beam addresses these high substitution costs by providing an
   abstraction layer that enables executing programs on any of the
   supported streaming frameworks. In this paper, we present a novel
   benchmark architecture for comparing the performance impact of using
   Apache Beam on three streaming frameworks: Apache Spark Streaming,
   Apache fink, and Apache Apex. We find significant performance penalties
   when using Apache Beam for application development in the surveyed
   systems. Overall, usage of Apache Beam for the examined streaming
   applications caused a high variance of query execution times with a
   slowdown of up to a factor of 58 compared to queries developed without
   the abstraction layer. All developed benchmark artifacts are publicly
   available to ensure reproducible results.},
DOI = {10.1109/ICDCS.2019.00138},
ISSN = {1063-6927},
ISBN = {978-1-7281-2519-0},
ResearcherID-Numbers = {Hesse, Guenter/AAL-2264-2020},
ORCID-Numbers = {Hesse, Guenter/0000-0002-7634-3021},
Unique-ID = {WOS:000565234200129},
}

@inproceedings{ WOS:000765039800007,
Author = {Sharkova, Darya and Chernokoz, Alexander and Trofimov, Artem and
   Sokolov, Nikita and Gorshkova, Ekaterina and Kuralenok, Igor and
   Novikov, Boris},
Editor = {Fletcher, G and Nakano, K and Sasaki, Y},
Title = {Adaptive SQL Query Optimization in Distributed Stream Processing: A
   Preliminary Study},
Booktitle = {SOFTWARE FOUNDATIONS FOR DATA INTEROPERABILITY, SFDI 2021},
Series = {Communications in Computer and Information Science},
Year = {2022},
Volume = {1457},
Pages = {96-109},
Note = {5th International Workshop on Software Foundations for Data
   Interoperability (SFDI), Copenhagen, DENMARK, AUG 16, 2021},
Abstract = {Distributed stream processing is widely adopted for real-time data
   analysis and management. SQL is becoming a common language for robust
   streaming analysis due to the introduction of time-varying relations and
   event time semantics. However, query optimization in state-of-the-art
   stream processing engines (SPEs) remains limited: runtime adjustments to
   execution plans are not applied. This fact restricts the optimization
   capabilities because SPEs lack the statistical data properties before
   query execution begins. Moreover, streaming queries are often
   long-lived, and these properties can change over time.
   Adaptive optimization, used in databases for queries with insufficient
   or unknown data statistics, can fit the streaming scenario. In this
   work, we explore the main challenges that SPEs face during the
   adjustment of adaptive optimization, such as predicting statistical
   properties of streams and execution graph migration. We demonstrate
   potential performance gains of our approach within an extension of the
   NEXMark streaming benchmark and outline our further work.},
DOI = {10.1007/978-3-030-93849-9\_7},
ISSN = {1865-0929},
EISSN = {1865-0937},
ISBN = {978-3-030-93849-9; 978-3-030-93848-2},
ResearcherID-Numbers = {Novikov, Boris/A-5213-2017},
ORCID-Numbers = {Novikov, Boris/0000-0003-4657-0757},
Unique-ID = {WOS:000765039800007},
}

@inproceedings{ WOS:000414279000016,
Author = {Bilal, Muhammad and Canini, Marco},
Book-Group-Author = {ACM},
Title = {Towards Automatic Parameter Tuning of Stream Processing Systems},
Booktitle = {PROCEEDINGS OF THE 2017 SYMPOSIUM ON CLOUD COMPUTING (SOCC `17)},
Year = {2017},
Pages = {189-200},
Note = {Symposium on Cloud Computing (SoCC), Santa Clara, CA, SEP 24-27, 2017},
Organization = {Assoc Comp Machinery; ACM SIGMOD; ACM SIGOPS},
Abstract = {Optimizing the performance of big-data streaming applications has become
   a daunting and time-consuming task: parameters may be tuned from a space
   of hundreds or even thousands of possible configurations. In this paper,
   we present a framework for automating parameter tuning for
   stream-processing systems. Our framework supports standard black-box
   optimization algorithms as well as a novel gray-box optimization
   algorithm. We demonstrate the multiple benefits of automated parameter
   tuning in optimizing three benchmark applications in Apache Storm. Our
   results show that a hill-climbing algorithm that uses a new heuristic
   sampling approach based on Latin Hypercube provides the best results.
   Our gray-box algorithm provides comparable results while being two to
   five times faster.},
DOI = {10.1145/3127479.3127492},
ISBN = {978-1-4503-5028-0},
ResearcherID-Numbers = {Canini, Marco/AAE-3229-2022},
ORCID-Numbers = {Canini, Marco/0000-0002-5051-4283},
Unique-ID = {WOS:000414279000016},
}

@inproceedings{ WOS:000413691000014,
Author = {HoseinyFarahabady, MohammadReza and Zomaya, Albert Y. and Tari, Zahir},
Book-Group-Author = {IEEE},
Title = {QoS- and Contention- Aware Resource Provisioning in a Stream Processing
   Engine},
Booktitle = {2017 IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPUTING (CLUSTER)},
Series = {IEEE International Conference on Cluster Computing},
Year = {2017},
Pages = {137-146},
Note = {IEEE International Conference on Cluster Computing (CLUSTER), Honolulu,
   HI, SEP 05-08, 2017},
Organization = {IEEE; IEEE Comp Soc; SIGPHC},
Abstract = {This paper addresses the shared resource contention problem associated
   with the auto-parallelization of running queries in distributed stream
   processing engines. In such platforms, analyzing a large amount of data
   often requires to execute user-defined queries over continues raw-inputs
   in a parallel fashion at each single host. However, previous studies
   showed that the collocated applications can fiercely compete for shared
   resources, resulting in a severe performance degradation among
   applications. This paper presents an advanced resource allocation
   strategy for handling scenarios in which the target applications have
   different quality of service (QoS) requirements while shared-resource
   interference is considered as a key performance-limiting parameter.
   To properly allocate the best possible resource to each query, the
   proposed controller predicts the performance degradation of the running
   pane-level as well as the window-level queries when co-running with
   other queries. This is addressed as an optimization problem where a set
   of cost functions is defined to achieve the following goals: a) reduce
   the sum of QoS violation incidents over all machines; b) keep the CPU
   utilization level within an accepted range; and c) avoid fierce shared
   resource interference among collocated applications. Particle swarm
   optimization is used to find an acceptable solution at each round of the
   controlling period. The performance of the proposed solution is
   benchmarked with Round-Robin and best-effort strategies, and the
   experimental results clearly demonstrate that the proposed controller
   has the following advantages over its opponents: it increases the
   overall resource utilization by 15\% on average while can reduce the
   average tuple latencies by 14\%. It also achieves an average 123\%
   improvement in preventing QoS violation incidents.},
DOI = {10.1109/CLUSTER.2017.21},
ISSN = {1552-5244},
ISBN = {978-1-5386-2326-8},
ResearcherID-Numbers = {Zomaya, Albert Y./G-9697-2017
   HoseinyFarahabady, M.Reza/H-4571-2013},
ORCID-Numbers = {Zomaya, Albert Y./0000-0002-3090-1059
   HoseinyFarahabady, M.Reza/0000-0002-7851-9377},
Unique-ID = {WOS:000413691000014},
}

@article{ WOS:000415405200004,
Author = {Esteves, Sergio and Janssens, Nico and Theeten, Bart and Veiga, Luis},
Title = {Empowering Stream Processing through Edge Clouds},
Journal = {SIGMOD RECORD},
Year = {2017},
Volume = {46},
Number = {3},
Pages = {23-28},
Month = {SEP},
Abstract = {CHive is a new streaming analytics platform to run distributed SQL-style
   queries on edge clouds. However, CHive is currently tightly coupled to a
   specific stream processing system (SPS), Apache Storm. In this paper we
   address the decoupling of the CHive query planner and optimizer from the
   runtime environment, and also extend the latter to support pluggable
   runtimes through a common API. As runtimes, we currently support Apache
   Spark and Flink streaming. The fundamental contribution of this paper is
   to assess the cost of employing interstream parallelism in SPS.
   Experimental evaluation indicates that we can enable popular SPS to be
   distributed on edge clouds with stable overhead in terms of throughput.},
ISSN = {0163-5808},
EISSN = {1943-5835},
ResearcherID-Numbers = {Veiga, Luís/AAM-2929-2020},
ORCID-Numbers = {Veiga, Luís/0000-0002-9285-0736},
Unique-ID = {WOS:000415405200004},
}

@inproceedings{ WOS:000649540400007,
Author = {Pagliari, Alessio and Huet, Fabrice and Urvoy-Keller, Guillaume},
Editor = {Lefevre, L and Varela, CA and Pallis, G and Toosi, AN and Rana, O and Buyya, R},
Title = {NAMB: A Quick and Flexible Stream Processing Application Prototype
   Generator},
Booktitle = {2020 20TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND
   INTERNET COMPUTING (CCGRID 2020)},
Year = {2020},
Pages = {61-70},
Note = {20th IEEE/ACM International Symposium on Cluster, Cloud and Internet
   Computing (CCGrid), Melbourne, AUSTRALIA, MAY 11-14, 2020},
Organization = {IEEE; Assoc Comp Machinery; IEEE Comp Soc; IEEE Tech Comm Scalable Comp},
Abstract = {The importance of Big Data is nowadays established, both in industry and
   research fields, especially stream processing for its capability to
   analyze continuous data streams and provide statistics in real-time.
   Several data stream processing (DSP) platforms exist like the Storm,
   Flink, Spark Streaming and Heron Apache projects, or industrial products
   such as Google MillWheel. Usually, each platform is tested and analyzed
   using either specifically crafted benchmarks or realistic applications.
   Unfortunately, these applications are only briefly described and their
   source code is generally not available. Hence, making quick evaluations
   often involves rewriting complete applications on different platforms.
   The lack of a generic prototype application also makes it difficult for
   a developer to quickly evaluate the impact of some design choices.
   To address these issues, we present NAMB (Not only A Micro-Benchmark), a
   generic application prototype generator for DSP platforms. Given a
   high-level description of a stream processing application and its
   workload, NAMB automatically generates the code for different platforms.
   It features a flexible architecture which makes it easy to support new
   platforms. We demonstrate the benefits of our proposal to quickly
   generate application prototypes as well as benchmarks used in published
   papers. Overall, our approach provides easily replicable, comparable and
   customizable prototypes for data stream platforms. Moreover, NAMB
   provides similar performance in terms of latency and throughput to
   existing benchmarks, while only requiring a simple high-level
   description.},
DOI = {10.1109/CCGrid49817.2020.00-87},
ISBN = {978-1-7281-6095-5},
Unique-ID = {WOS:000649540400007},
}

@article{ WOS:000503818800036,
Author = {Lombardi, Federico and Muti, Andrea and Aniello, Leonardo and Baldoni,
   Roberto and Bonomi, Silvia and Querzoni, Leonardo},
Title = {PASCAL: An architecture for proactive auto-scaling of distributed
   services},
Journal = {FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE},
Year = {2019},
Volume = {98},
Pages = {342-361},
Month = {SEP},
Abstract = {One of the main characteristics that today makes cloud services so
   popular is their ability to be elastic, i.e., they can adapt their
   provisioning to variable workloads, thus increasing resource utilization
   and reducing operating costs. At the core of any elastic service lies an
   automatic scaling mechanism that drives provisioning on the basis of a
   given strategy. In this paper we propose PASCAL, an architecture for
   Proactive Auto-SCALing of generic distributed services. PASCAL combines
   a proactive approach, to forecast incoming workloads, with a profiling
   system, to estimate required provision. Scale-in/out operations are
   decided according to an application-specific strategy, which aims at
   provisioning the minimum number of resources needed to sustain the
   foreseen workload. The main novelties introduced with PASCAL
   architecture are: (i) a strategy to proactively auto-scale a distributed
   stream processing system (namely, Apache Storm) with the aim of load
   balancing operators through an accurate system performance estimation
   model, and (ii) a strategy to proactively auto-scale a distributed
   datastore (namely, Apache Cassandra), focused on how to choose when
   executing scaling actions on the basis of the time needed for the
   activation/deactivation of storage nodes so as to have the configuration
   ready when needed. We provide a prototype implementation of PASCAL for
   both use cases and, through an experimental evaluation conducted on a
   private cloud, we validate our approach and demonstrate the
   effectiveness of the proposed strategies in terms of saved resources and
   response time. (C) 2019 Elsevier B.V. All rights reserved.},
DOI = {10.1016/j.future.2019.03.003},
ISSN = {0167-739X},
EISSN = {1872-7115},
ResearcherID-Numbers = {LOMBARDI, FEDERICO/ABG-2250-2021
   Querzoni, Leonardo/AAO-4561-2020
   Querzoni, Leonardo/AAX-7828-2021
   },
ORCID-Numbers = {LOMBARDI, FEDERICO/0000-0001-6463-8722
   Querzoni, Leonardo/0000-0002-8711-4216
   BONOMI, Silvia/0000-0001-9928-5357
   ANIELLO, LEONARDO/0000-0003-2886-8445},
Unique-ID = {WOS:000503818800036},
}

@inproceedings{ WOS:000485172700016,
Author = {Rodrigo, Arosha and Dayarathna, Miyuru and Jayasena, Sanath},
Editor = {Li, G and Yang, J and Gama, J and Natwichai, J and Tong, Y},
Title = {Privacy Preserving Elastic Stream Processing with Clouds Using
   Homomorphic Encryption},
Booktitle = {DATABASE SYSTEMS FOR ADVANCED APPLICATIONS (DASFAA 2019), PT II},
Series = {Lecture Notes in Computer Science},
Year = {2019},
Volume = {11447},
Pages = {264-280},
Note = {24th International Conference on Database Systems for Advanced
   Applications (DASFAA), Chiang Mai, THAILAND, APR 22-25, 2019},
Abstract = {Prevalence of the Infrastructure as a Service (IaaS) clouds has enabled
   organizations to elastically scale their stream processing applications
   to public clouds. However, current approaches for elastic stream
   processing do not consider the potential security vulnerabilities in
   cloud environments. In this paper we describe the design and
   implementation of an Elastic Switching Mechanism for data stream
   processing which is based on Homomorphic Encryption (HomoESM). The
   HomoESM not only does elastically scale data stream processing
   applications into public clouds but also preserves the privacy of such
   applications. Using a real world test setup, which includes an email
   filter benchmark and a web server access log processor benchmark (EDGAR)
   we demonstrate the effectiveness of our approach. Multiple experiments
   on Amazon EC2 indicate that the proposed approach for Homomorphic
   encryption provides significant results which is 10\% to 17\%
   improvement of average latency in the case of email filter benchmark and
   EDGAR benchmarks respectively. Furthermore, EDGAR add/ subtract
   operations and comparison operations showed 6.13\% and 26.17\% average
   latency improvements respectively. These promising results pave the way
   for real world deployments of privacy preserving elastic stream
   processing in the cloud.},
DOI = {10.1007/978-3-030-18579-4\_16},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-030-18579-4; 978-3-030-18578-7},
ResearcherID-Numbers = {Jayasena, Sanath/GXV-8641-2022},
Unique-ID = {WOS:000485172700016},
}

@inproceedings{ WOS:000264876000045,
Author = {Liang, Cao and Huang, Xinming},
Book-Group-Author = {IEEE},
Title = {SMARTCELL: A POWER-EFFICIENT RECONFIGURABLE ARCHITECTURE FOR DATA
   STREAMING APPLICATIONS},
Booktitle = {2008 IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS: SIPS 2008, PROCEEDINGS},
Series = {IEEE Workshop on Signal Processing Systems},
Year = {2008},
Pages = {257-262},
Note = {IEEE Workshop on Signal Processing Systems, Washington, DC, OCT 08-10,
   2008},
Organization = {IEEE; IEEE Signal Proc Soc; IEEE Circuits \& Syst Soc},
Abstract = {This paper presents SmartCell as a novel power efficient reconfigurable
   architecture targeted for data streaming applications. We describe the
   design details of the SmartCell architecture, including processing
   element, reconfigurable interconnection fabrics, instruction and control
   process and dynamic configuration scheme. The performance in terms of
   power efficiency and system throughput is evaluated through a set of
   benchmark applications, and is compared with ASIC, FPGA and RaPiD
   reconfigurable architecture. The results show that the SmartCell
   consumes about 52\% and 75\% less power than RaPiD and FPGA,
   respectively. It is demonstrated that SmartCell is a promising
   reconfigurable, power efficient and scalable computing architecture that
   can potentially bridge the gap between logic specific ASIC and
   configurable FPGA for data streaming applications.},
DOI = {10.1109/SIPS.2008.4671772},
ISSN = {1520-6130},
ISBN = {978-1-4244-2923-3},
Unique-ID = {WOS:000264876000045},
}

@inproceedings{ WOS:000811810900023,
Author = {Wecel, Krzysztof and Szmydt, Marcin and Strozyna, Milena},
Editor = {Abramowicz, W and Auer, S and Lewanska, E},
Title = {Stream Processing Tools for Analyzing Objects in Motion Sending
   High-Volume Location Data},
Booktitle = {24TH INTERNATIONAL CONFERENCE ON BUSINESS INFORMATION SYSTEMS (BIS):
   ENTERPRISE KNOWLEDGE AND DATA SPACES},
Year = {2021},
Pages = {257-268},
Note = {24th International Conference on Business Information Systems (BIS),
   ELECTR NETWORK, JUN 14-17, 2021},
Abstract = {Recently we observe a significant increase in the amount of easily
   accessible data on transport and mobility. This data is mostly massive
   streams of high velocity, magnitude, and heterogeneity, which represent
   a flow of goods, shipments and the movements of fleet. It is therefore
   necessary to develop a scalable framework and apply tools capable of
   handling these streams. In the paper we propose an approach for the
   selection of software for stream processing solutions that may be used
   in the transportation domain. We provide an overview of potential stream
   processing technologies, followed by the method for choosing the
   selected software for real-time analysis of data streams coming from
   objects in motion. We have selected two solutions: Apache Spark
   Streaming and Apache Flink, and benchmarked them on a real-world task.
   We identified the caveats and challenges when it comes to implementation
   of the solution in practice.},
DOI = {10.52825/bis.v1i.41},
ORCID-Numbers = {Wecel, Krzysztof/0000-0001-5641-3160},
Unique-ID = {WOS:000811810900023},
}

@article{ WOS:000875805600001,
Author = {Loff, Junior and Hoffmann, Renato B. and Pieper, Ricardo and Griebler,
   Dalvan and Fernandes, Luiz G.},
Title = {DSParLib: A C plus plus Template Library for Distributed Stream
   Parallelism},
Journal = {INTERNATIONAL JOURNAL OF PARALLEL PROGRAMMING},
Abstract = {Stream processing applications deal with millions of data items
   continuously generated over time. Often, they must be processed in
   real-time and scale performance, which requires the use of distributed
   parallel computing resources. In C/C++, the current state-of-the-art for
   distributed architectures and High-Performance Computing is Message
   Passing Interface (MPI). However, exploiting stream parallelism using
   MPI is complex and error-prone because it exposes many low-level details
   to the programmer. In this work, we introduce a new parallel programming
   abstraction for implementing distributed stream parallelism named
   DSParLib. Our abstraction of MPI simplifies parallel programming by
   providing a pattern-based and building block-oriented development to
   inter-connect, model, and parallelize data streams found in modern
   applications. Experiments conducted with five different stream
   processing applications and the representative PARSEC Ferret benchmark
   revealed that DSParLib is efficient and flexible. Also, DSParLib
   achieved similar or better performance, required less coding, and
   provided simpler abstractions to express parallelism with respect to
   handwritten MPI programs.},
DOI = {10.1007/s10766-022-00737-2},
EarlyAccessDate = {OCT 2022},
ISSN = {0885-7458},
EISSN = {1573-7640},
Unique-ID = {WOS:000875805600001},
}

@inproceedings{ WOS:000684175200016,
Author = {Jonathan, Albert and Chandra, Abhishek and Weissman, Jon},
Book-Group-Author = {ACM},
Title = {WASP: Wide-area Adaptive Stream Processing},
Booktitle = {PROCEEDINGS OF THE 2020 21ST INTERNATIONAL MIDDLEWARE CONFERENCE
   (MIDDLEWARE `20)},
Year = {2020},
Pages = {221-235},
Note = {21st International Middleware Conference (Middleware), ELECTR NETWORK,
   DEC 07-11, 2020},
Organization = {Assoc Comp Machinery; IFIP; Usenix; TU Delft},
Abstract = {Adaptability is critical for stream processing systems to ensure stable,
   low-latency, and high-throughput processing of long-running queries.
   Such adaptability is particularly challenging for wide-area stream
   processing due to the highly dynamic nature of the wide-area
   environment, which includes unpredictable workload patterns, variable
   network bandwidth, occurrence of stragglers, and failures.
   Unfortunately, existing adaptation techniques typically achieve these
   performance goals by compromising the quality/accuracy of the results,
   and they are often application-dependent. In this work, we rethink the
   adaptability property of wide-area stream processing systems and propose
   a resource-aware adaptation framework, called WASP. WASP adapts queries
   through a combination of multiple techniques: task re-assignment,
   operator scaling, and query re-planning, and applies them in a WAN-aware
   manner. It is able to automatically determine which adaptation action to
   take depending on the type of queries, dynamics, and optimization goals.
   We have implemented a WASP prototype on Apache Flink Experimental
   evaluation with the YSB benchmark and a real Twitter trace shows that
   WASP can handle various dynamics without compromising the quality of the
   results.},
DOI = {10.1145/3423211.3425668},
ISBN = {978-1-4503-8153-6},
Unique-ID = {WOS:000684175200016},
}

@inproceedings{ WOS:000426971900041,
Author = {Wang, Yidan and Tari, Zahir and HoseinyFarahabady, M. Reza and Zomaya,
   Albert Y.},
Editor = {Gkoulalasdivanis, A and Correia, MP and Avresky, DR},
Title = {QoS-aware Resource Allocation for Stream Processing Engines using
   Priority Channels},
Booktitle = {2017 IEEE 16TH INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND
   APPLICATIONS (NCA)},
Year = {2017},
Pages = {271-279},
Note = {IEEE 16th International Symposium on Network Computing and Applications
   (NCA), Cambridge, MA, OCT 30-NOV 01, 2017},
Organization = {IEEE Tech Committee Distributed Processing; Akamai Technologies Inc; Int
   Res Institute Autonomic Network Computing; IEEE Computer Soc},
Abstract = {This paper addresses the challenging problem of guaranteeing
   quality-of-service (QoS) requirements associated with parallel running
   queries in distributed stream processing engines. In such platforms, the
   real-time processing of streaming data often requires executing a set of
   user-defined queries over continues data flows. However, previous
   studies showed that guaranteeing QoS enforcement (such as end-to-end
   response time) for a collection of applications is a complex problem.
   This paper presents an advanced resource allocation strategy to tackle
   such a problem by considering the traffic pattern of individual data
   streams. To properly allocate resource for streaming queries execution,
   we define a certain number of priority channels to categorize the
   streaming data across the system. The resource allocation is addressed
   as an optimization problem where a set of cost functions is defined to
   achieve the following goals: a) reduce the sum of QoS violation
   incidents across all applications; b) increase the CPU utilization
   level, and (c) avoid the additional costs caused by frequent
   reconfigurations. The proposed solution does not depend on any
   assumption about the incoming data rate or the query processing time.
   The performance of the proposed solution is benchmarked, and the
   experimental results reveal that the proposed scheme increases the
   overall resource utilization by 23\% on average and reduces the QoS
   violations by 29\% against round-robin strategy. It could also prevent
   QoS violation incidents at different levels by tuning the cost function.},
ISBN = {978-1-5386-1465-5},
ResearcherID-Numbers = {Zomaya, Albert Y./G-9697-2017
   HoseinyFarahabady, M.Reza/H-4571-2013},
ORCID-Numbers = {Zomaya, Albert Y./0000-0002-3090-1059
   HoseinyFarahabady, M.Reza/0000-0002-7851-9377},
Unique-ID = {WOS:000426971900041},
}

@inproceedings{ WOS:000662554702043,
Author = {Stein, Oliver and Blamey, Ben and Karlsson, Johan and Sabirsh, Alan and
   Spjuth, Ola and Hellander, Andreas and Toor, Salman},
Editor = {Wu, XT and Jermaine, C and Xiong, L and Hu, XH and Kotevska, O and Lu, SY and Xu, WJ and Aluru, S and Zhai, CX and Al-Masri, E and Chen, ZY and Saltz, J},
Title = {Smart Resource Management for Data Streaming using an Online Bin-packing
   Strategy},
Booktitle = {2020 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)},
Series = {IEEE International Conference on Big Data},
Year = {2020},
Pages = {2207-2216},
Note = {8th IEEE International Conference on Big Data (Big Data), ELECTR
   NETWORK, DEC 10-13, 2020},
Organization = {IEEE; IEEE Comp Soc; IBM; Ankura},
Abstract = {Data stream processing frameworks provide reliable and efficient
   mechanisms for executing complex workflows over large datasets. A common
   challenge for the majority of currently available streaming frameworks
   is efficient utilization of resources. Most frameworks use static or
   semi-static settings for resource utilization that work well for
   established use cases but lead to marginal improvements for unseen
   scenarios. Another pressing issue is the efficient processing of large
   individual objects such as images and matrices typical for scientific
   datasets. HarmonicIO has proven to be a good solution for streams of
   relatively large individual objects, as demonstrated in a benchmark
   comparison with the Apache Spark and Kafka streaming frameworks. We here
   present an extension of the HarmonicIO framework based on the online
   bin-packing algorithm. The main focus is to compare different strategies
   adapted in streaming frameworks for efficient resource utilization.
   Based on a real world use case from large-scale microscopy pipelines, we
   compare two different strategies of auto-scaling implemented in the
   HarmonicIO and Spark Streaming frameworks.},
DOI = {10.1109/BigData50022.2020.9378241},
ISSN = {2639-1589},
ISBN = {978-1-7281-6251-5},
ResearcherID-Numbers = {Blamey, Ben/AAP-8222-2020},
ORCID-Numbers = {Blamey, Ben/0000-0003-1206-1428},
Unique-ID = {WOS:000662554702043},
}

@inproceedings{ WOS:000380516200040,
Author = {Lohrmann, Bjoern and Janacik, Peter and Kao, Odej},
Book-Group-Author = {IEEE},
Title = {Elastic Stream Processing with Latency Guarantees},
Booktitle = {2015 IEEE 35TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS},
Series = {IEEE International Conference on Distributed Computing Systems},
Year = {2015},
Pages = {399-410},
Note = {2015 IEEE 35th International Conference on Distributed Computing
   Systems, Ohio State Univ, Columbus, OH, JUN 29-JUL 02, 2015},
Abstract = {Many Big Data applications in science and industry have arisen, that
   require large amounts of streamed or event data to be analyzed with low
   latency. This paper presents a reactive strategy to enforce latency
   guarantees in data flows running on scalable Stream Processing Engines
   (SPEs), while minimizing resource consumption. We introduce a model for
   estimating the latency of a data flow, when the degrees of parallelism
   of the tasks within are changed. We describe how to continuously measure
   the necessary performance metrics for the model, and how it can be used
   to enforce latency guarantees, by determining appropriate scaling
   actions at runtime. Therefore, it leverages the elasticity inherent to
   common cloud technology and cluster resource management systems. We have
   implemented our strategy as part of the Nephele SPE. To showcase the
   effectiveness of our approach, we provide an experimental evaluation on
   a large commodity cluster, using both a synthetic workload as well as an
   application performing real-time sentiment analysis on real-world social
   media data.},
DOI = {10.1109/ICDCS.2015.48},
ISSN = {1063-6927},
ISBN = {978-1-4673-7214-5},
Unique-ID = {WOS:000380516200040},
}

@article{ WOS:000658339200008,
Author = {Runsewe, Olubisi and Samaan, Nancy},
Title = {Cloud Resource Scaling for Time-Bounded and Unbounded Big Data Streaming
   Applications},
Journal = {IEEE TRANSACTIONS ON CLOUD COMPUTING},
Year = {2021},
Volume = {9},
Number = {2},
Pages = {504-517},
Month = {APR-JUN},
Abstract = {Recent advancements in technology have led to a deluge of big data
   streams that require real-time analysis with strict latency constraints.
   A major challenge, however, is determining the amount of resources
   required by applications processing these streams given their high
   volume, velocity and variety. The majority of research efforts on
   resource scaling in the cloud are investigated from the cloud provider's
   perspective with little consideration for multiple resource bottlenecks.
   We aim at analyzing the resource scaling problem from an application
   provider's point of view such that efficient scaling decisions can be
   made. This paper provides two contributions to the study of resource
   scaling for big data streaming applications in the cloud. First, we
   present a Layered Multi-dimensional Hidden Markov Model (LMD-HMM) for
   managing time-bounded streaming applications. Second, to cater to
   unbounded streaming applications, we propose a framework based on a
   Layered Multi-dimensional Hidden Semi-Markov Model (LMD-HSMM). The
   parameters in our models are evaluated using modified Forward and
   Backward algorithms. Our detailed experimental evaluation results show
   that LMD-HMM is very effective with respect to cloud resource prediction
   for bounded streaming applications running for shorter periods while the
   LMD-HSMM accurately predicts the resource usage for streaming
   applications running for longer periods.},
DOI = {10.1109/TCC.2018.2876242},
ISSN = {2168-7161},
Unique-ID = {WOS:000658339200008},
}

@inproceedings{ WOS:000275708000003,
Author = {Brito, Andrey and Fetzer, Christof and Felber, Pascal},
Book-Group-Author = {IEEE Computer Soc},
Title = {Multithreading-Enabled Active Replication for Event Stream Processing
   Operators},
Booktitle = {2009 28TH IEEE INTERNATIONAL SYMPOSIUM ON RELIABLE DISTRIBUTED SYSTEMS,
   PROCEEDINGS},
Series = {Symposium on Reliable Distributed Systems Proceedings},
Year = {2009},
Pages = {22+},
Note = {28th IEEE International Symposium on Reliable Distributed Systems,
   Niagara Falls, NY, SEP 27-30, 2009},
Organization = {IEEE Comp Soc, TCDC},
Abstract = {Event Stream Processing (ESP) systems are very popular in monitoring
   applications. Algorithmic trading, network monitoring and sensor
   networks are good examples of applications that rely upon ESP systems.
   As these systems become larger and more widely deployed, they have to
   answer increasingly stronger requirements that are often difficult to
   satisfy. Fault-tolerance is a good example of such a non-trivial
   requirement. Making ESP operators fault-tolerant can add considerable
   performance overhead to the application. In this paper, we focus on
   active replication as an approach to provide fault-tolerance to ESP
   operators. More precisely, we address the performance costs of active
   replication for operators in distributed ESP applications. We use a
   speculation mechanism based on Software Transactional Memory (STM) to
   achieve the following goals: (i) enable replicas to make progress using
   optimistic delivery; (ii) enable early forwarding of speculative
   computation results; (m) enable active replication of multi-threaded
   operators using transactional executions. Experimental evaluation shows
   that, using this combination of mechanisms, one can implement highly
   efficient fault-tolerant ESP operators.},
DOI = {10.1109/SRDS.2009.37},
ISSN = {1060-9857},
EISSN = {2575-8462},
ISBN = {978-0-7695-3826-6},
ORCID-Numbers = {Felber, Pascal/0000-0003-1574-6721},
Unique-ID = {WOS:000275708000003},
}

@inproceedings{ WOS:000541051600075,
Author = {Loukopoulos, Thanasis and Tziritas, Nikos and Koziri, Maria and
   Stamoulis, George and Khan, Samee U. and Xu, Cheng-Zhong and Zomaya,
   Albert Y.},
Book-Group-Author = {IEEE},
Title = {Data Stream Processing at Network Edges},
Booktitle = {2018 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS (IPDPSW 2018)},
Series = {IEEE International Symposium on Parallel and Distributed Processing
   Workshops},
Year = {2018},
Pages = {657-665},
Note = {27th International Heterogeneity in Computing Workshop in conjunction
   with 32nd IEEE International Parallel and Distributed Processing
   Symposium (IPDPS), Vancouver, CANADA, MAY 21-25, 2018},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {This paper studies the problem of finding an assignment of data stream
   processing components onto servers under the objective to minimize both
   energy consumption and average delay experienced by end users within the
   system. The aforementioned problem is studied under the context of
   internet of things (IoT), where servers belonging to micro-datacenters
   are placed at network edges and thus close to data. We propose two
   algorithms to tackle the aforementioned problem taking into account
   limited server and network resources at microdatacenters. The first
   algorithm is called Delay Aware Algorithm (DA) and results in a delay
   efficient assignment without taking into account energy consumption. The
   second algorithm is called Energy Efficient and Delay Aware Algorithm
   (EFDA) and results in a both energy and delay efficient assignment of
   application processing components onto servers within the system. We
   provide an experimental evaluation to show the behavior of the proposed
   algorithms against algorithms in the literature.},
DOI = {10.1109/IPDPSW.2018.00106},
ISSN = {2164-7062},
ISBN = {978-1-5386-5555-9},
ResearcherID-Numbers = {XU, CHENGZHONG/AAX-1707-2020
   Stamoulis, Georgios/AAP-3076-2021
   Koziri, Maria/AAY-6435-2020
   Zomaya, Albert Y./G-9697-2017
   Khan, Samee U./AAA-3302-2019},
ORCID-Numbers = {XU, CHENGZHONG/0000-0001-9480-0356
   Zomaya, Albert Y./0000-0002-3090-1059
   Khan, Samee U./0000-0001-8650-4354},
Unique-ID = {WOS:000541051600075},
}

@inproceedings{ WOS:000391251800117,
Author = {Buddhika, Thilina and Pallickara, Shrideep},
Book-Group-Author = {IEEE},
Title = {NEPTUNE: Real Time Stream Processing for Internet of Things and Sensing
   Environments},
Booktitle = {2016 IEEE 30TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM (IPDPS 2016)},
Series = {International Parallel and Distributed Processing Symposium IPDPS},
Year = {2016},
Pages = {1143-1152},
Note = {30th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS), Illinois Inst Technol, Chicago, IL, MAY 23-27, 2016},
Organization = {IEEE; IEEE Comp Soc, Tech Comm Parallel Proc; ACM SIGARCH; IEEE Comp Soc
   Tech Comm Comp Architecture; IEEE Comp Soc Tech Comm Distributed Proc},
Abstract = {Improvements in miniaturization and networking capabilities of sensors
   have contributed to the proliferation of Internet of Things (IoT) and
   continuous sensing environments. Data streams generated in such settings
   must keep pace with generation rates and be processed in real time.
   Challenges in accomplishing this include: high data arrival rates,
   buffer overflows, context-switches, and object creation overheads.
   We propose a holistic framework that addresses the CPU, memory, network,
   and kernel issues involved in stream processing. Our prototype, Neptune,
   builds on our Granules cloud runtime. The framework maximizes bandwidth
   utilization in the presence of small messages via the use of buffering
   and dynamic compactions of packets based on payload entropy. Our use of
   thread-pools and batched processing reduces context switches and
   improves effective CPU utilizations. NEPTUNE alleviates memory pressure
   that can lead to swapping, page faults, and thrashing through efficient
   reuse of objects. To cope with buffer overflows we rely on flow control
   and throttling the preceding stages of a processing pipeline.
   Our benchmarks demonstrate the suitability of the Neptune and we
   contrast our performance with Apache Storm, the dominant
   stream-processing framework developed by Twitter. At a single node, we
   are able to achieve a processing rate of similar to 2 million stream
   packets per-second. In a distributed setup, we achieved a rate of
   similar to 100 million packets per-second.},
DOI = {10.1109/IPDPS.2016.43},
ISSN = {1530-2075},
ISBN = {978-1-5090-2140-6},
Unique-ID = {WOS:000391251800117},
}

@inproceedings{ WOS:000468499300051,
Author = {Zacheilas, Nikos and Dedousis, Dimitris and Kalogeraki, Vana},
Editor = {Abe, N and Liu, H and Pu, C and Hu, X and Ahmed, N and Qiao, M and Song, Y and Kossmann, D and Liu, B and Lee, K and Tang, J and He, J and Saltz, J},
Title = {Scalable Distributed Top-k Join Queries in Topic-Based Pub/ Sub Systems},
Booktitle = {2018 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)},
Series = {IEEE International Conference on Big Data},
Year = {2018},
Pages = {378-383},
Note = {IEEE International Conference on Big Data (Big Data), Seattle, WA, DEC
   10-13, 2018},
Organization = {IEEE; IEEE Comp Soc; Expedia Grp; Baidu; Squirrel AI Learning; Ankura;
   Springer},
Abstract = {In this paper, we provide a novel approach that enables the execution of
   top-k join queries over sliding windows in a way that reduces the amount
   of data that need to be analyzed by the stream processing operators. The
   main idea is that brokers individually invoke the query on their
   received messages and forward the top-k results to a stream processing
   operator that performs the merging of the results and provides to the
   end-user the final top-k results. Moreover, our system exploits the
   Bayesian Optimization technique to determine automatically the number of
   top-k results that should be provided by each broker. Our approach has
   been developed in the Kappa architecture that exploits topic-based
   scalable publish/subscribe (pub/sub) systems like Apache Kafka to
   efficiently forward the high volume of incoming messages to distributed
   processing systems (i.e., Apache Spark or Apache Flink) that perform the
   batch and stream analytics operations. Our detailed experimental
   evaluation on our local cluster illustrates that we can efficiently
   execute top-k join queries on our system with high accuracy and low
   latency.},
ISSN = {2639-1589},
ISBN = {978-1-5386-5035-6},
ResearcherID-Numbers = {Kalogeraki, Vana/ABI-1469-2020},
ORCID-Numbers = {Kalogeraki, Vana/0000-0002-6421-9947},
Unique-ID = {WOS:000468499300051},
}

@inproceedings{ WOS:000851014500006,
Author = {Eskandari, Leila and Mair, Jason and Huang, Zhiyi and Eyers, David},
Editor = {Heras, DB and Bouge, L and Mencagli, G and Jeannot, E and Sakellariou, R and Badia, RM and Barbosa, JG and Ricci, L and Scott, SL and Lankes, S and Weidendorfer, J},
Title = {A Topology and Traffic Aware Two-Level Scheduler for Stream Processing
   Systems in a Heterogeneous Cluster},
Booktitle = {EURO-PAR 2017: PARALLEL PROCESSING WORKSHOPS},
Series = {Lecture Notes in Computer Science},
Year = {2018},
Volume = {10659},
Pages = {68-79},
Note = {23rd International Conference on Parallel and Distributed Computing
   (Euro-Par), Santiago de Compostela, SPAIN, AUG 28-SEP 01, 2017},
Organization = {Univ Santiago Compostela, Centro Investigac Tecnoloxias Informac},
Abstract = {To efficiently handle a large volume of data, scheduling algorithms in
   stream processing systems need to minimise the data movement between
   communicating tasks to improve system throughput. However, finding an
   optimal scheduling algorithm for these systems is NP-hard. In this
   paper, we propose a heuristic scheduling algorithm for a heterogeneous
   cluster-T3 Scheduler-that can efficiently identify the communicating
   tasks and assign them to the same node, up to a specified level of
   utilisation for that node. Using three common micro-benchmarks and an
   evaluation using a real-world application, we demonstrate that
   T3-Scheduler outperforms current state-of-the-art scheduling algorithms,
   such as Aniello et al.'s popular `Online scheduler', improving
   throughput by 20-72\% for micro-benchmarks and 60\% for the real-world
   application.},
DOI = {10.1007/978-3-319-75178-8\_6},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-75178-8; 978-3-319-75177-1},
Unique-ID = {WOS:000851014500006},
}

@inproceedings{ WOS:000246796100011,
Author = {Ferdman, Michael and Falsafi, Babak},
Book-Group-Author = {IEEE Comp Soc},
Title = {Last-touch correlated data streaming},
Booktitle = {ISPASS 2007: IEEE INTERNATIONAL SYMPOSIUM ON PERFORMANCE ANALYSIS OF
   SYSTEMS AND SOFTWARE},
Series = {IEEE International Symposium on Performance Analysis of Systems and
   Software-ISPASS},
Year = {2007},
Pages = {105+},
Note = {IEEE International Symposium on Performance Analysis of Systems and
   Software, San Jose, CA, APR 25-27, 2007},
Organization = {IEEE Comp Soc},
Abstract = {Recent research advocates address-correlating predictors to identify
   cache block addresses for prefetch. Unfortunately, address-correlating
   predictors require correlation data storage proportional in size to a
   program's active memory footprint. As a result, current proposals for
   this class of predictor are either limited in coverage due to
   constrained on-chip storage requirements or limited in prediction look
   ahead due to long off-chip correlation data lookup.
   In this paper, we propose Last-Touch Correlated Data Streaming
   (LT-cords), a practical address-correlating predictor. The key idea of
   LT-cords is to record correlation data off chip in the order they will
   be used and stream them into a practically-sized on-chip table shortly
   before they are needed, thereby obviating the need for scalable on-chip
   tables and enabling low-latency lookup. We use cycle-accurate simulation
   of an 8-way out-of-order superscalar processor to show that: (1)
   LT-cords with 214KB of on-chip storage can achieve the same coverage as
   a last-touch predictor with unlimited storage, without sacrificing
   predictor lookahead, and (2) LT-cords improves performance by 60\% on
   average and 385\% at best in the benchmarks studied.},
DOI = {10.1109/ISPASS.2007.363741},
ISBN = {978-1-4244-1081-1},
Unique-ID = {WOS:000246796100011},
}

@article{ WOS:000441375500001,
Author = {Dolz, Manuel F. and Del Rio Astorga, David and Fernandez, Javier and
   Daniel Garcia, J. and Carretero, Jesus},
Title = {Towards Automatic Parallelization of Stream Processing Applications},
Journal = {IEEE ACCESS},
Year = {2018},
Volume = {6},
Pages = {39944-39961},
Abstract = {Parallelizing and optimizing codes for recent multi-/many-core
   processors have been recognized to be a complex task. For this reason,
   strategies to automatically transform sequential codes into parallel and
   discover optimization opportunities are crucial to relieve the burden to
   developers. In this paper, we present a compile-time framework to (semi)
   automatically find parallel patterns (Pipeline and Farm) and transform
   sequential streaming applications into parallel using GrPPI, a generic
   parallel pattern interface. This framework uses a novel pipeline
   stage-balancing technique which provides the code generator module with
   the necessary information to produce balanced pipelines. The evaluation,
   using a synthetic video benchmark and a real-world computer vision
   application, demonstrates that the presented framework is capable of
   producing parallel and optimized versions of the application. A
   comparison study under several thread-core oversubscribed conditions
   reveals that the framework can bring comparable performance results with
   respect to the Intel TBB programming framework.},
DOI = {10.1109/ACCESS.2018.2855064},
ISSN = {2169-3536},
ResearcherID-Numbers = {Sánchez, José Daniel García/I-3899-2014
   Sánchez, José Daniel García/AAB-6490-2019
   Carretero, Jesus/AAF-7996-2019
   Dolz, Manuel F./ABF-6232-2020
   },
ORCID-Numbers = {Sánchez, José Daniel García/0000-0002-1873-9706
   Sánchez, José Daniel García/0000-0002-1873-9706
   Carretero, Jesus/0000-0002-1413-4793
   Dolz, Manuel F./0000-0001-9466-3398
   RIO, DAVID DEL/0000-0003-0611-3332},
Unique-ID = {WOS:000441375500001},
}

@article{ WOS:000497517700005,
Author = {Zeuch, Steffen and Del Monte, Bonaventura and Karimov, Jeyhun and Lutz,
   Clemens and Renz, Manuel and Traub, Jonas and Bress, Sebastian and Rabl,
   Tilmann and Markl, Volker},
Title = {Analyzing Efficient Stream Processing on Modern Hardware},
Journal = {PROCEEDINGS OF THE VLDB ENDOWMENT},
Year = {2019},
Volume = {12},
Number = {5},
Pages = {516-530},
Month = {JAN},
Abstract = {Modern Stream Processing Engines (SPEs) process large data volumes under
   tight latency constraints. Many SPEs execute processing pipelines using
   message passing on shared-nothing architectures and apply a
   partition-based scale out strategy to handle high-velocity input
   streams. Furthermore, many state-of-the-art SPEs rely on a Java Virtual
   Machine to achieve platform independence and speed up system development
   by abstracting from the underlying hardware.
   In this paper, we show that taking the underlying hardware into account
   is essential to exploit modern hardware efficiently. To this end, we
   conduct an extensive experimental analysis of current SPEs and SPE
   design alternatives optimized for modern hardware. Our analysis
   highlights potential bottlenecks and reveals that state-of-the-art SPEs
   are not capable of fully exploiting current and emerging hardware
   trends, such as multi-core processors and high-speed networks. Based on
   our analysis, we describe a set of design changes to the common
   architecture of SPEs to scale up on modern hardware. We show that the
   single-node throughput can be increased by up to two orders of magnitude
   compared to state-of-the-art SPEs by applying specialized code
   generation, fusing operators, batch-style parallelization strategies,
   and optimized windowing. This speedup allows for deploying typical
   streaming applications on a single or a few nodes instead of large
   clusters.},
DOI = {10.14778/3303753.3303758},
ISSN = {2150-8097},
ResearcherID-Numbers = {Markl, Volker/AAX-1862-2020
   },
ORCID-Numbers = {Lutz, Clemens/0000-0002-6193-4734},
Unique-ID = {WOS:000497517700005},
}

@inproceedings{ WOS:000800208500019,
Author = {Jung, Kumseok and Gascon-Samson, Julien and Pattabiraman, Karthik},
Book-Group-Author = {IEEE},
Title = {OneOS: Middleware for Running Edge Computing Applications as Distributed
   POSIX Pipelines},
Booktitle = {2021 ACM/IEEE 6TH SYMPOSIUM ON EDGE COMPUTING (SEC 2021)},
Year = {2021},
Pages = {242-256},
Note = {6th ACM/IEEE Symposium on Edge Computing (SEC), ELECTR NETWORK, DEC
   14-17, 2021},
Organization = {IEEE; IEEE Comp Soc; Assoc Comp Machinery},
Abstract = {Edge computing application developers often need to employ a combination
   of software tools in order to deal with the challenges of heterogeneity
   and network dynamism. As a result, developers write extra code
   irrelevant to the core application logic, to provide interoperability
   between interacting tools. Existing software frameworks offer
   programming models and cloud-hosted services to ease the overall
   development process. However, the framework-specific APIs exacerbate the
   technology fragmentation problem, requiring developers to write more
   glue code between competing frameworks.
   In this paper, we present a middleware called OneOS, which provides a
   distributed computing environment through the standard POSIX API. OneOS
   maintains a global view of the computer network, presenting the same
   file system and process space to any user application running in the
   network. OneOS intercepts POSIX API calls and transparently handles the
   interaction with the corresponding I/O resource in the network. Using
   the OneOS Domain-Specific Language (DSL), users can distribute a legacy
   POSIX pipeline over the network. We evaluate the performance of OneOS
   against an open-source IoT Platform, ThingsJS, using an IoT stream
   processing benchmark suite, and a distributed video processing
   application. OneOS executes the programs about 3x faster than ThingsJS,
   and reduces the code size by about 25\%.},
DOI = {10.1145/3453142.3493505},
ISBN = {978-1-4503-8390-5},
Unique-ID = {WOS:000800208500019},
}

@inproceedings{ WOS:000543704600120,
Author = {Renart, Eduard Gibert and Balouek-Thomert, Daniel and Parashar, Manish},
Book-Group-Author = {IEEE},
Title = {An Edge-Based Framework for Enabling Data-Driven Pipelines for IoT
   Systems},
Booktitle = {2019 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS (IPDPSW)},
Series = {IEEE International Symposium on Parallel and Distributed Processing
   Workshops},
Year = {2019},
Pages = {885-894},
Note = {33rd IEEE International Parallel and Distributed Processing Symposium
   (IPDPS), Rio de Janeiro, BRAZIL, MAY 20-24, 2019},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {Due to the proliferation of the Internet of Things (IoT) paradigm, the
   number of devices connected to the Internet is growing. These devices
   are generating unprecedented amounts of data at the edges of the
   infrastructure. Although the generated data provides great potential,
   identifying and processing relevant data points hidden in streams of
   unimportant data, and doing this in near real time, remains a
   significant challenge. Existing stream processing platforms require the
   data to be transported to the cloud for processing, resulting in
   latencies that can prevent timely decision making or may reduce the
   amount of data processed. To tackle this problem, we designed an IoT
   Edge Framework, called R-Pulsar, that extends cloud capabilities to
   local devices and provides a programming model for deciding what, when,
   and where data get collected and processed. In this paper, we discuss
   motivating use cases and the architectural design of R-Pulsar. We have
   deployed and tested R-Pulsar on embedded devices (Raspberry Pi and
   Android phone) and present an experimental evaluation that demonstrates
   that R-Pulsar can enable timely data analytics by effectively leveraging
   edge and cloud resources.},
DOI = {10.1109/IPDPSW.2019.00146},
ISSN = {2164-7062},
ISBN = {978-1-5386-5555-9},
Unique-ID = {WOS:000543704600120},
}

@inproceedings{ WOS:000703983200091,
Author = {Mostafaei, Habib and Afridi, Shafi and Abawajy, Jemal H.},
Editor = {Lefevre, L and Patterson, S and Lee, YC and Shen, H and Ilager, S and Goudarzi, M and Toosi, AN and Buyya, R},
Title = {SNR: Network-aware Geo-Distributed Stream Analytics},
Booktitle = {21ST IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET
   COMPUTING (CCGRID 2021)},
Year = {2021},
Pages = {820-827},
Note = {21st IEEE/ACM International Symposium on Cluster, Cloud and Internet
   Computing (CCGrid), ELECTR NETWORK, MAY 10-13, 2021},
Organization = {IEEE; Assoc Comp Machinery; IEEE Comp Soc; IEEE Tech Comm Scalable Comp},
Abstract = {Emerging applications such as those running on the Internet of Things
   (IoT) devices produce constant data streams that need to be processed in
   real-time. Distributed stream processing systems (DSPs), with
   geographically distributed cluster networks interconnected via wide area
   network (WAN) links, have recently gained interest in handling these
   applications. However, these applications have stringent requirements
   such as low-latency and high bandwidth that must be guaranteed to ensure
   the quality of service (QoS). These application requirements raise
   fundamental DSPs resource management and scheduling challenge. In this
   paper, we formulate the problem of placement of worker nodes on a
   geo-distributed DSPs cluster network as a multi-criteria decision-making
   problem and propose an additive weighting-based approach to solve it.
   The proposed solution finds the trade-off among different network
   parameters and allows executing the tasks according to the desired
   performance metrics. We evaluated the proposed approach using the Yahoo!
   streaming benchmark on a testbed and compare it against mechanisms
   deployed in Apache Spark, Apache Storm, and Apache Flink. The results of
   the evaluation show that our approach improves the performance of Spark
   up to 2.2x-7.2x, Storm up to 1.2x-3.4x, and Flink up to 1.4x-3.3x
   compared to other approaches, which makes our approach useful for use in
   practical environments.},
DOI = {10.1109/CCGrid51090.2021.00100},
ISBN = {978-1-7281-9586-5},
ResearcherID-Numbers = {Mostafaei, Habib/A-4330-2012},
ORCID-Numbers = {Mostafaei, Habib/0000-0001-8282-1571},
Unique-ID = {WOS:000703983200091},
}

@inproceedings{ WOS:000275896500003,
Author = {Liu, Jiahong and Wu, Quanyuan and Liu, Wei},
Editor = {Chen, L and Liu, C},
Title = {Temporal Restriction Query Optimization for Event Stream Processing},
Booktitle = {ADVANCES IN WEB AND NETWORK TECHNOLOGIES, AND INFORMATION MANAGEMENT},
Series = {Lecture Notes in Computer Science},
Year = {2009},
Volume = {5731},
Pages = {25-35},
Note = {APWeb/WAIM 2009 International Workshops, Suzhou, PEOPLES R CHINA, APR
   02-04, 2009},
Organization = {Future Network Ctr; City Univ Hong Kong; City Appl R\&D Ctr},
Abstract = {The trend that organizations are linking Service Oriented Architecture
   (SOA) efforts closely to real-time processes makes research and
   industrial community increasingly focus on the SOA and Event Stream
   Processing (ESP) connection. ESP needs to correlate multiple continuous
   events involved in complex temporal relationship and attribute logic
   relationship to more abstract complex events in richer semantic. Due to
   high speed arrival rate of events and vast volume of registered complex
   event queries, memory consumption and incremental event query evaluation
   demand a comprehensive dedicate event stream processing framework with
   low-latency and high scalability. In this paper, we study problems of
   query optimization for ESP, especially topics on temporal restriction
   query. We first propose a framework to integrate ESP features with
   business process management and monitor. We then describe a query
   plan-based approach to efficiently execute ESP queries. Our approach
   uses algebraic conversion to efficiently handle temporal restriction
   queries, which are a key component of complex event processing, and
   computes temporal relevance condition at compile time to obtain event
   relevance time for a given expression. We demonstrate the effectiveness
   of our approach through a performance evaluation of our prototype
   implementation.},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-642-03995-9},
Unique-ID = {WOS:000275896500003},
}

@inproceedings{ WOS:000346481201180,
Author = {Dilawari, A. and Tahir, Muhammad},
Book-Group-Author = {IEEE},
Title = {Optimal Flow Splitting for Multi-Path Multi-Interface Wireless Data
   Streaming Networks},
Booktitle = {2013 IEEE 24TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE
   RADIO COMMUNICATIONS (PIMRC)},
Year = {2013},
Pages = {1878-1882},
Note = {IEEE 24th International Symposium on Personal, Indoor and Mobile Radio
   Communications (PIMRC), London, ENGLAND, SEP 08-11, 2013},
Organization = {IEEE},
Abstract = {We propose optimal flow splitting for wireless data streaming networks
   consisting of nodes that are equipped with more than one wireless
   communication interface. The objective is to efficiently distribute data
   traffic among multiple wireless interfaces, leveraging an additional
   axis of freedom capable of providing improved performance. For that
   purpose a distributed framework based on convex optimization is
   developed that achieves optimal resource utilization for multi-interface
   multi-path network configuration. Although flow splitting can be
   performed using single wireless interface, our performance evaluation
   results show an improved performance when employing multiple wireless
   interfaces. Performance evaluation results reveal that 50\% energy
   saving can be achieved when using optimal flow splitting for dual
   interface compared to single interface node architecture. In addition,
   the proposed solution is inherently robust to link outages due to the
   availability of multiple wireless interfaces. The proposed framework is
   quite flexible and can be easily extended to integrate any other
   performance parameters of interest.},
ResearcherID-Numbers = {Tahir, Muhammad/Y-8592-2019},
Unique-ID = {WOS:000346481201180},
}

@inproceedings{ WOS:000866521800003,
Author = {Zhang, Mingming and Gao, Yunjun and He, Chuan and Tan, Tianyu},
Book-Group-Author = {IEEE Comp Soc},
Title = {MicroStream: A Distributed In-memory Caching Service For Data Production},
Booktitle = {2022 IEEE 13TH INTERNATIONAL CONFERENCE ON JOINT CLOUD COMPUTING (JCC
   2022)},
Year = {2022},
Pages = {17-22},
Note = {13th IEEE International Conference on Joint Cloud Computing (JCC),
   Fremont, CA, AUG 15-18, 2022},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {Data-driven innovation and optimization have become an important
   direction for the intelligent transformation of enterprises. Data
   processing tasks have been developed and orchestrated to extract data
   insights, creating direct or indirect data dependencies between tasks or
   between tasks and the presentation layer. Traditional ETL
   (Extract-Transformation-Load) solutions share data through persistent
   storage, which has certain performance bottlenecks in hybrid cloud and
   multi-source data scenarios. In this paper, we propose MicroStream, a
   distributed data virtualization and caching middleware service.
   MicroStream shields the direct access of ETL tasks to the storage layer
   and converts batch access to the source database into micro-stream
   access. ETL jobs share data through the distributed in-memory caching of
   MicroStream. In resource-constrained scenarios, such a solution
   significantly improves the performance of data transformation while
   reducing the extra load that the transformation jobs imply on the source
   persistent layer. We present a detailed performance evaluation of
   MicroStream and show that its performance compares favorably with
   traditional database-oriented solutions.},
DOI = {10.1109/JCC56315.2022.00010},
ISBN = {978-1-6654-6285-3},
Unique-ID = {WOS:000866521800003},
}

@inproceedings{ WOS:000389517000004,
Author = {Xu, Le and Peng, Boyang and Gupta, Indranil},
Book-Group-Author = {IEEE},
Title = {Stela: Enabling Stream Processing Systems to Scale-in and Scale-out
   On-demand},
Booktitle = {PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON CLOUD ENGINEERING
   (IC2E)},
Series = {International Conference on Cloud Engineering},
Year = {2016},
Pages = {22-31},
Note = {IEEE International Conference on Cloud Engineering (IC2E), TU Berlin,
   Berlin, GERMANY, APR 04-08, 2016},
Organization = {IEEE; IEEE Comp Soc; IEEE Cloud Comp; STC Cloud Comp; TCBIS; TU Berlin},
Abstract = {The era of big data has led to the emergence of new real-time
   distributed stream processing engines like Apache Storm. We present
   Stela (STream processing ELAsticity), a stream processing system that
   supports scale-out and scale-in operations in an on-demand manner, i.e.,
   when the user requests such a scaling operation. Stela meets two goals:
   1) it optimizes post-scaling throughput, and 2) it minimizes
   interruption to the ongoing computation while the scaling operation is
   being carried out. We have integrated Stela into Apache Storm. We
   present experimental results using micro-benchmark Storm applications,
   as well as production applications from industry (Yahoo! Inc. and IBM).
   Our experiments show that compared to Apache Storm's default scheduler,
   Stela's scale-out operation achieves throughput that is 21-120\% higher,
   and interruption time that is significantly smaller. Stela's scale-in
   operation chooses the right set of servers to remove and achieves 2X-5X
   higher throughput than Storm's default strategy.},
DOI = {10.1109/IC2E.2016.38},
ISSN = {2373-3845},
ISBN = {978-1-5090-1961-8},
Unique-ID = {WOS:000389517000004},
}

@inproceedings{ WOS:000543704600113,
Author = {Rockenbach, Dinei A. and Stein, Charles M. and Griebler, Dalvan and
   Mencagli, Gabriele and Torquati, Massimo and Danelutto, Marco and
   Fernandes, Luiz G.},
Book-Group-Author = {IEEE},
Title = {Stream Processing on Multi-Cores with GPUs: Parallel Programming Models'
   Challenges},
Booktitle = {2019 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS (IPDPSW)},
Series = {IEEE International Symposium on Parallel and Distributed Processing
   Workshops},
Year = {2019},
Pages = {834-841},
Note = {33rd IEEE International Parallel and Distributed Processing Symposium
   (IPDPS), Rio de Janeiro, BRAZIL, MAY 20-24, 2019},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {The stream processing paradigm is used in several scientific and
   enterprise applications in order to continuously compute results out of
   data items coming from data sources such as sensors. The full
   exploitation of the potential parallelism offered by current
   heterogeneous multi-cores equipped with one or more GPUs is still a
   challenge in the context of stream processing applications. In this
   work, our main goal is to present the parallel programming challenges
   that the programmer has to face when exploiting CPUs and GPUs'
   parallelism at the same time using traditional programming models. We
   highlight the parallelization methodology in two use-cases (the
   Mandelbrot Streaming benchmark and the PARSEC's Dedup application) to
   demonstrate the issues and benefits of using heterogeneous parallel
   hardware. The experiments conducted demonstrate how a high-level
   parallel programming model targeting stream processing like the one
   offered by SPar can be used to reduce the programming effort still
   offering a good level of performance if compared with state-of-the-art
   programming models.},
DOI = {10.1109/IPDPSW.2019.00137},
ISSN = {2164-7062},
ISBN = {978-1-5386-5555-9},
ResearcherID-Numbers = {Griebler, Dalvan/C-2041-2017
   Fernandes, Luiz Gustavo L./N-1988-2018
   },
ORCID-Numbers = {Griebler, Dalvan/0000-0002-4690-3964
   Fernandes, Luiz Gustavo L./0000-0002-7506-3685
   Rockenbach, Dinei/0000-0002-2091-9626
   DANELUTTO, MARCO/0000-0002-7433-376X},
Unique-ID = {WOS:000543704600113},
}

@article{ WOS:000350927300011,
Author = {Yang, Dingyu and Cao, Jian and Wu, Sai and Wang, Jie},
Title = {Progressive online aggregation in a distributed stream system},
Journal = {JOURNAL OF SYSTEMS AND SOFTWARE},
Year = {2015},
Volume = {102},
Pages = {146-157},
Month = {APR},
Abstract = {Interactive query processing aims at generating approximate results with
   minimum response time. However, it is quite difficult for a
   batch-oriented processing system to progressively provide cumulatively
   accurate results in the context of a distributed environment. MapReduce
   Online extends the MapReduce framework to support online aggregation,
   but it is hindered by its processing speed in keeping up with ongoing
   real-time data events. We deploy the online aggregation algorithm over
   S4, a scalable stream processing system that is inspired by the combined
   functionalities of MapReduce and Actor model. Our system applies an
   asynchronous message communication mechanism from actor model to support
   online aggregation. It can process large scale data stream with high
   concurrency in a short response time. In this system, we adopt a
   distributed weighted random sampling algorithm to solve biased
   distribution between different streams. Furthermore, a multi-level query
   processing topology is developed to reduce overlapped processing for
   multiple queries. Our system can provide continuous window aggregation
   with a confidence interval and error bound. We have implemented our
   system and conducted plentiful experiments over the TPC-H benchmark. A
   large number of experiments are carried out to demonstrate that by using
   our system, high-quality query results can be generated within a short
   response time and that the approach outperforms MapReduce Online on data
   streams. (C) 2014 Elsevier Inc. All rights reserved.},
DOI = {10.1016/j.jss.2014.11.027},
ISSN = {0164-1212},
EISSN = {1873-1228},
Unique-ID = {WOS:000350927300011},
}

@inproceedings{ WOS:000386571900008,
Author = {Chakraborty, Rudraneel and Majumdar, Shikharesh},
Editor = {Obaidat, MS and Davoli, F and Giordano, S and Szczerbicka, H and Louta, M and Entrialgo, J and Saldana, J},
Title = {A Priority Based Resource Scheduling Technique for Multitenant Storm
   Clusters Work In Progress Paper},
Booktitle = {PROCEEDINGS OF THE 2016 INTERNATIONAL SYMPOSIUM ON PERFORMANCE
   EVALUATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS (SPECTS)},
Year = {2016},
Note = {International Symposium on Performance Evaluation of Computer and
   Telecommunication Systems (SPECTS) Part of SummerSim 2016
   Multiconference, Montreal, CANADA, JUL 24-27, 2016},
Organization = {Soc Modeling \& Simulat Int; IEEE; IEEE Commun Soc},
Abstract = {In this work in progress paper, we present our ongoing effort towards
   devising a priority based resource scheduling technique and framework
   for apache storm. Apache Storm is a popular distributed real time stream
   processing engine which has been widely adopted by key players in the
   industry including YAHOO and Twitter. An application running in storm is
   called a topology that is characterized by a Directed Acyclic Graph
   (DAG). To run multiple of such topologies in a storm cluster, storm
   provides with default, out of the box scheduler called Isolation
   Scheduler. Isolation Scheduler assigns resources to topologies based on
   static resource configuration and does not provide any means to
   prioritize topologies based on their varying business priority. As a
   result, performance degradation, even complete starvation of topologies
   with high business priority is possible when available cluster resources
   are insufficient. A priority based resource scheduling strategy is
   proposed in this paper to overcome this problem. A preliminary
   performance evaluation is performed to demonstrate effectiveness of the
   proposed scheduler over the default storm Isolation Scheduler.},
ISBN = {978-1-5108-2423-2},
Unique-ID = {WOS:000386571900008},
}

@inproceedings{ WOS:000473399100015,
Author = {Gupta, Harshit and Ramachandran, Umakishore},
Book-Group-Author = {Assoc Comp Machinery},
Title = {FogStore: A Geo-Distributed Key-Value Store Guaranteeing Low Latency for
   Strongly Consistent Access},
Booktitle = {DEBS'18: PROCEEDINGS OF THE 12TH ACM INTERNATIONAL CONFERENCE ON
   DISTRIBUTED AND EVENT-BASED SYSTEMS},
Year = {2018},
Pages = {148-159},
Note = {12th ACM International Conference on Distributed and Event-Based Systems
   (DEBS), Univ Waikato, Hamilton, NEW ZEALAND, JUN 25-29, 2018},
Organization = {ACM SIGMOD; ACM SIGSOFT},
Abstract = {We design Fogstore, a key-value store for event-based systems, that
   exploits the concept of relevance to guarantee low-latency access to
   relevant data with strong consistency guarantees, while providing
   tolerance from geographically correlated failures. Distributed
   event-based processing pipelines are envisioned to utilize the resources
   of densely geo-distributed infrastructures for low-latency responses -
   enabling real-time applications. Increasing complexity of such
   applications results in higher dependence on state, which has driven the
   incorporation of state-management as a core functionality of
   contemporary stream processing engines a la Apache Flink and Samza.
   Processing components executing under the same context (like location)
   often produce information that may be relevant to others, thereby
   necessitating shared state and an out-of-band globally-accessible
   data-store. Efficient access to application state is critical for
   overall performance, thus centralized data-stores are not a viable
   option due to the high-latency of network traversals. On the other hand,
   a highly geo-distributed datastore with low-latency implemented with
   current key-value stores would necessitate degrading client expectation
   of consistency as per the PACELC theorem. In this paper we exploit the
   notion of contextual relevance of events (data) in situation-awareness
   applications - and offer differential consistency guarantees for clients
   based on their context. We highlight important systems concerns that may
   arise with a highly geo-distributed system and show how Fogstore's
   design tackles them. We present, in detail, a prototype implementation
   of Fogstore's mechanisms on Apache Cassandra and a performance
   evaluation. Our evaluations show that Fogstore is able to achieve the
   throughput of eventually consistent configurations while serving data
   with strong consistency to the contextually relevant clients.},
DOI = {10.1145/3210284.3210297},
ISBN = {978-1-4503-5782-1},
Unique-ID = {WOS:000473399100015},
}

@inproceedings{ WOS:000704024700009,
Author = {Pieters, Ruben P. and Schrijven, Tom},
Editor = {Alferes, JJ and Johansson, M},
Title = {Faster Coroutine Pipelines: A Reconstruction},
Booktitle = {PRACTICAL ASPECTS OF DECLARATIVE LANGUAGES (PADL 2019)},
Series = {Lecture Notes in Computer Science},
Year = {2019},
Volume = {11372},
Pages = {133-149},
Note = {21st Symposium on Practical Aspects of Declarative Languages (PADL),
   Lisbon, PORTUGAL, JAN 14-15, 2019},
Abstract = {Spivey has recently presented a novel functional representation that
   supports the efficient composition, or merging, of coroutine pipelines
   for processing streams of data. This representation was inspired by
   Shivers and Might's three-continuation approach and is shown to be
   equivalent to a simple yet inefficient executable specification.
   Unfortunately, neither Shivers and Might's original work nor the
   equivalence proof sheds much light on the underlying principles allowing
   the derivation of this efficient representation from its specification.
   This paper gives the missing insight by reconstructing a systematic
   derivation in terms of known transformation steps from the simple
   specification to the efficient representation. This derivation sheds
   light on the limitations of the representation and on its applicability
   to other settings. In particular, it has enabled us to obtain a similar
   representation for pipes featuring two-way communication, similar to the
   Haskell pipes library. Our benchmarks confirm that this two-way
   representation retains the same improved performance characteristics.},
DOI = {10.1007/978-3-030-05998-9\_9},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-030-05998-9; 978-3-030-05997-2},
ORCID-Numbers = {Schrijvers, Tom/0000-0001-8771-5559},
Unique-ID = {WOS:000704024700009},
}

@inproceedings{ WOS:000286903000036,
Author = {Tournavitis, Georgios and Franke, Bjoern},
Book-Group-Author = {ACM},
Title = {Semi-Automatic Extraction and Exploitation of Hierarchical Pipeline
   Parallelism Using Profiling Information},
Booktitle = {PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON
   PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES},
Year = {2010},
Pages = {377-388},
Note = {19th International Conference on Parallel Architectures and Compilation
   Techniques, Austrian Acad Sci Vienna, Vienna, AUSTRIA, SEP 11-15, 2010},
Organization = {ACM SIGARCH; IEEE TCPP \& TCCA; IFIP WG10 3},
Abstract = {In recent years multi-core computer systems have left the realm of
   high-performance computing and virtually all of today's desktop
   computers and embedded computing systems are equipped with several
   processing cores. Still, no single parallel programming model has found
   widespread support and parallel programming remains an art for the
   majority of application programmers. In addition, there exists a
   plethora of sequential legacy applications for which automatic
   parallelization is the only hope to benefit from the increased
   processing power of modern multi-core systems. In the past automatic
   parallelization largely focused on data parallelism. In this paper we
   present a novel approach to extracting and exploiting pipeline
   parallelism from sequential applications. We use profiling to overcome
   the limitations of static data and control flow analysis enabling more
   aggressive parallelization. Our approach is orthogonal to existing
   automatic parallelization approaches and additional data parallelism may
   be exploited in the individual pipeline stages. The key contribution of
   this paper is a whole-program representation that supports profiling,
   parallelism extraction and exploitation. We demonstrate how this
   enhances conventional pipeline parallelization by incorporating support
   for multi-level loops and pipeline stage replication in a uniform and
   automatic way. We have evaluated our methodology on a set of multimedia
   and stream processing benchmarks and demonstrate speedups of up to 4.7
   on a eight-core Intel Xeon machine.},
DOI = {10.1145/1854273.1854321},
ISBN = {978-1-4503-0178-7},
ORCID-Numbers = {Franke, Bjorn/0000-0002-1219-8523},
Unique-ID = {WOS:000286903000036},
}

@inproceedings{ WOS:000584252700129,
Author = {Zhang, Shuhao and Wu, Yingjun and Zhang, Feng and He, Bingsheng},
Book-Group-Author = {IEEE},
Title = {Towards Concurrent Stateful Stream Processing on Multicore Processors},
Booktitle = {2020 IEEE 36TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE 2020)},
Series = {IEEE International Conference on Data Engineering},
Year = {2020},
Pages = {1537-1548},
Note = {IEEE 36th International Conference on Data Engineering (ICDE), Dallas,
   TX, APR 20-24, 2020},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {Recent data stream processing systems (DSPSs) can achieve excellent
   performance when processing large volumes of data under tight latency
   constraints. However, they sacrifice support for concurrent state access
   that eases the burden of developing stateful stream applications.
   Recently, some have proposed managing concurrent state access during
   stream processing by modeling state accesses as transactions. However,
   these are realized with locks involving serious contention overhead. The
   coarse-grained processing paradigm adopted in these proposals magnify
   contention issues and does not exploit modern multicore architectures to
   their full potential. This paper introduces TStream, a novel DSPS
   supporting efficient concurrent state access on multicore processors.
   Transactional semantics is employed like previous work, but scalability
   is greatly improved due to two novel designs: 1) dual-mode scheduling,
   which exposes more parallelism opportunities, 2) dynamic restructuring
   execution, which aggressively exploits the parallelism opportunities
   from dual-mode scheduling without centralized lock contentions. To
   validate our proposal, we evaluate TStream with a benchmark of four
   applications on a modern multicore machine. Experimental results show
   that 1) TStream achieves up to 4.8 times higher throughput with similar
   processing latency compared to the state-of-the-art and 2) unlike prior
   solutions, TStream is highly tolerant of varying application workloads
   such as key skewness and multi-partition state accesses.},
DOI = {10.1109/ICDE48307.2020.00136},
ISSN = {1084-4627},
ISBN = {978-1-7281-2903-7},
ORCID-Numbers = {zhang, shuhao/0000-0002-9927-6925
   He, Bingsheng/0000-0001-8618-4581},
Unique-ID = {WOS:000584252700129},
}

@inproceedings{ WOS:000521353900027,
Author = {Ndubuaku, Maryleen and Anjum, Ashiq and Liotta, Antonio},
Book-Group-Author = {IEEE},
Title = {Cloud-assisted Adaptive Stream Processing from Discriminative
   Representations},
Booktitle = {2019 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS (SMC)},
Series = {IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings},
Year = {2019},
Pages = {164-169},
Note = {IEEE International Conference on Systems, Man and Cybernetics (SMC),
   Bari, ITALY, OCT 06-09, 2019},
Organization = {IEEE},
Abstract = {As the streaming data generated by Internet of Things (IoT) ubiquitous
   sensors grow in massive scale, extracting interesting information
   (anomalies) in real-time becomes more challenging. Traditional systems
   which retrospectively perform all the processing in the cloud do not
   capture real-time changes in the data. Similarly, real-time solutions
   which rely on human monitors have the tendency to miss the anomalies due
   to their rare nature. In recent times, several machine learning
   techniques have been proposed for stream processing. Approaches based on
   supervised or semi-supervised learning fail to adapt to changing
   patterns of the streaming data and the data labelling costs are huge. To
   address these limitations, we propose a cloud-assisted framework where
   an intermediary node (edge) is introduced between the end devices and
   the cloud to assist in stream processing. A model deployed on the edge
   is designed to learn in an iterative manner to discriminate between
   similar and dissimilar data representations, making it easier to
   distinguish the anomalies. In this work, we have proposed an iterative
   method that combines the capabilities of deep clustering and
   l(2)-normalisation to achieve better discriminative representations.
   Experimental results demonstrate the proposed method achieves robust
   performance over state-of-the-art discriminative representation
   algorithms and sets new benchmark accuracy on transformation invariant
   image dataset.},
ISSN = {1062-922X},
ISBN = {978-1-7281-4569-3},
ResearcherID-Numbers = {Amaizu, Maryleen/AAD-4817-2022},
ORCID-Numbers = {Amaizu, Maryleen/0000-0002-4280-1450},
Unique-ID = {WOS:000521353900027},
}

@inproceedings{ WOS:000346498300077,
Author = {Mokhtari, Reza and Stumm, Michael},
Book-Group-Author = {IEEE},
Title = {BigKernel - High Performance CPU-GPU Communication Pipelining for Big
   Data-style Applications},
Booktitle = {2014 IEEE 28TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM},
Series = {International Parallel and Distributed Processing Symposium IPDPS},
Year = {2014},
Note = {IEEE 28th International Parallel \& Distributed Processing Symposium
   (IPDPS), Phoenix, AZ, MAY 19-23, 2014},
Organization = {IEEE},
Abstract = {GPUs offer an order of magnitude higher compute power and memory
   bandwidth than CPUs. GPUs therefore might appear to be well suited to
   accelerate computations that operate on voluminous data sets in
   independent ways; e.g., for transformations, filtering, aggregation,
   partitioning or other ``Big Data{''} style processing. Yet experience
   indicates that it is difficult, and often error-prone, to write GPGPU
   programs which efficiently process data that does not fit in GPU memory,
   partly because of the intricacies of GPU hardware architecture and
   programming models, and partly because of the limited bandwidth
   available between GPUs and CPUs.
   In this paper, we propose BigKernel, a scheme that provides
   pseudo-virtual memory to GPU applications and is implemented using a
   4-stage pipeline with automated prefetching to (i) optimize CPU-GPU
   communication and (ii) optimize GPU memory accesses. BigKernel
   simplifies the programming model by allowing programmers to write
   kernels using arbitrarily large data structures that can be partitioned
   into segments where each segment is operated on independently; these
   kernels are transformed into BigKernel using straight-forward compiler
   transformations.
   Our evaluation on six data-intensive benchmarks shows that BigKernel
   achieves an average speedup of 1.7 over state-of-the-art
   double-buffering techniques and an average speedup of 3.0 over
   corresponding multi-threaded CPU implementations.},
DOI = {10.1109/IPDPS.2014.89},
ISSN = {1530-2075},
ISBN = {978-0-7695-5207-1},
Unique-ID = {WOS:000346498300077},
}

@inproceedings{ WOS:000468511200102,
Author = {Chen, Fei and Wu, Song and Jin, Hai and Lin, Liwei and Li, Rui},
Book-Group-Author = {IEEE},
Title = {Radar: Reducing Tail Latencies for Batched Stream Processing with Blank
   Scheduling},
Booktitle = {IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND
   COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE
   4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS
   (HPCC/SMARTCITY/DSS)},
Year = {2018},
Pages = {797-804},
Note = {20th IEEE International Conference on High Performance Computing and
   Communications (HPCC) / 16th IEEE International Conference on Smart City
   (SmartCity) / 4th IEEE International Conference on Data Science and
   Systems (DSS), Exeter, ENGLAND, JUN 28-30, 2018},
Organization = {IEEE; IEEE Comp Soc; IEEE Tech Comm Scalable Comp; Univ Exeter},
Abstract = {Real time processing of stream data has become increasingly vital.
   Batched stream systems which discretize stream data into micro-batches
   and leverage batch system to process these micro-batch stream jobs have
   attracted wide attention from academia and industry. Such batched stream
   system always works on heterogeneous environments which have
   heterogeneous resources and heterogeneous tasks. Unfortunately, current
   batched stream system implementations designed and optimized for
   homogeneous environments perform poorly on heterogeneous environments.
   We attribute suboptimal performance in heterogeneous environments to
   schedule tasks according to data locality and free slots. On the one
   hand, data locality creates a barrier between large tasks of slow node
   and powerful capacity of fast node because slow nodes prefer local large
   tasks rather than remote small tasks. On another hand, due to
   scheduler's blind eye to task size, there is a very high probability
   that large tasks are scheduled in the last few waves. These two aspects
   hinder perfect load balancing, causing tail latencies of large tasks. To
   address these issues, we propose a blank scheduling framework called
   Radar. Being aware of node capacity and task size, Radar pre-steals
   large tasks from slow nodes and schedules tasks according to the
   principle of large task first. Then Radar fills the small free slots by
   choosing small tasks corresponding to node's capacity. We implement
   Radar in Spark-2.1.1. Experimental results with benchmark show that
   Radar can reduce job completion time by 27.78\% to 42.79\% over Spark
   Streaming. Experimental results with real Tencent production application
   show that Radar can reduce response time by 28.57\%.},
DOI = {10.1109/HPCC/SmartCity/DSS.2018.00134},
ISBN = {978-1-5386-6614-2},
Unique-ID = {WOS:000468511200102},
}

@inproceedings{ WOS:000399141700119,
Author = {Zaichenkov, Pavel and Gijsbers, Bert and Grelck, Clemens and Tveretina,
   Olga and Shafarenko, Alex},
Book-Group-Author = {IEEE},
Title = {A Case Study in Coordination Programming: Performance Evaluation of
   S-Net vs Intel's Concurrent Collections},
Booktitle = {PROCEEDINGS OF 2014 IEEE INTERNATIONAL PARALLEL \& DISTRIBUTED
   PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW)},
Year = {2014},
Pages = {1060-1068},
Note = {28th IEEE International Parallel \& Distributed Processing Symposium
   Workshops (IPDPSW), Phoenix, AZ, MAY 19-23, 2014},
Organization = {IEEE; IEEE Comp Soc; IEEE Comp Soc Tech Comm Parallel Proc; ACM SIGARCH;
   IEEE Comp Soc Tech Comm Comp Architecture; IEEE Comp Soc Tech Comm
   Distributed Proc},
Abstract = {We present a programming methodology and runtime performance case study
   comparing the declarative data flow coordination language S-NET with
   Intel's Concurrent Collections (CnC). As a coordination language S-NET
   achieves a near-complete separation of concerns between sequential
   software components implemented in a separate algorithmic language and
   their parallel orchestration in an asynchronous data flow streaming
   network.
   We investigate the merits of S-NET and CnC with the help of a relevant
   and non-trivial linear algebra problem: tiled Cholesky decomposition. We
   describe two alternative S-NET implementations of tiled Cholesky
   factorization and compare them with two CnC implementations, one with
   explicit performance tuning and one without, that have previously been
   used to illustrate Intel CnC. Our experiments on a 48-core machine
   demonstrate that S-NET manages to outperform CnC on this problem.},
DOI = {10.1109/IPDPSW.2014.118},
ISBN = {978-1-4799-4116-2},
ResearcherID-Numbers = {Grelck, Clemens/GYU-8487-2022},
Unique-ID = {WOS:000399141700119},
}

@inproceedings{ WOS:000584252700093,
Author = {Katsipoulakis, Nikos R. and Labrinidis, Alexandros and Chrysanthis,
   Panos K.},
Book-Group-Author = {IEEE},
Title = {SPEAr: Expediting Stream Processing with Accuracy Guarantees},
Booktitle = {2020 IEEE 36TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE 2020)},
Series = {IEEE International Conference on Data Engineering},
Year = {2020},
Pages = {1105-1116},
Note = {IEEE 36th International Conference on Data Engineering (ICDE), Dallas,
   TX, APR 20-24, 2020},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {Stream Processing Engines (SPEs) are used for real-time and continuous
   processing with stateful operations. This type of processing poses
   numerous challenges due to its associated complexity, unpredictable
   input, and need for timely results. As a result, users tend to
   overprovision resources, and online scaling is required in order to
   overcome overloaded situations. Current attempts for expediting stateful
   processing are impractical, due to their inability to uphold the quality
   of results, maintain performance, and reduce memory requirements.
   In this paper, we present the SPEAr system, which can expedite
   processing of stateful operations automatically by trading accuracy for
   performance. SPEAr detects when it can accelerate processing by
   employing online sampling and accuracy estimation at no additional cost.
   We built SPEAr on top of Storm and our experiments indicate that it can
   reduce processing times by more than an order of magnitude, use more
   than an order of magnitude less memory, and offer accuracy guarantees in
   real-world benchmarks.},
DOI = {10.1109/ICDE18307.2020.00100},
ISSN = {1084-4627},
ISBN = {978-1-7281-2903-7},
Unique-ID = {WOS:000584252700093},
}

@inproceedings{ WOS:000827652300002,
Author = {Garcia, Adriano Marques and Griebler, Dalvan and Schepke, Claudio and
   Fernandes, Luiz Gustavo L.},
Editor = {Gonzalez-Escribano, A and Garcia, JD and Torquati, M and Skavhaug, A},
Title = {Evaluating Micro-batch and Data Frequency for Stream Processing
   Applications on Multi-cores},
Booktitle = {30TH EUROMICRO INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND
   NETWORK-BASED PROCESSING (PDP 2022)},
Series = {Euromicro Conference on Parallel, Distributed and Network-Based
   Processing},
Year = {2022},
Pages = {10-17},
Note = {30th Euromicro International Conference on Parallel, Distributed and
   Network-Based Processing (PDP), ELECTR NETWORK, MAR 09-11, 2022},
Organization = {Univ Valladolid; Univ Valladolid, Dept Informatica; Euromicro},
Abstract = {In stream processing, data arrives constantly and is often
   unpredictable. It can show large fluctuations in arrival frequency,
   size, complexity, and other factors. These fluctuations can strongly
   impact application latency and throughput, which are critical factors in
   this domain. Therefore, there is a significant amount of research on
   self-adaptive techniques involving elasticity or micro-batching as a way
   to mitigate this impact. However, there is a lack of benchmarks and
   tools for helping researchers to investigate micro-batching and data
   stream frequency implications. In this paper, we extend a benchmarking
   framework to support dynamic micro-batching and data stream frequency
   management. We used it to create custom benchmarks and compare latency
   and throughput aspects from two different parallel libraries. We
   validate our solution through an extensive analysis of the impact of
   micro-batching and data stream frequency on stream processing
   applications using Intel TBB and FastFlow, which are two libraries that
   leverage stream parallelism on multi-core architectures. Our results
   demonstrated up to 33\% throughput gain over latency using
   micro-batches. Additionally, while TBB ensures lower latency, FastFlow
   ensures higher throughput in the parallel applications for different
   data stream frequency configurations.},
DOI = {10.1109/PDP55904.2022.00011},
ISSN = {1066-6192},
ISBN = {978-1-6654-6958-6},
Unique-ID = {WOS:000827652300002},
}

@inproceedings{ WOS:000426433500097,
Author = {Kazanskiy, Nikolay and Protsenko, Vladimir and Serafimovich, Pavel},
Editor = {Soifer, V and Kazanskiy, N and Korotkova, O and Sazhin, S},
Title = {Performance analysis of real-time face detection system based on stream
   data mining frameworks},
Booktitle = {3RD INTERNATIONAL CONFERENCE INFORMATION TECHNOLOGY AND NANOTECHNOLOGY
   (ITNT-2017)},
Series = {Procedia Engineering},
Year = {2017},
Volume = {201},
Pages = {806-816},
Note = {3rd International Conference on Information Technology and
   Nanotechnology (ITNT), Samara Natl Res Univ, Samara, RUSSIA, APR 25-27,
   2017},
Abstract = {This work describes performance analysis results of two face detection
   systems based on Apache Storm and IBM InfoSphere Streams frameworks.
   Profiling was evaluated on image sequences of four different sizes: 100
   x 100, 640 x 640, 1920 x 1080, and 4096 x 3112. Face detection was
   performed by OpenCV cascade classifier. Experiment was held under five
   CentOS nodes cluster. It was investigated that system based on Apache
   Storm was able to operate in real-time at 24 frames per second on used
   hardware configuration. Apache Storm was more scalable and demonstrated
   advantage in throughput over its counterpart. Experiment helped to
   reveal configuration parameters of frameworks that played a major role
   in face detection task on image sequences. (C) 2017 The Authors.
   Published by Elsevier Ltd.},
DOI = {10.1016/j.proeng.2017.09.602},
ISSN = {1877-7058},
ResearcherID-Numbers = {Serafimovich, Pavel G/A-4301-2014
   Kazanskiy, Nikolay/Q-2349-2015
   },
ORCID-Numbers = {Kazanskiy, Nikolay/0000-0002-0180-7522
   Protsenko, Vladimir/0000-0003-3107-8102},
Unique-ID = {WOS:000426433500097},
}

@article{ WOS:000437997500018,
Author = {del Rio Astorga, David and Dolz, Manuel F. and Fernandez, Javier and
   Daniel Garcia, J.},
Title = {Paving the way towards high-level parallel pattern interfaces for data
   stream processing},
Journal = {FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE},
Year = {2018},
Volume = {87},
Pages = {228-241},
Month = {OCT},
Abstract = {The emergence of the Internet of Things (IoT) data stream applications
   has posed a number of new challenges to existing infrastructures,
   processing engines, and programming models. In this sense, high-level
   interfaces, encapsulating algorithmic aspects in pattern-based
   constructions, have considerably reduced the development and
   parallelization efforts of this type of applications. An example of
   parallel pattern interface is GRPPI, a C++ generic high-level library
   that acts as a layer between developers and existing parallel
   programming frameworks, such as C++ threads, OpenMP and Intel TBB. In
   this paper, we complement the basic patterns supported by GRPPI with the
   new stream operators Split-Join and Window, and the advanced parallel
   patterns Stream-Pool, Windowed-Farm and Stream-Iterator for the
   aforementioned back ends. Thanks to these new stream operators, complex
   compositions among streaming patterns can be expressed. On the other
   hand, the collection of advanced patterns allows users to tackle some
   domain-specific applications, ranging from the evolutionary to the
   real-time computing areas, where compositions of basic patterns are not
   capable of fully mimicking the algorithmic behavior of their original
   sequential codes. The experimental evaluation of the new advanced
   patterns and the stream operators on a set of domain-specific use-cases,
   using different back ends and pattern-specific parameters, reports
   considerable performance gains with respect to the sequential versions.
   Additionally, we demonstrate the benefits of the GRPPI pattern interface
   from the usability, flexibility and readability points of view. (C) 2018
   Elsevier B.V. All rights reserved.},
DOI = {10.1016/j.future.2018.05.011},
ISSN = {0167-739X},
EISSN = {1872-7115},
ResearcherID-Numbers = {Sánchez, José Daniel García/AAB-6490-2019
   Dolz, Manuel F./ABF-6232-2020
   Sánchez, José Daniel García/I-3899-2014
   Fernandez Munoz, Javier/M-1542-2017},
ORCID-Numbers = {Sánchez, José Daniel García/0000-0002-1873-9706
   Dolz, Manuel F./0000-0001-9466-3398
   Sánchez, José Daniel García/0000-0002-1873-9706
   Fernandez Munoz, Javier/0000-0001-8539-5491},
Unique-ID = {WOS:000437997500018},
}

@article{ WOS:000559482800038,
Author = {Zhang, Yuan and Yan, Jinyao and Pu, Lingjun and Chen, Shiyu},
Title = {Dynamic Component Placement and Request Scheduling for IoT Big Data
   Streaming},
Journal = {IEEE INTERNET OF THINGS JOURNAL},
Year = {2020},
Volume = {7},
Number = {8},
Pages = {7156-7170},
Month = {AUG},
Abstract = {Internet-of-Things (IoT) big data streaming applications, such as video
   surveillance and automatic driving, tend to use mobile-edge computing
   (MEC) infrastructure to enhance their performance and augment their
   functionalities. Although extensive previous studies have worked on
   offloading requests to MEC servers, none of them has comprehensively and
   thoroughly considered the important features of IoT data streaming
   applications (i.e., component dependency and dynamic arrival) and the
   infrastructure provisioning (i.e., capacity constraint and colocation
   interference). In this article, we consider the offloading problem for
   dynamically arrived IoT data streaming requests on MEC servers in real
   time. We model it as a delay-sensitive multiuser multiresource online
   offloading problem respecting component dependency and capacity
   constraint. The problem is NP-hard with offloading decisions coupling
   together. To solve it, we decouple the problem into component placement
   problem and request scheduling problem and propose a two-stage DPGPD
   algorithm with polynomial time complexity. We show the first stage
   dynamic programming (DP) algorithm is the optimal solution and the
   second-stage greedy primal-dual (GPD) algorithm is asymptotic optimal.
   The simulation results show that our solution is effective yet efficient
   compared to benchmark solutions. (DP provides the optimal placement
   layout with 12x less decision time of Gurobi; and GPD provides the
   asymptotic optimal scheduling with 5x less average waiting time compared
   to least work left (LWL) in heavy workload.) We implement a dedicated
   prototype and exploit several representative big data streaming
   applications to evaluate it. Lab-scale experiment shows that our
   solution can provide over 3x less total completion time compared to
   local execution.},
DOI = {10.1109/JIOT.2020.2982458},
ISSN = {2327-4662},
ORCID-Numbers = {Chen, Shiyu/0000-0002-1515-4972},
Unique-ID = {WOS:000559482800038},
}

@inproceedings{ WOS:000627565500085,
Author = {Shaikh, Salman Ahmed and Lee, Jun and Matono, Akiyoshi and Kim,
   Kyoung-Sook},
Book-Group-Author = {Assoc Comp Machinery},
Title = {A Robust and Scalable Pipeline for the Real-time Processing and Analysis
   of Massive 3D Spatial Streams},
Booktitle = {IIWAS2019: THE 21ST INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION
   AND WEB-BASED APPLICATIONS \& SERVICES},
Year = {2019},
Pages = {622-626},
Note = {21st International Conference on Information Integration and Web-Based
   Applications and Services (iiWAS), Munich, GERMANY, DEC 02-04, 2019},
Organization = {Assoc Comp Machinery},
Abstract = {With the increase in the use of 3D scanner to sample the earth surface,
   there is a surge in the availability of 3D spatial data. 3D spatial data
   contains a wealth of information and can be of potential use if
   integrated, processed and analyzed in real-time. The 3D spatial data is
   generated as continuous data stream, however due to its size, velocity
   and inherent noise, it is processed offline. Many applications require
   real-time processing and analysis of spatial stream, for-instance,
   forest fire management, real-time road traffic analysis, disaster
   engulfed areas monitoring, etc., however they suffer from slow offline
   processing of traditional systems. This paper presents and demonstrates
   a robust and scalable pipeline for the real-time processing and analysis
   of 3D spatial streams. An experimental evaluation is also presented to
   prove the effectiveness of the proposed framework.},
DOI = {10.1145/3366030.3366105},
ISBN = {978-1-4503-7179-7},
ResearcherID-Numbers = {Lee, Jun/L-6934-2018},
ORCID-Numbers = {Lee, Jun/0000-0001-6138-3971},
Unique-ID = {WOS:000627565500085},
}

@inproceedings{ WOS:000336665300526,
Author = {Walczak, M. and Lewandowski, M. and Zolek, N.},
Book-Group-Author = {IEEE},
Title = {Optimization of real-time ultrasound PCIe data streaming and OpenCL
   processing for SAFT imaging},
Booktitle = {2013 IEEE INTERNATIONAL ULTRASONICS SYMPOSIUM (IUS)},
Series = {IEEE International Ultrasonics Symposium},
Year = {2013},
Pages = {2064-2067},
Note = {IEEE International Ultrasonics Symposium (IUS), Prague, CZECH REPUBLIC,
   JUL 21-25, 2013},
Organization = {IEEE},
Abstract = {Our goal is to develop a complete ultrasound platform based on real-time
   SAFT (Synthetic Aperture Focusing Technique) GPU processing. We are
   planning to integrate all the ultrasound modules and processing
   resources (GPU) in a single rack enclosure with the PCIe switch fabric
   backplane. The first developed module (RX64) provides acquisition and
   streaming of 64 ultrasound channels. We implemented and benchmarked data
   streaming from the RX64 to the GPU memory and the SAFT image
   reconstruction on the GPU. A high system performance was achieved using
   hardware assisted direct memory transfers and pipelined processing
   workflow. The complete system throughput, including 128 channel data
   transfer at 16kS per line and low-resolution 256x256 pixel image SAFT
   reconstruction on a single Nvidia K5000 GPU, reached 450 fps. The
   obtained results proved the feasibility of the ultrasound real-time
   imaging system with GPU SAFT processing.},
DOI = {10.1109/ULTSYM.2013.0527},
ISSN = {1948-5719},
ISBN = {978-1-4673-5686-2},
ResearcherID-Numbers = {Zolek, Norbert/AAU-7993-2021
   Lewandowski, Marcin/J-2303-2012
   Lewandowski, Marcin/AAB-6532-2019},
ORCID-Numbers = {Lewandowski, Marcin/0000-0001-8668-8368},
Unique-ID = {WOS:000336665300526},
}

@inproceedings{ WOS:000426912900054,
Author = {Imai, Shigeru and Patterson, Stacy and Varela, Carlos A.},
Book-Group-Author = {IEEE},
Title = {Maximum Sustainable Throughput Prediction for Data Stream Processing
   over Public Clouds},
Booktitle = {2017 17TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND GRID
   COMPUTING (CCGRID)},
Series = {IEEE-ACM International Symposium on Cluster Cloud and Grid Computing},
Year = {2017},
Pages = {504-513},
Note = {17th IEEE/ACM International Symposium on Cluster, Cloud and Grid
   Computing (CCGRID), Madrid, SPAIN, MAY 14-17, 2017},
Organization = {IEEE; Assoc Comp Machinery; IEEE Comp Soc; Mellanox Technologies; Univ
   Carlos III Madrid; ARCOS; IEEE TCSC},
Abstract = {In cloud-based stream processing services, the maximum sustainable
   throughput (MST) is defined as the maximum throughput that a system
   composed of a fixed number of virtual machines (VMs) can ingest
   indefinitely. If the incoming data rate exceeds the system's MST,
   unprocessed data accumulates, eventually making the system inoperable.
   Thus, it is important for the service provider to keep the MST always
   larger than the incoming data rate by dynamically changing the number of
   VMs used by the system. In this paper, we identify a common data
   processing environment used by modern data stream processing systems,
   and we propose MST prediction models for this environment. We train the
   models using linear regression with samples obtained from a few VMs and
   predict MST for a larger number of VMs. To minimize the time and cost
   for model training, we statistically determine a set of training samples
   using Intel's Storm benchmarks with representative resource usage
   patterns. Using typical use-case benchmarks on Amazon's EC2 public
   cloud, our experiments show that, training with up to 8 VMs, we can
   predict MST for streaming applications with less than 4\% average
   prediction error for 12 VMs, 9\% for 16 VMs, and 32\% for 24 VMs.
   Further, we evaluate our prediction models with simulation-based elastic
   VM scheduling on a realistic workload. These simulation results show
   that with 10\% over-provisioning, our proposed models' cost efficiency
   is on par with the cost of an optimal scaling policy without incurring
   any service level agreement violations.},
DOI = {10.1109/CCGRID.2017.105},
ISSN = {2376-4414},
ISBN = {978-1-5090-6611-7},
Unique-ID = {WOS:000426912900054},
}

@inproceedings{ WOS:000403398200112,
Author = {Zhang, Shuhao and He, Bingsheng and Dahlmeier, Daniel and Zhou, Amelie
   Chi and Heinze, Thomas},
Book-Group-Author = {IEEE},
Title = {Revisiting the Design of Data Stream Processing Systems on Multi-Core
   Processors},
Booktitle = {2017 IEEE 33RD INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE 2017)},
Series = {IEEE International Conference on Data Engineering},
Year = {2017},
Pages = {659-670},
Note = {IEEE 33rd International Conference on Data Engineering (ICDE), San
   Diego, CA, APR 19-22, 2017},
Organization = {IEEE; IEEE Comp Soc; Data Engn; Huawei; Intel; IBM; Microsoft; Amazon;
   SAP; CISCO; UC San Diego; Gordon \& Betty Moore Fdn; WEKA IO},
Abstract = {Driven by the rapidly increasing demand for handling real-time data
   streams, many data stream processing (DSP) systems have been proposed.
   Regardless of the different architectures of those DSP systems, they are
   mostly aiming at scaling out using a cluster of commodity machines and
   built around a number of key design aspects: a) pipelined processing
   with message passing, b) on-demand data parallelism, and c) JVM based
   implementation. However, there lacks a study on those key design aspects
   on modern scale-up architectures, where more CPU cores are being put on
   the same die, and the on-chip cache hierarchies are getting larger,
   deeper, and complex. Multiple sockets bring non-uniform memory access
   (NUMA) effort. In this paper, we revisit the aforementioned design
   aspects on a modern scale-up server. Specifically, we use a series of
   applications as micro benchmark to conduct detailed profiling studies on
   Apache Storm and Flink. From the profiling results, we observe two major
   performance issues: a) the massively parallel execution model causes
   serious front-end stalls, which are a major performance bottleneck issue
   on a single CPU socket, b) the lack of NUMA-aware mechanism causes major
   drawback on the scalability of DSP systems on multi-socket
   architectures. Addressing these issues should allow DSP systems to
   exploit modern scale-up architectures, which also benefits scaling out
   environments. We present our initial efforts on resolving the
   above-mentioned performance issues, which have shown up to 3.2x and 3.1x
   improvement on the performance of Storm and Flink, respectively.},
DOI = {10.1109/ICDE.2017.119},
ISSN = {1084-4627},
ISBN = {978-1-5090-6543-1},
ResearcherID-Numbers = {zhang, shuhao/Z-4484-2019
   },
ORCID-Numbers = {zhang, shuhao/0000-0002-9927-6925
   He, Bingsheng/0000-0001-8618-4581},
Unique-ID = {WOS:000403398200112},
}

@inproceedings{ WOS:000649540400063,
Author = {HoseinyFarahabady, M. Reza and Jannesari, Ali and Taheri, Javid and Bao,
   Wei and Zomaya, Albert Y. and Tari, Zahir},
Editor = {Lefevre, L and Varela, CA and Pallis, G and Toosi, AN and Rana, O and Buyya, R},
Title = {Q-Flink: A QoS-Aware Controller for Apache Flink},
Booktitle = {2020 20TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND
   INTERNET COMPUTING (CCGRID 2020)},
Year = {2020},
Pages = {629-638},
Note = {20th IEEE/ACM International Symposium on Cluster, Cloud and Internet
   Computing (CCGrid), Melbourne, AUSTRALIA, MAY 11-14, 2020},
Organization = {IEEE; Assoc Comp Machinery; IEEE Comp Soc; IEEE Tech Comm Scalable Comp},
Abstract = {Modern stream-data processing platforms are required to execute
   processing pipelines over high-volume, yet high-velocity, datasets under
   tight latency constraints. Apache Flink has emerged as an important new
   technology of large-scale platform that can distribute processing over a
   large number of computing nodes in a cluster (i.e., scale-out
   processing). Flink allows application developers to design and execute
   queries over continuous raw-inputs to analyze a large amount of
   streaming data in a parallel and distributed fashion. To increase the
   throughput of computing resources in stream processing platforms, a
   service provider might be tempted to use a consolidation strategy to
   pack as many processing applications as possible on the working nodes,
   with the hope of increasing the total revenue by improving the overall
   resource utilization. However, there is a hidden trap for achieving such
   a higher throughput solely by relying on an interference-oblivious
   consolidation strategy. In practice, collocated applications in a shared
   platform can fiercely compete with each others for obtaining the
   capacity of shared resources (e.g., cache and memory bandwidth) which in
   turn can lead to a severe performance degradation for all consolidated
   workloads.
   This paper addresses the shared resource contention problem associated
   with the auto-resource controlling mechanism of Apache Flink engine
   running across a distributed cluster. A controlling strategy is proposed
   to handle scenarios in which stream processing applications may have
   different quality of service (QoS) requirements while the resource
   interference is considered as the key performance-limiting parameter.
   The performance evaluation is carried out by comparing the proposed
   controller with the default Flink resource allocation strategy in a
   testbed cluster with total 32 Intel Xeon cores under different workload
   traffic with up to 4000 streaming applications chosen from various
   benchmarking tools. Experimental results demonstrate that the proposed
   controller can successfully decrease the average latency of high
   priority applications by 223\% during the burst traffic while
   maintaining the requested QoS enforcement levels.},
DOI = {10.1109/CCGrid49817.2020.00-30},
ISBN = {978-1-7281-6095-5},
ResearcherID-Numbers = {Zomaya, Albert Y./G-9697-2017
   Bao, Wei/ACK-4153-2022
   },
ORCID-Numbers = {Zomaya, Albert Y./0000-0002-3090-1059
   Bao, Wei/0000-0003-1874-1766
   Tari, Zahir/0000-0002-1235-9673
   Jannesari, Ali/0000-0001-8672-5317},
Unique-ID = {WOS:000649540400063},
}

@article{ WOS:000794016300007,
Author = {Livaja, Ivan and Pripuzic, Kresimir and Sovilj, Sinisa and Vukovic,
   Marin},
Title = {A distributed geospatial publish/subscribe system on Apache Spark},
Journal = {FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE},
Year = {2022},
Volume = {132},
Pages = {282-298},
Month = {JUL},
Abstract = {Publish/subscribe is a messaging pattern where message producers, called
   publishers, publish messages which they want to be distributed to
   message consumers, called subscribers. Subscribers are required to
   subscribe to messages of interest in advance to be able to receive them
   upon the publishing. In this paper, we discuss a special type of
   publish/subscribe systems, namely geospatial publish/subscribe systems
   (GeoPS systems), in which both published messages (i.e., publications)
   and subscriptions include a geospatial object. Such an object is used to
   express both the location information of a publication and the location
   of interest of a subscription. We argue that there is great potential
   for using GeoPS systems for the Internet of Things and Sensor Web
   applications. However, existing GeoPS systems are not applicable for
   this purpose since they are centralized and cannot cope with multiple
   highly frequent incoming geospatial data streams containing
   publications. To overcome this limitation, we present a distributed
   GeoPS system in the cluster which efficiently matches incoming
   publications in real-time with a set of stored subscriptions.
   Additionally, we propose four different (distributed) replication and
   partitioning strategies for managing subscriptions in our distributed
   GeoPS system. Finally, we present results of an extensive experimental
   evaluation in which we compare the throughput, latency and memory
   consumption of these strategies. These results clearly show that they
   are both efficient and scalable to larger clusters. The comparison with
   centralized state-of-the-art approaches shows that the additional
   processing overhead of our distributed strategies introduced by the
   Apache Spark is almost negligible. (C)\& nbsp;2022 Elsevier B.V. All
   rights reserved.},
DOI = {10.1016/j.future.2022.02.013},
ISSN = {0167-739X},
EISSN = {1872-7115},
ResearcherID-Numbers = {Pripužić, Krešimir/GLQ-7853-2022
   },
ORCID-Numbers = {Pripužić, Krešimir/0000-0001-7364-3021
   Sovilj, Sinisa/0000-0001-7416-0152},
Unique-ID = {WOS:000794016300007},
}

@inproceedings{ WOS:000391253600223,
Author = {Chintapalli, Sanket and Dagit, Derek and Evans, Bobby and Farivar, Reza
   and Graves, Thomas and Holderbaugh, Mark and Liu, Zhuo and Nusbaum, Kyle
   and Patil, Kishorkumar and Peng, Boyang Jerry and Poulosky, Paul},
Book-Group-Author = {IEEE},
Title = {Benchmarking Streaming Computation Engines: Storm, Flink and Spark
   Streaming},
Booktitle = {2016 IEEE 30TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM WORKSHOPS (IPDPSW)},
Series = {IEEE International Symposium on Parallel and Distributed Processing
   Workshops},
Year = {2016},
Pages = {1789-1792},
Note = {30th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS), Illinois Inst Technol, Chicago, IL, MAY 23-27, 2016},
Organization = {IEEE; IEEE Comp Soc, Tech Comm Parallel Proc; ACM SIGARCH; IEEE Comp Soc
   Tech Comm Comp Architecture; IEEE Comp Soc Tech Comm Distributed Proc},
Abstract = {Streaming data processing has been gaining attention due to its
   application into a wide range of scenarios. To serve the booming demands
   of streaming data processing, many computation engines have been
   developed. However, there is still a lack of real-world benchmarks that
   would be helpful when choosing the most appropriate platform for serving
   real-time streaming needs. In order to address this problem, we
   developed a streaming benchmark for three representative computation
   engines: Flink, Storm and Spark Streaming. Instead of testing
   speed-of-light event processing, we construct a full data pipeline using
   Kafka and Redis in order to more closely mimic the real-world production
   scenarios. Based on our experiments, we provide a performance comparison
   of the three data engines in terms of 99th percentile latency and
   throughput for various configurations.},
DOI = {10.1109/IPDPSW.2016.138},
ISSN = {2164-7062},
ISBN = {978-1-5090-3682-0},
Unique-ID = {WOS:000391253600223},
}

@inproceedings{ WOS:000238329200078,
Author = {Vijayakumar, Nithya N. and Liu, Ying and Plale, Beth},
Editor = {Turner, SJ and Lee, BS and Cai, W},
Title = {<bold>Calder Query Grid Service: Insights and Experimental
   Evaluation</bold>},
Booktitle = {SIXTH IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID:
   SPANNING THE WORLD AND BEYOND},
Year = {2006},
Pages = {539+},
Note = {6th IEEE International Symposium on Cluster Computing and the Grid
   (CCGRID 2006), Singapore, SINGAPORE, MAY 16-19, 2006},
Organization = {IEEE Comp Soc TCSC; ORACLE; HP; IBM; intel; Sun; Platform; PTC},
Abstract = {We have architected and evaluated a new kind of data resource, one that
   is composed of a logical collection of ephemeral data streams that could
   be viewed as a collection of publish-subscribe ``channels{''} over which
   rich data-access and semantic operations can be performed. This paper
   contributes new insight to stream processing under the highly
   asynchronous stream workloads often found in data-driven scientific
   applications, and presents insights gained through porting a distributed
   stream processing system to a Grid services framework. Experimental
   results reveal limits on stream processing rates that are directly tied
   to differences in stream rates.},
ISBN = {0-7695-2585-7},
ResearcherID-Numbers = {Plale, Beth/F-8803-2011},
ORCID-Numbers = {Plale, Beth/0000-0003-2164-8132},
Unique-ID = {WOS:000238329200078},
}

@inproceedings{ WOS:000447289500005,
Author = {Sajjad, Hooman Peiro and Vlassov, Vladimir and Liu, Ying},
Book-Group-Author = {IEEE},
Title = {Optimizing Windowed Aggregation over Geo-Distributed Data Streams},
Booktitle = {2018 IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING (IEEE EDGE)},
Year = {2018},
Pages = {33-41},
Note = {IEEE International Conference on Edge Computing (IEEE EDGE) Part of the
   IEEE World Congress on Services, San Francisco, CA, JUL 02-07, 2018},
Organization = {IEEE; IEEE Comp Soc; CCF, TCSC},
Abstract = {Real-time data analytics is essential since more and more applications
   require online decision making in a timely manner. However, efficient
   analysis of geo-distributed data streams is challenging. This is because
   data needs to be collected from all edge data centers, which aggregate
   data from local sources, in order to process most of the analytic tasks.
   Thus, most of the time edge data centers need to transfer data to a
   central data center over a wide area network, which is expensive.
   In this paper, we advocate for a coordinated approach of edge data
   centers in order to handle these analytic tasks efficiently and hence,
   reducing the communication cost among data centers. We focus on the
   windowed aggregation of data streams, which has been widely used in
   stream analytics. In general, aggregation of data streams among edge
   data centers in the same region reduces the amount of data that needs to
   be sent over cross-region communication links. Based on state-of-the-art
   research, we leverage intra-region links and design a low-overhead
   coordination algorithm that optimizes communication cost for data
   aggregation. Our algorithm has been evaluated using synthetic and Big
   Data Benchmark datasets. The evaluation results show that our algorithm
   reduces the bandwidth cost up to similar to 6x, as compared to the
   state-of-theart solution.},
DOI = {10.1109/EDGE.2018.00012},
ISBN = {978-1-5386-7238-9},
ResearcherID-Numbers = {Vlassov, Vladimir/AAE-9170-2019},
ORCID-Numbers = {Vlassov, Vladimir/0000-0002-6779-7435},
Unique-ID = {WOS:000447289500005},
}

@inproceedings{ WOS:000461057600005,
Author = {Prosperi, Laurent and Costan, Alexandru and Silva, Pedro and Antoniu,
   Gabriel},
Book-Group-Author = {IEEE},
Title = {Planner: Cost-efficient Execution Plans Placement for Uniform Stream
   Analytics on Edge and Cloud},
Booktitle = {PROCEEDINGS OF WORKS 2018: 13TH IEEE/ACM WORKSHOP ON WORKFLOWS IN
   SUPPORT OF LARGE-SCALE SCIENCE (WORKS)},
Year = {2018},
Pages = {42-51},
Note = {13th IEEE/ACM Workshop on Workflows in Support of Large-Scale Science
   (WORKS), Dallas, TX, NOV 11, 2018},
Organization = {IEEE; ACM; IEEE Comp Soc TCHPC; ACM SIGHPC},
Abstract = {Stream processing applications handle unbounded and continuous flows of
   data items which are generated from multiple geographically distributed
   sources. Two approaches are commonly used for processing: Cloud-based
   analytics and Edge analytics. The first one routes the whole data set to
   the Cloud, incurring significant costs and late results from the high
   latency networks that are traversed. The latter can give timely results
   but forces users to manually define which part of the computation should
   be executed on Edge and to interconnect it with the remaining part
   executed in the Cloud, leading to sub-optimal placements. In this paper,
   we introduce Planner, a middleware for uniform and transparent stream
   processing across Edge and Cloud. Planner automatically selects which
   parts of the execution graph will be executed at the Edge in order to
   minimize the network cost. Real-world micro-benchmarks show that Planner
   reduces the network usage by 40\% and the makespan (end-to-end
   processing time) by 15\% compared to state-of-the-art.},
DOI = {10.1109/WORKS.2018.00010},
ISBN = {978-1-7281-0196-5},
ResearcherID-Numbers = {Costan, Alexandru/AAC-1776-2020
   Antoniu, Gabriel/V-9919-2019},
ORCID-Numbers = {Costan, Alexandru/0000-0003-3111-6308
   },
Unique-ID = {WOS:000461057600005},
}

@inproceedings{ WOS:000343592200011,
Author = {Lai, Farley and Hasan, Syed Shabih and Laugesen, Austin and Chipara,
   Octav},
Book-Group-Author = {IEEE},
Title = {CSense: A Stream-Processing Toolkit for Robust and High-Rate Mobile
   Sensing Applications},
Booktitle = {PROCEEDINGS OF THE 13TH INTERNATIONAL SYMPOSIUM ON INFORMATION
   PROCESSING IN SENSOR NETWORKS (IPSN' 14)},
Year = {2014},
Pages = {119-129},
Note = {13th IEEE/ACM International Symposium on Information Processing in
   Sensor Networks (IPSN), Berlin, GERMANY, APR 15-17, 2014},
Organization = {Assoc Comp Machinery; IEEE; ACM SIGBED; IEEE Comp Soc; Carl Ossietzky
   Univ Oldenburg},
Abstract = {This paper presents CSense - a stream-processing toolkit for developing
   robust and high-rate mobile sensing application in Java. CSense
   addresses the needs of these systems by providing a new programming
   model that supports flexible application configuration, a high-level
   concurrency model, memory management, and compiler analyses and
   optimizations. Our compiler includes a novel flow analysis that
   optimizes the exchange of data across components from an
   application-wide perspective. A mobile sensing application benchmark
   indicates that flow analysis may reduce CPU utilization by as much as
   45\%. Static analysis is used to detect a range of programming errors
   including application composition errors, improper use of memory
   management, and data races. We identify that memory management and
   concurrency limit the scalability of stream processing systems. We
   incorporate memory pools, frame conversion optimizations, and custom
   synchronization primitives to develop a scalable run-time. CSense is
   evaluated on Galaxy Nexus phones running Android. Empirical results
   indicate that our run-time achieves 19 times higher steam processing
   rate compared to a realistic baseline implementation. We demonstrate the
   versatility of CSense by developing three mobile sensing applications.},
ISBN = {978-1-4799-3146-0},
ORCID-Numbers = {Chipara, Octav/0000-0002-4729-0602},
Unique-ID = {WOS:000343592200011},
}

@inproceedings{ WOS:000379304300015,
Author = {Zacheilas, Nikos and Zygouras, Nikolas and Panagiotou, Nikolaos and
   Kalogeraki, Vana and Gunopulos, Dimitrios},
Editor = {Jelasity, M and Kalyvianaki, E},
Title = {Dynamic Load Balancing Techniques for Distributed Complex Event
   Processing Systems},
Booktitle = {DISTRIBUTED APPLICATIONS AND INTEROPERABLE SYSTEMS, DAIS 2016},
Series = {Lecture Notes in Computer Science},
Year = {2016},
Volume = {9687},
Pages = {174-188},
Note = {16th IFIP WG 6.1 International Conference on Distributed Applications
   and Interoperable Systems (DAIS) held as part of the 11th International
   Federated Conference on Distributed Computing Techniques (DisCoTec),
   Heraklion, GREECE, JUN 04-07, 2016},
Organization = {Int Federat Informat Proc Working Grp 6 1; Int Federat Informat Proc},
Abstract = {Applying real-time, cost-effective Complex Event processing (CEP) in the
   cloud has been an important goal in recent years. Distributed Stream
   Processing Systems (DSPS) have been widely adopted by major computing
   companies such as Facebook and Twitter for performing scalable event
   processing in streaming data. However, dynamically balancing the load of
   the DSPS' components can be particularly challenging due to the high
   volume of data, the components' state management needs, and the low
   latency processing requirements. Systems should be able to cope with
   these challenges and adapt to dynamic and unpredictable load changes in
   real-time. Our approach makes the following contributions: (i) we
   formulate the load balancing problem in distributed CEP systems as an
   instance of the job-shop scheduling problem, and (ii) we present a novel
   framework that dynamically balances the load of CEP engines in real-time
   and adapts to sudden changes in the volume of streaming data by
   exploiting two balancing policies. Our detailed experimental evaluation
   using data from the Twitter social network indicates the benefits of our
   approach in the system's throughput.},
DOI = {10.1007/978-3-319-39577-7\_14},
ISSN = {0302-9743},
ISBN = {978-3-319-39577-7; 978-3-319-39576-0},
ResearcherID-Numbers = {Kalogeraki, Vana/ABI-1469-2020
   },
ORCID-Numbers = {Kalogeraki, Vana/0000-0002-6421-9947
   Gunopulos, Dimitrios/0000-0001-6339-1879},
Unique-ID = {WOS:000379304300015},
}

@inproceedings{ WOS:000630323900063,
Author = {Bang, Jiwon and Choi, Mi-Jung},
Book-Group-Author = {IEEE},
Title = {Docker environment based Apache Storm and Spark Benchmark Test},
Booktitle = {APNOMS 2020: 2020 21ST ASIA-PACIFIC NETWORK OPERATIONS AND MANAGEMENT
   SYMPOSIUM (APNOMS)},
Series = {Asia-Pacific Network Operations and Management Symposium-APNOMS},
Year = {2020},
Pages = {322-325},
Note = {21st Asia-Pacific Network Operations and Management Symposium (APNOMS),
   Daegu, SOUTH KOREA, SEP 22-25, 2020},
Organization = {KICS, KNOM; IEICE ICM; IEEE; IEEE Commun Soc},
Abstract = {With the development of various technologies such as high-speed Internet
   and SNS dissemination, there have been many fields that require
   processing of big data generated in real time. Accordingly, real-time
   streaming data processing technology has been developed, and
   representative platforms include Apache Storm, Apache Spark, and Hadoop.
   These processing technologies provide scalability to configure
   distributed systems using multiple servers because they vary in
   performance, such as throughput and processing speed, depending on the
   server environment, but the more the number of servers, the more
   difficult it is to manage. To solve this problem, a problem can be
   solved by using a docker, a kind of virtualization system that provides
   ease of expansion. However, there is a place to maintain a native
   environment without using Docker due to the problem that performance may
   be reduced, which is a disadvantage of all virtualization systems. In
   this paper, we build Apache Storm and Apache Spark, which are real-time
   data processing systems in Docker and Native environments and conduct
   performance measurements through experiments processing JSON-format data
   to verify how much performance decreases in Docker environments.},
ISSN = {2576-8565},
EISSN = {2576-8557},
ISBN = {978-89-950043-8-8},
Unique-ID = {WOS:000630323900063},
}

@article{ WOS:000555039700001,
Author = {Pieters, Ruben P. and Schrijvers, Tom},
Title = {Faster coroutine pipelines: A reconstruction},
Journal = {JOURNAL OF FUNCTIONAL PROGRAMMING},
Year = {2020},
Volume = {30},
Month = {AUG 3},
Abstract = {The three-continuation approach to coroutine pipelines efficiently
   represents a large number of connected components. Previous work in this
   area introduces this alternative encoding but does not shed much light
   on the underlying principles for deriving this encoding from its
   specification. This paper gives this missing insight by deriving the
   three-continuation encoding based on eliminating the mutual recursion in
   the definition of the connect operation. Using the same derivation
   steps, we are able to derive a similar encoding for a more general
   setting, namely bidirectional pipes. Additionally, we evaluate the
   encoding in an advertisement analytics benchmark where it is as
   performant aspipes,conduit, andstreamly, which are other common Haskell
   stream processing libraries.},
DOI = {10.1017/S0956796820000192},
Article-Number = {e22},
ISSN = {0956-7968},
EISSN = {1469-7653},
ORCID-Numbers = {Schrijvers, Tom/0000-0001-8771-5559},
Unique-ID = {WOS:000555039700001},
}

@article{ WOS:000498702800001,
Author = {Huang, Jiao and Huang, Jing and Gao, Shang and Yang, Bo},
Title = {Cost-Minimizing Online Algorithms for Geo-Distributed Data Analytics},
Journal = {IEEE ACCESS},
Year = {2019},
Volume = {7},
Pages = {163515-163525},
Abstract = {Modern enterprises often manage geographically distributed datacenters
   around the globe. In such environment, datasets are naturally collected
   and stored in different data centers and were later queried for complex
   analytics. In this paper, we study the Wide-Area Data Analytics problem,
   which aims to efficiently control data movements and achieve low latency
   for overall queries processing, both constrained by limited and
   expensive network resources across datacenters. Previous papers focus on
   offline settings of single analytical queries and do not consider time
   in optimizing system performance, and therefore ignores the dynamics of
   data and task placement in terms of inter-DC bandwidth utilization. In
   this paper, we consider the online setting and formulate a
   cost-minimizing optimization problem over time for arbitrary Directed
   Acyclic Graph query processing. Considering dynamics of network resource
   usage, we developed two online algorithms, Online Switch Resist (OSR)
   and Most Fixed Horizon Control (MFHC) with good competitive ratios. We
   performed extensive simulations and comparative studies using the TPC-CH
   benchmark and verified the efficacy of proposed algorithms. The
   algorithm we proposed is better than the existing algorithm, and its
   performance approximates the theoretical optimal value.},
DOI = {10.1109/ACCESS.2019.2951682},
ISSN = {2169-3536},
Unique-ID = {WOS:000498702800001},
}

@article{ WOS:000433473700009,
Author = {Fan, Xitian and Wu, Di and Cao, Wei and Luk, Wayne and Wang, Lingli},
Title = {Stream Processing Dual-Track CGRA for Object Inference},
Journal = {IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS},
Year = {2018},
Volume = {26},
Number = {6},
Pages = {1098-1111},
Month = {JUN},
Abstract = {With the development of machine learning technology, the exploration of
   energy-efficient and flexible architectures for object inference
   algorithms is of growing interest in recent years. However, not many
   publications concentrate on a coarse-grained reconfigurable architecture
   (CGRA) for object inference algorithms. This paper provides a stream
   processing, dual-track programming CGRA-based approach to address the
   inherent computing characteristics of algorithms in object inference.
   Based on the proposed approach, an architecture called stream dual-track
   CGRA (SDT-CGRA) is presented as an implementation prototype. To evaluate
   the performance, the SDT-CGRA is realized in Verilog HDL and implemented
   in Semiconductor Manufacturing International Corporation 55-nm process,
   with the footprint of 5.19 mm(2) at 450 MHz. Seven object inference
   algorithms, including convolutional neural network (CNN), k-means,
   principal component analysis (PCA), spatial pyramid matching (SPM),
   linear support vector machine (SVM), Softmax, and Joint Bayesian, are
   selected as benchmarks. The experimental results show that the SDT-CGRA
   can gain on average 343.8 times and 17.7 times higher energy efficiency
   for Softmax, PCA, and CNN, 621.0 times and 1261.8 times higher energy
   efficiency for k-means, SPM, linear-SVM, and Joint-Bayesian algorithms
   when compared with the Intel Xeon E5-2637 CPU and the Nvidia TitanX
   graphics processing unit. When compared with the state-of-the-art
   solutions of AlexNet on field-programmable gate array and CGRA, the
   proposed SDT-CGRA can achieve a 1.78 times increase in energy efficiency
   and a 13 times speedup, respectively.},
DOI = {10.1109/TVLSI.2018.2797600},
ISSN = {1063-8210},
EISSN = {1557-9999},
ORCID-Numbers = {Wang, Lingli/0000-0002-0579-3527},
Unique-ID = {WOS:000433473700009},
}

@article{ WOS:000742908500074,
Author = {Gencer, Can and Topolnik, Marko and Durina, Viliam and Demirci, Emin and
   Kahveci, Ensar B. and Gurbuz, Ali and Lukas, Ondrej and Bartok, Jozsef
   and Gierlach, Grzegorz and Hartman, Frantisek and Yilmaz, Ufuk and
   Dogan, Mehmet and Mandouh, Mohamed and Fragkoulis, Marios and
   Katsifodimos, Asterios},
Title = {Hazelcast Jet: Low-latency Stream Processing at the 99.99th Percentile},
Journal = {PROCEEDINGS OF THE VLDB ENDOWMENT},
Year = {2021},
Volume = {14},
Number = {12},
Pages = {3110-3121},
Month = {AUG},
Note = {47th International Conference on Very Large Data Bases (VLDB),
   Copenhagen, DENMARK, AUG 16-20, 2021},
Abstract = {Jet is an open-source, high-performance, distributed stream processor
   built at Hazelcast during the last five years. Jet was engineered with
   millisecond latency on the 99.99th percentile as its primary design
   goal. Originally Jet's purpose was to be an execution engine that
   performs complex business logic on top of streams generated by
   Hazelcast's In-memory Data Grid (IMDG): a set of in-memory, partitioned
   and replicated data structures. With time, Jet evolved into a
   full-fledged, scale-out stream processor that can handle out-of-order
   streams and provide exactly-once processing guarantees. Jet's end-to-end
   latency lies in the order of milliseconds, and its throughput in the
   order of millions of events per CPU-core. This paper presents the main
   design decisions we made in order to maximize the performance per
   CPU-core, alongside lessons learned, and an empirical performance
   evaluation.},
DOI = {10.14778/3476311.3476387},
ISSN = {2150-8097},
Unique-ID = {WOS:000742908500074},
}

@inproceedings{ WOS:000244520200072,
Author = {Gill, Gennette and Hansen, John and Singh, Montek},
Book-Group-Author = {IEEE},
Title = {Loop pipelining for high-throughput stream computation using self-timed
   rings},
Booktitle = {IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN, DIGEST OF
   TECHNICAL PAPERS, ICCAD},
Year = {2006},
Pages = {457+},
Note = {IEEE/ACM International Conference on Computer Aide Digest, San Jose, CA,
   NOV 05-09, 2006},
Organization = {IEEE; ACM},
Abstract = {We present a technique for increasing the throughput of stream
   processing architectures by removing the bottlenecks caused by loop
   structures. We implement loops as self-timed pipelined rings that can
   operate on multiple data sets concurrently. Our contribution includes a
   transformation algorithm which takes as input a high-level program and
   gives as output the structure of an optimized pipeline ring. Our
   technique handles nested loops and is further enhanced by loop
   unrolling. Simulations run on benchmark examples show a 1.3 to 4.9x
   speedup without unrolling and a 2.6 to 9.7x speedup with twofold loop
   unrolling.},
ISBN = {978-1-59593-389-8},
Unique-ID = {WOS:000244520200072},
}

@inproceedings{ WOS:000393314500064,
Author = {Fan, Jiahua and Chen, Haopeng and Hu, Fei},
Book-Group-Author = {IEEE},
Title = {Adaptive Task Scheduling in Storm},
Booktitle = {PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND
   NETWORK TECHNOLOGY (ICCSNT 2015)},
Year = {2015},
Pages = {309-314},
Note = {4th International Conference on Computer Science and Network Technology
   (ICCSNT), Harbin, PEOPLES R CHINA, DEC 19-20, 2015},
Organization = {Heilongjiang Univ; Dalian Jiaotong Univ; NE Normal Univ; Shaanxi Normal
   Univ; Harbin Inst Technol; IEEE; IEEE Harbin Sect},
Abstract = {Processing of stream data attracts more and more attention of many big
   companies and organizations. Storm is a well-known distributed stream
   processing system that is often used for real-time analysis, online
   machine learning, continuous computing, distributed remote process call
   (RPC), etc. In this paper, we study the default scheduler of Storm and
   other implementations of customized scheduler to discover the primary
   factors affecting the performance of the cluster. Then, we design and
   implement an adaptive task scheduler by adding load tracker to monitor
   the runtime status of the cluster and applying static and dynamic
   scheduling strategies. At last, we conduct experiments to assess our
   work by measuring average processing time, overall throughput and
   stability of the cluster through network bounded and CPU bounded
   benchmarks. As for average processing time of topologies, the adaptive
   scheduler achieves about 67\% and 30\% improvement on cluster of heavy
   and light load respectively.},
ISBN = {978-1-4673-8173-4},
Unique-ID = {WOS:000393314500064},
}

@inproceedings{ WOS:000696801700108,
Author = {Cermak, Milan and Celeda, Pavel},
Editor = {Ahmed, T and Festor, O and Ghamri-Doudane, Y and Kang, JM and Schaeffer-Filho, AE and Lahmadi, A and Madeira, E},
Title = {Stream-Based IP Flow Analysis},
Booktitle = {2021 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT
   (IM 2021)},
Year = {2021},
Pages = {736-741},
Note = {IFIP/IEEE International Symposium on Integrated Network Management (IM),
   ELECTR NETWORK, MAY 17-21, 2021},
Organization = {IFIP; IEEE},
Abstract = {As the complexity of Internet services, transmission speed, and data
   volume increases, current IP flow monitoring and analysis approaches
   cease to be sufficient, especially within high-speed and large-scale
   networks. Although IP flows consist only of selected network traffic
   features, their processing faces high computational demands, analysis
   delays, and large storage requirements. To address these challenges, we
   propose to improve the IP flow monitoring workflow by stream-based
   collection and analysis of IP flows utilizing a distributed data stream
   processing. This approach requires changing the paradigm of IP flow data
   monitoring and analysis, which is the main goal of our research. We
   analyze distributed stream processing systems, for which we design a
   novel performance benchmark to determine their suitability for
   stream-based processing of IP flow data. We define a stream-based
   workflow of IP flow collection and analysis based on the benchmark
   results, which we also implement as a publicly available and open-source
   framework Stream4Flow. Furthermore, we propose new analytical methods
   that leverage the stream-based IP flow data processing approach and
   extend network monitoring and threat detection capabilities.},
ISBN = {978-3-903176-32-4},
ORCID-Numbers = {Cermak, Milan/0000-0002-0212-6593},
Unique-ID = {WOS:000696801700108},
}

@inproceedings{ WOS:000747673800043,
Author = {Farhat, Omar and Daudjee, Khuzaima and Querzoni, Leonardo},
Book-Group-Author = {ASSOC COMP MACHINERY},
Title = {Klink: Progress-Aware Scheduling for Streaming Data Systems},
Booktitle = {SIGMOD `21: PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON
   MANAGEMENT OF DATA},
Series = {International Conference on Management of Data},
Year = {2021},
Pages = {485-498},
Note = {ACM SIGMOD International Conference on Management of Data (SIGMOD),
   ELECTR NETWORK, JUN 20-25, 2021},
Organization = {ACM SIGMOD; Assoc Comp Machinery},
Abstract = {Modern stream processing engines (SPEs) process large volumes of events
   propagated at high velocity through multiple queries. To improve
   performance, existing SPEs generally aim to minimize query output
   latency by minimizing, in turn, the propagation delay of events in query
   pipelines. However, for queries containing commonly used blocking
   operators such as windows, this scheduling approach can be inefficient.
   Watermarks are events popularly utilized by SPEs to correctly process
   window operators. Watermarks are injected into the stream to signify
   that no events preceding their timestamp should be further expected.
   Through the design and development of Klink, we leverage these
   watermarks to robustly infer stream progress based on window deadlines
   and network delay, and to schedule query pipeline execution that
   reflects stream progress. Klink aims to unblock window operators and to
   rapidly propagate events to output operators while performing judicious
   memory management. We integrate Klink into the popular open source SPE
   Apache Flink and demonstrate that Klink delivers significant performance
   gains over existing scheduling policies on benchmark workloads for both
   scale-up and scale-out deployments.},
DOI = {10.1145/3448016.3452794},
ISSN = {0730-8078},
ISBN = {978-1-4503-8343-1},
ORCID-Numbers = {Querzoni, Leonardo/0000-0002-8711-4216},
Unique-ID = {WOS:000747673800043},
}

@article{ WOS:000599145200001,
Author = {Ed-daoudy, Abderrahmane and Maalmi, Khalil},
Title = {A new Internet of Things architecture for real-time prediction of
   various diseases using machine learning on big data environment},
Journal = {JOURNAL OF BIG DATA},
Year = {2019},
Volume = {6},
Number = {1},
Month = {NOV 27},
Abstract = {A number of technologies enabled by Internet of Thing (IoT) have been
   used for the prevention of various chronic diseases, continuous and
   real-time tracking system is a particularly important one. Wearable
   medical devices with sensor, health cloud and mobile applications have
   continuously generating a huge amount of data which is often called as
   streaming big data. Due to the higher speed of the data generation, it
   is difficult to collect, process and analyze such massive data in
   real-time in order to perform real-time actions in case of emergencies
   and extracting hidden value. using traditional methods which are limited
   and time-consuming. Therefore, there is a significant need to real-time
   big data stream processing to ensure an effective and scalable solution.
   In order to overcome this issue, this work proposes a new architecture
   for real-time health status prediction and analytics system using big
   data technologies. The system focus on applying distributed machine
   learning model on streaming health data events ingested to Spark
   streaming through Kafka topics. Firstly, we transform the standard
   decision tree (DT) (C4.5) algorithm into a parallel, distributed,
   scalable and fast DT using Spark instead of Hadoop MapReduce which
   becomes limited for real-time computing. Secondly, this model is applied
   to streaming data coming from distributed sources of various diseases to
   predict health status. Based on several input attributes, the system
   predicts health status, send an alert message to care providers and
   store the details in a distributed database to perform health data
   analytics and stream reporting. We measure the performance of Spark DT
   against traditional machine learning tools including Weka. Finally,
   performance evaluation parameters such as throughput and execution time
   are calculated to show the effectiveness of the proposed architecture.
   The experimental results show that the proposed system is able to
   effectively process and predict real-time and massive amount of medical
   data enabled by IoT from distributed and various diseases.},
DOI = {10.1186/s40537-019-0271-7},
Article-Number = {104},
EISSN = {2196-1115},
ORCID-Numbers = {ED-DAOUDY, Abderrahmane/0000-0002-4417-2109
   MAALMI, Khalil/0000-0001-6881-0307},
Unique-ID = {WOS:000599145200001},
}

@inproceedings{ WOS:000434872100043,
Author = {Sahni, Jyoti and Vidyarthi, Deo Prakash},
Editor = {Singh, M and Gupta, PK and Tyagi, V and Sharma, A and Oren, T and Grosky, W},
Title = {Scalable Online Analytics on Cloud Infrastructures},
Booktitle = {ADVANCES IN COMPUTING AND DATA SCIENCES, ICACDS 2016},
Series = {Communications in Computer and Information Science},
Year = {2017},
Volume = {721},
Pages = {399-408},
Note = {1st International Conference on Advances in Computing and Data Sciences
   (ICACDS), Krishna Engn Coll, Dept Comp Sci \& Engn, Ghaziabad, INDIA,
   NOV 11-12, 2016},
Organization = {Comp Soc India, Special Interest Grp Cyber Forens; Govt India, Minist
   Def, DRDO; Comp Soc India, Ghaziabad Chapter},
Abstract = {The need for low latency analysis of high velocity real time continuous
   data streams has led to the emergence of Stream Processing Systems
   (SPSs). Contemporary SPSs allow a stream processing application to be
   hosted on Cloud infrastructures and dynamically scaled so as to adapt to
   the fluctuating data rates. However, the run time scalability
   incorporated in these SPSs are in their early adaptations and are based
   on simple local/global threshold based controls. This work studies the
   issues with the local and global auto scaling techniques that may lead
   to performance inefficiencies in real time traffic analysis on Cloud
   platforms and presents an efficient hybrid auto scaling strategy
   StreamScale which addresses the identified issues. The proposed
   StreamScale auto-scaling algorithm accounts for the gaps in the
   local/global scaling approaches and effectively identifies
   (de)parallelization opportunities in stream processing applications for
   maintaining QoS at reduced costs. Simulation based experimental
   evaluation on representative stream application topologies indicate that
   the proposed StreamScale auto-scaling algorithm exhibits better
   performance in comparison to both local and global auto-scaling
   approaches.},
DOI = {10.1007/978-981-10-5427-3\_43},
ISSN = {1865-0929},
EISSN = {1865-0937},
ISBN = {978-981-10-5427-3; 978-981-10-5426-6},
ORCID-Numbers = {Sahni, Jyoti/0000-0002-6438-0503},
Unique-ID = {WOS:000434872100043},
}

@inproceedings{ WOS:000565234200096,
Author = {Luo, Siqi and Chen, Xu and Zhou, Zhi},
Book-Group-Author = {IEEE Comp Soc},
Title = {F3C: Fog-enabled Joint Computation, Communication and Caching Resource
   Sharing for Energy-Efficient IoT Data Stream Processing},
Booktitle = {2019 39TH IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS
   (ICDCS 2019)},
Series = {IEEE International Conference on Distributed Computing Systems},
Year = {2019},
Pages = {1019-1028},
Note = {39th IEEE International Conference on Distributed Computing Systems
   (ICDCS), Richardson, TX, JUL 07-09, 2019},
Organization = {IEEE; IEEE Comp Soc; Univ Texas Dallas, Dept Comp Sci},
Abstract = {Fog/edge computing has been recently regarded as a promising approach
   for supporting emerging mission-critical Internet of Things (IoT)
   applications on capacity and battery constrained devices. By harvesting
   and collaborating a massive crowd of devices in close proximity for
   computation, communication and caching resource sharing (i.e., 3C
   resources), it enables great potentials in low-latency and
   energy-efficient IoT task execution. To efficiently exploit 3C resources
   of fog devices in proximity, we propose F3C, a fog-enabled 3C resource
   sharing framework for energy-efficient IoT data stream processing by
   solving an energy cost minimization problem under 3C constraints.
   Nevertheless, the minimization problem proves to be NP-hard via
   reduction to a Generalized Assignment Problem (GAP). To cope with such
   challenge, we propose an efficient F3C algorithm based on an iterative
   task team formation mechanism which regards each task's 3C resource
   sharing as a subproblem solved by the elaborated min cost flow
   transformation. Via utility improving iterations, the proposed F3C
   algorithm is shown to converge to a stable system point. Extensive
   performance evaluations demonstrate that our F3C algorithm can achieve
   superior performance in energy saving compared to various benchmarks.},
DOI = {10.1109/ICDCS.2019.00105},
ISSN = {1063-6927},
ISBN = {978-1-7281-2519-0},
ResearcherID-Numbers = {Zhou, Zhi/AAS-1383-2020
   Chen, Xu/GXW-3072-2022},
ORCID-Numbers = {Zhou, Zhi/0000-0003-0307-266X
   },
Unique-ID = {WOS:000565234200096},
}

@inproceedings{ WOS:000273293000018,
Author = {Zhang, Xiangliang and Furtlehner, Cyril and Sebag, Michele},
Editor = {Cesta, A and Fakotakis, N},
Title = {Distributed and Incremental Clustering Based on Weighted Affinity
   Propagation},
Booktitle = {STAIRS 2008},
Series = {Frontiers in Artificial Intelligence and Applications},
Year = {2008},
Volume = {179},
Pages = {199+},
Note = {4th Starting Artificial Intelligence Researchers Symposium, Patras,
   GREECE, 2008},
Organization = {ISTC CNR; Natl Res Council Italy; ECAI},
Abstract = {A new clustering algorithm Affinity Propagation (AP) is hindered by its
   quadratic complexity. The Weighted Affinity Propagation (WAP) proposed
   in this paper is used to eliminate this limitation, support two scalable
   algorithms. Distributed AP clustering handles large datasets by merging
   the exemplars learned from Subsets. Incremental AP extends AP to online
   clustering of data streams. The paper validates all proposed algorithms
   on benchmark and on real-world datasets. Experimental results show that
   the proposed approaches offer a good trade-off between computational
   effort and performance.},
DOI = {10.3233/978-1-58603-893-9-199},
ISSN = {0922-6389},
EISSN = {1879-8314},
ISBN = {978-1-58603-893-9},
Unique-ID = {WOS:000273293000018},
}

@inproceedings{ WOS:000167653300232,
Author = {Maierhofer, M and Bailey, C and Batatia, H and Sotudeh, R},
Editor = {Arabnia, HR},
Title = {An investigation of arbitration in servers for distributed multimedia
   applications},
Booktitle = {INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED PROCESSING
   TECHNIQUES AND APPLICATIONS, VOLS I-V, PROCEEDINGS},
Year = {1999},
Pages = {1564-1570},
Note = {International Conference on Parallel and Distributed Processing
   Techniques and Applications (PDPTA 99), LAS VEGAS, NV, JUN 28-JUL 01,
   1999},
Organization = {Comp Sci Res Educ \& Applicat Press; Comp Vis Res \& Applicat Tech; Int
   Assoc Math \& Comp Simulat; Int Technol Inst; Java High Performance Comp
   Res Grp; Korea Informat Processing Soc; US DOE, Natl Supercomp Ctr
   Energy \& Environm Las Vegas; Sundance Digital Signal Processing Inc;
   World Sci \& Engn Soc},
Abstract = {For many client-server based multimedia applications, server performance
   is a crucial factor. Such applications often require the reliable
   support of continuous real-time data streaming to deliver audio-visual
   data to end users.
   In conventional multimedia servers, storage and network controllers can
   operate independently and concurrently. Conflicting accesses to shared
   resources, such as the system bus and main memory are traditionally
   resolved by arbitration, which can hence affect a server's ability to
   deliver streams to the network concurrently.
   We use simulations to study a number of arbitration protocols and their
   effects on server performance in a video-on-demand scenario. Our
   findings suggest that these protocol yield comparable performance
   (parallel data streams), as long as storage controllers are not treated
   preferentially. Moreover, the maximum bus tenure of I/O devices should
   be restricted to avoid starvation of network controllers operating with
   small block size.},
ISBN = {1-892512-15-7},
ResearcherID-Numbers = {Batatia, hadj/AAH-9695-2019},
ORCID-Numbers = {Batatia, hadj/0000-0003-0433-2152},
Unique-ID = {WOS:000167653300232},
}

@article{ WOS:000630261600001,
Author = {Zhang, Ziyu and Liu, Zitan and Jiang, Qingcai and Chen, Junshi and An,
   Hong},
Title = {RDMA-Based Apache Storm for High-Performance Stream Data Processing},
Journal = {INTERNATIONAL JOURNAL OF PARALLEL PROGRAMMING},
Year = {2021},
Volume = {49},
Number = {5, SI},
Pages = {671-684},
Month = {OCT},
Abstract = {Apache Storm is a scalable fault-tolerant distributed real time
   stream-processing framework widely used in big data applications. For
   distributed data-sensitive applications, low-latency, high-throughput
   communication modules have a critical impact on overall system
   performance. Apache Storm currently uses Netty as its communication
   component, an asynchronous server/client framework based on TCP/IP
   protocol stack. The TCP/IP protocol stack has inherent performance flaws
   due to frequent memory copying and context switching. The Netty
   component not only limits the performance of the Storm but also
   increases the CPU load in the IPoIB (IP over InfiniBand) communication
   mode. In this paper, we introduce two new implementations for Apache
   Storm communication components with the help of RDMA technology. The
   performance evaluation on Mellanox QDR Cards (40 Gbps) shows that our
   implementations can achieve speedup up to 5x compared with IPoIB and 10
   x with Gigabit Ethernet. Our implementations also significantly reduce
   the CPU load and increase the throughput of the system.},
DOI = {10.1007/s10766-021-00696-0},
EarlyAccessDate = {MAR 2021},
ISSN = {0885-7458},
EISSN = {1573-7640},
ORCID-Numbers = {Zhang, Ziyu/0000-0001-6293-7227},
Unique-ID = {WOS:000630261600001},
}

@inproceedings{ WOS:000386610400056,
Author = {Kritikakis, Charalabos and Chrysos, Grigorios and Dollas, Apostolos and
   Pnevmatikatos, Dionisios N.},
Book-Group-Author = {IEEE},
Title = {An FPGA-based High-Throughput Stream Join Architecture},
Booktitle = {2016 26TH INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE LOGIC AND
   APPLICATIONS (FPL)},
Series = {International Conference on Field Programmable and Logic Applications},
Year = {2016},
Note = {26th International Conference on Field-Programmable Logic and
   Applications (FPL), Ecole Polytechnique Federale de Lausanne, Lausanne,
   SWITZERLAND, AUG 29-SEP 02, 2016},
Organization = {Huawei; EcoCloud; Micron; Xilinx; Intel PSG; IBM Zurich Res Labs; Atomic
   Rules; Algo Logic},
Abstract = {Stream join is a fundamental operation that combines information from
   different high-speed and high-volume data streams. This paper presents
   an FPGA-based architecture that maps the most performance-efficient
   stream join algorithm, i.e. ScaleJoin, to reconfigurable logic. The
   system was fully implemented on a Convey HC-2ex hybrid computer and the
   experimental performance evaluation shows that the proposed system
   outperforms by up to one order of magnitude the corresponding fully
   optimized parallel software-based solution running on a high-end 48-core
   multiprocessor platform. The proposed architecture can be used as a
   generic template for mapping stream processing algorithms to
   reconfigurable logic, taking into consideration real-world challenges.},
DOI = {10.1109/FPL.2016.7577354},
ISSN = {1946-1488},
ResearcherID-Numbers = {Dollas, Apostolos/AAN-2886-2021
   },
ORCID-Numbers = {Dollas, Apostolos/0000-0003-0060-6240
   Pnevmatikatos, Dionisios/0000-0003-3533-2761},
Unique-ID = {WOS:000386610400056},
}

@inproceedings{ WOS:000526051100099,
Author = {Gokalgandhi, Bhargav and Seskar, Ivan},
Book-Group-Author = {IEEE},
Title = {Distributed Processing for Encoding and Decoding of Binary LDPC codes
   using MPI},
Booktitle = {IEEE CONFERENCE ON COMPUTER COMMUNICATIONS WORKSHOPS (IEEE INFOCOM 2019
   WKSHPS)},
Series = {IEEE Conference on Computer Communications Workshops},
Year = {2019},
Pages = {596-601},
Note = {IEEE Conference on Computer Communications (IEEE INFOCOM), Paris,
   FRANCE, APR 29-MAY 02, 2019},
Organization = {IEEE},
Abstract = {Low Density Parity Check (LDPC) codes are linear error correcting codes
   used in communication systems for Forward Error Correction (FEC). But,
   intensive computation is required for encoding and decoding of LDPC
   codes, making it difficult for practical usage in general purpose
   software based signal processing systems. In order to accelerate the
   encoding and decoding of LDPC codes, distributed processing over
   multiple multi-core CPUs using Message Passing Interface (MPI) is
   performed. Implementation is done using Stream Processing and Batch
   Processing mechanisms and the execution time for both implementations is
   compared w.r.t variation in number of CPUs and number of cores per CPU.
   Performance evaluation of distributed processing is shown by variation
   in execution time w.r.t. increase in number of processors (CPU cores).},
ISSN = {2159-4228},
ISBN = {978-1-7281-1878-9},
ORCID-Numbers = {Gokalgandhi, Bhargav/0000-0002-9075-2921},
Unique-ID = {WOS:000526051100099},
}

@article{ WOS:000340185600003,
Author = {Sui, Zhiquan and Harvey, Neil and Pallickara, Shrideep},
Title = {On the distributed orchestration of stochastic discrete event
   simulations},
Journal = {CONCURRENCY AND COMPUTATION-PRACTICE \& EXPERIENCE},
Year = {2014},
Volume = {26},
Number = {11},
Pages = {1889-1907},
Month = {AUG 10},
Abstract = {Discrete event simulations are a powerful technique for modeling
   stochastic systems with multiple components where interactions between
   these components are governed by the probability distribution functions
   associated with them. Complex discrete event simulations are often
   computationally intensive with long completion times. This paper
   describes our solution to the problem of orchestrating the execution of
   a stochastic, discrete event simulation where computational hot spots
   evolve spatially over time. Our performance benchmarks report on our
   ability to balance computational loads in these settings. Copyright (C)
   2013 John Wiley \& Sons, Ltd.},
DOI = {10.1002/cpe.3121},
ISSN = {1532-0626},
EISSN = {1532-0634},
Unique-ID = {WOS:000340185600003},
}

@inproceedings{ WOS:000380615600013,
Author = {Peng, Boyang and Hosseini, Mohammad and Hong, Zhihao and Farivar, Reza
   and Campbell, Roy},
Book-Group-Author = {ACM},
Title = {R-Storm: Resource-Aware Scheduling in Storm},
Booktitle = {PROCEEDINGS OF THE 16TH ANNUAL MIDDLEWARE CONFERENCE},
Year = {2015},
Pages = {149-161},
Note = {16th Annual Middleware Conference, Vancouver, CANADA, DEC 07-11, 2015},
Organization = {HP; Assoc Comp Machinery; IBM; USENIX},
Abstract = {The era of big data has led to the emergence of new systems for
   real-time distributed stream processing, e.g., Apache Storm is one of
   the most popular stream processing systems in industry today. However,
   Storm, like many other stream processing systems lacks an intelligent
   scheduling mechanism. The default round-robin scheduling currently
   deployed in Storm disregards resource demands and availability, and can
   therefore be inefficient at times. We present R-Storm (Resource-Aware
   Storm), a system that implements resource aware scheduling within Storm.
   R-Storm is designed to increase overall throughput by maximizing
   resource utilization while minimizing network latency. When scheduling
   tasks, R-Storm can satisfy both soft and hard resource constraints as
   well as minimizing network distance between components that communicate
   with each other. We evaluate R-Storm on set of micro-benchmark Storm
   applications as well as Storm applications used in production at Yahoo!
   Inc. From our experimental results we conclude that R-Storm achieves
   30-47\% higher throughput and 69-350\% better CPU utilization than
   default Storm for the micro-benchmarks. For the Yahoo! Storm
   applications, R-Storm outperforms default Storm by around 50\% based on
   overall throughput. We also demonstrate that R-Storm performs much
   better when scheduling multiple Storm applications than default Storm.},
DOI = {10.1145/2814576.2814808},
ISBN = {978-1-4503-3618-5},
ResearcherID-Numbers = {Campbell, Roy/O-1141-2019},
ORCID-Numbers = {Campbell, Roy/0000-0002-3754-7777},
Unique-ID = {WOS:000380615600013},
}

@inproceedings{ WOS:000426972400156,
Author = {Grulich, Philipp M. and Zukunft, Olaf},
Editor = {Wu, Y and Min, G and Georgalas, N and AlDubi, A and Jin, X and Yang, L and Ma, J and Yang, P},
Title = {Smart Stream-based car information systems that scale: An experimental
   evaluation},
Booktitle = {2017 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND
   IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER,
   PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA)},
Year = {2017},
Pages = {1030-1037},
Note = {EEE International Conference on Internet of Things (iThings) and IEEE
   Green Computing and Communications (GreenCom) and IEEE Cyber, Physical
   and Social Computing (CPSCom) and IEEE Smart Data (SmartData), Exeter,
   ENGLAND, JUN 21-23, 2017},
Organization = {IEEE; IEEE Comp Soc; IEEETCSC; univ exeter},
Abstract = {Real-time information from embedded sources is hard to process if the
   number of sources is high. One typical example of this application area
   are car information systems where the cyber physical system of a car
   connects to arbitrary sources in and outside of the car to deliver value
   adding information to the driver of the car. In this paper, we propose a
   new architecture for such a car information system based on a smart data
   streaming infrastructure. This architecture has been implemented and we
   have run several experiments to examine the quality of our proposed
   solution. The current implementation is based on Spark Streaming,
   Couchbase and written in Scala. We have deployed our implementation on a
   distributed system using cloud services. This allows us to perform
   experiments with a high load as typical for the application scenario.
   First results from our experiments show that our proposed solution for a
   smart data based car information system is resilient to typical failures
   and scales for the described use cases.},
DOI = {10.1109/iThings-GreenCom-CPSCom-SmartData.2017.181},
ISBN = {978-1-5386-3066-2},
Unique-ID = {WOS:000426972400156},
}

@inproceedings{ WOS:000461467400070,
Author = {Rokicki, Markus and Zerr, Sergej and Siersdorfer, Stefan},
Book-Group-Author = {ACM},
Title = {Just in Time: Controlling Temporal Performance in Crowdsourcing
   Competitions},
Booktitle = {PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB
   (WWW'16)},
Year = {2016},
Pages = {816-826},
Note = {25th International Conference on World Wide Web (WWW), Montreal, CANADA,
   MAY 11-15, 2016},
Organization = {Assoc Comp Machinery; Int WWW Conf Comm; ACM SIGWEB; Google; Microsoft;
   Palais Congres Montreal; Tourisme Montreal; Yahoo Res; Baidu; Bookwitty;
   Cisco; YelloPages; IBM Res; UQAM},
Abstract = {Many modern data analytics applications in areas such as crisis
   management, stock trading, and healthcare, rely on components capable of
   nearly real-time processing of streaming data produced at varying rates.
   In addition to automatic processing methods, many tasks involved in
   those applications require further human assessment and analysis.
   However, current crowdsourcing platforms and systems do not support
   stream processing with variable loads. In this paper, we investigate how
   incentive mechanisms in competition based crowdsourcing can be employed
   in such scenarios. More specifically, we explore techniques for
   stimulating workers to dynamically adapt to both anticipated and sudden
   changes in data volume and processing demand, and we analyze effects
   such as data processing throughput, peak to -average ratios, and
   saturation effects. To this end, we study a wide range of incentive
   schemes and utility functions inspired by real world applications. Our
   large-scale experimental evaluation with more than 900 participants and
   more than 6200 hours of work spent by crowd workers demonstrates that
   our competition based mechanisms are capable of adjusting the throughput
   of online workers and lead to substantial on-demand performance boosts.},
DOI = {10.1145/2872427.2883075},
ISBN = {978-1-4503-4143-1},
Unique-ID = {WOS:000461467400070},
}

@article{ WOS:000459547800006,
Author = {Mortazavi-Dehkordi, Mahmood and Zamanifar, Kamran},
Title = {Efficient resource scheduling for the analysis of Big Data streams},
Journal = {INTELLIGENT DATA ANALYSIS},
Year = {2019},
Volume = {23},
Number = {1},
Pages = {77-102},
Abstract = {The emergence of Big Data has had a profound impact on how data are
   analyzed. Open source distributed stream processing platforms have
   gained popularity for analyzing streaming Big Data as they provide low
   latency required for streaming Big Data applications using cluster
   resources. However, existing resource schedulers are still lacking the
   efficiency that Big Data analytical applications require. Recent works
   have already considered streaming Big Data characteristics to improve
   the efficiency of scheduling in the platforms. Nevertheless, they have
   not taken into account the specific attributes of analytical
   applications. This study, therefore, presents Bframework, an efficient
   resource scheduling framework used by streaming Big Data analysis
   applications based on cluster resources. Bframework proposes a query
   model using Directed Graphs (DGs) and introduces operator assignment and
   operator scheduling algorithms based on a novel partitioning algorithm.
   Bframework is highly adaptable to the fluctuation of streaming Big Data
   and the availability of cluster resources. Experiments with the
   benchmark and well-known real-world queries show that Bframework can
   significantly reduce the latency of streaming Big Data analysis queries
   up to about 65\%.},
DOI = {10.3233/IDA-173691},
ISSN = {1088-467X},
EISSN = {1571-4128},
Unique-ID = {WOS:000459547800006},
}

@article{ WOS:000426811500005,
Author = {Antaris, Stefanos and Rafailidis, Dimitrios},
Title = {In-Memory Stream Indexing of Massive and Fast Incoming Multimedia
   Content},
Journal = {IEEE TRANSACTIONS ON BIG DATA},
Year = {2018},
Volume = {4},
Number = {1},
Pages = {40-54},
Month = {JAN-MAR},
Abstract = {In this article, a media storm indexing mechanism is presented, where
   media storms are defined as fast incoming batches. We propose an
   approximate media storm indexing mechanism to index/store massive image
   collections with varying incoming image rate. To evaluate the proposed
   indexing mechanism, two architectures are used: i) a baseline
   architecture, which utilizes a disk-based processing strategy and ii) an
   in-memory architecture, which uses the Flink distributed stream
   processing framework. This study is the first in the literature to
   utilize an in-memory processing strategy to provide a media storm
   indexing mechanism. In the experimental evaluation conducted on two
   image datasets, among the largest publicly available with 80 M and 1 B
   images, a media storm generator is implemented to evaluate the proposed
   media storm indexing mechanism on different indexing workloads, that is,
   images that come with high volume and different velocity at the scale of
   105 and 106 incoming images per second. Using the approximate media
   storm indexing mechanism a significant speedup factor, equal to 26.32 on
   average, is achieved compared with conventional indexing techniques,
   while maintaining high search accuracy, after having indexed the media
   storms. Finally, the implementations of both architectures and media
   storm indexing mechanisms are made publicly available.},
DOI = {10.1109/TBDATA.2017.2697441},
ISSN = {2332-7790},
ORCID-Numbers = {Rafailidis, Dimitrios/0000-0002-7366-3716},
Unique-ID = {WOS:000426811500005},
}

@inproceedings{ WOS:000366168000030,
Author = {Viel, Emeric and Ueda, Haruyasu},
Book-Group-Author = {IEEE},
Title = {Data Stream Partitioning Re-Optimization Based on Runtime Dependency
   Mining},
Booktitle = {2014 IEEE 30TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING WORKSHOPS
   (ICDEW)},
Year = {2014},
Pages = {199-206},
Note = {IEEE 30th International Conference on Data Engineering (ICDE), Chicago,
   IL, MAR 31-APR 04, 2014},
Organization = {IEEE; Microsoft; Qatar Comp Res Inst; HERE Nokia; Purdue Univ, Cyber
   Ctr; NW Univ, McCormick Sch Engn; Google},
Abstract = {In distributed data stream processing, a program made of multiple
   queries can be parallelized by partitioning input streams according to
   the values of specific attributes, or partitioning keys. Applying
   different partitioning keys to different queries requires
   re-partitioning intermediary streams, causing extra communication and
   reduced throughput. Repartitionings can be avoided by detecting
   dependencies between the partitioning keys applicable to each query.
   Existing partitioning optimization methods analyze query syntax at
   compile-time to detect inter-key dependencies and avoid repartitionings.
   This paper extends those compile-time methods by adding a runtime
   re-optimization step based on the mining of temporal approximate
   dependencies (TADs) between partitioning keys. A TAD is defined in this
   paper as a type of dependency that can be approximately valid over a
   moving time window. Our evaluation, based on a simulation of the Linear
   Road Benchmark, showed a 94.5\% reduction of the extra communication
   cost.},
ISBN = {978-1-4799-3481-2},
Unique-ID = {WOS:000366168000030},
}

@inproceedings{ WOS:000851014500003,
Author = {Dazzi, Patrizio and Mordacchini, Matteo},
Editor = {Heras, DB and Bouge, L and Mencagli, G and Jeannot, E and Sakellariou, R and Badia, RM and Barbosa, JG and Ricci, L and Scott, SL and Lankes, S and Weidendorfer, J},
Title = {NOA-AID: Network Overlays for Adaptive Information Aggregation, Indexing
   and Discovery at the Edge},
Booktitle = {EURO-PAR 2017: PARALLEL PROCESSING WORKSHOPS},
Series = {Lecture Notes in Computer Science},
Year = {2018},
Volume = {10659},
Pages = {29-41},
Note = {23rd International Conference on Parallel and Distributed Computing
   (Euro-Par), Santiago de Compostela, SPAIN, AUG 28-SEP 01, 2017},
Organization = {Univ Santiago Compostela, Centro Investigac Tecnoloxias Informac},
Abstract = {This paper presents NOA-AID a network architecture for targeting highly
   distributed systems, composed of a large set of distributed stream
   processing devices, aimed at adaptive information indexing, aggregation
   and discovery in streams of data. The architecture is organized on two
   layers. The upper layer is aimed at supporting the information discovery
   process by providing a distributed index structure. The lower layer is
   mainly devoted to resource aggregation based on epidemic protocols
   targeting highly distributed and dynamic scenarios, well suited to
   stream-oriented scenarios. We present a theoretical study on the costs
   of information management operations, also giving an empirical
   validation of such findings. Finally, we presented an experimental
   evaluation of the ability of our solution to be effective and efficient
   in retrieving meaningful information in streams on a highly-dynamic and
   distributed scenario.},
DOI = {10.1007/978-3-319-75178-8\_3},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-75178-8; 978-3-319-75177-1},
ORCID-Numbers = {Mordacchini, Matteo/0000-0002-1406-828X
   Dazzi, Patrizio/0000-0001-8504-1503},
Unique-ID = {WOS:000851014500003},
}

@inproceedings{ WOS:000628649800041,
Author = {Grulich, Philipp M. and Traub, Jonas and Bress, Sebastian and
   Katsifodimos, Asterios and Markl, Volker and Rabl, Tilmann},
Book-Group-Author = {Assoc Comp Machinery},
Title = {Poster: Generating Reproducible Out-of-Order Data Streams},
Booktitle = {DEBS'19: PROCEEDINGS OF THE 13TH ACM INTERNATIONAL CONFERENCE ON
   DISTRIBUTED AND EVENT-BASED SYSTEMS},
Year = {2019},
Pages = {256-257},
Note = {13th ACM International Conference on Distributed and Event-Based Systems
   (DEBS), Tech Univ Darmstadt, Darmstadt, GERMANY, JUN 24-28, 2019},
Organization = {Assoc Comp Machinery; ACM SIGMOD; ACM SIGSOFT; Internet \& Digitisat;
   CROSSING GmbH; SAP; Axxessio; DFG Collaborat Res Ctr 1053, MAKI Multi
   Mechanism Adapt Future Internet},
Abstract = {Evaluating modern stream processing systems in a reproducible manner
   requires data streams with different data distributions, data rates, and
   real-world characteristics such as delayed and out-of-order tuples. In
   this paper, we present an open source stream generator which generates
   reproducible and deterministic out-of-order streams based on real data
   files, simulating arbitrary fractions of out-of-order tuples and their
   respective delays.},
DOI = {10.1145/3328905.3332511},
ISBN = {978-1-4503-6794-3},
ResearcherID-Numbers = {Markl, Volker/AAX-1862-2020},
Unique-ID = {WOS:000628649800041},
}

@article{ WOS:000613217600001,
Author = {Dubuc, Timothee and Stahl, Frederic and Roesch, Etienne B.},
Title = {Mapping the Big Data Landscape: Technologies, Platforms and Paradigms
   for Real-Time Analytics of Data Streams},
Journal = {IEEE ACCESS},
Year = {2021},
Volume = {9},
Pages = {15351-15374},
Abstract = {The `Big Data' of yesterday is the `data' of today. As technology
   progresses, new challenges arise and new solutions are developed. Due to
   the emergence of Internet of Things applications within the last decade,
   the field of Data Mining has been faced with the challenge of processing
   and analysing data streams in real-time, and under high data throughput
   conditions. This is often referred to as the Velocity aspect of Big
   Data. Whereas there are numerous reviews on Data Stream Mining
   techniques and applications, there is very little work surveying Data
   Stream processing paradigms and associated technologies, from data
   collection through to pre-processing and feature processing, from the
   perspective of the user, not that of the service provider. In this
   article, we evaluate a particular type of solution, which focuses on
   streaming data, and processing pipelines that permit online analysis of
   data streams that cannot be stored as-is on the computing platform. We
   review foundational computational concepts such as distributed
   computation, fault-tolerant computing, and computational
   paradigms/architectures. We then review the available technological
   solutions, and applications that pertain to data stream mining as case
   studies of these theoretical concepts. We conclude with a discussion of
   the field of data stream processing/analytics, future directions and
   research challenges.},
DOI = {10.1109/ACCESS.2020.3046132},
ISSN = {2169-3536},
ORCID-Numbers = {Stahl, Frederic/0000-0002-4860-0203
   Roesch, Etienne/0000-0002-8913-4173},
Unique-ID = {WOS:000613217600001},
}

@inproceedings{ WOS:000345593400006,
Author = {McCurdy, Collin and Marin, Gabriel and Vetter, Jeffrey S.},
Editor = {Jarvis, S and Wright, S and Hammond, S},
Title = {Characterizing the Impact of Prefetching on Scientific Application
   Performance},
Booktitle = {HIGH PERFORMANCE COMPUTING SYSTEMS: PERFORMANCE MODELING, BENCHMARKING
   AND SIMULATION},
Series = {Lecture Notes in Computer Science},
Year = {2014},
Volume = {8551},
Pages = {115-135},
Note = {4th International Workshop on Performance Modeling, Benchmarking and
   Simulation of High-Performance Computing Systems (PMBS), Denver, CO, NOV
   18, 2013},
Abstract = {In order to better understand the impact of hardware and software data
   prefetching on scientific application performance, this paper introduces
   two analysis techniques, one micro-architecture-centric and the other
   application-centric. We use these techniques to analyze representative
   full-scale production applications from five important Exascale target
   areas. We find that despite a great diversity in prefetching
   effectiveness across and even within applications, there is a strong
   correlation between regions where prefetching is most needed, due to
   high levels of memory traffic, and where it is most effective. We also
   observe that the application-centric analysis can explain many of the
   differences in prefetching effectiveness observed across the studied
   applications.},
DOI = {10.1007/978-3-319-10214-6\_6},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-10214-6; 978-3-319-10213-9},
Unique-ID = {WOS:000345593400006},
}

@inproceedings{ WOS:000471023700007,
Author = {Hoffmann, Moritz and Lattuada, Andrea and Liagouris, John and Kalavri,
   Vasiliki and Dimitrova, Desislava and Wicki, Sebastian and Chothia,
   Zaheer and Roscoe, Timothy},
Book-Group-Author = {USENIX Assoc},
Title = {SnailTrail: Generalizing Critical Paths for Online Analysis of
   Distributed Dataflows},
Booktitle = {PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND
   IMPLEMENTATION (NSDI'18)},
Year = {2018},
Pages = {95-110},
Note = {15th USENIX Symposium on Networked Systems Design and Implementation,
   Renton, WA, APR 09-11, 2018},
Organization = {USENIX; Facebook; NSF; ByteDance; Google; Microsoft; Amazon; King
   Abdullah Univ Sci \& Technol; NetApp; VMWARE; Two Sigma; Cisco; Meraki;
   SIGCOMM; SIGOPS},
Abstract = {We rigorously generalize critical path analysis (CPA) to long-running
   and streaming computations and present SnailTrail, a system built on
   Timely Dataflow, which applies our analysis to a range of popular
   distributed dataflow engines. Our technique uses the novel metric of
   critical participation, computed on time-based snapshots of execution
   traces, that provides immediate insights into specific parts of the
   computation. This allows SnailTrail to work online in real-time, rather
   than requiring complete offline traces as with traditional CPA. It is
   thus applicable to scenarios like model training in machine learning,
   and sensor stream processing.
   SnailTrail assumes only a highly general model of dataflow computation
   (which we define) and we show it can be applied to systems as diverse as
   Spark, Flink, TensorFlow, and Timely Dataflow itself. We further show
   with examples from all four of these systems that SnailTrail is fast and
   scalable, and that critical participation can deliver performance
   analysis and insights not available using prior techniques.},
ISBN = {978-1-939133-01-4},
Unique-ID = {WOS:000471023700007},
}

@article{ WOS:000315546800010,
Author = {Ericson, Kathleen and Pallickara, Shrideep},
Title = {On the performance of high dimensional data clustering and
   classification algorithms},
Journal = {FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE},
Year = {2013},
Volume = {29},
Number = {4},
Pages = {1024-1034},
Month = {JUN},
Abstract = {There is often a need to perform machine learning tasks on voluminous
   amounts of data. These tasks have application in fields such as pattern
   recognition, data mining, bioinformatics, and recommendation systems.
   Here we evaluate the performance of 4 clustering algorithms and 2
   classification algorithms supported by Mahout within two different cloud
   runtimes, Hadoop and Granules. Our benchmarks use the same Mahout
   backend code, ensuring a fair comparison. The differences between these
   implementations stem from how the Hadoop and Granules runtimes (1)
   support and manage the lifecycle of individual computations, and (2) how
   they orchestrate exchange of data between different stages of the
   computational pipeline during successive iterations of the clustering
   algorithm. We include an analysis of our results for each of these
   algorithms in a distributed setting, as well as a discussion on measures
   for failure recovery. (c) 2012 Elsevier B.V. All rights reserved.},
DOI = {10.1016/j.future.2012.05.026},
ISSN = {0167-739X},
EISSN = {1872-7115},
Unique-ID = {WOS:000315546800010},
}

@inproceedings{ WOS:000529303200020,
Author = {Villalba, Alvaro and Carrera, David},
Editor = {Mencagli, G and Heras, DB},
Title = {Multi-tenant Pub/Sub Processing for Real-Time Data Streams},
Booktitle = {EURO-PAR 2018: PARALLEL PROCESSING WORKSHOPS},
Series = {Lecture Notes in Computer Science},
Year = {2019},
Volume = {11339},
Pages = {251-262},
Note = {International European Conference on Parallel and Distributed Computing
   (Euro-Par), Turin, ITALY, AUG 27-28, 2018},
Abstract = {Devices and sensors generate streams of data across a diversity of
   locations and protocols. That data usually reaches a central platform
   that is used to store and process the streams. Processing can be done in
   real time, with transformations and enrichment happening on-the-fly, but
   it can also happen after data is stored and organized in repositories.
   In the former case, stream processing technologies are required to
   operate on the data; in the latter batch analytics and queries are of
   common use.
   This paper introduces a runtime to dynamically construct data stream
   processing topologies based on user-supplied code. These dynamic
   topologies are built on-the-fly using a data subscription model defined
   by the applications that consume data. Each user-defined processing unit
   is called a Service Object. Every Service Object consumes input data
   streams and may produce output streams that others can consume. The
   subscription-based programing model enables multiple users to deploy
   their own data-processing services. The runtime does the dynamic
   forwarding of data and execution of Service Objects from different
   users. Data streams can originate in real-world devices or they can be
   the outputs of Service Objects.
   The runtime leverages Apache STORM for parallel data processing, that
   combined with dynamic user-code injection provides multi-tenant stream
   processing topologies. In this work we describe the runtime, its
   features and implementation details, as well as we include a performance
   evaluation of some of its core components.},
DOI = {10.1007/978-3-030-10549-5\_20},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-030-10549-5; 978-3-030-10548-8},
Unique-ID = {WOS:000529303200020},
}

@inproceedings{ WOS:000385263700036,
Author = {Najafi, Mohammadreza and Sadoghi, Mohammad and Jacobsen, Hans-Arno},
Book-Group-Author = {USENIX Assoc},
Title = {SplitJoin: A Scalable, Low-latency Stream Join Architecture with
   Adjustable Ordering Precision},
Booktitle = {PROCEEDINGS OF USENIX ATC `16: 2016 USENIX ANNUAL TECHNICAL CONFERENCE},
Year = {2016},
Pages = {493-505},
Note = {USENIX Annual Technical Conference (ATC), Denver, CO, JUN 22-24, 2016},
Organization = {USENIX; facebook; Google; VMWare; Apple; HUAWEI; NetApp; Microsoft Res;
   Microsoft; ACM Queue; ADMIN; CRC Press; Linux Pro Magazine; LXer; Morgan
   \& Claypool Publishers; No Starch Press; OReilly Media; Raspberry Pi
   Geek; Ubuntu User; Virus Bulletin; UserFriendly Org},
Abstract = {There is a rising interest in accelerating stream processing through
   modern parallel hardware, yet it remains a challenge as how to exploit
   the available resources to achieve higher throughput without sacrificing
   latency due to the increased length of processing pipeline and
   communication path and the need for central coordination. To achieve
   these objectives, we introduce a novel top-down data flow model for
   stream join processing (arguably, one of the most resource-intensive
   operators in stream processing), called SplitJoin, that operates by
   splitting the join operation into independent storing and processing
   steps that gracefully scale with respect to the number of cores.
   Furthermore, SplitJoin eliminates the need for global coordination while
   preserving the order of input streams by re-thinking how streams are
   channeled into distributed join computation cores and maintaining the
   order of output streams by proposing a novel distributed punctuation
   technique. Throughout our experimental analysis, SplitJoin offered up to
   60\% improvement in throughput while reducing latency by up to 3.3X
   compared to state-of-the-art solutions.},
ISBN = {978-1-931971-30-0},
Unique-ID = {WOS:000385263700036},
}

@article{ WOS:000323832900005,
Author = {Simoncelli, Davide and Dusi, Maurizio and Gringoli, Francesco and
   Niccolini, Saverio},
Title = {Stream-monitoring with BlockMon: Convergence of Network Measurements and
   Data Analytics Platforms},
Journal = {ACM SIGCOMM COMPUTER COMMUNICATION REVIEW},
Year = {2013},
Volume = {43},
Number = {2},
Pages = {29-35},
Month = {APR},
Abstract = {Recent work in network measurements focuses on scaling the performance
   of monitoring platforms to 10Gb/s and beyond. Concurrently, IT community
   focuses on scaling the analysis of big-data over a cluster of nodes. So
   far, combinations of these approaches have targeted fexibility and
   usability over real-timeliness of results and efficient allocation of
   resources. In this paper we show how to meet both objectives with
   BlockMon, a network monitoring platform originally designed to work on a
   single node, which we extended to run distributed stream-data analytics
   tasks. We compare its performance against Storm and Apache S4, the
   state-of-the-art open-source stream-processing platforms, by
   implementing a phone call anomaly detection system and a Twitter
   trending algorithm: our enhanced BlockMon has a gain in performance of
   over 2.5x and 23x, respectively. Given the different nature of those
   applications and the performance of BlockMon as single-node network
   monitor {[}1], we expect our results to hold for a broadrange of
   applications, making distributed BlockMon a good candidate for the
   convergence of network-measurement and IT-analysis platforms.},
DOI = {10.1145/2479957.2479962},
ISSN = {0146-4833},
EISSN = {1943-5819},
Unique-ID = {WOS:000323832900005},
}

@article{ WOS:000502789700016,
Author = {Wang, Yimeng and Li, Yongbo and Lan, Tian and Aggarwal, Vaneet},
Title = {DeepChunk: Deep Q-Learning for Chunk-Based Caching in Wireless Data
   Processing Networks},
Journal = {IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING},
Year = {2019},
Volume = {5},
Number = {4},
Pages = {1034-1045},
Month = {DEC},
Abstract = {A Data Processing Network (DPN) streams massive volumes of data
   collected and stored by the network to multiple processing units to
   compute desired results in a timely fashion. Due to ever-increasing
   traffic, distributed cache nodes can be deployed to store hot data and
   rapidly deliver them for consumption. However, prior work on caching
   policies has primarily focused on the potential gains in network
   performance, e.g., cache hit ratio and download latency, while
   neglecting the impact of cache on data processing and consumption. In
   this paper, we propose a novel framework, DeepChunk, which leverages
   deep Q-learning for chunk-based caching in wireless DPN. We show that
   cache policies must be optimized for both network performance during
   data delivery and processing efficiency during data consumption.
   Specifically, DeepChunk utilizes a model-free approach by jointly
   learning limited network, data streaming, and processing statistics at
   runtime and making cache update decisions under the guidance of deep
   Q-learning. It enables a joint optimization of multiple objectives
   including chunk hit ratio, processing stall time, and object download
   time while being self-adaptive under the time-varying workload and
   network conditions. We build a prototype implementation of DeepChunk
   with Ceph, a popular distributed object storage system. Based on
   real-world Wifi and 4G traces, our extensive experiments and evaluation
   demonstrate significant improvement, i.e., 52\% increase in total reward
   and 68\% decrease in processing stall time, over a number of baseline
   caching policies.},
DOI = {10.1109/TCCN.2019.2947550},
ISSN = {2332-7731},
ResearcherID-Numbers = {Aggarwal, Vaneet/A-4843-2017},
ORCID-Numbers = {Wang, Yimeng/0000-0002-2379-5884
   Aggarwal, Vaneet/0000-0001-9131-4723},
Unique-ID = {WOS:000502789700016},
}

@inproceedings{ WOS:000662554703011,
Author = {Gilroy, Justin and Paronyan, Satine and Acoltzi, Jonathan and Fukuda,
   Munehiro},
Editor = {Wu, XT and Jermaine, C and Xiong, L and Hu, XH and Kotevska, O and Lu, SY and Xu, WJ and Aluru, S and Zhai, CX and Al-Masri, E and Chen, ZY and Saltz, J},
Title = {Agent-Navigable Dynamic Graph Construction and Visualization over
   Distributed Memory},
Booktitle = {2020 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)},
Series = {IEEE International Conference on Big Data},
Year = {2020},
Pages = {2957-2966},
Note = {8th IEEE International Conference on Big Data (Big Data), ELECTR
   NETWORK, DEC 10-13, 2020},
Organization = {IEEE; IEEE Comp Soc; IBM; Ankura},
Abstract = {Some graph analyses, such as social network and biological network, need
   large-scale graph construction and maintenance over distributed memory
   space. Distributed data-streaming tools, including MapReduce and Spark,
   restrict some computational freedom of incremental graph modification
   and run-time graph visualization. Instead, we take an agent-based
   approach. We construct a graph from a scientific dataset in CSV, tab,
   and XML formats; dispatch many reactive agents on it; and analyze the
   graph in the form of their collective group behavior: propagation,
   flocking, and collision. The key to success is how to automate the
   run-time construction and visualization of agent-navigable graphs mapped
   over distributed memory. We implemented this distributed graph-computing
   support in the multi-agent spatial simulation (MASS) library, coupled
   with the Cytoscape graph visualization software. This paper presents the
   MASS implementation techniques and demonstrates its execution
   performance in comparison to MapReduce and Spark, using two benchmark
   programs: (1) an incremental construction of a complete graph and (2) a
   KD tree construction.},
DOI = {10.1109/BigData50022.2020.9378298},
ISSN = {2639-1589},
ISBN = {978-1-7281-6251-5},
Unique-ID = {WOS:000662554703011},
}

@inproceedings{ WOS:000569720900074,
Author = {Mebrek, Wafaa and Bouzeghoub, Amel},
Book-Group-Author = {ACM},
Title = {A Stream Reasoning framework based on a Multi-Agents model},
Booktitle = {PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING
   (SAC'20)},
Year = {2020},
Pages = {509-512},
Note = {35th Annual ACM Symposium on Applied Computing (SAC), Czech Tech Univ,
   ELECTR NETWORK, MAR 30-APR 03, 2020},
Organization = {ACM; Masaryk Univ Czechia; Microsoft Res; ACM Special Interest Grp Appl
   Comp; Natl Inst Technol Calicut},
Abstract = {Processing on-the-fly high volume of data streams is increasingly
   needed. To cope with the heterogeneity of this data, RDF model is more
   and more being adopted leading to plethora of RDF Stream Processing
   (RSP) systems and languages dealing with issues such as continuous
   querying, incremental reasoning and complex event processing (CEP).
   However, most of them has implemented centralized approaches and
   therefore suffer from some limitations as collaboration, sharing,
   expressiveness and scalability. Multi-agents systems have widely proven
   their worth and efficiency in particular their intrinsic decentralized
   property along with their cooperation and communication mechanism. In
   this paper we propose a new framework MAS4MEAN (Multi-Agent System for
   streaM rEAsoNing) based on a multi-agents model to embrace their
   benefits and tackle the challenges of increasing the scalability and
   ease of deployment in highly dynamic environments. A preliminary
   experimental evaluation with a real-world dataset show promising results
   when compared to an existing work.},
DOI = {10.1145/3341105.3374111},
ISBN = {978-1-4503-6866-7},
Unique-ID = {WOS:000569720900074},
}

@inproceedings{ WOS:000380545200041,
Author = {Kreutzer, Moritz and Hager, Georg and Wellein, Gerhard and Pieper,
   Andreas and Alvermann, Andreas and Fehske, Holger},
Book-Group-Author = {IEEE},
Title = {Performance Engineering of the Kernel Polynomial Method on Large-Scale
   CPU-GPU Systems},
Booktitle = {2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM (IPDPS)},
Series = {International Parallel and Distributed Processing Symposium IPDPS},
Year = {2015},
Pages = {417-426},
Note = {29th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS), Hyderabad, INDIA, MAY 25-29, 2015},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {The Kernel Polynomial Method (KPM) is a well-established scheme in
   quantum physics and quantum chemistry to determine the eigenvalue
   density and spectral properties of large sparse matrices. In this work
   we demonstrate the high optimization potential and feasibility of
   peta-scale heterogeneous CPU-GPU implementations of the KPM. At the node
   level we show that it is possible to decouple the sparse matrix problem
   posed by KPM from main memory bandwidth both on CPU and GPU. To
   alleviate the effects of scattered data access we combine loosely
   coupled outer iterations with tightly coupled block sparse matrix
   multiple vector operations, which enables pure data streaming. All
   optimizations are guided by a performance analysis and modelling process
   that indicates how the computational bottlenecks change with each
   optimization step. Finally we use the optimized node-level KPM with a
   hybrid-parallel framework to perform large scale heterogeneous
   electronic structure calculations for novel topological materials on a
   petascale-class Cray XC30 system.},
DOI = {10.1109/IPDPS.2015.76},
ISSN = {1530-2075},
ISBN = {978-1-4799-8648-4},
ResearcherID-Numbers = {Hager, Georg/AAG-6433-2020},
ORCID-Numbers = {Hager, Georg/0000-0002-8723-2781},
Unique-ID = {WOS:000380545200041},
}

@inproceedings{ WOS:000390674600056,
Author = {HoseinyFarahabady, M. Reza and Samani, Hamid R. Dehghani and Wang, Yidan
   and Zomaya, Albert Y. and Tari, Zahir},
Editor = {Pellegrini, A and GkoulalasDivanis, A and DiSanzo, P and Avresky, DR},
Title = {A QoS-Aware Controller for Apache Storm},
Booktitle = {15TH IEEE INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS
   (IEEE NCA 2016)},
Year = {2016},
Pages = {334-342},
Note = {15th IEEE International Symposium on Network Computing and Applications
   (IEEE NCA), Cambridge, MA, OCT 30-NOV 02, 2016},
Organization = {IEEE; IEEE Comp Soc Tech Comm Distributed Proc; Akamai Technologies Inc;
   Int Res Inst Autonom Network Comp; IEEE Comp Soc},
Abstract = {Apache Storm has recently emerged as an attractive fault-tolerant
   open-source distributed data processing platform that has been chosen by
   many industry leaders to develop real-time applications for processing a
   huge amount of data in a scalable manner. A key aspect to achieve the
   best performance in this system lies on the design of an efficient
   scheduler for component execution, called topology, on the available
   computing resources. In response to workload fluctuations, we propose an
   advanced scheduler for Apache Storm that provides improved performance
   with highly dynamic behavior. While enforcing the required
   Quality-of-Service (QoS) of individual data streams, the controller
   allocates computing resources based on decisions that consider the
   future states of non-controllable disturbance parameters, e.g. arriving
   rate of tuples or resource utilization in each worker node. The
   performance evaluation is carried out by comparing the proposed solution
   with two well-known alternatives, namely the Storm's default scheduler
   and the best-effort approach (i.e. the heuristic that is based on the
   first-fit decreasing approximation algorithm). Experimental results
   clearly show that the proposed controller increases the overall resource
   utilization by 31\% on average compared to the two others solutions,
   without significant negative impact on the QoS enforcement level.},
ISBN = {978-1-5090-3216-7},
ResearcherID-Numbers = {Zomaya, Albert Y./G-9697-2017
   HoseinyFarahabady, M.Reza/H-4571-2013},
ORCID-Numbers = {Zomaya, Albert Y./0000-0002-3090-1059
   HoseinyFarahabady, M.Reza/0000-0002-7851-9377},
Unique-ID = {WOS:000390674600056},
}

@inproceedings{ WOS:000408271500017,
Author = {Jambi, Sahar and Anderson, Kenneth M.},
Book-Group-Author = {IEEE},
Title = {Engineering Scalable Distributed Services for Real-Time Big Data
   Analytics},
Booktitle = {2017 THIRD IEEE INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE
   AND APPLICATIONS (IEEE BIGDATASERVICE 2017)},
Year = {2017},
Pages = {131-140},
Note = {3rd IEEE International Conference on Big Data Computing Service and
   Applications (BigDataService), San Francisco, CA, APR 06-10, 2017},
Organization = {IEEE; IEEE Comp Soc; San Jose State Univ; Beihang Univ; ITC NSTI;
   Arizona State Univ; Peking Univ; NW Polytechn Univ; Deakin Univ
   Australia; Univ Leeds; UOttawa; Taiyuan Univ Technol; UTS},
Abstract = {There is high demand for tools that analyze large sets of streaming data
   in both industrial and academic settings. While existing work has
   examined a wide range of issues, we focus on query support. In
   particular, we focus on providing analysts flexibility with respect to
   the types of queries they can make on large data sets in real time as
   well as over historical data. We have designed and implemented a
   lightweight service-based framework-EPIC Real-Time that manages a set of
   queries that can be applied to user initiated data analysis events (such
   as studying tweets generated during a disaster). Our prototype combines
   stream processing and batch processing techniques inspired by the Lambda
   Architecture. We investigate a core set of query types that can answer a
   wide range of queries asked by analysts who study crisis events. In this
   paper, we present a prototype implementation of EPIC Real-Time which
   makes use of event driven and reactive programming techniques. We also
   present a performance evaluation on how efficiently the real-time and
   batch-oriented queries perform, how well these queries meet the needs of
   our analysts, and provide insight into how EPIC Real-Time performs along
   a number of dimensions including performance, usability, scalability,
   and reliability.},
DOI = {10.1109/BigDataService.2017.22},
ISBN = {978-1-5090-6318-5},
ResearcherID-Numbers = {Anderson, Kenneth M/A-2971-2008},
ORCID-Numbers = {Anderson, Kenneth M/0000-0001-9860-7908},
Unique-ID = {WOS:000408271500017},
}

@inproceedings{ WOS:000458692200033,
Author = {Jonathan, Albert and Chandra, Abhishek and Weissman, Jon},
Book-Group-Author = {ACM},
Title = {Multi-Query Optimization in Wide-Area Streaming Analytics},
Booktitle = {PROCEEDINGS OF THE 2018 ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC `18)},
Year = {2018},
Pages = {412-425},
Note = {ACM Symposium on Cloud Computing (SoCC), Carlsbad, CA, OCT 11-13, 2018},
Organization = {Assoc Comp Machinery; ACM SIGMOD; ACM SIGOPS},
Abstract = {Wide-area data analytics has gained much attention in recent years due
   to the increasing need for analyzing data that are geographically
   distributed. Many of such queries often require real-time analysis on
   data streams that are continuously being generated across multiple
   locations. Yet, analyzing these geo-distributed data streams in a timely
   manner is very challenging due to the highly heterogeneous and limited
   bandwidth availability of the wide-area network (WAN). This paper
   examines the opportunity of applying multi-query optimization in the
   context of wide-area streaming analytics, with the goal of utilizing WAN
   bandwidth efficiently while achieving high throughput and low latency
   execution. Our approach is based on the insight that many streaming
   analytics queries often exhibit common executions, whether in consuming
   a common set of input data or performing the same data processing. In
   this work, we study different types of sharing opportunities and propose
   a practical online algorithm that allows streaming analytics queries to
   share their common executions incrementally. We further address the
   importance of WAN awareness in applying multi-query optimization.
   Without WAN awareness, sharing executions in a wide-area environment may
   lead to performance degradation. We have implemented our WAN-aware
   multi-query optimization in a prototype implementation based on Apache
   Flink. Experimental evaluation using Twitter traces on a real wide-area
   system deployment across geo-distributed EC2 data centers shows that our
   technique is able to achieve 21\% higher throughput while saving WAN
   bandwidth consumption by 33\% compared to a WAN-aware, sharing-agnostic
   system.},
DOI = {10.1145/3267809.3267842},
ISBN = {978-1-4503-6011-1},
Unique-ID = {WOS:000458692200033},
}

@article{ WOS:000622094200008,
Author = {Buddhika, Thilina and Pallickara, Sangmi Lee and Pallickara, Shrideep},
Title = {Pebbles: Leveraging Sketches for Processing Voluminous, High Velocity
   Data Streams},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2021},
Volume = {32},
Number = {8},
Pages = {2005-2020},
Month = {AUG 1},
Abstract = {Voluminous, time-series data streams originating in continuous sensing
   environments pose data ingestion and processing challenges. We present a
   holistic methodology centered around data sketching to address both
   challenges. We introduce an order-preserving sketching algorithm that we
   have designed for space-efficient representation of multi-feature
   streams with native support for stream processing related operations.
   Observational streams are preprocessed at the edges of the network
   generating sketched streams to reduce data transfer costs and energy
   consumption. Ingested sketched streams are then processed using
   sketch-aware extensions to existing stream processing APIs delivering
   improved performance. Our benchmarks with real-world datasets show up to
   a similar to 8x reduction in data volumes transferred and a similar to
   27x improvement in throughput.},
DOI = {10.1109/TPDS.2021.3055265},
ISSN = {1045-9219},
EISSN = {1558-2183},
Unique-ID = {WOS:000622094200008},
}

@article{ WOS:000736445900001,
Author = {HoseinyFarahabady, MohammadReza and Taheri, Javid and Zomaya, Albert Y.
   and Tari, Zahir},
Title = {Energy efficient resource controller for Apache Storm},
Journal = {CONCURRENCY AND COMPUTATION-PRACTICE \& EXPERIENCE},
Abstract = {Apache Storm is a distributed processing engine that can reliably
   process unbounded streams of data for real-time applications. While
   recent research activities mostly focused on devising a resource
   allocation and task scheduling algorithm to satisfy high performance or
   low latency requirements of Storm applications across a distributed and
   multi-core system, finding a solution that can optimize the energy
   consumption of running applications remains an important research
   question to be further explored. In this article, we present a
   controlling strategy for CPU throttling that continuously optimize the
   level of consumed energy of a Storm platform by adjusting the voltage
   and frequency of the CPU cores while running the assigned tasks under
   latency constraints defined by the end-users. The experimental results
   running over a Storm cluster with 4 physical nodes (total 24 cores)
   validates the effectiveness of proposed solution when running multiple
   compute-intensive operations. In particular, the proposed controller can
   keep the latency of analytic tasks, in terms of 99th latency percentile,
   within the quality of service requirement specified by the end-user
   while reducing the total energy consumption by 18\% on average across
   the entire Storm platform.},
DOI = {10.1002/cpe.6799},
EarlyAccessDate = {DEC 2021},
Article-Number = {e6799},
ISSN = {1532-0626},
EISSN = {1532-0634},
ResearcherID-Numbers = {Zomaya, Albert Y./G-9697-2017
   Taheri, Javid/I-2045-2013
   },
ORCID-Numbers = {Zomaya, Albert Y./0000-0002-3090-1059
   HoseinyFarahabady, MohammadReza/0000-0002-7851-9377
   Taheri, Javid/0000-0001-9194-010X
   Tari, Zahir/0000-0002-1235-9673},
Unique-ID = {WOS:000736445900001},
}

@inproceedings{ WOS:000380462900025,
Author = {Baer, Arian and Finamore, Alessandro and Casas, Pedro and Golab, Lukasz
   and Mellia, Marco},
Editor = {Lin, J and Hu, XH and Chang, W and Nambiar, R and Aggarwal, C and Cercone, N and Honavar, V and Huan, J and Mobasher, B and Pyne, S},
Book-Group-Author = {IEEE},
Title = {Large-Scale Network Traffic Monitoring with DBStream, a System for
   Rolling Big Data Analysis},
Booktitle = {2014 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)},
Series = {IEEE International Conference on Big Data},
Year = {2014},
Pages = {165-170},
Note = {IEEE International Conference on Big Data, Washington, DC, OCT 27-30,
   2014},
Organization = {IEEE; IEEE Comp Soc; ELSEVIER; Natl Sci Fdn; CISCO; CCF},
Abstract = {The complexity of the Internet has rapidly increased, making it more
   important and challenging to design scalable network monitoring tools.
   Network monitoring typically requires rolling data analysis, i.e.,
   continuously and incrementally updating (rolling-over) various reports
   and statistics over high-volume data streams. In this paper, we describe
   DBStream, which is an SQL-based system that explicitly supports
   incremental queries for rolling data analysis. We also present a
   performance comparison of DBStream with a parallel data processing
   engine (Spark), showing that, in some scenarios, a single DBStream node
   can outperform a cluster of ten Spark nodes on rolling network
   monitoring workloads. Although our performance evaluation is based on
   network monitoring data, our results can be generalized to other big
   data problems with high volume and velocity.},
ISSN = {2639-1589},
ISBN = {978-1-4799-5666-1},
ResearcherID-Numbers = {Mellia, Marco/G-7997-2018},
ORCID-Numbers = {Mellia, Marco/0000-0003-1859-6693},
Unique-ID = {WOS:000380462900025},
}

@inproceedings{ WOS:000541531400040,
Author = {Hoseinyfarahabady, M. Reza and Farhangsadr, Nazanin and Zomaya, Albert
   Y. and Tari, Zahir and Khan, Samee U.},
Editor = {Shi, Y and Fu, H and Tian, Y and Krzhizhanovskaya, VV and Lees, MH and Dongarra, J and Sloot, PMA},
Title = {Elastic CPU Cap Mechanism for Timely Dataflow Applications},
Booktitle = {COMPUTATIONAL SCIENCE - ICCS 2018, PT I},
Series = {Lecture Notes in Computer Science},
Year = {2018},
Volume = {10860},
Pages = {554-568},
Note = {18th International Conference on Computational Science (ICCS), Wuxi,
   PEOPLES R CHINA, JUN 11-13, 2018},
Organization = {Univ Chinese Acad Sci; Natl Supercomputing Ctr Wuxi; Univ Amsterdam; NTU
   Singapore; Univ Tennessee},
Abstract = {Sudden surges in the incoming workload can cause adverse consequences on
   the run-time performance of data-flow applications. Our work addresses
   the problem of limiting CPU associated with the elastic scaling of
   timely data-flow (TDF) applications running in a shared computing
   environment while each application can possess a different quality of
   service (QoS) requirement. The key argument here is that an unwise
   consolidation decision to dynamically scale up/out the computing
   resources for responding to unexpected workload changes can degrade the
   performance of some (if not all) collocated applications due to their
   fierce competition getting the shared resources (such as the last level
   cache). The proposed solution uses a queue-based model to predict the
   performance degradation of running data-flow applications together. The
   problem of CPU cap adjustment is addressed as an optimization problem,
   where the aim is to reduce the quality of service violation incidents
   among applications while raising the CPU utilization level of server
   nodes as well as preventing the formation of bottlenecks due to the
   fierce competition among collocated applications. The controller uses
   and efficient dynamic method to find a solution at each round of the
   controlling epoch. The performance evaluation is carried out by
   comparing the proposed controller against an enhanced QoS-aware version
   of round robin strategy which is deployed in many commercial packages.
   Experimental results confirmed that the proposed solution improves QoS
   satisfaction by near to 148\% on average while it can reduce the latency
   of processing data records for applications in the highest QoS classes
   by near to 19\% during workload surges.},
DOI = {10.1007/978-3-319-93698-7\_42},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-93698-7; 978-3-319-93697-0},
ResearcherID-Numbers = {Khan, Samee U./AAA-3302-2019
   Zomaya, Albert Y./G-9697-2017
   },
ORCID-Numbers = {Khan, Samee U./0000-0001-8650-4354
   Zomaya, Albert Y./0000-0002-3090-1059
   HoseinyFarahabady, MohammadReza/0000-0002-7851-9377
   Tari, Zahir/0000-0002-1235-9673},
Unique-ID = {WOS:000541531400040},
}

@article{ WOS:000368383200021,
Author = {Tudoran, Radu and Costan, Alexandru and Nano, Olivier and Santos, Ivo
   and Soncu, Hakan and Antoniu, Gabriel},
Title = {JetStream: Enabling high throughput live event streaming on multi-site
   clouds},
Journal = {FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE},
Year = {2016},
Volume = {54},
Pages = {274-291},
Month = {JAN},
Abstract = {Scientific and commercial applications operate nowadays on tens of cloud
   datacenters around the globe, following similar patterns: they aggregate
   monitoring or sensor data, assess the QoS or run global data mining
   queries based on inter-site event stream processing. Enabling fast data
   transfers across geographically distributed sites allows such
   applications to manage the continuous streams of events in real time and
   quickly react to changes. However, traditional event processing engines
   often consider data resources as second-class citizens and support
   access to data only as a side-effect of computation (i.e. they are not
   concerned by the transfer of events from their source to the processing
   site): This is an efficient approach as long as the processing is
   executed in a single cluster where nodes are interconnected by low
   latency networks. In a distributed environment, consisting of multiple
   datacenters, with orders of magnitude differences in capabilities and
   connected by a WAN, this will undoubtedly lead to significant latency
   and performance variations. This is namely the challenge we address in
   this paper, by proposing JetStream, a high performance batch-based
   streaming middleware for efficient transfers of events between cloud
   datacenters. JetStream is able to self-adapt to the streaming conditions
   by modeling and monitoring a set of context parameters. It further
   aggregates the available bandwidth by enabling multi-route streaming
   across cloud sites, while at the same time optimizing resource
   utilization and increasing cost efficiency. The prototype was validated
   on tens of nodes from US and Europe datacenters of the Windows Azure
   cloud with synthetic benchmarks and a real-life application monitoring
   the ALICE experiment at CERN. The results show a 3 x increase of the
   transfer rate using the adaptive multi-route streaming, compared to
   state of the art solutions. (c) 2015 Elsevier B.V. All rights reserved.},
DOI = {10.1016/j.future.2015.01.016},
ISSN = {0167-739X},
EISSN = {1872-7115},
ResearcherID-Numbers = {Antoniu, Gabriel/V-9919-2019
   Costan, Alexandru/AAC-1776-2020},
ORCID-Numbers = {Costan, Alexandru/0000-0003-3111-6308},
Unique-ID = {WOS:000368383200021},
}

@article{ WOS:000498569400001,
Author = {Maroulis, Stathis and Zacheilas, Nikos and Kalogeraki, Vana},
Title = {A Holistic Energy-Efficient Real-Time Scheduler for Mixed Stream and
   Batch Processing Workloads},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2019},
Volume = {30},
Number = {12},
Pages = {2624-2635},
Month = {DEC},
Abstract = {In recent years we have experienced a wide adoption of novel distributed
   processing frameworks such as Apache Spark for handling batch and stream
   processing big data applications. An important aspect that has not been
   examined in these systems yet, is the energy consumption during the
   applications' execution. Reducing the energy consumption of modern
   datacenters is a necessity, as datacenters contribute over 2 percent of
   the total US electric usage. However, efficiently scheduling
   applications in distributed processing systems can be challenging as
   there is a trade-off between minimizing the datacenter \& x0027;s energy
   usage and satisfying the application performance requirements. In this
   work we propose, ExpREsS, a scheduler for orchestrating the execution of
   Spark applications in a way that enables us to minimize the energy
   consumption while ensuring that the applications' performance
   requirements are met. Our approach exploits time-series segmentation for
   capturing the applications' energy usage and execution times, and then
   applies a novel DVFS technique to minimize the energy consumption. In
   order to tackle the limited number of application \& x0027;s profiling
   runs, we exploit regression techniques to predict the applications'
   execution times and power consumption. Our detailed experimental
   evaluation using realistic workloads on our local cluster illustrates
   the working and benefits of our approach.},
DOI = {10.1109/TPDS.2019.2922606},
ISSN = {1045-9219},
EISSN = {1558-2183},
ResearcherID-Numbers = {Kalogeraki, Vana/ABI-1469-2020
   },
ORCID-Numbers = {Kalogeraki, Vana/0000-0002-6421-9947
   Maroulis, Stathis/0000-0002-2872-7821},
Unique-ID = {WOS:000498569400001},
}

@article{ WOS:000833417900005,
Author = {Mostafaei, Habib and Afridi, Shafi and Abawajy, Jemal},
Title = {Network-aware worker placement for wide-area streaming analytics},
Journal = {FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE},
Year = {2022},
Volume = {136},
Pages = {270-281},
Month = {NOV},
Abstract = {Many organizations leverage Distributed Stream processing systems (DPSs)
   to get insights from the data generated by different users/devices,
   e.g., the Internet of Things (IoT) devices or user clicks on a website,
   on geographically distributed datacenters. The worker nodes in such
   environments are connected through Wide Area Network (WAN) links with
   various delays and bandwidth. Therefore, minimizing the execution
   latency of a task on the worker nodes while using the links with enough
   bandwidth and lower cost to steer the traffic of the applications is a
   challenging task. In this paper, we formulate the worker node placement
   for a geo-distributed DSPs network as a multi-criteria decision-making
   problem. Then, we propose an additive weighting-based approach to solve
   it. The users can prioritize the worker node placement according to the
   network-relevant parameters. We also propose a framework that can be
   integrated with the current DPSs to execute the tasks. We test our
   placement approach on three widely used stream processing systems, i.e.,
   Apache Spark, Apache Storm, and Apache Flink, on three custom graphs
   adopted from the real cloud providers. We run the streaming query of the
   Yahoo! streaming benchmark on these three DPSs. The experimental results
   show that our approach improves the performance of Spark up to
   2.2x-7.2x, Storm up to 1.2x-3.4x, and Flink up to 1.4x-3.3x compared
   with other placement approaches, which makes our framework useful for
   use in practical environments. (C) 2022 The Author(s). Published by
   Elsevier B.V.},
DOI = {10.1016/j.future.2022.06.009},
ISSN = {0167-739X},
EISSN = {1872-7115},
ResearcherID-Numbers = {Mostafaei, Habib/A-4330-2012},
ORCID-Numbers = {Mostafaei, Habib/0000-0001-8282-1571},
Unique-ID = {WOS:000833417900005},
}

@inproceedings{ WOS:000452644300004,
Author = {Maroulis, Stathis and Zacheilas, Nikos and Kalogeraki, Vana},
Editor = {Wang, XR and Stewart, C and Lei, H},
Title = {ExpREsS: EneRgy Efficient Scheduling of Mixed Stream and Batch
   Processing Workloads},
Booktitle = {2017 IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC COMPUTING (ICAC)},
Year = {2017},
Pages = {27-32},
Note = {14th IEEE International Conference on Autonomic Computing (ICAC), Ohio
   State Univ, Columbus, OH, JUL 17-21, 2017},
Organization = {IEEE; IEEE Comp Soc; IEEE Comp Soc Tech Comm Internet; USENIX; SPEC Res
   Grp; NSF; Google; Huawei; Microsoft; Ohio State Univ, Dept Comp Sci \&
   Engn; Ohio State Univ, Translat Data Analyt Inst},
Abstract = {Nowadays we see the wide adoption of novel distributed processing
   frameworks such as Apache Spark for handling batch and stream processing
   big data applications. An important aspect that has not been examined in
   these systems is their energy consumption during the application
   execution. Reducing the power consumption of modern datacenters is a
   necessity as datacenters contribute over 2\% of the total US electric
   usage. One way of addressing this energy issue is by scheduling the
   applications in an energy-efficient way. However, efficiently scheduling
   applications can be challenging as we need to consider the trade-off
   between the datacenter's energy usage and per application performance
   requirements. In this work we propose, ExpREsS, a scheduler for
   orchestrating the execution of Spark applications so that it both
   minimizes the energy consumption and satisfies the applications'
   performance requirements. Our approach exploits time-series prediction
   models for capturing the applications' energy usage and execution times,
   and then applies a novel DVFS technique to minimize the energy
   consumption. Our detailed experimental evaluation using realistic
   workloads on our local cluster illustrates the working and benefits of
   our approach.},
DOI = {10.1109/ICAC.2017.43},
ISBN = {978-1-5386-1762-5},
ResearcherID-Numbers = {Kalogeraki, Vana/ABI-1469-2020
   Maroulis, Stathis/U-3733-2019},
ORCID-Numbers = {Kalogeraki, Vana/0000-0002-6421-9947
   },
Unique-ID = {WOS:000452644300004},
}

@article{ WOS:000366167500003,
Author = {Kumbhare, Alok Gautam and Simmhan, Yogesh and Frincu, Marc and Prasanna,
   Viktor K.},
Title = {Reactive Resource Provisioning Heuristics for Dynamic Dataflows on Cloud
   Infrastructure},
Journal = {IEEE TRANSACTIONS ON CLOUD COMPUTING},
Year = {2015},
Volume = {3},
Number = {2},
Pages = {105-118},
Month = {APR-JUN},
Abstract = {The need for low latency analysis over high-velocity data streams
   motivates the need for distributed continuous dataflow systems.
   Contemporary stream processing systems use simple techniques to scale on
   elastic cloud resources to handle variable data rates. However,
   application QoS is also impacted by variability in resource performance
   exhibited by clouds and hence necessitates autonomic methods of
   provisioning elastic resources to support such applications on cloud
   infrastructure. We develop the concept of ``dynamic dataflows{''} which
   utilize alternate tasks as additional control over the dataflow's cost
   and QoS. Further, we formalize an optimization problem to represent
   deployment and runtime resource provisioning that allows us to balance
   the application's QoS, value, and the resource cost. We propose two
   greedy heuristics, centralized and sharded, based on the variable-sized
   bin packing algorithm and compare against a Genetic Algorithm (GA) based
   heuristic that gives a near-optimal solution. A large-scale simulation
   study, using the linear road benchmark and VM performance traces from
   the AWS public cloud, shows that while GA-based heuristic provides a
   better quality schedule, the greedy heuristics are more practical, and
   can intelligently utilize cloud elasticity to mitigate the effect of
   variability, both in input data rates and cloud resource performance, to
   meet the QoS of fast data applications.},
DOI = {10.1109/TCC.2015.2394316},
ISSN = {2168-7161},
ResearcherID-Numbers = {Frincu, Marc E/C-2934-2012
   },
ORCID-Numbers = {Frincu, Marc E/0000-0003-1034-8409
   Simmhan, Yogesh/0000-0003-4140-7774},
Unique-ID = {WOS:000366167500003},
}

@article{ WOS:000434678500011,
Author = {Dayarathna, Miyuru and Perera, Srinath},
Title = {Recent Advancements in Event Processing},
Journal = {ACM COMPUTING SURVEYS},
Year = {2018},
Volume = {51},
Number = {2},
Month = {JUN},
Abstract = {Event processing (EP) is a data processing technology that conducts
   online processing of event information. In this survey, we summarize the
   latest cutting-edge work done on EP from both industrial and academic
   research community viewpoints. We divide the entire field of EP into
   three subareas: EP system architectures, EP use cases, and EP open
   research topics. Then we deep dive into the details of each subsection.
   We investigate the system architecture characteristics of novel EP
   platforms, such as Apache Storm, Apache Spark, and Apache Flink. We
   found significant advancements made on novel application areas, such as
   the Internet of Things; streaming machine learning (ML); and processing
   of complex data types such as text, video data streams, and graphs.
   Furthermore, there has been significant body of contributions made on
   event ordering, system scalability, development of EP languages and
   exploration of use of heterogeneous devices for EP, which we investigate
   in the latter half of this article. Through our study, we found key
   areas that require significant attention from the EP community, such as
   Streaming ML, EP system benchmarking, and graph stream processing.},
DOI = {10.1145/3170432},
Article-Number = {33},
ISSN = {0360-0300},
EISSN = {1557-7341},
Unique-ID = {WOS:000434678500011},
}

@article{ WOS:000352123000002,
Author = {Pripuzic, Kresimir and Zarko, Ivana Podnar and Aberer, Karl},
Title = {Time- and Space-Efficient Sliding Window Top-k Query Processing},
Journal = {ACM TRANSACTIONS ON DATABASE SYSTEMS},
Year = {2015},
Volume = {40},
Number = {1},
Abstract = {A sliding window top-k (top-k/w) query monitors incoming data stream
   objects within a sliding window of size w to identify the k
   highest-ranked objects with respect to a given scoring function over
   time. Processing of such queries is challenging because, even when an
   object is not a top-k/w object at the time when it enters the processing
   system, it might become one in the future. Thus a set of potential
   top-k/w objects has to be stored in memory while its size should be
   minimized to efficiently cope with high data streaming rates. Existing
   approaches typically store top-k/w and candidate sliding window objects
   in a k-skyband over a two-dimensional score-time space. However, due to
   continuous changes of the k-skyband, its maintenance is quite costly.
   Probabilistic k-skyband is a novel data structure storing data stream
   objects from a sliding window with significant probability to become
   top-k/w objects in future. Continuous probabilistic k-skyband.
   maintenance offers considerably improved runtime performance compared to
   k-skyband maintenance, especially for large values of k, at the expense
   of a small and controllable error rate. We propose two possible
   probabilistic k-skyband usages: (i) When it is used to process all
   sliding window objects, the resulting top-k/w algorithm is approximate
   and adequate for processing random-order data streams. (ii) When
   probabilistic k-skyband is used to process only a subset of most recent
   sliding window objects, it can improve the runtime performance of
   continuous k-skyband maintenance, resulting in a novel exact top-k/w
   algorithm. Our experimental evaluation systematically compares different
   top-k/w processing algorithms and shows that while competing algorithms
   offer either time efficiency at the expanse of space efficiency or
   vice-versa, our algorithms based on the probabilistic k-skyband are both
   time and space efficient.},
DOI = {10.1145/2736701},
Article-Number = {1},
ISSN = {0362-5915},
EISSN = {1557-4644},
ResearcherID-Numbers = {Pripužić, Krešimir/H-9233-2017
   Pripužić, Krešimir/GLQ-7853-2022
   Zarko, Ivana Podnar/E-8711-2015
   },
ORCID-Numbers = {Pripužić, Krešimir/0000-0001-7364-3021
   Pripužić, Krešimir/0000-0001-7364-3021
   Podnar Zarko, Ivana/0000-0001-5619-2142},
Unique-ID = {WOS:000352123000002},
}

@article{ WOS:000512937700016,
Author = {Mortazavi-Dehkordi, Mahmood and Zamanifar, Kamran},
Title = {Efficient deadline-aware scheduling for the analysis of Big Data streams
   in public Cloud},
Journal = {CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND
   APPLICATIONS},
Year = {2020},
Volume = {23},
Number = {1, SI},
Pages = {241-263},
Month = {MAR},
Abstract = {The emergence of Big Data has had a profound impact on how data are
   analyzed. Open source distributed stream processing platforms have
   gained popularity for analyzing streaming Big Data as they provide low
   latency required for streaming Big Data applications using Cloud
   resources. However, existing resource schedulers are still lacking the
   efficiency and deadline meeting that Big Data analytical applications
   require. Recent works have already considered streaming Big Data
   characteristics to improve the efficiency and the likelihood of deadline
   meeting for scheduling in the platforms. Nevertheless, they have not
   taken into account the specific attributes of analytical application,
   public Cloud utilization cost and delays caused by performance
   degradation of leasing public Cloud resources. This study, therefore,
   presents BCframework, an efficient deadline-aware scheduling framework
   used by streaming Big Data analysis applications based on public Cloud
   resources. BCframework proposes a scheduling model which considers
   public Cloud utilization cost, performance variation, deadline meeting
   and latency reduction requirements of streaming Big Data analytical
   applications. Furthermore, it introduces two operator scheduling
   algorithms based on both a novel partitioning algorithm and an operator
   replication method. BCframework is highly adaptable to the fluctuation
   of streaming Big Data and the performance degradation of public Cloud
   resources. Experiments with the benchmark and real-world queries show
   that BCframework can significantly reduce the latency and utilization
   cost and also minimize deadline violations and provisioned virtual
   machine instances.},
DOI = {10.1007/s10586-019-02908-2},
ISSN = {1386-7857},
EISSN = {1573-7543},
Unique-ID = {WOS:000512937700016},
}

@inproceedings{ WOS:000386979000095,
Author = {Gad, Ruediger and Kappes, Martin and Medina-Bulo, Inmaculada},
Book-Group-Author = {IEEE},
Title = {Local Programming Language Barriers in Stream-based Systems},
Booktitle = {2016 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC)},
Year = {2016},
Pages = {569-574},
Note = {IEEE Symposium on Computers and Communication (ISCC), Messina, ITALY,
   JUN 27-JUL 01, 2016},
Organization = {IEEE},
Abstract = {Stream-based data processing systems, such as Complex Event Processing
   or data stream mining systems, may be composed of several components
   which may be implemented in various programming languages. In
   distributed scenarios, computer networks typically represent important
   bottlenecks. However, the performance of data exchange in local contexts
   may be as important as the performance of data exchange via computer
   networks. Local programming language barriers may represent important
   bottlenecks for components that are located on the same computer system.
   In distributed scenarios, it may be beneficial to relocate components on
   a single physical host for exploiting the higher local data throughput.
   The properties of stream-based systems pose challenges like high
   throughput requirements but also open up optimization potential such as
   leveraging batched transfers. We performed an experimental analysis of
   ways for bridging local programming language barriers using the examples
   of C, Java, and Python and analyzed the impact of batched forwarding.
   While local data exchange can be expected to offer a higher throughput
   than exchange across networks, our results show that batch forwarding
   can increase the local throughput by factors of up to 47.6 and we
   measured net throughputs up to 39.5 Gbps.},
ISBN = {978-1-5090-0679-3},
ResearcherID-Numbers = {Medina-Bulo, Inmaculada/L-5523-2014},
ORCID-Numbers = {Medina-Bulo, Inmaculada/0000-0002-7543-2671},
Unique-ID = {WOS:000386979000095},
}

@inproceedings{ WOS:000861398600011,
Author = {Rajput, Kaustubh Rajendra and Kulkarni, Chinmay Dilip and Cho, Byungjin
   and Wang, Wei and Kim, In Kee},
Editor = {Ardagna, CA and Bian, H and Chang, CK and Chang, RN and Damiani, E and Elia, G and He, Q and Puig, V and Ward, R and Xhafa, F and Zhang, J},
Title = {EdgeFaaSBench: Benchmarking Edge Devices Using Serverless Computing},
Booktitle = {2022 IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING \& COMMUNICATIONS
   (IEEE EDGE 2022)},
Year = {2022},
Pages = {93-103},
Note = {6th IEEE International Conference on Edge Computing and Communications
   (IEEE EDGE), Barcelona, SPAIN, JUL 11-15, 2022},
Organization = {IEEE; IEEE Comp Soc},
Abstract = {Due to the development of small-size, energy-efficient, and powerful
   CPUs and GPUs for single board computers, various edge devices are
   widely adopted for hosting real-world applications, including real-time
   object detection, autonomous driving, and sensor stream processing. At
   the same time, serverless computing receives increasing attention as a
   new application deployment model because of its simplicity, scalability,
   event-driven processing, and short-lived computation. Therefore, there
   is a growing demand for applying serverless computing to edge computing
   environments. However, due to the lack of characterization of serverless
   edge computing (e.g., application performance and impact from resource
   heterogeneity), researchers and practitioners have to conduct tedious
   measurements to understand the performance of serverless applications on
   edge devices in non-systematic ways.
   We create EdgeFaaSBench, a novel benchmark suite for serverless
   computing on edge devices, to bridge this gap. EdgeFaaSBench is
   developed on top of Apache OpenFaaS with Docker Swarm and can run
   various serverless benchmark workloads on edge devices with different
   hardware specifications (e.g., GPUs). EdgeFaaSBench contains 14
   different benchmark workloads running on heterogeneous edge devices and
   captures various system-level, application-level, and
   serverless-specific metrics, including system utilization, response
   time, cold/warm start times, and impact of concurrent function
   executions. Experimental studies are conducted on two widely used edge
   devices, Raspberry Pi 4B and Jetson Nano, to show EdgeFaaSBench's
   capabilities to benchmark serverless computing on edge devices.},
DOI = {10.1109/EDGE55608.2022.00024},
ISBN = {978-1-6654-8140-3},
Unique-ID = {WOS:000861398600011},
}

@article{ WOS:000184090400003,
Author = {Krishnamurthy, R and Schwan, K and West, R and Rosu, MC},
Title = {On Network CoProcessors for scalable, predictable media services},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2003},
Volume = {14},
Number = {7},
Pages = {655-670},
Month = {JUL},
Abstract = {This paper presents the embedded realization and experimental evaluation
   of a media stream scheduler on Network Interface (NI) CoProcessor
   boards. When using media frames as scheduling units, the scheduler is
   able to operate in real-time on streams traversing the CoProcessor,
   resulting in its ability to stream video to remote clients at real-time
   rates. The contributions of this paper are its detailed evaluation of
   the effects of placing application or kernel-level functionality, like
   packet scheduling on NIs, rather than the host machines to which they
   are attached. The main benefits of such placement are 1) that traffic is
   eliminated from the host bus and memory subsystem, thereby allowing
   increased host CPU utilization for other tasks, and 2) that NI-based
   scheduling is immune to host-CPU loading, unlike host-based media
   schedulers that are easily affected even by transient load conditions.
   An outcome of this work is a proposed cluster architecture for building
   scalable media servers by distributing schedulers and media stream
   producers across the multiple NIs used by a single server and by
   clustering a number of such servers using commodity network hardware and
   software.},
DOI = {10.1109/TPDS.2003.1214318},
ISSN = {1045-9219},
EISSN = {1558-2183},
ResearcherID-Numbers = {Ramalingam, Krishnamurthy/E-4740-2013},
Unique-ID = {WOS:000184090400003},
}

@inproceedings{ WOS:000771734600010,
Author = {Gkolemis, Evangelos and Doka, Katerina and Koziris, Nectarios},
Editor = {Alistarh, D and Delis, A and Pallis, G},
Title = {Automatic Scaling of Resources in a Storm Topology},
Booktitle = {ALGORITHMIC ASPECTS OF CLOUD COMPUTING, ALGOCLOUD 2017},
Series = {Lecture Notes in Computer Science},
Year = {2018},
Volume = {10739},
Pages = {157-169},
Note = {3rd International Workshop on Algorithmic Aspects of Cloud Computing
   (ALGOCLOUD), Vienna, AUSTRIA, SEP 05, 2017},
Abstract = {In the Big Data era, the batch processing of large volumes of data is
   simply not enough - data needs to be processed fast to support
   continuous reactions to changing conditions in real-time. Distributed
   stream processing systems have emerged as platforms of choice for
   applications that rely on real-time analytics, with Apache Storm {[}2]
   being one of the most prevalent representatives. Whether deployed on
   physical or virtual infrastructures, distributed stream processing
   systems are expected to make the most out of the available resources,
   i.e., achieve the highest throughput or lowest latency with the minimum
   resource utilisation. However, for Storm - as for most such systems -
   this is a cumbersome trial-and-error procedure, tied to the specific
   workload that needs to be processed and requiring manual tweaking of
   resource-related topology parameters. To this end, we propose ARiSTO, a
   system that automatically decides on the appropriate amount of resources
   to be provisioned for each node of the Storm workflow topology based on
   user-defined performance and cost constraints. ARiSTO employs two
   mechanisms: a static, model-based one, used at bootstrap time to predict
   the resource-related parameters that better fit the user needs and a
   dynamic, rule-based one that elastically auto-scales the allocated
   resources in order to maintain the desired performance even under
   changes in load. The experimental evaluation of our prototype proves the
   ability of ARiSto to efficiently decide on the resource-related
   configuration parameters, maintaining the desired throughput at all
   times.},
DOI = {10.1007/978-3-319-74875-7\_10},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-74875-7; 978-3-319-74874-0},
Unique-ID = {WOS:000771734600010},
}

@inproceedings{ WOS:000558104700020,
Author = {Pohl, Constantin and Sattler, Kai-Uwe},
Editor = {Welzer, T and Eder, J and Podgorelec, V and Latific, AK},
Title = {Adaptive Partitioning and Order-Preserved Merging of Data Streams},
Booktitle = {ADVANCES IN DATABASES AND INFORMATION SYSTEMS, ADBIS 2019},
Series = {Lecture Notes in Computer Science},
Year = {2019},
Volume = {11695},
Pages = {267-282},
Note = {23rd European Conference on Advances in Databases and Information
   Systems (ADBIS), Bled, SLOVENIA, SEP 08-11, 2019},
Abstract = {Partitioning is a key concept for utilizing modern hardware, especially
   to exploit parallelism opportunities from many-core CPUs. In data
   streaming scenarios where parameters like tuple arrival rates can vary,
   adaptive strategies for partitioning solve the problem of overestimating
   or underestimating query workloads. While there are many possibilities
   to partition the data flow, threads running partitions independently
   from each other lead to unordered output inevitably. This is a
   considerable difficulty for applications where tuple order matters, like
   in stream reasoning or complex event processing scenarios.
   In this paper, we address this problem by combining an adaptive
   partitioning approach with an order-preserving merge algorithm. Since
   reordering output tuples can only worsen latency, we mainly focus on the
   throughput of queries while keeping the delay on individual tuples
   minimal. We run micro-benchmarks as well as the Linear Road benchmark,
   demonstrating correctness and effectiveness of our approach while
   scaling out on a single Xeon Phi many-core CPU up to 256 partitions.},
DOI = {10.1007/978-3-030-28730-6\_17},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-030-28730-6; 978-3-030-28729-0},
ORCID-Numbers = {Pohl, Constantin/0000-0002-5965-4047},
Unique-ID = {WOS:000558104700020},
}

@inproceedings{ WOS:000410290200007,
Author = {Cipriani, Nazario and Schiller, Oliver and Mitschang, Bernhard},
Editor = {Bernadino, J and Cruz, I and Desai, BC},
Title = {M-TOP: Multi-Target Operator Placement of Query Graphs for Data Streams},
Booktitle = {PROCEEDINGS OF THE 15TH INTERNATIONAL DATABASE ENGINEERING \&
   APPLICATIONS SYMPOSIUM (IDEAS `11)},
Year = {2011},
Pages = {52-60},
Note = {15th International Database Engineering and Applications Symposium
   (IDEAS), Lisbon, PORTUGAL, SEP 21-23, 2011},
Organization = {Assoc Comp Machinery; Concordia Univ; Inst Super Engn Lisboa; BytePress;
   ConfSys org; ISEL IPC},
Abstract = {Nowadays, many applications processes stream-based data, such as
   financial market analysis, network intrusion detection, or visualization
   applications. To process stream-based data in an application independent
   manner, distributed stream processing systems emerged. They typically
   translate a query to an operator graph, place the operators to stream
   processing nodes, and execute them to process the streamed data. The
   operator placement is crucial in such systems, as it deeply influences
   query execution. Often, different stream-based applications require
   dedicated placement of query graphs according to their specific
   objectives, e.g. bandwidth not less than 500 MBit/s and costs not more
   that 1 cost unit. This fact constraints operator placement. Existing
   approaches do not take into account application-specific objectives,
   thus not reflecting application-specific placement decisions. As
   objectives might conflict among each other, operator placement is
   subject to delicate trade-offs, such as bandwidth maximization is more
   important than cost reduction. Thus, the challenge is to find a solution
   which considers the application-specific objectives and their
   trade-offs.
   We present M-TOP, an QoS-aware multi-target operator placement framework
   for data stream systems. Particularly, we propose an operator placement
   strategy considering application-specific targets consisting of
   objectives, their respective trade-offs specifications, bottleneck
   conditions, and ranking schemes to compute a suitable placement. We
   integrated M-TOP into NexusDS, our distributed data stream processing
   middleware, and provide an experimental evaluation to show the
   effectiveness of M-TOP.},
ISBN = {978-1-4503-0627-0},
Unique-ID = {WOS:000410290200007},
}

@inproceedings{ WOS:000554828703101,
Author = {Twaty, Muaz and Ghrab, Amine and Skhiri, Sabri},
Editor = {Baru, C and Huan, J and Khan, L and Hu, XH and Ak, R and Tian, Y and Barga, R and Zaniolo, C and Lee, K and Ye, YF},
Title = {GraphOpt: a Framework for Automatic Parameters Tuning of Graph
   Processing Frameworks},
Booktitle = {2019 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)},
Series = {IEEE International Conference on Big Data},
Year = {2019},
Pages = {3744-3753},
Note = {IEEE International Conference on Big Data (Big Data), Los Angeles, CA,
   DEC 09-12, 2019},
Organization = {IEEE Comp Soc; IEEE; Baidu; Very; Ankura},
Abstract = {Finding the optimal configuration of a black-box system is a difficult
   problem that requires a lot of time and human labor. Big data processing
   frameworks are among the increasingly popular systems whose tuning is a
   complex and time consuming. The challenge of automatically finding the
   optimal parameters of big data frameworks attracted a lot of research in
   recent years. Some of the studies focused on optimizing specific
   frameworks such as distributed stream processing {[}1] {[}2], or finding
   the best cloud configurations {[}3], while others proposed general
   services for optimizing any black-box system {[}4]. In this paper, we
   introduce a new use case in the domain of automatic parameter tuning:
   optimizing the parameters of distributed graph processing frameworks.
   This task is notably difficult given the particular challenges of
   distributed graph processing that include the graph partitioning and the
   iterative nature of graphs algorithms. To address this challenge, we
   designed and implemented GraphOpt: an efficient and scalable black-box
   optimization framework that automatically tunes distributed graph
   processing frameworks. GraphOpt implements slate-of-the-art optimization
   algorithms and introduces a new hill-climbing-based search algorithm.
   These algorithms are used to optimize the performance of two major graph
   processing frameworks: Giraph and GraphX. Extensive experiments were run
   on GraphOpt using multiple graph benchmarks to evaluate its performance
   and show that it provides up to 47.8\% improvement compared to random
   search and an average improvement of up to 5.7\%.},
ISSN = {2639-1589},
ISBN = {978-1-7281-0858-2},
Unique-ID = {WOS:000554828703101},
}

@inproceedings{ WOS:000469271000001,
Author = {Nikolakopoulos, Yiannis and Papatriantafilou, Marina and Brauer, Peter
   and Lundqvist, Martin and Gulisano, Vincenzo and Tsigas, Philippas},
Book-Group-Author = {Assoc Comp Machinery},
Title = {Highly Concurrent Stream Synchronization in Many-core Embedded Systems},
Booktitle = {THIRD ACM INTERNATIONAL WORKSHOP ON MANY-CORE EMBEDDED SYSTEMS (MES
   2016)},
Year = {2016},
Pages = {2-9},
Note = {3rd ACM International Workshop on Many-Core Embedded Systems (MES),
   Seoul, SOUTH KOREA, JUN 19, 2016},
Organization = {Assoc Comp Machinery},
Abstract = {Embedded many-core architectures are expected to serve as significant
   components in the infrastructure of upcoming technologies like networks
   for the Internet of Things (IoT), facing real-time and stream processing
   challenges. In this work we explore the applicability of ScaleGate, a
   synchronization object from the massive data stream processing domain,
   on many-core embedded systems. We propose a new implementation of
   ScaleGate on the Epiphany architecture, a scalable embedded many-core
   co-processor, and study communication patterns that appear in the
   context of a baseband signal processing application. Our experimental
   evaluation shows significant improvements over standard barrier-based
   approaches, due to the asynchrony exploited by the use of ScaleGate.},
DOI = {10.1145/2934495.2934496},
ISBN = {978-1-4503-4262-9},
ResearcherID-Numbers = {Gulisano, Vincenzo/AAV-3888-2020
   },
ORCID-Numbers = {/0000-0002-2136-9179
   Tsigas, Philippas/0000-0001-9635-9154
   Papatriantafilou, Marina/0000-0001-9094-8871},
Unique-ID = {WOS:000469271000001},
}

@inproceedings{ WOS:000661912700018,
Author = {HoseinyFarahabady, M. Reza and Taheri, Javid and Zomaya, Albert Y. and
   Tari, Zahir},
Editor = {GkoulalasDivanis, A and Marchetti, M and Avresky, DR},
Title = {A Dynamic Resource Controller for Resolving Quality of Service Issues in
   Modern Streaming Processing Engines},
Booktitle = {2020 IEEE 19TH INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND
   APPLICATIONS (NCA)},
Series = {IEEE International Symposium on Network Computing and Applications},
Year = {2020},
Note = {IEEE 19th International Symposium on Network Computing and Applications
   (NCA), ELECTR NETWORK, NOV 24-27, 2020},
Organization = {IEEE; IEEE Comp Soc; IEEE Comp Soc Tech Comm Distributed Proc;
   Massachusetts Inst Technol; Akamai Technologies Inc; IBM, Thomas J.
   Watson Res Ctr; IBM Watson Hlth; Cornell Univ; BBN Cambridge; Microsoft
   Res; CNRS, LAAS; Univ Tennessee; Natl Sci Fdn; DARPA; Cisco; Argonne
   Natl Lab; European Res Council; Univ Illinois Urbana Champaign; Int Res
   Inst Autonom Network Comp; Oakridge Natl Labs},
Abstract = {Devising an elastic resource allocation controller of data analytical
   applications in virtualized data-center has received a great attention
   recently, mainly due to the fact that even a slight performance
   improvement can translate to huge monetary savings in practical
   large-scale execution. Apache Flink is among modern streamed data
   processing run-times that can provide both low latency and high
   throughput computation in to execute processing pipelines over
   high-volume and high-velocity data-items under tight latency
   constraints. However, a yet to be answered challenge in a large-scale
   platform with tens of worker nodes is how to resolve the run-time
   violation in the quality of service (QoS) level in a multi-tenant data
   streaming platforms, particularly when the amount of workload generated
   by different users fluctuates. Studies showed that a static resource
   allocation algorithm (round-robin), which is used by default in Apache
   Flink, suffer from lack of responsiveness to sudden traffic surges
   happening unpredictably during the run-time. In this paper, we address
   the problem of resource management in a Flink platform for ensuring
   different QoS enforcement levels in a platform with shared computing
   resources. The proposed solution applies theoretical principals borrowed
   from close-loop control theory to design a CPU and memory adjustment
   mechanism with the primary goal to fulfill the different QoS levels
   requested by submitted applications while the resource interference is
   considered as the critical performance-limiting factor. The performance
   evaluation is carried out by comparing the proposed resource allocation
   mechanism with two static heuristics (round robin and class-based
   weighted fair queuing) in a 80-core cluster under multiple traffic
   patterns resembling sudden changes in the incoming workloads of
   low-priory streaming applications. The experimental results confirm the
   stability of the proposed controller to regulate the underlying platform
   resources to smoothly follow the target values (QoS violation rates).
   Particularly, the proposed solution can achieve higher efficiency
   compared to the other heuristics by reducing the response-time of high
   priority applications by 53\% while maintaining the enforced QoS levels
   during the burst traffic periods.},
ISSN = {2643-7910},
EISSN = {2643-7929},
ISBN = {978-1-7281-8326-8},
ResearcherID-Numbers = {Zomaya, Albert Y./G-9697-2017},
ORCID-Numbers = {Zomaya, Albert Y./0000-0002-3090-1059},
Unique-ID = {WOS:000661912700018},
}

@inproceedings{ WOS:000346246900043,
Author = {Saleh, Omran and Sattler, Kai-Uwe},
Editor = {Meersman, R and Panetto, H and Dillon, T and Missikoff, M and Liu, L and Pastor, O and Cuzzocrea, A and Sellis, T},
Title = {On Efficient Processing of Linked Stream Data},
Booktitle = {ON THE MOVE TO MEANINGFUL INTERNET SYSTEMS: OTM 2014 CONFERENCES},
Series = {Lecture Notes in Computer Science},
Year = {2014},
Volume = {8841},
Pages = {700-717},
Note = {On The Move (OTM) Event, Amantea, ITALY, OCT 27-31, 2014},
Abstract = {Today, many application areas require continuous processing of data
   streams in an efficient manner and real-time fashion. Processing these
   continuous flows of data, integrating dynamic data with other data
   sources, and providing the required semantics lead to real challenges.
   Thus, Linked Stream Data (LSD) has been proposed which combines two
   concepts: Linked Open Data and Data Stream Processing (DSP). Recently,
   several LSD engines have been developed, including C-SPARQL and CQELS,
   which are based on SPARQL extensions for continuous query processing.
   However, this SPARQL-centric view makes it difficult to express complex
   processing pipelines. In this paper, we propose a LSD engine based on a
   more general stream processing approach. Instead of a variant of SPARQL,
   our engine provides a dataflow specification language called PipeFlow
   which is compiled into native code. PipeFlow supports native stream
   processing operators (e.g., window, aggregates, and joins), complex
   event processing as well as RDF data transformation operators such as
   tuplifier and triplifier to efficiently support LSD queries and provide
   a higher degree of expressiveness. We discuss the main concepts
   addressing the challenges of LSD processing and describe the usage of
   these concepts for processing queries from LSBench and SRBench. We show
   the effectiveness of our system in terms of query execution times
   through a comparison with existing systems as well as through a detailed
   performance analysis of our system implementation.},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-662-45563-0; 978-3-662-45562-3},
ResearcherID-Numbers = {Sattler, Kai-Uwe/F-9003-2014},
Unique-ID = {WOS:000346246900043},
}

@article{ WOS:000543009300002,
Author = {KhudaBukhsh, Wasiur R. and Kar, Sounak and Alt, Bastian and Rizk, Amr
   and Koeppl, Heinz},
Title = {Generalized Cost-Based Job Scheduling in Very Large Heterogeneous
   Cluster Systems},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2020},
Volume = {31},
Number = {11},
Pages = {2594-2604},
Month = {NOV 11},
Abstract = {We study job assignment in large, heterogeneous resource-sharing
   clusters of servers with finite buffers. This load balancing problem
   arises naturally in today's communication and big data systems, such as
   Amazon Web Services, Network Service Function Chains, and Stream
   Processing. Arriving jobs are dispatched to a server, following a load
   balancing policy that optimizes a performance criterion such as job
   completion time. Our contribution is a randomized Cost-Based Scheduling
   (CBS) policy in which the job assignment is driven by general cost
   functions of the server queue lengths. Beyond existing schemes, such as
   the Join the Shortest Queue (JSQ), the power of d or the SQ(d) and the
   capacity-weighted JSQ, the notion of CBS yields new application-specific
   policies such as hybrid locally uniform JSQ. As today's data center
   clusters have thousands of servers, exact analysis of CBS policies is
   tedious. In this article, we derive a scaling limit when the number of
   servers grows large, facilitating a comparison of various CBS policies
   with respect to their transient as well as steady state behavior. A
   byproduct of our derivations is the relationship between the queue
   filling proportions and the server buffer sizes, which cannot be
   obtained from infinite buffer models. Finally, we provide extensive
   numerical evaluations and discuss several applications including
   multi-stage systems.},
DOI = {10.1109/TPDS.2020.2997771},
ISSN = {1045-9219},
EISSN = {1558-2183},
ORCID-Numbers = {Alt, Bastian/0000-0002-1522-5400
   KhudaBukhsh, Wasiur R./0000-0003-1803-0470},
Unique-ID = {WOS:000543009300002},
}

@inproceedings{ WOS:000380481500043,
Author = {Cardellini, Valeria and Grassi, Vincenzo and Lo Presti, Francesco and
   Nardelli, Matteo},
Book-Group-Author = {IEEE},
Title = {On QoS-aware Scheduling of Data Stream Applications over Fog Computing
   Infrastructures},
Booktitle = {2015 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC)},
Year = {2015},
Pages = {271-276},
Note = {IEEE Symposium on Computers and Communication (ISCC), Larnaca, CYPRUS,
   JUL 06-09, 2015},
Organization = {IEEE; IEEE, Cyprus Sect; IEEE Commun Soc; IEEE Comp Soc},
Abstract = {Fog computing is rapidly changing the distributed computing landscape by
   extending the Cloud computing paradigm to include wide-spread resources
   located at the network edges. This diffused infrastructure is well
   suited for the implementation of data stream processing (DSP)
   applications, by possibly exploiting local computing resources. Storm is
   an open source, scalable, and fault-tolerant DSP system designed for
   locally distributed clusters. We made it suitable to operate in a
   geographically distributed and highly variable environment; to this end,
   we extended Storm with new components that allow to execute a
   distributed QoS-aware scheduler and give self-adaptation capabilities to
   the system.
   In this paper we provide a thorough experimental evaluation of the
   proposed solution using two sets of DSP applications: the former is
   characterized by a simple topology with different requirements; the
   latter comprises some well known applications (i.e., Word Count, Log
   Processing). The results show that the distributed QoS-aware scheduler
   outperforms the centralized default one, improving the application
   performance and enhancing the system with runtime adaptation
   capabilities. However, complex topologies involving many operators may
   cause some instability that can decrease the DSP application
   availability.},
ISBN = {978-1-4673-7194-0},
ResearcherID-Numbers = {Nardelli, Matteo/K-7215-2016
   Cardellini, Valeria/F-8409-2012},
ORCID-Numbers = {Nardelli, Matteo/0000-0002-9519-9387
   Cardellini, Valeria/0000-0002-6870-7083},
Unique-ID = {WOS:000380481500043},
}

@inproceedings{ WOS:000249117700054,
Author = {Liang, Jin and Gu, Xiaohui and Nahrstedt, Klara},
Book-Group-Author = {IEEE},
Title = {Self-configuring information management for large-scale service overlays},
Booktitle = {INFOCOM 2007, VOLS 1-5},
Series = {IEEE INFOCOM},
Year = {2007},
Pages = {472+},
Note = {26th IEEE Conference on Computer Communications (INFOCOM 2007),
   Anchorage, AK, MAY 06-12, 2007},
Organization = {IEEE Commun Soc; CONTENT; Natl Sci Fdn; US DOE; Telefonica; GM; NARUS},
Abstract = {Service overlay networks (SON) provide important infrastructure support
   for many emerging distributed applications such as web service
   composition, distributed stream processing, and workflow management.
   Quality-sensitive distributed applications such as multimedia services
   and on-line data analysis often desire the SON to provide up-to-date
   dynamic information about different overlay nodes and overlay links.
   However, it is a challenging task to provide scalable and efficient
   information management for large-scale SONs, where both system
   conditions and application requirements can change over time. In this
   paper, we present InfoEye, a model-based self-configuring distributed
   information management system that consists of a set of monitoring
   sensors deployed on different overlay nodes. InfoEye can dynamically
   configure the operations of different sensors based on current
   statistical application query patterns and system attribute
   distributions. Thus, InfoEye can greatly improve the scalability of SON
   by answering information queries with minimum monitoring overhead. We
   have implemented a prototype of InfoEye and evaluated its performance
   using both extensive simulations and micro-benchmark experiments on
   PlanetLab. The experimental results show that InfoEye can significantly
   reduce the information management overhead compared with existing
   approaches. In addition, InfoEye can quickly reconfigure itself in
   response to application requirement and system information pattern
   changes.},
DOI = {10.1109/INFCOM.2007.62},
ISSN = {0743-166X},
ISBN = {978-1-4244-1046-0},
Unique-ID = {WOS:000249117700054},
}

@article{ WOS:000182162900007,
Author = {Plale, B and Schwan, K},
Title = {Dynamic querying of streaming data with the dQUOB system},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2003},
Volume = {14},
Number = {4},
Pages = {422-432},
Month = {APR},
Abstract = {Data streaming has established itself as a viable communication
   abstraction in data-intensive parallel and distributed computations,
   occurring in applications such as scientific visualization performance
   monitoring, and large-scale data transfer. A known problem in
   large-scale event communication is tailoring the data received at the
   consumer. It is the general problem of extracting data of interest from
   a data source, a problem that the database community,has successfully
   addressed with SOL queries, a time tested, user-friendly way for,
   noncomputer scientists to access data. By leveraging the efficiency of
   query processing provided by relational queries, the dQUOB system
   provides a conceptual relational data model and SOL query access over
   streaming data. Queries can be used to extract data, combine streams,
   and create hew streams. The. language augments queries with an action to
   enable more complex data. transformations such as Fourier transforms.
   The dQUOB system has been applied to two large-scale distributed
   applications: a safety critical autonomous robotics simulation and
   scientific software visualization for global atmospheric transport
   modeling. In this paper, we present the dQUOB system and the results
   of-performance evaluation undertaken to assess its applicability in
   data-intensive wide-area computations, where the benefit of portable
   data transformation must be evaluated against the cost of continuous
   query evaluation.},
DOI = {10.1109/TPDS.2003.1195413},
ISSN = {1045-9219},
EISSN = {1558-2183},
ResearcherID-Numbers = {Plale, Beth/F-8803-2011},
ORCID-Numbers = {Plale, Beth/0000-0003-2164-8132},
Unique-ID = {WOS:000182162900007},
}

@article{ WOS:000836798500003,
Author = {Henning, Soeren and Hasselbring, Wilhelm},
Title = {A configurable method for benchmarking scalability of cloud-native
   applications},
Journal = {EMPIRICAL SOFTWARE ENGINEERING},
Year = {2022},
Volume = {27},
Number = {6},
Month = {NOV},
Abstract = {Cloud-native applications constitute a recent trend for designing
   large-scale software systems. However, even though several cloud-native
   tools and patterns have emerged to support scalability, there is no
   commonly accepted method to empirically benchmark their scalability. In
   this study, we present a benchmarking method, allowing researchers and
   practitioners to conduct empirical scalability evaluations of
   cloud-native applications, frameworks, and deployment options. Our
   benchmarking method consists of scalability metrics, measurement
   methods, and an architecture for a scalability benchmarking tool,
   particularly suited for cloud-native applications. Following fundamental
   scalability definitions and established benchmarking best practices, we
   propose to quantify scalability by performing isolated experiments for
   different load and resource combinations, which asses whether specified
   service level objectives (SLOs) are achieved. To balance usability and
   reproducibility, our benchmarking method provides configuration options,
   controlling the trade-off between overall execution time and statistical
   grounding. We perform an extensive experimental evaluation of our
   method's configuration options for the special case of event-driven
   microservices. For this purpose, we use benchmark implementations of the
   two stream processing frameworks Kafka Streams and Flink and run our
   experiments in two public clouds and one private cloud. We find that,
   independent of the cloud platform, it only takes a few repetitions (<=
   5) and short execution times (<= 5 minutes) to assess whether SLOs are
   achieved. Combined with our findings from evaluating different search
   strategies, we conclude that our method allows to benchmark scalability
   in reasonable time.},
DOI = {10.1007/s10664-022-10162-1},
Article-Number = {143},
ISSN = {1382-3256},
EISSN = {1573-7616},
ORCID-Numbers = {Henning, Soren/0000-0001-6912-2549},
Unique-ID = {WOS:000836798500003},
}

@inproceedings{ WOS:000589872400079,
Author = {Lambachri, Tariq and El Hassani, Amir Hajjam and Andres, Emmanuel},
Book-Group-Author = {IEEE},
Title = {Aligning pattern extraction algorithms for the lambda architecture},
Booktitle = {2018 9TH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE, SYSTEMS
   AND APPLICATIONS (IISA)},
Series = {International Conference Information Intelligence Systems and
   Applications},
Year = {2018},
Pages = {440-444},
Note = {9th International Conference on Information, Intelligence, Systems and
   Applications (IISA), Zakynthos, GREECE, JUL 23-25, 2018},
Organization = {Inst Elect \& Elect Engineers; Biol \& Artificial Intelligence Fdn; Univ
   Piraeus, Res Ctr; Technol Educ Inst Ionian Isl},
Abstract = {For quite some time now, data have become the new oil of the digital
   industry. The spread and evolution of information technologies and
   connectivity between people and devices have enabled a new dimension of
   big-data storage and analytics that could bring major improvements
   across industries.
   In this paper, we propose a new, frequent itemset mining approach. The
   challenge is to apply traditional extraction techniques in a distributed
   environment. The main originality of our mining method is to take
   benefits of a performant existing algorithm and use a novel data
   structure to maintain frequent sequential patterns coupled with a quick
   pruning strategy. The proposed approach has been implemented using Spark
   to further improve the efficiency of iterative computation. Numeric
   experiment results using standard benchmark datasets by comparing the
   proposed algorithm with the existing algorithm, FP -Growth, demonstrate
   that our approach has better efficiency and scalability.},
ISSN = {2379-3732},
ISBN = {978-1-5386-8161-9},
ResearcherID-Numbers = {Hajjam, Amir/ABF-0303-2022},
ORCID-Numbers = {Hajjam, Amir/0000-0002-8470-806X},
Unique-ID = {WOS:000589872400079},
}

@inproceedings{ WOS:000266241500012,
Author = {Xia, Cathy H. and Liu, Zhen and Towsley, Don and Lelarge, Marc},
Book-Group-Author = {ACM},
Title = {Scalability of Fork/Join Queueing Networks with Blocking},
Booktitle = {SIGMETRICS'07: PROCEEDINGS OF THE 2007 INTERNATIONAL CONFERENCE ON
   MEASUREMENT \& MODELING OF COMPUTER SYSTEMS},
Series = {ACM SIGMETRICS Performance Evaluation Review Special Issue},
Year = {2007},
Volume = {35},
Number = {1},
Pages = {133+},
Note = {International Conference on Measurement and Modeling of Computer
   Systems, San Diego, CA, JUN 12-16, 2007},
Organization = {ACM SIGMETRICS; HP Res; IBM Res; Google; Microsoft Res; VMWare},
Abstract = {This paper investigates how the throughput of a general fork/join
   queueing network with blocking behaves as the number of nodes increases
   to infinity while the processing speed and buffer space of each node
   stay unchanged. The problem is motivated by applications arising from
   distributed systems and computer networks. One example is large-scale
   distributed stream processing systems where TCP is used as the transport
   protocol for data transfer in between processing components. Other
   examples include reliable multicast in overlay networks, and reliable
   data transfer in ad hoc networks. Using an analytical approach, the
   paper establishes bounds on the asymptotic throughput of such a network.
   For a subclass of networks which are balanced, we obtain sufficient
   conditions under which the network stays scalable in the sense that the
   throughput is lower bounded by a positive constant as the network size
   increases. Necessary conditions of throughput scalability are derived
   for general networks. The special class of series-parallel networks is
   then studied in greater detail, where the asymptotic behavior of the
   throughput is characterized.},
DOI = {10.1145/1269899.1254898},
ISSN = {0163-5999},
ResearcherID-Numbers = {Xia, Cathy H/AAX-4667-2021},
Unique-ID = {WOS:000266241500012},
}

@inproceedings{ WOS:000241726200058,
Author = {Kuntschke, Richard and Kemper, Alfons},
Editor = {Grust, T and Hopfner, H and Illarramendi, A and Jablonski, S and Mesiti, M and Muller, S and Patranjan, PL and Sattler, KU and Spiliopoulou, M and Wijsen, J},
Title = {Data stream sharing},
Booktitle = {CURRENT TRENDS IN DATABASE TECHNOLOGY - EDBT 2006},
Series = {Lecture Notes in Computer Science},
Year = {2006},
Volume = {4254},
Pages = {769-788},
Note = {2nd International Workshop on Database Technologies for Handing XML
   Information on the Web, Munich, GERMANY, MAR 26, 2006},
Organization = {Univ Erlangen-Nurenberg; Technis Univ Munchen; Extending Database
   Technol},
Abstract = {Recent research efforts in the fields of data stream processing and data
   stream management systems (DSMSs) show the increasing importance of
   processing data streams, e. g., in the e-science domain. Together with
   the advent of peer-to-peer (P2P) networks and grid computing, this leads
   to the necessity of developing new techniques for distributing and
   processing continuous queries over data streams in such networks. In
   this paper, we present a novel approach for optimizing the integration,
   distribution, and execution of newly registered continuous queries over
   data streams in grid-based P2P networks. We introduce Windowed XQuery
   (WXQuery), our XQuery-based subscription language for continuous queries
   over XML data streams supporting window-based operators. Concentrating
   on filtering and window-based aggregation, we present our stream sharing
   algorithms as well as experimental evaluation results from the
   astrophysics application domain to assess our approach.},
ISSN = {0302-9743},
ISBN = {3-540-46788-2},
Unique-ID = {WOS:000241726200058},
}

@article{ WOS:000259128800002,
Author = {Campanile, Ferdinando and Coppolino, Luigi and Giordano, Salvatore and
   Romano, Luigi},
Title = {A business process monitor for a mobile phone recharging system},
Journal = {JOURNAL OF SYSTEMS ARCHITECTURE},
Year = {2008},
Volume = {54},
Number = {9},
Pages = {843-848},
Month = {SEP},
Note = {15th Euromicro International Conference on Parallel, Distributed and
   Network-Based Processing, Naples, ITALY, FEB 07-09, 2007},
Organization = {ICAR; Facolta Sci Mat Fis Nat; AMD; STMicroelectronics},
Abstract = {Dependable (i.e. accurate and timely) monitoring is a key aspect of
   business process management, since it provides information which is
   crucial for determining the actual Quality of Service (QoS) delivered to
   individual parties, and for promptly handling off-plan deviations. This
   paper describes a business process monitor for the recharging system of
   a mobile phone network provider. The monitored system is currently in
   operation for the major mobile phone company in Italy, namely Telecom
   Italia Mobile (TIM). Due to the amazingly high throughput of the
   monitored system, meeting the performance requirements for the monitor
   was a challenging issue. A buffer-based implementation of the monitor
   system failed to meet such requirements. In this paper, we propose a
   stream-based architecture, which exceeds the performance requirements
   imposed by the monitored application. The paper provides a detailed
   description of the monitor system architecture, including a discussion
   of technology choices, and an experimental evaluation of the performance
   boost achieved by resorting to a streaming approach. The proposed
   solution also exploits grammar-based pluggable parsers for rapid and
   seamless integration of heterogeneous data feeds. (c) 2008 Elsevier B.V.
   All rights reserved.},
DOI = {10.1016/j.sysarc.2008.02.005},
ISSN = {1383-7621},
EISSN = {1873-6165},
ResearcherID-Numbers = {Coppolino, Luigi/AAI-9532-2021
   },
ORCID-Numbers = {Coppolino, Luigi/0000-0002-2079-8713},
Unique-ID = {WOS:000259128800002},
}

@article{ WOS:000404270600105,
Author = {Baccarelli, Enzo and Naranjo, Paola G. Vinueza and Scarpiniti, Michele
   and Shojafar, Mohammad and Abawajy, Jemal H.},
Title = {Fog of Everything: Energy-Efficient Networked Computing Architectures,
   Research Challenges, and a Case Study},
Journal = {IEEE ACCESS},
Year = {2017},
Volume = {5},
Pages = {9882-9910},
Abstract = {Fog computing (FC) and Internet of Everything (IoE) are two emerging
   technological paradigms that, to date, have been considered
   standing-alone. However, because of their complementary features, we
   expect that their integration can foster a number of computing and
   network-intensive pervasive applications under the incoming realm of the
   future Internet. Motivated by this consideration, the goal of this
   position paper is fivefold. First, we review the technological
   attributes and platforms proposed in the current literature for the
   standing-alone FC and IoE paradigms. Second, by leveraging some use
   cases as illustrative examples, we point out that the integration of the
   FC and IoE paradigms may give rise to opportunities for new applications
   in the realms of the IoE, Smart City, Industry 4.0, and Big Data
   Streaming, while introducing new open issues. Third, we propose a novel
   technological paradigm, the Fog of Everything (FoE) paradigm, that
   integrates FC and IoE and then we detail the main building blocks and
   services of the corresponding technological platform and protocol stack.
   Fourth, as a proof-of-concept, we present the simulated energy delay
   performance of a small-scale FoE prototype, namely, the V-FoE prototype.
   Afterward, we compare the obtained performance with the corresponding
   one of a benchmark technological platform, e.g., the V-D2D one. It
   exploits only device-to-device links to establish inter-thing ``ad
   hoc{''} communication. Last, we point out the position of the proposed
   FoE paradigm over a spectrum of seemingly related recent research
   projects.},
DOI = {10.1109/ACCESS.2017.2702013},
ISSN = {2169-3536},
ResearcherID-Numbers = {Shojafar, Mohammad/C-9151-2013
   Naranjo, Paola Gabriela Vinueza/E-8084-2018
   Scarpiniti, Michele/K-5383-2015},
ORCID-Numbers = {Shojafar, Mohammad/0000-0003-3284-5086
   Naranjo, Paola Gabriela Vinueza/0000-0002-3658-5288
   Scarpiniti, Michele/0000-0002-3164-6256},
Unique-ID = {WOS:000404270600105},
}

@inproceedings{ WOS:000295216600073,
Author = {Kalyvianaki, Evangelia and Wiesemann, Wolfram and Vu, Quang Hieu and
   Kuhn, Daniel and Pietzuch, Peter},
Book-Group-Author = {IEEE},
Title = {SQPR: Stream Query Planning with Reuse},
Booktitle = {IEEE 27TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE 2011)},
Series = {IEEE International Conference on Data Engineering},
Year = {2011},
Pages = {840-851},
Note = {IEEE 27th International Conference on Data Engineering (ICDE 2011),
   Hannover, GERMANY, APR 11-16, 2011},
Organization = {IEEE},
Abstract = {When users submit new queries to a distributed stream processing system
   (DSPS), a query planner must allocate physical resources, such as CPU
   cores, memory and network bandwidth, from a set of hosts to queries.
   Allocation decisions must provide the correct mix of resources required
   by queries, while achieving an efficient overall allocation to scale in
   the number of admitted queries. By exploiting overlap between queries
   and reusing partial results, a query planner can conserve resources but
   has to carry out more complex planning decisions.
   In this paper, we describe SQPR, a query planner that targets DSPSs in
   data centre environments with heterogeneous resources. SQPR models query
   admission, allocation and reuse as a single constrained optimisation
   problem and solves an approximate version to achieve scalability. It
   prevents individual resources from becoming bottlenecks by re-planning
   past allocation decisions and supports different allocation objectives.
   As our experimental evaluation in comparison with a state-of-the-art
   planner shows SQPR makes efficient resource allocation decisions, even
   with a high utilisation of resources, with acceptable overheads.},
ISSN = {1084-4627},
ISBN = {978-1-4244-8958-9},
Unique-ID = {WOS:000295216600073},
}

@article{ WOS:000441113900004,
Author = {Kauffman, Sean and Havelund, Klaus and Joshi, Rajeev and Fischmeister,
   Sebastian},
Title = {Inferring event stream abstractions},
Journal = {FORMAL METHODS IN SYSTEM DESIGN},
Year = {2018},
Volume = {53},
Number = {1, SI},
Pages = {54-82},
Month = {AUG},
Abstract = {We propose a formalism for specifying event stream abstractions for use
   in spacecraft telemetry processing. Our work is motivated by the need to
   quickly process streams with millions of events generated e.g. by the
   Curiosity rover on Mars. The approach builds a hierarchy of event
   abstractions for telemetry visualization and querying to aid human
   comprehension. Such abstractions can also be used as input to other
   runtime verification tools. Our notation is inspired by Allen's Temporal
   Logic, and provides a rule-based declarative way to express event
   abstractions. We present an algorithm for applying specifications to an
   event stream and explore modifications to improve the algorithm's
   asymptotic complexity. The system is implemented in both Scala and C,
   with the specification language implemented as internal as well as
   external DSLs. We illustrate the solution with several examples, a
   performance evaluation, and a real telemetry analysis scenario.},
DOI = {10.1007/s10703-018-0317-z},
ISSN = {0925-9856},
EISSN = {1572-8102},
ORCID-Numbers = {Kauffman, Sean/0000-0001-6341-3898
   Havelund, Klaus/0000-0001-7079-0472},
Unique-ID = {WOS:000441113900004},
}

@inproceedings{ WOS:000461823300024,
Author = {Dunner, Celestine and Parnell, Thomas and Sarigiannis, Dimitrios and
   Ioannou, Nikolas and Anghel, Andreea and Ravi, Gummadi and Kandasamy,
   Madhusudanan and Pozidis, Haralampos},
Editor = {Bengio, S and Wallach, H and Larochelle, H and Grauman, K and CesaBianchi, N and Garnett, R},
Title = {Snap ML: A Hierarchical Framework for Machine Learning},
Booktitle = {ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 31 (NIPS 2018)},
Series = {Advances in Neural Information Processing Systems},
Year = {2018},
Volume = {31},
Note = {32nd Conference on Neural Information Processing Systems (NIPS),
   Montreal, CANADA, DEC 02-08, 2018},
Abstract = {We describe a new software framework for fast training of generalized
   linear models. The framework, named Snap Machine Learning (Snap ML),
   combines recent advances in machine learning systems and algorithms in a
   nested manner to reflect the hierarchical architecture of modern
   computing systems. We prove theoretically that such a hierarchical
   system can accelerate training in distributed environments where
   intra-node communication is cheaper than inter-node communication.
   Additionally, we provide a review of the implementation of Snap ML in
   terms of GPU acceleration, pipelining, communication patterns and
   software architecture, highlighting aspects that were critical for
   achieving high performance. We evaluate the performance of Snap ML in
   both single-node and multi-node environments, quantifying the benefit of
   the hierarchical scheme and the data streaming functionality, and
   comparing with other widely-used machine learning software frameworks.
   Finally, we present a logistic regression benchmark on the Criteo
   Terabyte Click Logs dataset and show that Snap ML achieves the same test
   loss an order of magnitude faster than any of the previously reported
   results, including those obtained using TensorFlow and scikit-learn.},
ISSN = {1049-5258},
Unique-ID = {WOS:000461823300024},
}

@article{ WOS:000408254700007,
Author = {Ma, Kun and Yang, Bo},
Title = {Stream-based live entity resolution approach with adaptive duplicate
   count strategy},
Journal = {INTERNATIONAL JOURNAL OF WEB AND GRID SERVICES},
Year = {2017},
Volume = {13},
Number = {3, SI},
Pages = {351-373},
Abstract = {Recently, researchers have been more concerned about large-scale news
   and tweet data generated by the social media. Some cloud service
   providers utilise the data to find public sentiments for the tenants.
   The challenge is how to clean the big data in the cloud before making
   further analysis. To address this issue, we propose a new live entity
   resolution approach at a time to find duplicates from the news and tweet
   data. We investigate possible solutions to address live entity
   resolution in the cloud, to make sliding window size adaptive using
   multistep distance and window size dependent duplicate count strategy
   with alterable window step, and find duplicates by overlapping boundary
   objects in adjacent blocks. Finally, our experimental evaluation based
   on the news data on large datasets shows the high effectiveness and
   efficiency of the proposed approaches.},
DOI = {10.1504/IJWGS.2017.10006055},
ISSN = {1741-1106},
EISSN = {1741-1114},
Unique-ID = {WOS:000408254700007},
}

@inproceedings{ WOS:000364535600023,
Author = {Dehghanzadeh, Soheila and Dell'Aglio, Daniele and Gao, Shen and Della
   Valle, Emanuele and Mileo, Alessandra and Bernstein, Abraham},
Editor = {Cimiano, P and Frasincar, F and Houben, GJ and Schwabe, D},
Title = {Approximate Continuous Query Answering over Streams and Dynamic Linked
   Data Sets},
Booktitle = {ENGINEERING THE WEB IN THE BIG DATA ERA},
Series = {Lecture Notes in Computer Science},
Year = {2015},
Volume = {9114},
Pages = {307-325},
Note = {15th International Conference on Web Engineering (ICWE), Rotterdam,
   NETHERLANDS, JUN 23-25, 2015},
Organization = {Erasmus Studio; Erasmus Res Inst Management; Erasmus Sch Econ; Erasmus
   Univ Rotterdam; Google; Int Soc Web Engn e V; SIKS},
Abstract = {To perform complex tasks, RDF Stream Processing Web applications
   evaluate continuous queries over streams and quasi-static (background)
   data. While the former are pushed in the application, the latter are
   continuously retrieved from the sources. As soon as the background data
   increase the volume and become distributed over the Web, the cost to
   retrieve them increases and applications become unresponsive. In this
   paper, we address the problem of optimizing the evaluation of these
   queries by leveraging local views on background data. Local views
   enhance performance, but require maintenance processes, because changes
   in the background data sources are not automatically reflected in the
   application. We propose a two-step query-driven maintenance process to
   maintain the local view: it exploits information from the query (e.g.,
   the sliding window definition and the current window content) to
   maintain the local view based on user-defined Quality of Service
   constraints. Experimental evaluation show the effectiveness of the
   approach.},
DOI = {10.1007/978-3-319-19890-3\_20},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-19890-3; 978-3-319-19889-7},
ResearcherID-Numbers = {Dell'Aglio, Daniele/AAH-4635-2019
   Mileo, Alessandra/K-7175-2015
   },
ORCID-Numbers = {Dell'Aglio, Daniele/0000-0003-4904-2511
   Mileo, Alessandra/0000-0002-6614-6462
   Bernstein, Abraham/0000-0002-0128-4602},
Unique-ID = {WOS:000364535600023},
}

@article{ WOS:000416492900011,
Author = {Katsipoulakis, Nikos R. and Labrinidis, Alexandros and Chrysanthis,
   Panos K.},
Title = {A Holistic View of Stream Partitioning Costs},
Journal = {PROCEEDINGS OF THE VLDB ENDOWMENT},
Year = {2017},
Volume = {10},
Number = {11},
Pages = {1286-1297},
Month = {AUG},
Abstract = {Stream processing has become the dominant processing model for
   monitoring and real-time analytics. Modern Parallel Stream Processing
   Engines (pSPEs) have made it feasible to increase the performance in
   both monitoring and analytical queries by parallelizing a query's
   execution and distributing the load on multiple workers. A determining
   factor for the performance of a pSPE is the partitioning algorithm used
   to disseminate tuples to workers. Until now, partitioning methods in
   pSPEs have been similar to the ones used in parallel databases and only
   recently load-aware algorithms have been employed to improve the
   effectiveness of parallel execution.
   We identify and demonstrate the need to incorporate aggregation costs in
   the partitioning model when executing stateful operations in parallel,
   in order to minimize the overall latency and/or throughput. Towards
   this, we propose new stream partitioning algorithms, that consider both
   tuple imbalance and aggregation cost. We evaluate our proposed
   algorithms and show that they can achieve up to an order of magnitude
   better performance, compared to the current state of the art.},
DOI = {10.14778/3137628.3137639},
ISSN = {2150-8097},
ORCID-Numbers = {Chrysanthis, Panos/0000-0001-7189-9816},
Unique-ID = {WOS:000416492900011},
}

@article{ WOS:000354412400038,
Author = {Su, Yan and Shi, Feng and Talpur, Shahnawaz and Wang, Yizhuo and Hu,
   Sensen and Wei, Jin},
Title = {Achieving self-aware parallelism in stream programs},
Journal = {CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND
   APPLICATIONS},
Year = {2015},
Volume = {18},
Number = {2, SI},
Pages = {949-962},
Month = {JUN},
Abstract = {The age of big data open the door to a new approach in data exploration
   and utilization. With the increasing complexities and dynamics of modern
   IT systems and services, it has become a challenge to effectively
   exploit parallelism on multicore platforms in computing systems that are
   heterogeneous, dynamic and decentralised. Self-aware software is a
   response to these demands in dealing with distributed applications in
   changing environments. It is a closed-loop system with a series of
   optimization strategies to adjust itself dynamicly during data
   processing. We focus on incorporating adaptation mechanisms into the
   stream programs for exposing distributed parallelism. In the traditional
   stream programming models, changing data and status normally require
   human supervision to adjust the stream graph for performance. As
   one-time optimization strategy, the reconfiguration and maintenance lead
   to costly and time-consuming procedures during the operating phase. To
   address these problems, we propose a self-aware stream programming model
   called StreamAware. A key property of this model is that exposing
   self-aware parallelism in the message driven execution paradigm, which
   provides dynamic and reconfigurable stream graph in adapting to the data
   flow changes. The model defines the self-awareness loop based on finite
   state machine for stream applications to adjust their own stream graph
   with continuous optimization strategy. This paper presents three
   different self-aware systems built using StreamAware. The empirical
   evaluation demonstrate how these systems can exploit self-aware
   parallelism using the Parsec benchmark problems, optimize performance
   per Watt, and respond to significant changes in stream processing.},
DOI = {10.1007/s10586-014-0412-x},
ISSN = {1386-7857},
EISSN = {1573-7543},
ResearcherID-Numbers = {Talpur, Shahnawaz/C-3733-2012},
Unique-ID = {WOS:000354412400038},
}

@inproceedings{ WOS:000467257000029,
Author = {Maron, Carlos A. F. and Vogel, Adriano and Griebler, Dalvan and
   Fernandes, Luiz Gustavo},
Book-Group-Author = {IEEE},
Title = {Should PARSEC Benchmarks be More Parametric? A Case Study with Dedup},
Booktitle = {2019 27TH EUROMICRO INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED
   AND NETWORK-BASED PROCESSING (PDP)},
Series = {Euromicro Conference on Parallel Distributed and Network-Based
   Processing},
Year = {2019},
Pages = {217-221},
Note = {27th Euromicro International Conference on Parallel, Distributed and
   Network-Based Processing (PDP), Pavia, ITALY, FEB 13-15, 2019},
Organization = {IEEE Comp Soc; Euromicro},
Abstract = {Parallel applications of the same domain can present similar patterns of
   behavior and characteristics. Characterizing common application
   behaviors can help for understanding performance aspects in the
   real-world scenario. One way to better understand and evaluate
   applications' characteristics is by using customizable/parametric
   benchmarks that enable users to represent important characteristics at
   run-time. We observed that parameterization techniques should be better
   exploited in the available benchmarks, especially on stream processing
   domain. For instance, although widely used, the stream processing
   benchmarks available in PARSEC do not support the simulation and
   evaluation of relevant and modern characteristics. Therefore, our goal
   is to identify the stream parallelism characteristics present in PARSEC.
   We also implemented a ready to use parameterization support and
   evaluated the application behaviors considering relevant performance
   metrics for stream parallelism (service time, throughput, latency). We
   choose Dedup to be our case study. The experimental results have shown
   performance improvements in our parameterization support for Dedup.
   Moreover, this support increased the customization space for benchmark
   users, which is simple to use. In the future, our solution can be
   potentially explored on different parallel architectures and parallel
   programming frameworks.},
DOI = {10.1109/EMPDP.2019.8671592},
ISSN = {1066-6192},
ISBN = {978-1-7281-1644-0},
ResearcherID-Numbers = {Fernandes, Luiz Gustavo L./N-1988-2018
   Griebler, Dalvan/C-2041-2017
   Vogel, Adriano/W-7420-2019
   Vogel, Adriano/GZG-8215-2022},
ORCID-Numbers = {Fernandes, Luiz Gustavo L./0000-0002-7506-3685
   Griebler, Dalvan/0000-0002-4690-3964
   Vogel, Adriano/0000-0003-3299-2641
   },
Unique-ID = {WOS:000467257000029},
}

@article{ WOS:000171177900003,
Author = {Eager, D and Vernon, M and Zahorjan, J},
Title = {Minimizing bandwidth requirements for on-demand data delivery},
Journal = {IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING},
Year = {2001},
Volume = {13},
Number = {5},
Pages = {742-757},
Month = {SEP-OCT},
Note = {5th International Workshop on Multimedia Information Systems (MIS 99),
   PALM SPRINGS DESERT, CA, OCT 21-23, 1999},
Abstract = {Two recent techniques for multicast or broadcast delivery of streaming
   media can provide immediate service to each client request, yet achieve
   considerable client stream sharing which leads to significant server and
   network bandwidth savings. This paper considers 1) how well these
   recently proposed techniques perform relative to each other and 2)
   whether there are new practical delivery techniques that can achieve
   better bandwidth savings than the previous techniques over a wide range
   of client request rates. The principal results are as follows: First,
   the recent partitioned dynamic skyscraper technique is adapted to
   provide immediate service to each client request more simply and
   directly than the original dynamic skyscraper method, Second, at
   moderate to high client request rates, the dynamic skyscraper method has
   required server bandwidth that is significantly lower than the recent
   optimized stream tapping/patching/controlled multicast technique. Third,
   the minimum required server bandwidth for any delivery technique that
   provides immediate real-time delivery to clients increases
   logarithmically (with constant factor equal to one) as a function of the
   client request arrival rate. Furthermore, it is (theoretically) possible
   to achieve very close to the minimum required server bandwidth if client
   receive bandwidth is equal to two times the data streaming rate and
   client storage capacity is sufficient for buffering data from shared
   streams. Finally, we propose a new practical delivery technique, called
   hierarchical multicast stream merging (HMSM), which has a required
   server bandwidth that is lower than the partitioned dynamic skyscraper
   and is reasonably close to the minimum achievable required server
   bandwidth over a wide range of client request rates.},
DOI = {10.1109/69.956098},
ISSN = {1041-4347},
EISSN = {1558-2191},
Unique-ID = {WOS:000171177900003},
}

@inproceedings{ WOS:000628649800039,
Author = {Coenen, Manuel and Wagner, Christoph and Echler, Alexander and
   Frischbier, Sebastian},
Book-Group-Author = {Assoc Comp Machinery},
Title = {Poster: Benchmarking Financial Data Feed Systems},
Booktitle = {DEBS'19: PROCEEDINGS OF THE 13TH ACM INTERNATIONAL CONFERENCE ON
   DISTRIBUTED AND EVENT-BASED SYSTEMS},
Year = {2019},
Pages = {252-253},
Note = {13th ACM International Conference on Distributed and Event-Based Systems
   (DEBS), Tech Univ Darmstadt, Darmstadt, GERMANY, JUN 24-28, 2019},
Organization = {Assoc Comp Machinery; ACM SIGMOD; ACM SIGSOFT; Internet \& Digitisat;
   CROSSING GmbH; SAP; Axxessio; DFG Collaborat Res Ctr 1053, MAKI Multi
   Mechanism Adapt Future Internet},
Abstract = {Data-driven solutions for the investment industry require eventbased
   backend systems to process high-volume financial data feeds with low
   latency, high throughput, and guaranteed delivery modes.
   At vwd we process an average of 18 billion incoming event notifications
   from 500+ data sources for 30 million symbols per day and peak rates of
   1+ million notifications per second using custom-built platforms that
   keep audit logs of every event.
   We currently assess modern open source event-processing platforms such
   as Kafka, NATS, Redis, Flink or Storm for the use in our ticker plant to
   reduce the maintenance effort for cross-cutting concerns and leverage
   hybrid deployment models. For comparability and repeatability we
   benchmark candidates with a standardized workload we derived from our
   real data feeds.
   We have enhanced an existing light-weight open source benchmarking tool
   in its processing, logging, and reporting capabilities to cope with our
   workloads. The resulting tool wrench can simulate workloads or replay
   snapshots in volume and dynamics like those we process in our ticker
   plant. We provide the tool as open source.
   As part of ongoing work we contribute details on (a) our workload and
   requirements for benchmarking candidate platforms for financial feed
   processing; (b) the current state of the tool wrench.},
DOI = {10.1145/3328905.3332506},
ISBN = {978-1-4503-6794-3},
Unique-ID = {WOS:000628649800039},
}

@article{ WOS:000573950700003,
Author = {Stehle, Elias and Jacobsen, Hans-Arno},
Title = {ParPaRaw: Massively Parallel Parsing of Delimiter-Separated Raw Data},
Journal = {PROCEEDINGS OF THE VLDB ENDOWMENT},
Year = {2020},
Volume = {13},
Number = {5},
Pages = {616-628},
Month = {JAN},
Abstract = {Parsing is essential for a wide range of use cases, such as stream
   processing, bulk loading, and in-situ querying of raw data. Yet, the
   compute-intense step often constitutes a major bottleneck in the data
   ingestion pipeline, since parsing of inputs that require more involved
   parsing rules is challenging to parallelise. This work proposes a
   massively parallel algorithm for parsing delimiter-separated data
   formats on GPUs. Other than the state-of-the-art, the proposed approach
   does not require an initial sequential pass over the input to determine
   a thread's parsing context. That is, how a thread, beginning somewhere
   in the middle of the input, should interpret a certain symbol (e.g.,
   whether to interpret a comma as a delimiter or as part of a larger
   string enclosed in double-quotes). Instead of tailoring the approach to
   a single format, we are able to perform a massively parallel finite
   state machine (FSM) simulation, which is more flexible and powerful,
   supporting more expressive parsing rules with general applicability.
   Achieving a parsing rate of as much as 14.2 GB/s, our experimental
   evaluation on a GPU with 3 584 cores shows that the presented approach
   is able to scale to thousands of cores and beyond. With an end-to-end
   streaming approach, we are able to exploit the full-duplex capabilities
   of the PCIe bus and hide latency from data transfers. Considering the
   end-to-end performance, the algorithm parses 4:8 GB in as little as 0:44
   seconds, including data transfers.},
DOI = {10.14778/3377369.3377372},
ISSN = {2150-8097},
Unique-ID = {WOS:000573950700003},
}

@inproceedings{ WOS:000426952300034,
Author = {HoseinyFarahabady, MohammadReza and Taheri, Javid and Tari, Zahir and
   Zomaya, Albert Y.},
Book-Group-Author = {IEEE},
Title = {A Dynamic Resource Controller for a Lambda Architecture},
Booktitle = {2017 46TH INTERNATIONAL CONFERENCE ON PARALLEL PROCESSING (ICPP)},
Series = {Proceedings of the International Conference on Parallel Processing},
Year = {2017},
Pages = {332-341},
Note = {46th International Conference on Parallel Processing Workshops (ICPPW),
   Bristol, ENGLAND, AUG 14-17, 2017},
Organization = {CRAY Supercomp Company; Intel; ARM; OCF; SGI; Univ Bristol;
   VirginiaTech; Int Assoc Comp \& Communications},
Abstract = {Lambda architecture is a novel event-driven serverless paradigm that
   allows companies to build scalable and reliable enterprise applications.
   As an attractive alternative to traditional service oriented
   architecture (SOA), Lambda architecture can be used in many use cases
   including BI tools, in-memory graph databases, OLAP, and streaming data
   processing. In practice, an important aim of Lambda's service providers
   is devising an efficient way to co-locate multiple Lambda functions with
   different attributes into a set of available computing resources.
   However, previous studies showed that consolidated workloads can compete
   fiercely for shared resources, resulting in severe performance
   variability/degradation. This paper proposes a resource allocation
   mechanism for a Lambda platform based on the model predictive control
   framework. Performance evaluation is carried out by comparing the
   proposed solution with multiple resource allocation heuristics, namely
   enhanced versions of spread and binpack, and best-effort approaches.
   Results confirm that the proposed controller increases the overall
   resource utilization by 37\% on average and achieves a significant
   improvement in preventing QoS violation incidents compared to others.},
DOI = {10.1109/ICPP.2017.42},
ISSN = {0190-3918},
ISBN = {978-1-5386-1042-8},
ResearcherID-Numbers = {Zomaya, Albert Y./G-9697-2017
   HoseinyFarahabady, M.Reza/H-4571-2013
   Taheri, Javid/I-2045-2013
   },
ORCID-Numbers = {Zomaya, Albert Y./0000-0002-3090-1059
   HoseinyFarahabady, M.Reza/0000-0002-7851-9377
   Taheri, Javid/0000-0001-9194-010X
   Tari, Zahir/0000-0002-1235-9673},
Unique-ID = {WOS:000426952300034},
}

@article{ WOS:000823983100001,
Author = {Savvides, Savvas and Kumar, Seema and Stephen, Julian James and Eugster,
   Patrick},
Title = {C3PO: Cloud-based Confidentiality-preserving Continuous Query Processing},
Journal = {ACM TRANSACTIONS ON PRIVACY AND SECURITY},
Year = {2022},
Volume = {25},
Number = {1},
Month = {FEB},
Abstract = {With the advent of the Internet of things (IoT), billions of devices are
   expected to continuously collect and process sensitive data (e.g.,
   location, personal health factors). Due to the limited computational
   capacity available on IoT devices, the current de facto model for
   building IoT applications is to send the gathered data to the cloud for
   computation. While building private cloud infrastructures for handling
   large amounts of data streams can be expensive, using low-cost public
   (untrusted) cloud infrastructures for processing continuous queries
   including sensitive data leads to strong concerns over data
   confidentiality.
   This article presents C3PO, a confidentiality-preserving, continuous
   query processing engine, that leverages the public cloud. The key idea
   is to intelligently utilize partially homomorphic and
   property-preserving encryption to perform as many computationally
   intensive operations as possible-without revealing plaintext-in the
   untrusted cloud. C3PO provides simple abstractions to the developer to
   hide the complexities of applying complex cryptographic primitives,
   reasoning about the performance of such primitives, deciding which
   computations can be executed in an untrusted tier, and optimizing cloud
   resource usage. An empirical evaluation with several benchmarks and case
   studies shows the feasibility of our approach. We consider different
   classes of IoT devices that differ in their computational and memory
   resources (from a Raspberry Pi 3 to a very small device with a Cortex-M3
   microprocessor) and through the use of optimizations, we demonstrate the
   feasibility of using partially homomorphic and property-preserving
   encryption on IoT devices.},
DOI = {10.1145/3472717},
Article-Number = {1},
ISSN = {2471-2566},
EISSN = {2471-2574},
Unique-ID = {WOS:000823983100001},
}

@article{ WOS:000742891100057,
Author = {Jacob, Vincent and Song, Fei and Stiegler, Arnaud and Rad, Bijan and
   Diao, Yanlei and Tatbul, Nesime},
Title = {Exathlon: A Benchmark for Explainable Anomaly Detection over Time Series},
Journal = {PROCEEDINGS OF THE VLDB ENDOWMENT},
Year = {2021},
Volume = {14},
Number = {11},
Pages = {2613-2626},
Month = {JUL},
Note = {47th International Conference on Very Large Data Bases (VLDB),
   Copenhagen, DENMARK, AUG 16-20, 2021},
Abstract = {Access to high-quality data repositories and benchmarks have been
   instrumental in advancing the state of the art in many experimental
   research domains. While advanced analytics tasks over time series data
   have been gaining lots of attention, lack of such community resources
   severely limits scientific progress. In this paper, we present Exathlon,
   the first comprehensive public benchmark for explainable anomaly
   detection over high-dimensional time series data. Exathlon has been
   systematically constructed based on real data traces from repeated
   executions of large-scale stream processing jobs on an Apache Spark
   cluster. Some of these executions were intentionally disturbed by
   introducing instances of six different types of anomalous events (e.g.,
   misbehaving inputs, resource contention, process failures). For each of
   the anomaly instances, ground truth labels for the root cause interval
   as well as those for the extended effect interval are provided,
   supporting the development and evaluation of a wide range of anomaly
   detection (AD) and explanation discovery (ED) tasks. We demonstrate the
   practical utility of Exathlon's dataset, evaluation methodology, and
   end-to-end data science pipeline design through an experimental study
   with three state-of-the-art AD and ED techniques.},
DOI = {10.14778/3476249.3476307},
ISSN = {2150-8097},
Unique-ID = {WOS:000742891100057},
}

@inproceedings{ WOS:000380404600027,
Author = {Zacheilas, Nikos and Kalogeraki, Vana and Zygouras, Nikolas and
   Panagiotou, Nikolaos and Gunopulos, Dimitrios},
Editor = {Ho, H and Ooi, BC and Zaki, MJ and Hu, XH and Haas, L and Kumar, V and Rachuri, S and Yu, SP and Hsiao, MHI and Li, J and Luo, F and Pyne, S and Ogan, K},
Title = {Elastic Complex Event Processing exploiting Prediction},
Booktitle = {PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA},
Year = {2015},
Pages = {213-222},
Note = {IEEE International Conference on Big Data, Santa Clara, CA, OCT 29-NOV
   01, 2015},
Organization = {IEEE; IEEE Comp Soc; Natl Sci Fdn; CCF; HUAWEI; Springer; ELSEVIER;
   CISCO; Intel},
Abstract = {Supporting real-time, cost-effective execution of Complex Event
   processing applications in the cloud has been an important goal for many
   scientists in recent years. Distributed Stream Processing Systems (DSPS)
   have been widely adopted by major computing companies as a powerful
   approach for large-scale Complex Event processing (CEP). However,
   determining the appropriate degree of parallelism of the DSPS'
   components can be particularly challenging as the volume of data streams
   is becoming increasingly large, the rule set is becoming continuously
   complex, and the system must be able to handle such large data stream
   volumes in real-time, taking into consideration changes in the
   burstiness levels and data characteristics. In this paper we describe
   our solution to building elastic complex event processing systems on top
   of our distributed CEP system which combines two commonly used
   frameworks, Storm and Esper, in order to provide both ease of usage and
   scalability. Our approach makes the following contributions: (i) we
   provide a mechanism for predicting the load and latency of the Esper
   engines in upcoming time windows, and (ii) we propose a novel algorithm
   for automatically adjusting the number of engines to use in the upcoming
   windows, taking into account the cost and the performance gains of
   possible changes. Our detailed experimental evaluation with a real
   traffic monitoring application that analyzes bus traces from the city of
   Dublin indicates the benefits in the working of our approach. Our
   proposal outperforms the current state of the art technique in regards
   to the amount of tuples that it can process by four orders of magnitude.},
ISBN = {978-1-4799-9925-5},
ResearcherID-Numbers = {Kalogeraki, Vana/ABI-1469-2020
   },
ORCID-Numbers = {Kalogeraki, Vana/0000-0002-6421-9947
   Gunopulos, Dimitrios/0000-0001-6339-1879},
Unique-ID = {WOS:000380404600027},
}

@inproceedings{ WOS:000520117900006,
Author = {Schelter, Sebastian and Celebi, Ufuk and Dunning, Ted},
Editor = {Malik, T and Maltzahn, C and Jimenez, I},
Title = {Efficient Incremental Cooccurrence Analysis for Item-Based Collaborative
   Filtering},
Booktitle = {SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT (SSDBM 2019)},
Year = {2019},
Pages = {61-72},
Note = {31st International Conference on Scientific and Statistical Database
   Management (SSDBM), Univ Calif, Santa Cruz, CA, JUL 23-25, 2019},
Organization = {Ctr Res Open Source Software},
Abstract = {Recommender systems are ubiquitous in the modern internet, where they
   help users find items they might like. A widely deployed recommendation
   approach is item-based collaborative filtering. This approach relies on
   analyzing large item cooccurrence matrices that denote how many users
   interacted with a pair of items. The potentially quadratic number of
   items to compare poses a scalability bottleneck in analyzing such item
   cooccurrences. Additionally, this problem intensifies in real world use
   cases with incrementally growing datasets, especially when the
   recommendation model is regularly recomputed from scratch. We highlight
   the connection between the growing cost of item-based recommendation and
   densification processes in common interaction datasets. Based on our
   findings, we propose an efficient incremental algorithm for item-sed
   collaborative filtering based on cooccurrence analysis. This approach
   restricts the number of interactions to consider from `power users' and
   `iquitous items' to guarantee a provably constant amount of work per
   user-item interaction to process. We discuss efficient implementations
   of our algorithm on a single machine as well as on a distributed stream
   processing engine, and present an extensive experimental evaluation. Our
   results confirm the asymptotic benefits of the incremental approach.
   Furthermore, we find that our implementation is an order of magnitude
   faster than existing open source recommender libraries on many datasets,
   and at the same time scales to high dimensional datasets which these
   existing recommenders fail to process.},
DOI = {10.1145/3335783.3335784},
ISBN = {978-1-4503-6216-0},
ORCID-Numbers = {Dunning, Ted/0000-0002-7655-673X},
Unique-ID = {WOS:000520117900006},
}

@article{ WOS:000537106200301,
Author = {Ordonez-Ante, Leandro and Van Seghbroeck, Gregory and Wauters, Tim and
   Volckaert, Bruno and De Turck, Filip},
Title = {Explora: Interactive Querying of Multidimensional Data in the Context of
   Smart Cities},
Journal = {SENSORS},
Year = {2020},
Volume = {20},
Number = {9},
Month = {MAY},
Abstract = {Citizen engagement is one of the key factors for smart city initiatives
   to remain sustainable over time. This in turn entails providing citizens
   and other relevant stakeholders with the latest data and tools that
   enable them to derive insights that add value to their day-to-day life.
   The massive volume of data being constantly produced in these smart city
   environments makes satisfying this requirement particularly challenging.
   This paper introduces Explora, a generic framework for serving
   interactive low-latency requests, typical of visual exploratory
   applications on spatiotemporal data, which leverages the stream
   processing for deriving-on ingestion time-synopsis data structures that
   concisely capture the spatial and temporal trends and dynamics of the
   sensed variables and serve as compacted data sets to provide fast
   (approximate) answers to visual queries on smart city data. The
   experimental evaluation conducted on proof-of-concept implementations of
   Explora, based on traditional database and distributed data processing
   setups, accounts for a decrease of up to 2 orders of magnitude in query
   latency compared to queries running on the base raw data at the expense
   of less than 10\% query accuracy and 30\% data footprint. The
   implementation of the framework on real smart city data along with the
   obtained experimental results prove the feasibility of the proposed
   approach.},
DOI = {10.3390/s20092737},
Article-Number = {2737},
EISSN = {1424-8220},
ResearcherID-Numbers = {Volckaert, Bruno/G-6288-2015
   },
ORCID-Numbers = {Volckaert, Bruno/0000-0003-0575-5894
   De Turck, Filip/0000-0003-4824-1199
   Ordonez-Ante, Leandro/0000-0002-1215-9209},
Unique-ID = {WOS:000537106200301},
}

@article{ WOS:000637532700005,
Author = {Fang, Junhua and Zhang, Rong and Zhao, Yan and Zheng, Kai and Zhou,
   Xiaofang and Zhou, Aoying},
Title = {A-DSP: An Adaptive Join Algorithm for Dynamic Data Stream on Cloud
   System},
Journal = {IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING},
Year = {2021},
Volume = {33},
Number = {5},
Pages = {1861-1876},
Month = {MAY 1},
Abstract = {The join operations, including both equi and non-equi joins, are
   essential to the complex data analytics in the big data era. However,
   they are not inherently supported by existing DSPEs (Distributed Stream
   Processing Engines). The state-of-the-art join solutions on DSPEs rely
   on either complicated routing strategies or resource-inefficient
   processing structures, which are susceptible to dynamic workload,
   especially when the DSPEs face various join predicate operations and
   skewed data distribution. In this paper, we propose a new cost-effective
   stream join framework, named A-DSP (Adaptive Dimensional Space
   Processing), which enhances the adaptability of real-time join model and
   minimizes the resource used over the dynamic workloads. Our proposal
   includes: 1) a join model generation algorithm devised to adaptively
   switch between different join schemes so as to minimize the number of
   processing task required; 2) a load-balancing mechanism which maximizes
   the processing throughput; and 3) a lightweight algorithm designed for
   cutting down unnecessary migration cost. Extensive experiments are
   conducted to compare our proposal against state-of-the-art solutions on
   both benchmark and real-world workloads. The experimental results verify
   the effectiveness of our method, especially on reducing the operational
   cost under pay-as-you-go pricing scheme.},
DOI = {10.1109/TKDE.2019.2947055},
ISSN = {1041-4347},
EISSN = {1558-2191},
Unique-ID = {WOS:000637532700005},
}

@article{ WOS:000455246300001,
Author = {Gautam, Bhaskar and Basava, Annappa},
Title = {Performance prediction of data streams on high-performance architecture},
Journal = {HUMAN-CENTRIC COMPUTING AND INFORMATION SCIENCES},
Year = {2019},
Volume = {9},
Month = {JAN 7},
Abstract = {Worldwide sensor streams are expanding continuously with unbounded
   velocity in volume, and for this acceleration, there is an adaptation of
   large stream data processing system from the homogeneous to rack-scale
   architecture which makes serious concern in the domain of workload
   optimization, scheduling, and resource management algorithms. Our
   proposed framework is based on providing architecture independent
   performance prediction model to enable resource adaptive distributed
   stream data processing platform. It is comprised of seven pre-defined
   domain for dynamic data stream metrics including a self-driven model
   which tries to fit these metrics using ridge regularization regression
   algorithm. Another significant contribution lies in fully-automated
   performance prediction model inherited from the state-of-the-art
   distributed data management system for distributed stream processing
   systems using Gaussian processes regression that cluster metrics with
   the help of dimensionality reduction algorithm. We implemented its base
   on Apache Heron and evaluated with proposed Benchmark Suite comprising
   of five domain-specific topologies. To assess the proposed
   methodologies, we forcefully ingest tuple skewness among the
   benchmarking topologies to set up the ground truth for predictions and
   found that accuracy of predicting the performance of data streams
   increased up to 80.62\% from 66.36\% along with the reduction of error
   from 37.14 to 16.06\%.},
DOI = {10.1186/s13673-018-0163-4},
Article-Number = {2},
ISSN = {2192-1962},
ResearcherID-Numbers = {B, ANNAPPA/P-3077-2014
   Gautam, Bhaskar/W-8945-2018},
ORCID-Numbers = {B, ANNAPPA/0000-0002-4049-3677
   Gautam, Bhaskar/0000-0002-3258-9927},
Unique-ID = {WOS:000455246300001},
}

@article{ WOS:000721218700001,
Author = {Matesanz, Philip and Graen, Timo and Fiege, Andrea and Nolting, Michael
   and Nejdl, Wolfgang},
Title = {Demand-Driven Data Acquisition for Large Scale Fleets},
Journal = {SENSORS},
Year = {2021},
Volume = {21},
Number = {21},
Month = {NOV},
Abstract = {Automakers manage vast fleets of connected vehicles and face an
   ever-increasing demand for their sensor readings. This demand originates
   from many stakeholders, each potentially requiring different sensors
   from different vehicles. Currently, this demand remains largely
   unfulfilled due to a lack of systems that can handle such diverse
   demands efficiently. Vehicles are usually passive participants in data
   acquisition, each continuously reading and transmitting the same static
   set of sensors. However, in a multi-tenant setup with diverse data
   demands, each vehicle potentially needs to provide different data
   instead. We present a system that performs such vehicle-specific
   minimization of data acquisition by mapping individual data demands to
   individual vehicles. We collect personal data only after prior consent
   and fulfill the requirements of the GDPR. Non-personal data can be
   collected by directly addressing individual vehicles. The system
   consists of a software component natively integrated with a major
   automaker's vehicle platform and a cloud platform brokering access to
   acquired data. Sensor readings are either provided via near real-time
   streaming or as recorded trip files that provide specific consistency
   guarantees. A performance evaluation with over 200,000 simulated
   vehicles has shown that our system can increase server capacity
   on-demand and process streaming data within 269 ms on average during
   peak load. The resulting architecture can be used by other automakers or
   operators of large sensor networks. Native vehicle integration is not
   mandatory; the architecture can also be used with retrofitted hardware
   such as OBD readers.},
DOI = {10.3390/s21217190},
Article-Number = {7190},
EISSN = {1424-8220},
ORCID-Numbers = {Fiege, Andrea/0000-0002-9423-8508
   Matesanz, Philip/0000-0002-3546-031X
   Nejdl, Wolfgang/0000-0003-3374-2193},
Unique-ID = {WOS:000721218700001},
}

@article{ WOS:000873531200001,
Author = {Murshed, Belal Abdullah Hezam and Mallappa, Suresha and Abawajy, Jemal
   and Saif, Mufeed Ahmed Naji and Al-ariki, Hasib Daowd Esmail and
   Abdulwahab, Hudhaifa Mohammed},
Title = {Short text topic modelling approaches in the context of big data:
   taxonomy, survey, and analysis},
Journal = {ARTIFICIAL INTELLIGENCE REVIEW},
Abstract = {Social media platforms such as (Twitter, Facebook, and Weibo) are being
   increasingly embraced by individuals, groups, and organizations as a
   valuable source of information. This social media generated information
   comes in the form of tweets or posts, and normally characterized as
   short text, huge, sparse, and low density. Since many real-world
   applications need semantic interpretation of such short texts, research
   in Short Text Topic Modeling (STTM) has recently gained a lot of
   interest to reveal unique and cohesive latent topics. This article
   examines the current state of the art in STTM algorithms. It presents a
   comprehensive survey and taxonomy of STTM algorithms for short text
   topic modelling. The article also includes a qualitative and
   quantitative study of the STTM algorithms, as well as analyses of the
   various strengths and drawbacks of STTM techniques. Moreover, a
   comparative analysis of the topic quality and performance of
   representative STTM models is presented. The performance evaluation is
   conducted on two real-world Twitter datasets: the Real-World Pandemic
   Twitter (RW-Pand-Twitter) dataset and Real-world Cyberbullying Twitter
   (RW-CB-Twitter) dataset in terms of several metrics such as topic
   coherence, purity, NMI, and accuracy. Finally, the open challenges and
   future research directions in this promising field are discussed to
   highlight the trends of research in STTM. The work presented in this
   paper is useful for researchers interested in learning state-of-the-art
   short text topic modelling and researchers focusing on developing new
   algorithms for short text topic modelling.},
DOI = {10.1007/s10462-022-10254-w},
EarlyAccessDate = {OCT 2022},
ISSN = {0269-2821},
EISSN = {1573-7462},
ORCID-Numbers = {Murshed, Belal Abdullah Hezam/0000-0003-2187-5044
   Ahmed, Mufeed/0000-0002-0399-6339},
Unique-ID = {WOS:000873531200001},
}

@article{ WOS:000569080000001,
Author = {Koo, Jahwan and Faseeh Qureshi, Nawab Muhammad and Siddiqui, Isma Farah
   and Abbas, Asad and Bashir, Ali Kashif},
Title = {IoT-enabled directed acyclic graph in spark cluster},
Journal = {JOURNAL OF CLOUD COMPUTING-ADVANCES SYSTEMS AND APPLICATIONS},
Year = {2020},
Volume = {9},
Number = {1},
Month = {SEP 14},
Abstract = {Real-time data streaming fetches live sensory segments of the dataset in
   the heterogeneous distributed computing environment. This process
   assembles data chunks at a rapid encapsulation rate through a streaming
   technique that bundles sensor segments into multiple micro-batches and
   extracts into a repository, respectively. Recently, the acquisition
   process is enhanced with an additional feature of exchanging IoT
   devices' dataset comprised of two components: (i) sensory data and (ii)
   metadata. The body of sensory data includes record information, and the
   metadata part consists of logs, heterogeneous events, and routing path
   tables to transmit micro-batch streams into the repository. Real-time
   acquisition procedure uses the Directed Acyclic Graph (DAG) to extract
   live query outcomes from in-place micro-batches through MapReduce stages
   and returns a result set. However, few bottlenecks affect the
   performance during the execution process, such as (i) homogeneous
   micro-batches formation only, (ii) complexity of dataset
   diversification, (iii) heterogeneous data tuples processing, and (iv)
   linear DAG workflow only. As a result, it produces huge processing
   latency and the additional cost of extracting event-enabled IoT
   datasets. Thus, the Spark cluster that processes Resilient Distributed
   Dataset (RDD) in a fast-pace using Random access memory (RAM) defies
   expected robustness in processing IoT streams in the distributed
   computing environment. This paper presents an IoT-enabled Directed
   Acyclic Graph (I-DAG) technique that labels micro-batches at the stage
   of building a stream event and arranges stream elements with event
   labels. In the next step, heterogeneous stream events are processed
   through the I-DAG workflow, which has non-linear DAG operation for
   extracting queries' results in a Spark cluster. The performance
   evaluation shows that I-DAG resolves homogeneous IoT-enabled stream
   event issues and provides an effective stream event heterogeneous
   solution for IoT-enabled datasets in spark clusters.},
DOI = {10.1186/s13677-020-00195-6},
Article-Number = {50},
EISSN = {2192-113X},
ResearcherID-Numbers = {Siddiqui, Isma F/Q-9976-2018
   Qureshi, Nawab Muhammad Faseeh/AFH-3963-2022
   Bashir, Ali Kashif/R-4015-2019},
ORCID-Numbers = {Siddiqui, Isma F/0000-0002-2058-4336
   Qureshi, Nawab Muhammad Faseeh/0000-0002-5035-2640
   Bashir, Ali Kashif/0000-0003-2601-9327},
Unique-ID = {WOS:000569080000001},
}

@inproceedings{ WOS:000520117900007,
Author = {Mytilinis, Ioannis and Tsoumakos, Dimitrios and Koziris, Nectarios},
Editor = {Malik, T and Maltzahn, C and Jimenez, I},
Title = {Maintaining Wavelet Synopses for Sliding-Window Aggregates},
Booktitle = {SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT (SSDBM 2019)},
Year = {2019},
Pages = {73-84},
Note = {31st International Conference on Scientific and Statistical Database
   Management (SSDBM), Univ Calif, Santa Cruz, CA, JUL 23-25, 2019},
Organization = {Ctr Res Open Source Software},
Abstract = {The IoT era has brought forth a computing paradigm shift from
   traditional high-end servers to ``edge{''} devices of limited processing
   and memory capabilities. These devices, together with sensors, regularly
   produce very high data volumes nowadays. For many real-time
   applications, storing and indexing an unbounded stream may not be an
   option. Thus, it is important that we design algorithms and systems that
   can both work at the edge of the network and be able to answer queries
   on distributed, streaming data. Moreover, in many streaming scenarios,
   fresh data tend to be prioritized. A sliding-window model is an
   important case of stream processing, where only the most recent elements
   remain active and the rest are discarded. In this work, we study the
   problem of maintaining basic aggregate statistics over a sliding-window
   data stream under the constraint of limited memory. As in IoT scenarios
   the available memory is typically much less than the window size,
   queries are answered from compact synopses that are maintained in an
   on-line fashion. For the efficient construction of such synopses, in
   this work, we propose wavelet-based algorithms that provide
   deterministic guarantees and produce almost exact results. Our
   algorithms can work on any kind of numerical data and do not have the
   positive-numbers constraint of techniques such as the exponential
   histograms. Our experimental evaluation indicates that, in terms of
   accuracy and space-efficiency, our solution outperforms the exponential
   histograms and deterministic waves techniques.},
DOI = {10.1145/3335783.3335793},
ISBN = {978-1-4503-6216-0},
ResearcherID-Numbers = {Tsoumakos, Dimitrios/AAF-1957-2021},
Unique-ID = {WOS:000520117900007},
}

@inproceedings{ WOS:000380404600362,
Author = {Rafailidis, Dimitrios and Antaris, Stefanos},
Editor = {Ho, H and Ooi, BC and Zaki, MJ and Hu, XH and Haas, L and Kumar, V and Rachuri, S and Yu, SP and Hsiao, MHI and Li, J and Luo, F and Pyne, S and Ogan, K},
Title = {Indexing Media Storms on Flink},
Booktitle = {PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA},
Year = {2015},
Pages = {2836-2838},
Note = {IEEE International Conference on Big Data, Santa Clara, CA, OCT 29-NOV
   01, 2015},
Organization = {IEEE; IEEE Comp Soc; Natl Sci Fdn; CCF; HUAWEI; Springer; ELSEVIER;
   CISCO; Intel},
Abstract = {We propose a media storm indexing algorithm using Map-Reduce in our
   recently proposed CDVC framework. In this study, CDVC is built on Flink,
   an open-source platform for stream data processing. The question we
   answer is how to store massive image collections; for instance, with
   over one million images per second, as well as with varying incoming
   rate. In our experiments with two benchmark datasets of 80M and 1B image
   descriptors, we evaluate the proposed algorithm on different indexing
   workloads, that is, images that come with high volume and different
   velocity at the scale of 10(5)-10(6) images per second. Using a limited
   set of computational nodes, we show that we achieve a significant speed
   up factor of nine, on average, compared to conventional indexing
   techniques, in all settings. Finally, we make our source code publicly
   available.},
ISBN = {978-1-4799-9925-5},
Unique-ID = {WOS:000380404600362},
}

@inproceedings{ WOS:000485040000015,
Author = {Kang, Jian and Samarasinghe, Gihan and Senanayake, Upul and Conjeti,
   Sailesh and Sowmya, Arcot},
Book-Group-Author = {IEEE},
Title = {DEEP LEARNING FOR VOLUMETRIC SEGMENTATION IN SPATIO-TEMPORAL DATA:
   APPLICATION TO SEGMENTATION OF PROSTATE IN DCE-MRI},
Booktitle = {2019 IEEE 16TH INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI 2019)},
Series = {IEEE International Symposium on Biomedical Imaging},
Year = {2019},
Pages = {61-65},
Note = {16th IEEE International Symposium on Biomedical Imaging (ISBI), Venice,
   ITALY, APR 08-11, 2019},
Organization = {Inst Elect \& Elect Engineers; IEEE Engn Med \& Biol Soc; IEEE Signal
   Proc Soc; Canon Med Res Europe Ltd; UAI, United Imaging Intelligence;
   Baidu; GSK; Kitware},
Abstract = {Segmentation of the prostate in MR images is an essential step that
   underpins the success of subsequent analysis methods, such as cancer
   lesion detection inside the tumour and registration between different
   modalities. This work focuses on leveraging deep learning for analysis
   of longitudinal volumetric datasets, particularly for the task of
   segmentation, and presents proof-of-concept for segmentation of the
   prostate in 3D+T DCE-MRI sequences. A two-stream processing pipeline is
   proposed for this task, comprising a spatial stream modelled using a
   volumetric fully convolutional network and a temporal stream modeled
   using recurrent neural networks with Long Short-term Memory (LSTM)
   units. The predictions of the two streams are fused using deep neural
   networks. The proposed method has been validated on a public benchmark
   dataset of 17 patients, each with 40 temporal volumes. When averaged
   over three experiments, a highly competitive Dice overlap score of
   0.8688 and sensitivity of 0,8694 were achieved. As a spatio-temporal
   segmentation method, it can easily migrate to other datasets.},
ISSN = {1945-7928},
ISBN = {978-1-5386-3641-1},
Unique-ID = {WOS:000485040000015},
}

@inproceedings{ WOS:000578516400026,
Author = {Kesavan, Suraj P. and Fujiwara, Takanori and Li, Jianping Kelvin and
   Ross, Caitlin and Mubarak, Misbah and Carothers, Christopher D. and
   Ross, Robert B. and Ma, Kwan-Liu},
Editor = {Beck, F and Seo, J and Wang, C},
Title = {A Visual Analytics Framework for Reviewing Streaming Performance Data},
Booktitle = {2020 IEEE PACIFIC VISUALIZATION SYMPOSIUM (PACIFICVIS)},
Series = {IEEE Pacific Visualization Symposium},
Year = {2020},
Pages = {206-215},
Note = {IEEE Pacific Visualization Symposium (PacificVis), Tianjin, PEOPLES R
   CHINA, APR 14-17, 2020},
Organization = {IEEE; IEEE Comp Soc; IEEE Comp Soc Visualizat \& Graph Tech Comm},
Abstract = {Understanding and tuning the performance of extreme-scale parallel
   computing systems demands a streaming approach due to the computational
   cost of applying offline algorithms to vast amounts of performance log
   data. Analyzing large streaming data is challenging because the rate of
   receiving data and limited time to comprehend data make it difficult for
   the analysts to sufficiently examine the data without missing important
   changes or patterns. To support streaming data analysis, we introduce a
   visual analytic framework comprising of three modules: data management,
   analysis, and interactive visualization. The data management module
   collects various computing and communication performance metrics from
   the monitored system using streaming data processing techniques and
   feeds the data to the other two modules. The analysis module
   automatically identifies important changes and patterns at the required
   latency. In particular, we introduce a set of online and progressive
   analysis methods for not only controlling the computational costs but
   also helping analysts better follow the critical aspects of the analysis
   results. Finally, the interactive visualization module provides the
   analysts with a coherent view of the changes and patterns in the
   continuously captured performance data. Through a multi-faceted case
   study on performance analysis of parallel discrete-event simulation, we
   demonstrate the effectiveness of our framework for identifying
   bottlenecks and locating outliers.},
DOI = {10.1109/PacificVis48177.2020.9280},
ISSN = {2165-8765},
ISBN = {978-1-7281-5697-2},
ResearcherID-Numbers = {Kesavan, Suraj/AAU-1377-2021
   },
ORCID-Numbers = {Kesavan, Suraj/0000-0001-8524-6648
   Fujiwara, Takanori/0000-0002-6382-2752},
Unique-ID = {WOS:000578516400026},
}

@inproceedings{ WOS:000428513600196,
Author = {Rajoria, Nitish and Kamei, Hiromu and Mitsugi, Jin and Kawakita, Yuusuke
   and Ichikawa, Haruhisa},
Book-Group-Author = {IEEE},
Title = {Multi-Carrier Backscatter Communication System for Concurrent Wireless
   and Batteryless Sensing},
Booktitle = {2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS,
   SIGNAL PROCESSING AND NETWORKING (WISPNET)},
Year = {2017},
Pages = {1078-1082},
Note = {2nd IEEE International Conference on Wireless Communications, Signal
   Processing and Networking (WiSPNET), Chennai, INDIA, MAR 22-24, 2017},
Organization = {IEEE; IEEE Commun Soc; SSN; iNSERB INDIA; Aconf; ISRO Bangalore; Pearson
   India Educ Serv Private Ltd; IEEE MAS Sect; IEEE Commun Madras Chapter;
   DST SERB New Delhi},
Abstract = {Wireless and batteryless sensing has recently attracted significant
   attention of researchers in IoT and WSN applications. It turns out to be
   more challenging when simultaneous data acquisition from multiple
   sensors is required. This paper introduces a non-orthogonal multiple
   access technique MSMA, using extremely simple wireless and batteryless
   sensor tags and a reader to support concurrent streaming from multiple
   sensors. By simultaneously handling non-orthogonal subcarriers, produced
   either by multiple or single sensor tag, it can realize concurrent
   sensor data streaming, which can be used in health monitoring of
   machinery and civil structures. The paper explains the two primary
   challenges in MSMA, the optimal assignment of subcarrier frequencies and
   the unavoidable harmonics from one subcarrier to others. Since the
   mutual interference among subcarriers is unevenly distributed over the
   available frequency band, random allocation of subcarrier frequencies
   may result in degraded system performance. Results show that the
   interference can be canceled out with the signal processing technique
   and the system communication capacity can be increased significantly
   with a proposed heuristic approach compared to random allocation of
   subcarrier frequencies to the sensor tags.},
ISBN = {978-1-5090-4442-9},
ResearcherID-Numbers = {Kawakita, Yuusuke/AAD-3122-2019},
ORCID-Numbers = {Kawakita, Yuusuke/0000-0002-0169-6228},
Unique-ID = {WOS:000428513600196},
}

@inproceedings{ WOS:000401904700011,
Author = {Mossel, Annette and Kroeter, Manuel},
Editor = {Veas, E and Langlotz, T and Martinezcarranza, J and Grasset, R and Sugimoto, M and Martin, A},
Title = {Streaming and Exploration of Dynamically Changing Dense 3D
   Reconstructions in Immersive Virtual Reality},
Booktitle = {ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED
   AND AUGMENTED REALITY (ISMAR-ADJUNCT)},
Year = {2016},
Pages = {43-48},
Note = {15th IEEE International Symposium on Mixed and Augmented Reality
   (ISMAR-Adjunct), Merida, MEXICO, SEP 19-23, 2016},
Organization = {IEEE; IEEE Comp Soc; DAQRI; ARTOOLKIT; Off Naval Res; Off Naval Res, Sci
   \& Technol; Vuforia; Intel; Envrmnt; PREFIXA; fayteq},
Abstract = {We introduce a novel framework that enables large-scale dense 3D scene
   reconstruction, data streaming over the network and immersive
   exploration of the reconstructed environment using virtual reality. The
   system is operated by two remote entities, where one entity - for
   instance an autonomous aerial vehicle - captures and reconstructs the
   environment as well as transmits the data to another entity - such as
   human observer - that can immersivly explore the 3D scene, decoupled
   from the view of the capturing entity. The performance evaluation
   revealed the framework's capabilities to perform RGB-D data capturing,
   dense 3D reconstruction, streaming and dynamic scene updating in real
   time for indoor environments up to a size of 100m(2), using either a
   state-of-the-art mobile computer or a workstation. Thereby, our work
   provides a foundation for enabling immersive exploration of remotely
   captured and incrementally reconstructed dense 3D scenes, which has not
   shown before and opens up new research aspects in future.},
DOI = {10.1109/ISMAR-Adjunct.2016.28},
ISBN = {978-1-5090-3740-7},
Unique-ID = {WOS:000401904700011},
}

@inproceedings{ WOS:000309229600029,
Author = {Tan, Yongmin and Hiep Nguyen and Shen, Zhiming and Gu, Xiaohui and
   Venkatramani, Chitra and Rajan, Deepak},
Book-Group-Author = {IEEE},
Title = {PREPARE: Predictive Performance Anomaly Prevention for Virtualized Cloud
   Systems},
Booktitle = {2012 IEEE 32ND INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS
   (ICDCS)},
Series = {IEEE International Conference on Distributed Computing Systems},
Year = {2012},
Pages = {285-294},
Note = {32nd IEEE International Conference on Distributed Computing Systems
   (ICDCS), Macau, PEOPLES R CHINA, JUN 18-21, 2012},
Organization = {IEEE; IEEE Comp Soc; IEEE Comp Soc Tech Comm Distributed Proc; Univ
   Macau; USA Natl Sci Fdn (NSF); Intel; IBM; Japan Adv Inst Sci \& Technol
   (JAIST)},
Abstract = {Virtualized cloud systems are prone to performance anomalies due to
   various reasons such as resource contentions, software bugs, and
   hardware failures. In this paper, we present a novel PREdictive
   Performance Anomaly pREvention (PREPARE) system that provides automatic
   performance anomaly prevention for virtualized cloud computing
   infrastructures. PREPARE integrates online anomaly prediction,
   learning-based cause inference, and predictive prevention actuation to
   minimize the performance anomaly penalty without human intervention. We
   have implemented PREPARE on top of the Xen platform and tested it on the
   NCSU's Virtual Computing Lab using a commercial data stream processing
   system (IBM System S) and an online auction benchmark (RUBiS). The
   experimental results show that PREPARE can effectively prevent
   performance anomalies while imposing low overhead to the cloud
   infrastructure.},
DOI = {10.1109/ICDCS.2012.65},
ISSN = {1063-6927},
Unique-ID = {WOS:000309229600029},
}

@inproceedings{ WOS:000165049300044,
Author = {Pechanek, GG and Vassiliadis, S},
Editor = {Vajda, F},
Title = {The ManArray (TM) embedded processor architecture},
Booktitle = {PROCEEDINGS OF THE 26TH EUROMICRO CONFERENCE, VOLS I AND II},
Series = {EUROMICRO CONFERENCE - PROCEEDINGS},
Year = {2000},
Pages = {348-355},
Note = {26th Euromicro Conference, MAASTRICHT, NETHERLANDS, SEP 05-07, 2000},
Abstract = {The BOPS(R) ManArray(TM) architecture is presented as a scalable DSP
   platform for the embedded processor domain. In this domain,
   ManArray-based processors use a single architecture definition, that
   supports multiple configurations of processing elements (PEs) from low
   end single PE to large arrays of PEs, and single tool set. The ManArray
   (selectable) parallelism architecture mixes control oriented operations,
   VLIWs, packed data operations, and distributed array processing in a
   cohesive, independently selectable manner. In addition, scalable
   conditional execution and single-cycle communications across a high
   connectivity, low cast network are integrated in the architecture. This
   allows another level of selectivity that enhances the application of the
   parallel resources to high performance algorithms. Coupled,with the
   array DSP is a scalable DMA engine that runs in the background and
   provides programmer-selectable data-distribution patterns and a
   high-bandwidth data-streaming interface to system peripherals and global
   memory. This paper introduces the embedded scalable MonArray
   architecture and a number of benchmarks. For example, a standard ASIC
   flow DSP/coprocessor core, the BOPS2040, can process a distributed
   256-point complex FFT in 425 cycles and an 8x8 2D IDCT that meets IEEE
   standards in 34 cycles.},
ISSN = {1089-6503},
ISBN = {0-7695-0781-6},
Unique-ID = {WOS:000165049300044},
}

@article{ WOS:000233043200004,
Author = {Mokbel, MF and Xiong, XP and Aref, WG and Hammad, MA},
Title = {Continuous query processing of spatio-temporal data streams in PLACE},
Journal = {GEOINFORMATICA},
Year = {2005},
Volume = {9},
Number = {4},
Pages = {343-365},
Month = {DEC},
Note = {2nd Workshop on Spatio-Temporal Database Management (STDBM 04), Toronto,
   CANADA, AUG 30, 2004},
Abstract = {The tremendous increase in the use of cellular phones, GPS-like devices,
   and RFIDs results in highly dynamic environments where objects as well
   as queries are continuously moving. In this paper, we present a
   continuous query processor designed specifically for highly dynamic
   environments (e.g., location-aware environments). We implemented the
   proposed continuous query processor inside the PLACE server (Pervasive
   Location-Aware Computing Environments); a scalable location-aware
   database server developed at Purdue University. The PLACE server extends
   data streaming management systems to support location-aware
   environments. These environments are characterized by the wide variety
   of continuous spatio-temporal queries and the unbounded spatio-temporal
   streams. The proposed continuous query processor includes: (1) New
   incremental spatio-temporal operators to support a wide variety of
   continuous spatio-temporal queries, (2) Extended semantics of sliding
   window queries to deal with spatial sliding windows as well as temporal
   sliding windows, and (3) A shared-execution framework for scalable
   execution of a set of concurrent continuous spatio-temporal queries.
   Experimental evaluation shows promising performance of the continuous
   query processor of the PLACE server.},
DOI = {10.1007/s10707-005-4576-7},
ISSN = {1384-6175},
EISSN = {1573-7624},
ResearcherID-Numbers = {Aref, Walid/D-4403-2019
   Mokbel, Mohamed/AAX-6146-2021
   },
ORCID-Numbers = {Aref, Walid/0000-0001-8169-7775
   Mokbel, Mohamed/0000-0002-6686-1757},
Unique-ID = {WOS:000233043200004},
}

@inproceedings{ WOS:000630462100007,
Author = {Venugopal, Vinu E. and Theobald, Martin and Chaychi, Samira and
   Tawakuli, Amal},
Book-Group-Author = {IEEE},
Title = {AIR: A Light-Weight Yet High-Performance Dataflow Engine based on
   Asynchronous Iterative Routing},
Booktitle = {2020 IEEE 32ND INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE AND HIGH
   PERFORMANCE COMPUTING (SBAC-PAD 2020)},
Series = {International Symposium on Computer Architecture and High Performance
   Computing},
Year = {2020},
Pages = {51-58},
Note = {32nd IEEE International Symposium on Computer Architecture and
   High-Performance Computing (SBAC-PAD) / 11th Workshop on Applications
   for Multi-Core Architectures (WAMCA), ELECTR NETWORK, SEP 08-11, 2020},
Organization = {Univ Porto, Fac Sci, Comp Sci Dept; IEEE Comp Soc; Brazilian Comp Soc},
Abstract = {Distributed Stream Processing Engines (DSPEs) are currently among the
   most emerging topics in data management, with applications ranging from
   real-time event monitoring to processing complex dataflow programs and
   big data analytics. In this paper, we describe the architecture of our
   AIR engine, which is designed from scratch in C++ using the Message
   Passing Interface (MPI), pthreads for multithreading, and is directly
   deployed on top of a common HPC workload manager such as SLURM. AIR
   implements a light-weight, dynamic sharding protocol (referred to as
   ``Asynchronous Iterative Routing{''}), which facilitates a direct and
   asynchronous communication among all worker nodes and thereby completely
   avoids any additional communication overhead with a dedicated master
   node. With its unique design, AIR fills the gap between the prevalent
   scale-out (but Java-based) architectures like Apache Spark and Flink, on
   one hand, and recent scale-up (and C++ based) prototypes such as
   StreamBox and PiCo, on the other hand. Our experiments over various
   benchmark settings confirm that AIR performs as good as the best
   scale-up SPEs on a single-node setup, while it outperforms existing
   scale-out DSPEs in terms of processing latency and sustainable
   throughput by a factor of up to 15 in a distributed setting.},
DOI = {10.1109/SBAC-PAD49847.2020.00018},
ISSN = {1550-6533},
ISBN = {978-1-7281-9924-5},
Unique-ID = {WOS:000630462100007},
}

@article{ WOS:000809919200015,
Author = {Nandi, Arijit and Xhafa, Fatos},
Title = {A federated learning method for real-time emotion state classification
   from multi-modal streaming},
Journal = {METHODS},
Year = {2022},
Volume = {204},
Pages = {340-347},
Month = {AUG},
Abstract = {Emotional and physical health are strongly connected and should be taken
   care of simultaneously to ensure completely healthy persons. A person's
   emotional health can be determined by detecting emotional states from
   various physiological measurements (EDA, RB, EEG, etc.). Affective
   Computing has become the field of interest, which uses software and
   hardware to detect emotional states. In the IoT era, wearable
   sensor-based real-time multi-modal emotion state classification has
   become one of the hottest topics. In such setting, a data stream is
   generated from wearable-sensor devices, data accessibility is restricted
   to those devices only and usually a high data generation rate should be
   processed to achieve real-time emotion state responses. Additionally,
   protecting the users' data privacy makes the processing of such data
   even more challenging. Traditional classifiers have limitations to
   achieve high accuracy of emotional state detection under demanding
   requirements of decentralized data and protecting users' privacy of
   sensitive information as such classifiers need to see all data. Here
   comes the federated learning, whose main idea is to create a global
   classifier without accessing the users' local data. Therefore, we have
   developed a federated learning framework for real-time emotion state
   classification using multi-modal physiological data streams from
   wearable sensors, called Fed-ReMECS. The main findings of our Fed-ReMECS
   framework are the development of an efficient and scalable real-time
   emotion classification system from distributed multimodal physiological
   data streams, where the global classifier is built without accessing
   (privacy protection) the users' data in an IoT environment. The
   experimental study is conducted using the popularly used multi-modal
   benchmark DEAP dataset for emotion classification. The results show the
   effectiveness of our developed approach in terms of accuracy,
   efficiency, scalability and users' data privacy protection.},
DOI = {10.1016/j.ymeth.2022.03.005},
ISSN = {1046-2023},
EISSN = {1095-9130},
ResearcherID-Numbers = {NANDI, ARIJIT/AAL-8768-2020},
ORCID-Numbers = {NANDI, ARIJIT/0000-0003-4238-5183},
Unique-ID = {WOS:000809919200015},
}

@article{ WOS:000284931600008,
Author = {Yu, Chenjie and Petrov, Peter},
Title = {Energy- and Performance-Efficient Communication Framework for Embedded
   MPSoCs through Application-Driven Release Consistency},
Journal = {ACM TRANSACTIONS ON DESIGN AUTOMATION OF ELECTRONIC SYSTEMS},
Year = {2010},
Volume = {16},
Number = {1},
Month = {NOV},
Abstract = {We present a framework for performance-, bandwidth-, and
   energy-efficient intercore communication in embedded MultiProcessor
   Systems-on-a-Chip (MPSoC). The methodology seamlessly integrates
   compiler, operating system, and hardware support to achieve a low-cost
   communication between synchronized producers and consumers. The
   technique is especially beneficial for data-streaming applications
   exploiting pipeline parallelism with computational phases mapped to
   separate cores. Code transformations utilizing a simple ISA support
   ensure that producer writes are propagated to consumers with a single
   interconnect transaction per cache block just prior to the producer
   exiting its synchronization region. Furthermore, in order to completely
   eliminate misses to shared data caused by interference with private data
   and also to minimize the cache energy, we integrate to the proposed
   framework a cache way partitioning policy based on a simple cache
   configurability support, which isolates the shared buffers from other
   cache traffic. This mechanism results in significant power savings since
   only a subset of the cache ways needs to be looked up for each cache
   access. The end result of the proposed framework is a single
   communication transaction per shared cache block between a producer and
   a consumer with no coherence misses on the consumer caches. Our
   experiments demonstrate significant reductions in interconnect traffic,
   cache misses, and energy for a set of multiprocessor benchmarks.},
DOI = {10.1145/1870109.1870117},
Article-Number = {8},
ISSN = {1084-4309},
EISSN = {1557-7309},
Unique-ID = {WOS:000284931600008},
}

@article{ WOS:000311921300003,
Author = {Schulz, Christian},
Title = {Efficient local search on the GPU-Investigations on the vehicle routing
   problem},
Journal = {JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING},
Year = {2013},
Volume = {73},
Number = {1, SI},
Pages = {14-31},
Month = {JAN},
Abstract = {We study how to implement local search efficiently on data parallel
   accelerators such as Graphics Processing Units. The Distance-constrained
   Capacitated Vehicle Routing Problem, a computationally very hard
   discrete optimization problem with high industrial relevance, is the
   selected vehicle for our investigations. More precisely, we investigate
   local search with the Best Improving strategy for the 2-opt and 3-opt
   operators on a giant tour representation. Resource extension functions
   are used for constant time move evaluation. Using CUDA, a basic
   implementation called The Benchmark Version has been developed and
   deployed on a Fermi architecture Graphics Processing Unit. Both
   neighborhood setup and evaluation are performed entirely on the device.
   The Benchmark Version is the initial step of an incremental improvement
   process where a number of important implementation aspects have been
   systematically studied. Ten well-known test instances from the
   literature are used in computational experiments, and profiling tools
   are used to identify bottlenecks. In the final version, the device is
   fully saturated, given a large enough problem instance. A speedup of
   almost an order of magnitude relative to The Benchmark Version is
   observed. We conclude that, with some effort, local search may be
   implemented very efficiently on Graphics Processing Units. Our
   experiments show that a maximum efficiency, however, requires a
   neighborhood cardinality of at least one million. Full exploration of a
   billion neighbors takes a few seconds and may be deemed too expensive
   with the current technology. Reduced neighborhoods through filtering is
   an obvious remedy. Experiments on simple models of neighborhood
   filtering indicate, however, that the speedup effect is limited on data
   parallel accelerators. We believe these insights are valuable in the
   design of new metaheuristics that fully utilize modern, heterogeneous
   processors. (C) 2012 Elsevier Inc. All rights reserved.},
DOI = {10.1016/j.jpdc.2012.02.020},
ISSN = {0743-7315},
EISSN = {1096-0848},
ORCID-Numbers = {Schulz, Christian/0000-0002-2823-3506},
Unique-ID = {WOS:000311921300003},
}

@inproceedings{ WOS:000284328500007,
Author = {Despres, Philippe and Rinkel, Jean and Hasegawa, Bruce H. and Prevrhal,
   Sven},
Book-Author = {Verhaegen, F
   Seuntjens, J},
Title = {Stream processors: a new platform for Monte Carlo calculations},
Booktitle = {INTERNATIONAL WORKSHOP ON MONTE CARLO TECHNIQUES IN RADIOTHERAPY
   DELIVERY AND VERIFICATION - THIRD MCGILL INTERNATIONAL WORKSHOP},
Series = {Journal of Physics Conference Series},
Year = {2008},
Volume = {102},
Note = {International Workshop on Monte Carlo Techniques in Radiotherapy
   Delivery and Verification, McGill Univ, Montreal, CANADA, MAY 29-JUN 01,
   2007},
Abstract = {Graphics processing units (GPUs) and similar stream processors are
   increasingly used for general-purpose calculations. Their pipelined
   architecture can be exploited to accelerate various algorithms,
   sometimes with spectacular results. Monte Carlo codes, being
   computationally intensive, are likely to benefit from the development of
   stream processing platforms. We explore this potential here with a
   simple subroutine sometimes used in Monte Carlo techniques. More
   specifically, a ray tracing algorithm that computes the exact
   radiological path in a voxel grid was implemented in CPU and GPU
   versions, which then were compared in terms of execution speed. This
   benchmarking experiment was conducted under various conditions, in order
   to assess the memory and bandwidth limitations of each platform. The
   results show that the GPU provides a significant speed improvement
   factor over the CPU. For the specific hardware used in this work, namely
   a nVidia 7600 GS GPU, a speed increase factor up to 6 was achieved over
   an Xeon 2.4 GHz CPU. With the development of faster stream processors,
   this factor is expected to reach levels that can potentially change how
   Monte Carlo techniques are used, for example in radiation therapy
   planning. The ongoing development of simpler language extensions and
   programming interfaces also promises to increase the accessibility of
   these devices. Overall, stream processors are likely to play an
   increasingly larger role in scientific computing, and in particular in
   Monte Carlo techniques.},
DOI = {10.1088/1742-6596/102/1/012007},
Article-Number = {012007},
ISSN = {1742-6588},
EISSN = {1742-6596},
ResearcherID-Numbers = {Després, Philippe/Q-7321-2019},
ORCID-Numbers = {Després, Philippe/0000-0002-4163-7353},
Unique-ID = {WOS:000284328500007},
}

@inproceedings{ WOS:000403774200001,
Author = {Fox, Geoffrey},
Editor = {Shen, H and Sang, Y and Tian, H},
Title = {Big Data on Clouds and HPC},
Booktitle = {2016 17TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED
   COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT)},
Year = {2016},
Pages = {XIX},
Note = {17th International Conference on Parallel and Distributed Computing,
   Applications and Technologies (PDCAT), Guangzhou, PEOPLES R CHINA, DEC
   16-18, 2016},
Organization = {IEEE Comp Soc; Sun Yat Sen Univ; IEEE Comp Soc Tech Comm Parallel Proc},
Abstract = {We review several questions at the intersection of Big Data, Clouds and
   HPC with the large scale simulations usually run on supercomputers and
   the target of the exascale initiative. We base this on an analysis of
   many big data and simulation problems and a set of properties - the Big
   Data Ogres - characterizing them where we distinguish data and model
   properties. We consider broad topics: What are the application and user
   requirements? e.g. is the data streaming, how similar are commercial and
   scientific requirements? What is execution structure of problems? e.g.
   is it dataflow or more like MPI? Should we use threads or processes'? Is
   execution pleasingly parallel? What about the many choices for
   infrastructure and middleware? Should we use classic HPC cluster, Docker
   or OpenStack? Where are Big Data (Apache) approaches superior/inferior
   to those familiar from Grid and HPC work? The choice of language - C++,
   Java, Scala, Python, R highlights perfoimance v. productivity
   trade-offs. What is actual performance of Big Data implementations and
   what are good benchmarks? Is software sustainability important and is
   the Apache model a good approach to this? The difference between
   capability and capacity computing on HPC clusters.},
ISBN = {978-1-5090-5081-9},
Unique-ID = {WOS:000403774200001},
}

@article{ WOS:000414699100007,
Author = {Schaffner, Michael and Scheidegger, Florian and Cavigelli, Lukas and
   Kaeslin, Hubert and Benini, Luca and Smolic, Aljosa},
Title = {Towards Edge-Aware Spatio-Temporal Filtering in Real-Time},
Journal = {IEEE TRANSACTIONS ON IMAGE PROCESSING},
Year = {2018},
Volume = {27},
Number = {1},
Pages = {265-280},
Month = {JAN},
Abstract = {Spatio-temporal edge-aware (STEA) filtering methods have recently
   received increased attention due to their ability to efficiently solve
   or approximate important image-domain problems in a temporally
   consistent manner - which is a crucial property for video-processing
   applications. However, existing STEA methods are currently unsuited for
   real-time, embedded stream-processing settings due to their high
   processing latency, large memory, and bandwidth requirements, and the
   need for accurate optical flow to enable filtering along motion paths.
   To this end, we propose an efficient STEA filtering pipeline based on
   the recently proposed permeability filter (PF), which offers high
   quality and halo reduction capabilities. Using mathematical properties
   of the PF, we reformulate its temporal extension as a causal, non-linear
   infinite impulse response filter, which can be efficiently evaluated due
   to its incremental nature. We bootstrap our own accurate flow using the
   PF and its temporal extension by interpolating a quasi-dense nearest
   neighbour field obtained with an improved PatchMatch algorithm, which
   employs binarized octal orientation maps (BOOM) descriptors to find
   correspondences among subsequent frames. Our method is able to create
   temporally consistent results for a variety of applications such as
   optical flow estimation, sparse data upsampling, visual saliency
   computation and disparity estimation. We benchmark our optical flow
   estimation on the MPI Sintel dataset, where we currently achieve a
   Pareto optimal qualityefficiency tradeoff with an average endpoint error
   of 7.68 at 0.59 s single-core execution time on a recent desktop
   machine.},
DOI = {10.1109/TIP.2017.2757259},
ISSN = {1057-7149},
EISSN = {1941-0042},
ResearcherID-Numbers = {Cavigelli, Lukas/M-1836-2015
   Cavigelli, Lukas/T-6355-2019
   },
ORCID-Numbers = {Cavigelli, Lukas/0000-0003-1767-7715
   Scheidegger, Florian/0000-0003-0430-3634
   BENINI, LUCA/0000-0001-8068-3806},
Unique-ID = {WOS:000414699100007},
}

@article{ WOS:000341498400006,
Author = {Gijsbers, Bert and Grelck, Clemens},
Title = {An Efficient Scalable Runtime System for Macro Data Flow Processing
   Using S-NET},
Journal = {INTERNATIONAL JOURNAL OF PARALLEL PROGRAMMING},
Year = {2014},
Volume = {42},
Number = {6},
Pages = {988-1011},
Month = {DEC},
Abstract = {S-Net is a declarative coordination language and component technology
   aimed at radically facilitating software engineering for modern parallel
   compute systems by near-complete separation of concerns between
   application (component) engineering and concurrency orchestration. S-Net
   builds on the concept of stream processing to structure networks of
   communicating asynchronous components implemented in a conventional
   (sequential) language. In this paper we present the design,
   implementation and evaluation of a new and innovative runtime system for
   S-Net streaming networks. The Front runtime system outperforms the
   existing implementations of S-Net by orders of magnitude for stress-test
   benchmarks, significantly reduces runtimes of fully-fledged parallel
   applications with compute-intensive components and achieves good
   scalability on our 48-core test system.},
DOI = {10.1007/s10766-013-0271-8},
ISSN = {0885-7458},
EISSN = {1573-7640},
ResearcherID-Numbers = {Grelck, Clemens/GYU-8487-2022},
Unique-ID = {WOS:000341498400006},
}

@article{ WOS:000286677100007,
Author = {Wu, Shiow-yang and He, Cheng-en},
Title = {QoS-Aware Dynamic Adaptation for Cooperative Media Streaming in Mobile
   Environments},
Journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
Year = {2011},
Volume = {22},
Number = {3},
Pages = {439-450},
Month = {MAR},
Abstract = {Media streaming is expected to be one of the most promising services in
   mobile environments. Effective data streaming management techniques are,
   therefore, in strong demand. In an earlier paper, the ideas and benefits
   of two-level cooperative media streaming with headlight prefetching and
   dynamic chaining were demonstrated {[}1]. Though complementary to each
   other, they operate in session-wide static and distinctive modes.
   Moreover, users do not have control over the quality and cost levels of
   the streaming services. The performance degradation or cost increment
   can reach an unacceptable level under fast or highly unstable moving
   patterns. In this paper, we propose the QoS-based dynamic adaptation
   techniques for the flexible employment and smooth integration of
   headlight prefetching and dynamic chaining to continuously provide
   quality streaming services to mobile users. The QoS-aware dynamic
   headlight prefetching is for the cooperation between streaming access
   points to dynamically adjust the prefetching scheme in response to the
   fast changing moving patterns. Adaptive P2P media streaming is for the
   cooperation between mobile users such that multiple peers can be used as
   streaming sources to increase the likelihood of successful chaining.
   Furthermore, a QoS-based technique is developed to dynamically trigger
   and proportionally adjust the prefetching degree when the stability and
   quality of P2P streaming service vary. With extensive simulation and
   performance evaluation, we demonstrate that the proposed dynamic
   adaptation techniques significantly improve the service quality and
   streaming performance of cooperative media streaming in mobile
   environments.},
DOI = {10.1109/TPDS.2010.81},
ISSN = {1045-9219},
EISSN = {1558-2183},
Unique-ID = {WOS:000286677100007},
}

@inproceedings{ WOS:000378997100016,
Author = {Kolchin, Maxim and Wetz, Peter and Kiesling, Elmar and Tjoa, A. Min},
Editor = {Bozzon, A and CudreMauroux, P and Pautasso, C},
Title = {YABench: A Comprehensive Framework for RDF Stream Processor Correctness
   and Performance Assessment},
Booktitle = {WEB ENGINEERING (ICWE 2016)},
Series = {Lecture Notes in Computer Science},
Year = {2016},
Volume = {9671},
Pages = {280-298},
Note = {16th International Conference on Web Engineering (ICWE), Lugano,
   SWITZERLAND, JUN 06-09, 2016},
Organization = {Univ Svizzera Italiana, Fac Informat; innoQ; Int Soc Web Engn; Atomikos;
   Nokia; lastminuet com Grp; Google; Springer},
Abstract = {RDF stream processing (RSP) has become a vibrant area of research in the
   semantic web community. Recent advances have resulted in the development
   of several RSP engines that leverage semantics to facilitate reasoning
   over flows of incoming data. These engines vary greatly in terms of
   implemented query syntax, their evaluation and operational semantics,
   and in various performance dimensions. Existing benchmarks tackle
   particular aspects such as functional coverage, result correctness, or
   performance. None of them, however, assess RSP engine behavior
   comprehensively with respect to all these dimensions. In this paper, we
   introduce YABench, a novel benchmarking framework for RSP engines.
   YABench extends the concept of correctness checking and provides a
   flexible and comprehensive tool set to analyze and evaluate RSP engine
   behavior. It is highly configurable and provides quantifiable and
   reproducible results on correctness and performance characteristics. To
   validate our approach, we replicate results of the existing CSRBench
   benchmark with YABench. We then assess two well-established RSP engines,
   CQELS and C-SPARQL, through more comprehensive experiments. In
   particular, we measure precision, recall, performance, and scalability
   characteristics while varying throughput and query complexity. Finally,
   we discuss implications on the development of future stream processing
   engines and benchmarks.},
DOI = {10.1007/978-3-319-38791-8\_16},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-38791-8; 978-3-319-38790-1},
ResearcherID-Numbers = {Tjoa, A Min/AAL-5676-2020
   },
ORCID-Numbers = {Tjoa, A Min/0000-0002-8295-9252
   Kiesling, Elmar/0000-0002-7856-2113},
Unique-ID = {WOS:000378997100016},
}

@inproceedings{ WOS:000364835300005,
Author = {Chen, Qiming and Hsu, Meichun},
Editor = {Hameurlain, A and Kung, J and Wagner, R and Cuzzocrea, A and Dayal, U},
Title = {Cut-and-Rewind: Extending Query Engine for Continuous Stream Analytics},
Booktitle = {TRANSACTIONS ON LARGE-SCALE DATA- AND KNOWLEDGE-CENTERED SYSTEMS XXI},
Series = {Lecture Notes in Computer Science},
Year = {2015},
Volume = {9260},
Pages = {94-114},
Note = {14th International Conference on Data Warehousing and Knowledge
   Discovery (DaWaK), Vienna, AUSTRIA, SEP 03-06, 2012},
Abstract = {Combining data warehousing and stream processing technologies has great
   potential in offering low-latency data-intensive analytics.
   Unfortunately, such convergence has not been properly addressed so far.
   The current generation of stream processing systems is in general built
   separately from the data warehouse and query engine, which can cause
   significant overhead in data access and data movement, and is unable to
   take advantage of the functionalities already offered by the existing
   data warehouse systems.
   In this work we tackle some hard problems in integrating stream
   analytics capability into the existing query engine. We define an
   extended SQL query model that unifies queries over both static relations
   and dynamic streaming data, and develop techniques to extend query
   engines to support the unified model. We propose the cut-and-rewind
   query execution model to allow a query with full SQL expressive power to
   be applied to stream data by converting the latter into a sequence of
   ``chunks{''}, and executing the query over each chunk sequentially, but
   without shutting the query instance down between chunks for continuously
   maintaining the application context across the execution cycles as
   required by sliding-window operators. We also propose the cycle-based
   transaction model to support Continuous Querying with Continuous
   Persisting (CQCP) with cycle-based isolation and visibility.
   We have prototyped our approach by extending the PostgreSQL. This work
   has resulted in a new kind of tightly integrated, highly efficient
   system with the advanced stream processing capability as well as the
   full DBMS functionality. We demonstrate the system with the popular
   Linear Road benchmark, and report the performance. By leveraging the
   matured code base of a query engine to the maximal extent, we can
   significantly reduce the engineering investment needed for developing
   the streaming technology. Providing this capability on proprietary
   parallel analytics engine is work in progress.},
DOI = {10.1007/978-3-662-47804-2\_5},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-662-47804-2; 978-3-662-47803-5},
Unique-ID = {WOS:000364835300005},
}

@article{ WOS:000396364000013,
Author = {Khoshkbarforoushha, Alireza and Ranjan, Rajiv and Gaire, Raj and
   Abbasnejad, Ehsan and Wang, Lizhe and Zomaya, Albert Y.},
Title = {Distribution Based Workload Modelling of Continuous Queries in Clouds},
Journal = {IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING},
Year = {2017},
Volume = {5},
Number = {1},
Pages = {120-133},
Month = {JAN-MAR},
Abstract = {Resource usage estimation for managing streaming workload in emerging
   applications domains such as enterprise computing, smart cities, remote
   healthcare, and astronomy, has emerged as a challenging research
   problem. Such resource estimation for processing continuous queries over
   streaming data is challenging due to: (i) uncertain stream arrival
   patterns, (ii) need to process different mixes of queries, and (iii)
   varying resource consumption. Existing techniques approximate resource
   usage for a query as a single point value which may not be sufficient
   because it is neither expressive enough nor does it capture the
   aforementioned nature of streaming workload. In this paper, we present a
   novel approach of using mixture density networks to estimate the whole
   spectrum of resource usage as probability density functions. We have
   evaluated our technique using the linear road benchmark and TPC-H in
   both private and public clouds. The efficiency and applicability of the
   proposed approach is demonstrated via two novel applications: i)
   predictable auto-scaling policy setting which highlights the potential
   of distribution prediction in consistent definition of cloud elasticity
   rules; and ii) a distribution based admission controller which is able
   to efficiently admit or reject incoming queries based on probabilistic
   service level agreements compliance goals.},
DOI = {10.1109/TETC.2016.2597546},
ISSN = {2168-6750},
ResearcherID-Numbers = {Zomaya, Albert Y./G-9697-2017
   Ranjan, Rajiv/F-4700-2011
   Gaire, Raj/S-6923-2019
   Wang, Lizhe/L-7453-2014},
ORCID-Numbers = {Zomaya, Albert Y./0000-0002-3090-1059
   Ranjan, Rajiv/0000-0002-6610-1328
   Gaire, Raj/0000-0003-2499-2553
   Wang, Lizhe/0000-0003-2766-0845},
Unique-ID = {WOS:000396364000013},
}

@article{ WOS:000371932100001,
Author = {Vaidya, Pranav S. and Lee, John Jaehwan and Pai, Vijay S. and Lee,
   Miyoung and Hur, Sungjin},
Title = {Symbiote Coprocessor Unit-A Streaming Coprocessor for Data Stream
   Acceleration},
Journal = {IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS},
Year = {2016},
Volume = {24},
Number = {3},
Pages = {813-826},
Month = {MAR},
Abstract = {This paper describes the design and the architecture of symbiote
   coprocessor unit (SCU)-a programmable streaming coprocessor for a
   heterogeneous reconfigurable logic-assisted data stream management
   systems (DSMSs) such as symbiote. The SCU is intended for streaming
   applications with real-time event and data processing that have stricter
   deadlines, high-bandwidth, and high-accuracy requirements. To meet these
   requirements, the SCU exploits unique characteristics of DSMSs, such as
   single-pass tuple processing, windowed operators, and inherent data
   level parallelism, using a single-instruction multiple-data very large
   instruction word (SIMD-VLIW) microarchitecture and a novel inverted
   distributed register file. In order to better explain the instruction
   set, design, and functionality of the various units in the SCU, this
   paper also provides a brief overview of SymQL-a procedural query
   language that we developed to describe the queries that can be executed
   on the SCU. Finally, this paper presents the performance of SCU using
   four queries that represent common data stream processing use-cases, one
   of them being similar to a query found in the Linear Road Benchmark.
   Using these queries on SCU simulation, we show that the SCU outperforms
   a software-only DSMS running on an AMD Opteron 2350 quad-core processor
   by 1.5-42 times.},
DOI = {10.1109/TVLSI.2015.2432063},
ISSN = {1063-8210},
EISSN = {1557-9999},
ORCID-Numbers = {Lee, John/0000-0002-5335-9071},
Unique-ID = {WOS:000371932100001},
}

@article{ WOS:000407407800006,
Author = {Suarez-Cetrulo, Andres L. and Cervantes, Alejandro},
Title = {An online classification algorithm for large scale data streams: iGNGSVM},
Journal = {NEUROCOMPUTING},
Year = {2017},
Volume = {262},
Number = {SI},
Pages = {67-76},
Month = {NOV 1},
Abstract = {Stream Processing has recently become one of the current commercial
   trends to face huge amounts of data. However, normally these techniques
   need specific infrastructures and high resources in terms of memory and
   computing nodes. This paper shows how mini-batch techniques and topology
   extraction methods can help making gigabytes of data to be manageable
   for just one server using computationally costly Machine Learning
   techniques as Support Vector Machines. The algorithm iGNGSVM is proposed
   to improve the performance of Support Vector Machines in datasets where
   the data is continuously arriving. It is benchmarked against a
   mini-batch version of LibSVM, achieving good accuracy rates and
   performing faster than this. (C) 2017 Elsevier B.V. All rights reserved.},
DOI = {10.1016/j.neucom.2016.12.093},
ISSN = {0925-2312},
EISSN = {1872-8286},
ResearcherID-Numbers = {Suárez-Cetrulo, Andrés L/O-8756-2019
   Cervantes, Alejandro/AIA-5653-2022},
ORCID-Numbers = {Suárez-Cetrulo, Andrés L/0000-0001-5266-5053
   Cervantes, Alejandro/0000-0001-5442-953X},
Unique-ID = {WOS:000407407800006},
}

@article{ WOS:000364238100002,
Author = {Mullen, Tim R. and Kothe, Christian A. E. and Chi, Yu Mike and Ojeda,
   Alejandro and Kerth, Trevor and Makeig, Scott and Jung, Tzyy-Ping and
   Cauwenberghs, Gert},
Title = {Real-Time Neuroimaging and Cognitive Monitoring Using Wearable Dry EEG},
Journal = {IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING},
Year = {2015},
Volume = {62},
Number = {11},
Pages = {2553-2567},
Month = {NOV},
Abstract = {Goal: We present and evaluate a wearable high-density dry-electrode EEG
   system and an open-source software framework for online neuroimaging and
   state classification. Methods: The system integrates a 64-channel dry
   EEG form factor with wireless data streaming for online analysis. A
   real-time software framework is applied, including adaptive artifact
   rejection, cortical source localization, multivariate effective
   connectivity inference, data visualization, and cognitive state
   classification from connectivity features using a constrained logistic
   regression approach (ProxConn). We evaluate the system identification
   methods on simulated 64-channel EEG data. Then, we evaluate system
   performance, using ProxConn and a benchmark ERP method, in classifying
   response errors in nine subjects using the dry EEG system. Results:
   Simulations yielded high accuracy (AUC = 0.97 +/- 0.021) for real-time
   cortical connectivity estimation. Response error classification using
   cortical effective connectivity {[}short-time direct-directed transfer
   function (sdDTF)] was significantly above chance with similar
   performance (AUC) for cLORETA (0.74 +/- 0.09) and LCMV (0.72 +/- 0.08)
   source localization. Cortical ERP-based classification was equivalent to
   ProxConn for cLORETA (0.74 +/- 0.16) but significantly better for LCMV
   (0.82 +/- 0.12). Conclusion: We demonstrated the feasibility for
   real-time cortical connectivity analysis and cognitive state
   classification from high-density wearable dry EEG. Significance: This
   paper is the first validated application of these methods to 64-channel
   dry EEG. This study addresses a need for robust real-time measurement
   and interpretation of complex brain activity in the dynamic environment
   of the wearable setting. Such advances can have broad impact in
   research, medicine, and brain-computer interfaces. The pipelines are
   made freely available in the open-source SIFT and BCILAB toolboxes.},
DOI = {10.1109/TBME.2015.2481482},
ISSN = {0018-9294},
EISSN = {1558-2531},
ORCID-Numbers = {Ojeda, Alejandro/0000-0002-7878-0129
   Jung, Tzyy-Ping/0000-0002-8377-2166},
Unique-ID = {WOS:000364238100002},
}

@article{ WOS:000356756200002,
Author = {Rooholamin, Seyed A. and Ziavras, Sotirios G.},
Title = {Modular vector processor architecture targeting at data-level
   parallelism},
Journal = {MICROPROCESSORS AND MICROSYSTEMS},
Year = {2015},
Volume = {39},
Number = {4-5},
Pages = {237-249},
Month = {JUN-JUL},
Abstract = {Taking advantage of DLP (Data-Level Parallelism) is indispensable in
   most data streaming and multimedia applications. Several architectures
   have been proposed to improve both the performance and energy
   consumption for such applications. Superscalar and VLIW (Very Long
   Instruction Word) processors along with SIMD (Single-Instruction
   Multiple-Data) and vector processor (VP) accelerators, are among the
   available options for designers to accomplish their desired
   requirements. We present an innovative architecture for a VP which
   separates the path for performing data shuffle and memory-indexed
   accesses from the data path for executing other vector instructions that
   access the memory. This separation speeds up the most common memory
   access operations by avoiding extra delays and unnecessary stalls. In
   our lane-based VP design, each vector lane uses its own private memory
   to avoid any stalls during memory access instructions. The proposed VP,
   which is developed in VHDL and prototyped on an FPGA, serves as a
   coprocessor for one or more scalar cores. Benchmarking shows that our VP
   can achieve very high performance. For example, it achieves a larger
   than 1500-fold speedup in the color space converting benchmark compared
   to running the code on a scalar core. The inclusion of distributed data
   shuffle engines across vector lanes has a spectacular impact on the
   execution time, primarily for applications like FFT (Fast-Fourier
   Transform) that require large amounts of data shuffling. Compared to
   running the benchmark on a VP without the shuffle engines, the speedup
   is 5.92 and 7.33 for the 64-point FFT without and with compiler
   optimization, respectively. Compared to runs on the scalar core, the
   achieved speed-ups for this benchmark are 52.07 and 110.45 without and
   with compiler optimization, respectively. (C) 2015 Elsevier B.V. All
   rights reserved.},
DOI = {10.1016/j.micpro.2015.04.007},
ISSN = {0141-9331},
EISSN = {1872-9436},
ResearcherID-Numbers = {Ziavras, Sotirios/T-2179-2019
   },
ORCID-Numbers = {Ziavras, Sotirios/0000-0002-3764-1528},
Unique-ID = {WOS:000356756200002},
}

@inproceedings{ WOS:000606970300036,
Author = {Carpio, Francisco and Delgado, Marta and Jukan, Admela},
Book-Group-Author = {IEEE},
Title = {Engineering and Experimentally Benchmarking a Container-based Edge
   Computing System},
Booktitle = {ICC 2020 - 2020 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS (ICC)},
Series = {IEEE International Conference on Communications},
Year = {2020},
Note = {IEEE International Conference on Communications (IEEE ICC) / Workshop on
   NOMA for 5G and Beyond, ELECTR NETWORK, JUN 07-11, 2020},
Organization = {IEEE; Huawei; ZTE; Qualcomm},
Abstract = {While edge computing is envisioned to superbly serve latency sensitive
   applications, the implementation-based studies benchmarking its
   performance are few and far between. To address this gap, we engineer a
   modular edge cloud computing system architecture that is built on latest
   advances in containerization techniques, including Kafka, for data
   streaming, Docker, as application platform, and Firebase Cloud, as
   realtime database system. We benchmark the performance of the system in
   terms of scalability, resource utilization and latency by comparing
   three scenarios: cloud-only, edge-only and combined edge-cloud. The
   measurements show that edge-only solution outperforms other scenarios
   only when deployed with data located at one edge only, i.e., without
   edge computing wide data synchronization. In case of applications
   requiring data synchronization through the cloud, edge-cloud scales
   around a factor 10 times better than cloudonly, until certain number of
   concurrent users in the system, and above this point, cloud-only scales
   better. In terms of resource utilization, we observe that whereas the
   mean utilization increases linearly with the number of user requests,
   the maximum values for the memory and the network I/O heavily increase
   when with an increasing amount of data.},
ISSN = {1550-3607},
ISBN = {978-1-7281-5089-5},
ORCID-Numbers = {Carpio, Francisco/0000-0002-6217-4052},
Unique-ID = {WOS:000606970300036},
}

@inproceedings{ WOS:000345643500036,
Author = {Arias Fisteus, Jesus and Fernandez Garcia, Norberto and Sanchez
   Fernandez, Luis and Fuentes-Lorenzo, Damaris},
Editor = {Presutti, V and Blomqvist, E and Troncy, R and Sack, H and Papadakis, I and Tordai, A},
Title = {Publication of RDF Streams with Ztreamy},
Booktitle = {SEMANTIC WEB: ESWC 2014 SATELLITE EVENTS},
Series = {Lecture Notes in Computer Science},
Year = {2014},
Volume = {8798},
Pages = {286-291},
Note = {11th ESWC Conference, Anissaras, GREECE, MAY 25-29, 2014},
Organization = {Planet Data; FIRE, Forging Online Educ; Annomarket; LinkedUp; Linked
   Data Benchmark Council; LinkedTV; Preserving Linked Data; MediaMixer;
   Fluid Operat; VideoLectures NET; Yahoo Labs; XLike; xLiMe},
Abstract = {There is currently an interest in the Semantic Web community for the
   development of tools and techniques to process RDF streams. Implementing
   an effective RDF stream processing system requires to address several
   aspects including stream generation, querying, reasoning, etc. In this
   work we focus on one of them: the distribution of RDF streams through
   the Web. In order to address this issue, we have developed Ztreamy, a
   scalable middleware which allows to publish and consume RDF streams
   through HTTP. The goal of this demo is to show the functionality of
   Ztreamy in two different scenarios with actual, heterogeneous streaming
   data.},
DOI = {10.1007/978-3-319-11955-7\_36},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-11955-7; 978-3-319-11954-0},
ResearcherID-Numbers = {Sanchez-Fernandez, Luis/I-3867-2015
   Fisteus, Jesus Arias/H-6230-2012},
ORCID-Numbers = {Sanchez-Fernandez, Luis/0000-0002-9801-4747
   Fisteus, Jesus Arias/0000-0002-4381-2071},
Unique-ID = {WOS:000345643500036},
}

@article{ WOS:000300454200013,
Author = {Bourennane, S. and Fossati, C.},
Title = {Comparison of shape descriptors for hand posture recognition in video},
Journal = {SIGNAL IMAGE AND VIDEO PROCESSING},
Year = {2012},
Volume = {6},
Number = {1},
Pages = {147-157},
Month = {MAR},
Abstract = {Hand posture recognition remains a challenging task for in-line systems
   working directly in the video stream. In this work, we compare several
   shape descriptors, with the objective of finding a good compromise
   between accuracy of recognition and computation load for a real-time
   application. Experiments are run on two families of contour-based
   Fourier descriptors and two sets of region-based moments, all of them
   are invariant to translation, rotation and scale changes of hands. These
   methods are independent of the camera view point. Systematic tests are
   performed on the Triesch benchmark database and on our own large
   database, which includes more realistic conditions. Temporal filtering
   and a method for unknown posture detection are considered to improve
   posture recognition results in case of video stream processing.},
DOI = {10.1007/s11760-010-0176-6},
ISSN = {1863-1703},
EISSN = {1863-1711},
ResearcherID-Numbers = {FOSSATI, Caroline/G-7315-2015},
Unique-ID = {WOS:000300454200013},
}

@inproceedings{ WOS:000389255100172,
Author = {Ploennigs, Joern and Chen, Bei and Palmes, Paulito and Lloyd, Raymond},
Editor = {Zhou, ZH and Wang, W and Kumar, R and Toivonen, H and Pei, J and Huang, JZ and Wu, X},
Title = {e(2)-Diagnoser: A system for monitoring, forecasting and diagnosing
   energy usage},
Booktitle = {2014 IEEE International Conference on Data Mining Workshop (ICDMW)},
Year = {2014},
Pages = {1231-1234},
Note = {14th IEEE International Conference on Data Mining (IEEE ICDM), Shenzhen,
   PEOPLES R CHINA, DEC 14-17, 2014},
Organization = {Baidu; HUAWEI; PINGAN; IBM Res; KNIME; Alberta Innovates Ctr Machine
   Learning; IEEE; IEEE Comp Soc},
Abstract = {We propose e(2)-Diagnoser, a real-time data mining system for the energy
   management of smart, sensor-equipped buildings. The main features of
   e(2)-Diagnoser are: (i) fast extraction of a large portfolio of
   buildings' benchmarks at multiple places; and (ii) accurate prediction
   of buildings' energy usage down to submeter level to detect and diagnose
   abnormal energy consumptions. Fundamentally, the e(2)-Diagnoser system
   is built on a novel statistical learning algorithm using the Generalized
   Additive Model (GAM) to simultaneously monitor the mean and variation of
   the energy usage as well as identify the influencing factors such as
   weather conditions. Its implementation is based on stream processing
   platform that integrates data from various sources using semantic web
   technologies and provides an interactive user interface to visualize
   results. The platform is scalable and can be easily adapted to other
   applications such as smartgrid networks. Here we describe the
   architecture, methodology, and show the web-interface to demonstrate the
   main functions in the e(2)-Diagnoser.},
DOI = {10.1109/ICDMW.2014.56},
ISBN = {978-1-4799-4274-9},
ORCID-Numbers = {Ploennigs, Joern/0000-0002-6320-8891},
Unique-ID = {WOS:000389255100172},
}

@article{ WOS:000261953900003,
Author = {Chakraborty, Samarjit and Mitra, Tulika and Roychoudhury, Abhik and
   Thiele, Lothar},
Title = {Cache-aware timing analysis of streaming applications},
Journal = {REAL-TIME SYSTEMS},
Year = {2009},
Volume = {41},
Number = {1},
Pages = {52-85},
Month = {JAN},
Abstract = {Of late, there has been a considerable interest in models, algorithms
   and methodologies specifically targeted towards designing hardware and
   software for streaming applications. Such applications process
   potentially infinite streams of audio/video data or network packets and
   are found in a wide range of devices, starting from mobile phones to
   set-top boxes. Given a streaming application and an architecture, the
   timing analysis problem is to determine the timing properties of the
   processed data stream, given the timing properties of the input stream.
   This problem arises while determining many common performance metrics
   related to streaming applications and the mapping of such applications
   onto hardware architectures. Such metrics include the maximum delay
   experienced by any data item of the stream and the maximum backlog or
   the buffer requirement to store the incoming stream. Most of the
   previous work related to estimating or optimizing these metrics take a
   high-level view of the architecture and neglect micro-architectural
   features such as caches. In this paper, we show that an accurate
   estimation of these metrics, however, heavily relies on an appropriate
   modeling of the processor micro-architecture. Towards this, we present a
   novel framework for cache-aware timing analysis of stream processing
   applications. Our framework accurately models the evolution of the
   instruction cache of the underlying processor as a stream is processed,
   and the fact that the execution time involved in processing any data
   item depends on all the previous data items occurring in the stream. The
   main contribution of our method lies in its ability to seamlessly
   integrate program analysis techniques for micro-architectural modeling
   with known analytical methods for analyzing streaming applications,
   which treat the arrival/service of event streams as mathematical
   functions. This combination is powerful as it allows to model the
   code/cache-behavior of the streaming application, as well as the manner
   in which it is triggered by event arrivals. We employ our analysis
   method to an MPEG-2 encoder application and our experiments indicate
   that detailed modeling of the cache behavior is efficient, scalable and
   leads to more accurate timing/buffer size estimates.},
DOI = {10.1007/s11241-008-9062-5},
ISSN = {0922-6443},
EISSN = {1573-1383},
ResearcherID-Numbers = {Chakraborty, Samarjit/AAU-9569-2020
   Mitra, Tulika/J-4464-2017},
ORCID-Numbers = {Chakraborty, Samarjit/0000-0002-0503-6235
   ROYCHOUDHURY, Abhik/0000-0002-7127-1137
   Mitra, Tulika/0000-0003-4136-4188},
Unique-ID = {WOS:000261953900003},
}

@inproceedings{ WOS:000493300600001,
Author = {Turrisi da Costa, Victor G. and Santana, Everton Jose and Lopes, Jessica
   F. and Barbon, Jr., Sylvio},
Editor = {Miani, R and Camargos, L and Zarpelao, B and Rosas, E and Pasquini, R},
Title = {Evaluating the Four-Way Performance Trade-Off for Stream Classification},
Booktitle = {GREEN, PERVASIVE, AND CLOUD COMPUTING, GPC 2019},
Series = {Lecture Notes in Computer Science},
Year = {2019},
Volume = {11484},
Pages = {3-17},
Note = {14th International Conference on Green, Pervasive and Cloud Computing
   (GPC), Uberlandia, BRAZIL, MAY 26-28, 2019},
Abstract = {Machine Learning (ML) solutions need to deal efficiently with a huge
   amount of data available, addressing scalability concerns without
   sacrificing predictive performance. Moreover, this data comes in the
   form of a continuous and evolving stream imposing new constraints, e.g.,
   limited memory and energy resources. In the same way, energy-aware ML
   algorithms are gaining relevance due to the power constraints of
   hardware platforms in several real-life applications, as the Internet of
   Things (IoT). Many algorithms have been proposed to cope with the
   mutable nature of data streams, with the Very Fast Decision Tree (VFDT)
   being one of the most widely used. An adaptation of the VFDT, called
   Strict VFDT (SVFDT), can significantly reduce memory usage without
   putting aside the predictive performance and time efficiency. However,
   the analysis of energy consumption regarding data stream processing of
   the VFDT and SVFDT is overlooked. In this work, we compare the four-way
   relationship between predictive performance, memory costs, time
   efficiency and energy consumption, tuning the hyperparameters of the
   algorithms to optimise the resources devoted to it. Experiments over 23
   benchmark datasets revealed that the SVFDT-I is the most energy-friendly
   algorithm and greatly reduced memory consumption, being statistically
   superior to the VFDT.},
DOI = {10.1007/978-3-030-19223-5\_1},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-030-19223-5; 978-3-030-19222-8},
ResearcherID-Numbers = {Barbon Junior, Sylvio/L-6137-2013
   },
ORCID-Numbers = {Barbon Junior, Sylvio/0000-0002-4988-0702
   Fernandes Lopes, Jessica/0000-0002-2871-7252
   Santana, Everton/0000-0002-6014-9857},
Unique-ID = {WOS:000493300600001},
}

@inproceedings{ WOS:000309266000090,
Author = {Ravishankar, Chirag and Ananthanarayanan, Sundaram and Garg, Siddharth
   and Kennings, Andrew},
Book-Group-Author = {IEEE},
Title = {Analysis and Evaluation of Greedy Thread Swapping Based Dynamic Power
   Management for MPSoC Platforms},
Booktitle = {2012 13TH INTERNATIONAL SYMPOSIUM ON QUALITY ELECTRONIC DESIGN (ISQED)},
Series = {International Symposium on Quality Electronic Design},
Year = {2012},
Pages = {617-624},
Note = {13th International Symposium on Quality Electronic Design (ISQED), Santa
   Clara, CA, MAR 19-21, 2012},
Organization = {IEEE; IEEE Elect Devices Soc; IEEE Reliabil Soc; IEEE Circuits \& Syst
   Soc; ACM Special Interest Grp Design Automat (ACM/sigDA); Cadence Design
   Syst; Global Foundries; IBM; Intel; Mentor Graph; Synopsys; Chip Design
   Magazine; EDACafe; Low-Power Design; M \& E Tech; Newtechpress; Int Soc
   Qual Elect Design; IEEE Components, Packaging \& Mfg Technol Soc (CPMT)},
Abstract = {Thread migration (TM) is a recently proposed dynamic power management
   technique for heterogeneous multi-processor system-on-chip (MPSoC)
   platforms that eliminates the area and power overheads incurred by
   fine-grained dynamic voltage and frequency scaling (DVFS) based power
   management. In this paper, we take the first step towards formally
   analyzing and experimentally evaluating the use of power-aware TM for
   parallel data streaming applications on MPSoC platforms. From an
   analysis perspective, we characterize the optimal mapping of threads to
   cores and prove the convergence properties of a complexity effective
   greedy thread swapping based TM algorithm to the globally optimal
   solution. The proposed techniques are evaluated on a 9-core FPGA based
   MPSoC prototype equipped with fully-functional TM and DVFS support, and
   running a parallelized video encoding benchmark based on the Motion
   Picture Experts Group (MPEG-2) standard. Our experimental results
   validate the proposed theoretical analysis, and show that the proposed
   TM algorithm provides within 8\% of the DVFS performance under the same
   power budget, and assuming no overheads for DVFS. Assuming voltage
   regulator inefficiency of 80\%, the proposed TM algorithm has 9\% higher
   performance than DVFS, again under the same total power budget.},
ISSN = {1948-3287},
ISBN = {978-1-4673-1036-9; 978-1-4673-1035-2},
Unique-ID = {WOS:000309266000090},
}

@article{ WOS:000386244000005,
Author = {Zhang, Yunquan and Cao, Ting and Li, Shigang and Tian, Xinhui and Yuan,
   Liang and Jia, Haipeng and Vasilakos, Athanasios V.},
Title = {Parallel Processing Systems for Big Data: A Survey},
Journal = {PROCEEDINGS OF THE IEEE},
Year = {2016},
Volume = {104},
Number = {11, SI},
Pages = {2114-2136},
Month = {NOV},
Abstract = {The volume, variety, and velocity properties of big data and the
   valuable information it contains have motivated the investigation of
   many new parallel data processing systems in addition to the approaches
   using traditional database management systems (DBMSs). MapReduce
   pioneered this paradigm change and rapidly became the primary big data
   processing system for its simplicity, scalability, and fine-grain fault
   tolerance. However, compared with DBMSs, MapReduce also arouses
   controversy in processing efficiency, low-level abstraction, and rigid
   dataflow. Inspired by MapReduce, nowadays the big data systems are
   blooming. Some of them follow MapReduce's idea, but with more flexible
   models for general-purpose usage. Some absorb the advantages of DBMSs
   with higher abstraction. There are also specific systems for certain
   applications, such as machine learning and stream data processing. To
   explore new research opportunities and assist users in selecting
   suitable processing systems for specific applications, this survey paper
   will give a high-level overview of the existing parallel data processing
   systems categorized by the data input as batch processing, stream
   processing, graph processing, and machine learning processing and
   introduce representative projects in each category. As the pioneer, the
   original MapReduce system, as well as its active variants and extensions
   on dataflow, data access, parameter tuning, communication, and energy
   optimizations will be discussed at first. System benchmarks and open
   issues for big data processing will also be studied in this survey.},
DOI = {10.1109/JPROC.2016.2591592},
ISSN = {0018-9219},
EISSN = {1558-2256},
ResearcherID-Numbers = {Vasilakos, Athanasios/J-2824-2017
   },
ORCID-Numbers = {Vasilakos, Athanasios/0000-0003-1902-9877},
Unique-ID = {WOS:000386244000005},
}

@inproceedings{ WOS:000424789300020,
Author = {Steffl, Samuel and Reda, Sherief},
Book-Group-Author = {IEEE},
Title = {LACore: A Supercomputing-Like Linear Algebra Accelerator for SoC-Based
   Designs},
Booktitle = {2017 IEEE 35TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD)},
Series = {Proceedings IEEE International Conference on Computer Design},
Year = {2017},
Pages = {137-144},
Note = {35th IEEE International Conference on Computer Design (ICCD), Boston,
   MA, NOV 05-08, 2017},
Organization = {NSF; IEEE; IEEE Circuits \& Syst Soc; IEEE Comp Soc},
Abstract = {Linear algebra operations are at the heart of scientific computing
   solvers, machine learning and artificial intelligence. In this paper,
   LACore, a novel, programmable accelerator architecture for
   general-purpose linear algebra applications, is presented. LACore
   enables many of the architectural features typically available in custom
   supercomputing machines in an accelerator form factor that can be
   deployed in System-On-a-Chip (SoC) based designs. LACore has several
   architectural features including heterogeneous data-streaming
   LAMemUnits, a configurable systolic datapath that supports scalar,
   vector and multi-stream output modes, and a decoupled architecture that
   overlap memory transfer and execution. To evaluate LACore, we
   implemented its architecture as an extension to the RISC-V ISA in the
   gem5 cycle-accurate simulator. The LACore ISA was implemented in gcc,
   and a C-programming software framework, the LACoreAPI, has been
   developed for high-level programming of the LACore. Using the HPCC
   benchmark suite, we compare our LACore architecture against three other
   platforms: an in-order RISC-V CPU, a superscalar x86 CPU with SSE2, and
   a scaled NVIDIA Fermi GPU. The LACore outperforms the superscalar x86
   processor in the benchmark suite by an average of 3.43x, and outperforms
   the scaled Fermi GPU by an average of 12.04x, within the same or less
   design area.},
DOI = {10.1109/ICCD.2017.29},
ISSN = {1063-6404},
ISBN = {978-1-5386-2254-4},
Unique-ID = {WOS:000424789300020},
}

@inproceedings{ WOS:000589508500015,
Author = {Trotter, Michael and Wood, Timothy and Hwang, Jinho},
Book-Group-Author = {IEEE},
Title = {Forecasting a Storm: Divining Optimal Configurations using Genetic
   Algorithms and Supervised Learning},
Booktitle = {2019 IEEE INTERNATIONAL CONFERENCE ON AUTONOMIC COMPUTING (ICAC 2019)},
Year = {2019},
Pages = {136-146},
Note = {16th IEEE International Conference on Autonomic Computing (ICAC), Umea,
   SWEDEN, JUN 16-20, 2019},
Organization = {IEEE; IEEE Comp Soc; Ericsson Res; Huawei; Tieto; Google; Raytheon;
   CodeMill},
Abstract = {With the advent of Big Data platforms like Apache Storm, computations
   once deemed infeasible locally become possible at scale. However, doing
   so entails orchestrating powerful yet expensive clusters. With its focus
   on stream processing, Storm optimizes for low-latency and high
   throughput. However, to realize this goal and thereby maximize the
   utility of these clusters' resources, operators must execute these tasks
   under their optimal configurations. Yet, the search space for finding
   such configurations is so vast and time-consuming to explore so as to be
   effectively intractable due to issues like the temporal overhead of
   testing new candidate configurations, the sheer number of permutations
   of parameters within each configuration and their interdependence among
   each other.
   In order to efficiently cover the search space, we automate the process
   with genetic algorithms. Moreover, we fuse this technique not only with
   additional cluster information gleaned from JMX profiling and Storm
   performance data but also with classifiers constructed from training
   data from past executions of a plethora of Storm topologies. Utilizing a
   diverse set of Storm benchmark topologies as evaluation data, we show
   that the fully enhanced genetic algorithms can efficiently find
   configurations that perform on average 4.67x better than ``rules of
   thumb{''}-derived manual baselines. Moreover, we demonstrate that our
   fully refined classifiers enhance the GA throughput on average across
   the topologies by 22\% while reducing search time by a factor of 6.47x.},
DOI = {10.1109/ICAC.2019.00026},
ISBN = {978-1-7281-2411-7},
ResearcherID-Numbers = {Horn, Geir/AAV-6432-2020
   },
ORCID-Numbers = {Horn, Geir/0000-0002-8028-4247
   Wood, Timothy/0000-0002-6728-4197},
Unique-ID = {WOS:000589508500015},
}

@article{ WOS:000597159800003,
Author = {Fu, Zhongming and Tang, Zhuo and Yang, Li and Li, Kenli and Li, Keqin},
Title = {ImRP: A Predictive Partition Method for Data Skew Alleviation in Spark
   Streaming Environment},
Journal = {PARALLEL COMPUTING},
Year = {2020},
Volume = {100},
Month = {DEC},
Abstract = {Spark Streaming is an extension of the core Spark engine that enables
   scalable, high-throughput, fault-tolerant stream processing of live data
   streams. It treats stream as a series of deterministic batches and
   handles them as regular jobs. However, for a stream job responsible for
   a batch, data skew (i.e., the imbalance in the amount of data allocated
   to each reduce task), can degrade the job performance significantly
   because of load imbalance. In this paper, we propose an improved range
   partitioner (ImRP) to alleviate the reduce skew for stream jobs in Spark
   Streaming. Unlike previous work, ImRP does not require any pre-run
   sampling of input data and generates the data partition scheme based on
   the intermediate data distribution estimated by the previous batch
   processing, in which a prediction model EWMA (Exponentially Weighted
   Moving Average) is adopted. To lighten the data skew, ImRP presents a
   novel method of calculating the partition borders optimally, and a
   mechanism of splitting the border key clusters when the semantics of
   shuffle operators permit. Besides, ImRP considers the integrated
   partition size and heterogeneity of computing environments when
   balancing the load among reduce tasks appropriately. We implement ImRP
   in Spark-3.0 and evaluate its performance on four representative
   benchmarks: wordCount, sort, pageRank, and LDA. The results show that by
   mitigating the data skew, ImRP can decrease the execution time of stream
   jobs substantially compared with some other partition strategies,
   especially when the skew degree of input batch is serious.},
DOI = {10.1016/j.parco.2020.102699},
Article-Number = {102699},
ISSN = {0167-8191},
EISSN = {1872-7336},
ORCID-Numbers = {Xiao, Guoqing/0000-0001-5008-4829},
Unique-ID = {WOS:000597159800003},
}

@article{ WOS:000732312200001,
Author = {Jin, Leilei and Fu, Wenjie and Ling, Ming and Shi, Longxing},
Title = {A Fast Cross-Layer Dynamic Power Estimation Method by Tracking
   Cycle-Accurate Activity Factors With Spark Streaming},
Journal = {IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS},
Year = {2022},
Volume = {30},
Number = {4},
Pages = {353-364},
Month = {APR},
Abstract = {The advent of autonomous power-limited systems poses a new challenge for
   early design space exploration. The existing architecture-level power
   evaluation tools lose accuracy due to ignoring features of circuit-level
   behaviors and influences of process, voltage, and temperature
   variations. Although power estimations based on SPICE or PrimeTime PX
   (PTPX) are accurate enough, they come at the cost of long simulation
   time and are available only in very late phases of design flow. In this
   article, a fast and accurate dynamic power evaluation method is
   proposed, which estimates activity factors at the circuit level. The
   impact of process variation at the gate level is considered through the
   proposed effective capacitance model. Activity factors are then
   estimated by the model and input vectors of the circuit. Input vectors
   are generated by architecture-level simulations in the form of
   streaming. For real-time and high-speed power evaluation, a data
   streaming framework is proposed for massive parallelism. The cross-layer
   estimation is verified based on the functional units of PULPino
   processor running SPEC CPU2006 benchmarks. Compared with the SPICE
   results using SMIC 28-nm PDK, our cycle-by-cycle dynamic power analysis
   shows an average error of 5.4\%. Meanwhile, our approach realizes 65.2\%
   faster than the traditional PTPX simulation and 48.8\% faster compared
   with the state-of-art cross-level evaluation method.},
DOI = {10.1109/TVLSI.2021.3111000},
EarlyAccessDate = {SEP 2021},
ISSN = {1063-8210},
EISSN = {1557-9999},
ORCID-Numbers = {Ling, Ming/0000-0002-8866-7189
   Jin, Leilei/0000-0002-0534-3593},
Unique-ID = {WOS:000732312200001},
}

@inproceedings{ WOS:000703983200018,
Author = {Zhu, Jianyong and Yang, Renyu and Hu, Chunming and Wo, Tianyu and Xue,
   Shiqing and Ouyang, Jin and Xu, Jie},
Editor = {Lefevre, L and Patterson, S and Lee, YC and Shen, H and Ilager, S and Goudarzi, M and Toosi, AN and Buyya, R},
Title = {Perph: A Workload Co-location Agent with Online Performance Prediction
   and Resource Inference},
Booktitle = {21ST IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET
   COMPUTING (CCGRID 2021)},
Year = {2021},
Pages = {176-185},
Note = {21st IEEE/ACM International Symposium on Cluster, Cloud and Internet
   Computing (CCGrid), ELECTR NETWORK, MAY 10-13, 2021},
Organization = {IEEE; Assoc Comp Machinery; IEEE Comp Soc; IEEE Tech Comm Scalable Comp},
Abstract = {Striking a balance between improved cluster utilization and guaranteed
   application QoS is a long-standing research problem in cluster resource
   management. The majority of current solutions require a large number of
   sandboxed experimentation for different workload combinations and
   leverage them to predict possible interference for incoming workloads.
   This results in non-negligible time complexity that severely restricts
   its applicability to complex workload co-locations. The nature of pure
   offline profiling may also lead to model aging problem that drastically
   degrades the model precision. In this paper, we present Perph, a runtime
   agent on a per node basis, which decouples ML-based performance
   prediction and resource inference from centralized scheduler. We exploit
   the sensitivity of long-running applications to multi-resources for
   establishing a relationship between resource allocation and
   consequential performance. We use Online Gradient Boost Regression Tree
   (OGBRT) to enable the continuous model evolution. Once performance
   degradation is detected, resource inference is conducted to work out a
   proper slice of resources that will be reallocated to recover the target
   performance. The integration with Node Manager (NM) of Apache YARN shows
   that the throughput of Kafka data-streaming application is 2.0x and
   1.82x times that of isolation execution schemes in native YARN and pure
   cgroup cpu subsystem. In TPC-C benchmarking, the throughput can also be
   improved by 35\% and 23\% respectively against YARN native and cgroup
   cpu subsystem.},
DOI = {10.1109/CCGrid51090.2021.00027},
ISBN = {978-1-7281-9586-5},
Unique-ID = {WOS:000703983200018},
}

@inproceedings{ WOS:000380404600143,
Author = {Luckow, Andre and Kennedy, Ken and Manhardt, Fabian and Djerekarov, Emil
   and Vorster, Bennie and Apon, Amy},
Editor = {Ho, H and Ooi, BC and Zaki, MJ and Hu, XH and Haas, L and Kumar, V and Rachuri, S and Yu, SP and Hsiao, MHI and Li, J and Luo, F and Pyne, S and Ogan, K},
Title = {Automotive Big Data: Applications, Workloads and Infrastructures},
Booktitle = {PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA},
Year = {2015},
Pages = {1201-1210},
Note = {IEEE International Conference on Big Data, Santa Clara, CA, OCT 29-NOV
   01, 2015},
Organization = {IEEE; IEEE Comp Soc; Natl Sci Fdn; CCF; HUAWEI; Springer; ELSEVIER;
   CISCO; Intel},
Abstract = {Data is increasingly affecting the automotive industry, from vehicle
   development, to manufacturing and service processes, to online services
   centered around the connected vehicle. Connected, mobile and Internet of
   Things devices and machines generate immense amounts of sensor data. The
   ability to process and analyze this data to extract insights and
   knowledge that enable intelligent services, new ways to understand
   business problems, improvements of processes and decisions, is a
   critical capability. Hadoop is a scalable platform for compute and
   storage and emerged as de-facto standard for Big Data processing at
   Internet companies and in the scientific community. However, there is a
   lack of understanding of how and for what use cases these new Hadoop
   capabilities can be efficiently used to augment automotive applications
   and systems. This paper surveys use cases and applications for deploying
   Hadoop in the automotive industry.
   Over the years a rich ecosystem emerged around Hadoop comprising tools
   for parallel, in-memory and stream processing (most notable MapReduce
   and Spark), SQL and NOSQL engines (Hive, HBase), and machine learning
   (Mahout, MLlib). It is critical to develop an understanding of
   automotive applications and their characteristics and requirements for
   data discovery, integration, exploration and analytics. We then map
   these requirements to a confined technical architecture consisting of
   core Hadoop services and libraries for data ingest, processing and
   analytics. The objective of this paper is to address questions, such as:
   What applications and datasets are suitable for Hadoop? How can a
   diverse set of frameworks and tools be managed on multi-tenant Hadoop
   cluster? How do these tools integrate with existing relational data
   management systems? How can enterprise security requirements be
   addressed? What are the performance characteristics of these tools for
   real-world automotive applications? To address the last question, we
   utilize a standard benchmark (TPCx-HS), and two application benchmarks
   (SQL and machine learning) that operate on a dataset of multiple
   Terabytes and billions of rows.},
ISBN = {978-1-4799-9925-5},
ORCID-Numbers = {Manhardt, Fabian/0000-0002-4577-4590},
Unique-ID = {WOS:000380404600143},
}

@article{ WOS:000577624800030,
Author = {Libri, Antonio and Bartolini, Andrea and Benini, Luca},
Title = {pAElla: Edge AI-Based Real-Time Malware Detection in Data Centers},
Journal = {IEEE INTERNET OF THINGS JOURNAL},
Year = {2020},
Volume = {7},
Number = {10},
Pages = {9589-9599},
Month = {OCT},
Abstract = {The increasing use of Internet-of-Things (IoT) devices for monitoring a
   wide spectrum of applications, along with the challenges of ``big
   data{''} streaming support they often require for data analysis, is
   nowadays pushing for increased attention to the emerging edge computing
   paradigm. In particular, smart approaches to manage and analyze data
   directly on the network edge, are more and more investigated, and
   artificial intelligence (AI)-powered edge computing is envisaged to be a
   promising direction. In this article, we focus on data centers (DCs) and
   supercomputers (SCs), where a new generation of high-resolution
   monitoring systems is being deployed, opening new opportunities for
   analysis like anomaly detection and security, but introducing new
   challenges for handling the vast amount of data it produces. In detail,
   we report on a novel lightweight and scalable approach to increase the
   security of DCs/SCs, which involves AI-powered edge computing on
   high-resolution power consumption. The method-called pAElla-targets
   real-time malware detection (MD), it runs on an out-of-band IoT-based
   monitoring system for DCs/SCs, and involves power spectral density of
   power measurements, along with autoencoders. Results are promising, with
   an F1-score close to 1, and a false alarm and malware miss rate close to
   0\%. We compare our method with State-of-the-Art (SoA) MD techniques and
   show that, in the context of DCs/SCs, pAElla can cover a wider range of
   malware, significantly outperforming SoA approaches in terms of
   accuracy. Moreover, we propose a methodology for online training
   suitable for DCs/SCs in production, and release open data set and code.},
DOI = {10.1109/JIOT.2020.2986702},
ISSN = {2327-4662},
ResearcherID-Numbers = {Bartolini, Andrea/P-3440-2019
   },
ORCID-Numbers = {Bartolini, Andrea/0000-0002-1148-2450
   Libri, Antonio/0000-0002-8511-5231
   BENINI, LUCA/0000-0001-8068-3806},
Unique-ID = {WOS:000577624800030},
}

@article{ WOS:000351437800003,
Author = {Thomasian, Alexander},
Title = {Analysis of Fork/Join and Related Queueing Systems},
Journal = {ACM COMPUTING SURVEYS},
Year = {2015},
Volume = {47},
Number = {2},
Month = {JAN},
Abstract = {Fork/join (F/J) requests arise in contexts such as parallel computing,
   query processing in parallel databases, and parallel disk access in
   RAID. F/J requests spawn K tasks that are sent to K parallel servers,
   and the completion of all K tasks marks the completion of an F/J
   request. The exact formula for the mean response time of K = 2-way F/J
   requests derived under Markovian assumptions (R-2(F/J)) served as the
   starting point for an approximate expression for R-K(F/J) for 2 < K <=
   32. When servers process independent requests in addition to F/J
   requests, the mean response time of F/J requests is better approximated
   by R-K(max), which is the maximum of the response times of tasks
   constituting F/J requests. R-K(max) is easier to compute and serves as
   an upper bound to R-K(F/J). We discuss techniques to compute R-K(max)
   and generally the maximum of K random variables denoting the processing
   times of the tasks of a parallel computation (X) over bar (max)(K).
   Graph models of computations such as Petri nets-a more general form of
   parallelism than F/J requests-are also discussed in this work. Jobs with
   precedence constraints may require multiple resources, which are
   represented by a queueing network model. We also discuss various
   queueing systems related to F/J queueing systems and outline their
   analysis.},
DOI = {10.1145/2628913},
Article-Number = {17},
ISSN = {0360-0300},
EISSN = {1557-7341},
Unique-ID = {WOS:000351437800003},
}
