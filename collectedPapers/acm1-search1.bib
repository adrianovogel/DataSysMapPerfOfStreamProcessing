@article{10.1145/1071690.1064221,
author = {Kumar, Abhishek and Sung, Minho and Xu, Jun (Jim) and Zegura, Ellen W.},
title = {A Data Streaming Algorithm for Estimating Subpopulation Flow Size Distribution},
year = {2005},
issue_date = {June 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/1071690.1064221},
doi = {10.1145/1071690.1064221},
abstract = {Statistical information about the flow sizes in the traffic passing through a network link helps a network operator to characterize network resource usage, infer traffic demands, detect traffic anomalies, and improve network performance through traffic engineering. Previous work on estimating the flow size distribution for the complete population of flows has produced techniques that either make inferences from sampled network traffic, or use data streaming approaches. In this work, we identify and solve a more challenging problem of estimating the size distribution and other statistical information about arbitrary subpopulations of flows. Inferring subpopulation flow statistics is more challenging than the complete population counterpart, since subpopulations of interest are often specified a posteriori (i.e., after the data collection is done), making it impossible for the data collection module to "plan in advance".Our solution consists of a novel mechanism that combines data streaming with traditional packet sampling to provide highly accurate estimates of subpopulation flow statistics. The algorithm employs two data collection modules operating in parallel --- a NetFlow-like packet sampler and a streaming data structure made up of an array of counters. Combining the data collected by these two modules, our estimation algorithm uses a statistical estimation procedure that correlates and decodes the outputs (observations) from both data collection modules to obtain flow statistics for any arbitrary subpopulation. Evaluations of this algorithm on real-world Internet traffic traces demonstrate its high measurement accuracy.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jun},
pages = {61–72},
numpages = {12},
keywords = {traffic analysis, flow statistics, data streaming, EM algorithm, statistical inference}
}

@inproceedings{10.1145/1064212.1064221,
author = {Kumar, Abhishek and Sung, Minho and Xu, Jun (Jim) and Zegura, Ellen W.},
title = {A Data Streaming Algorithm for Estimating Subpopulation Flow Size Distribution},
year = {2005},
isbn = {1595930221},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1064212.1064221},
doi = {10.1145/1064212.1064221},
abstract = {Statistical information about the flow sizes in the traffic passing through a network link helps a network operator to characterize network resource usage, infer traffic demands, detect traffic anomalies, and improve network performance through traffic engineering. Previous work on estimating the flow size distribution for the complete population of flows has produced techniques that either make inferences from sampled network traffic, or use data streaming approaches. In this work, we identify and solve a more challenging problem of estimating the size distribution and other statistical information about arbitrary subpopulations of flows. Inferring subpopulation flow statistics is more challenging than the complete population counterpart, since subpopulations of interest are often specified a posteriori (i.e., after the data collection is done), making it impossible for the data collection module to "plan in advance".Our solution consists of a novel mechanism that combines data streaming with traditional packet sampling to provide highly accurate estimates of subpopulation flow statistics. The algorithm employs two data collection modules operating in parallel --- a NetFlow-like packet sampler and a streaming data structure made up of an array of counters. Combining the data collected by these two modules, our estimation algorithm uses a statistical estimation procedure that correlates and decodes the outputs (observations) from both data collection modules to obtain flow statistics for any arbitrary subpopulation. Evaluations of this algorithm on real-world Internet traffic traces demonstrate its high measurement accuracy.},
booktitle = {Proceedings of the 2005 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {61–72},
numpages = {12},
keywords = {flow statistics, traffic analysis, data streaming, statistical inference, EM algorithm},
location = {Banff, Alberta, Canada},
series = {SIGMETRICS '05}
}

@article{10.1145/1140103.1140295,
author = {Lall, Ashwin and Sekar, Vyas and Ogihara, Mitsunori and Xu, Jun and Zhang, Hui},
title = {Data Streaming Algorithms for Estimating Entropy of Network Traffic},
year = {2006},
issue_date = {June 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/1140103.1140295},
doi = {10.1145/1140103.1140295},
abstract = {Using entropy of traffic distributions has been shown to aid a wide variety of network monitoring applications such as anomaly detection, clustering to reveal interesting patterns, and traffic classification. However, realizing this potential benefit in practice requires accurate algorithms that can operate on high-speed links, with low CPU and memory requirements. In this paper, we investigate the problem of estimating the entropy in a streaming computation model. We give lower bounds for this problem, showing that neither approximation nor randomization alone will let us compute the entropy efficiently. We present two algorithms for randomly approximating the entropy in a time and space efficient manner, applicable for use on very high speed (greater than OC-48) links. The first algorithm for entropy estimation is inspired by the structural similarity with the seminal work of Alon et al. for estimating frequency moments, and we provide strong theoretical guarantees on the error and resource usage. Our second algorithm utilizes the observation that the performance of the streaming algorithm can be enhanced by separating the high-frequency items (or elephants) from the low-frequency items (or mice). We evaluate our algorithms on traffic traces from different deployment scenarios.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jun},
pages = {145–156},
numpages = {12},
keywords = {traffic analysis, data streaming}
}

@inproceedings{10.1145/1140277.1140295,
author = {Lall, Ashwin and Sekar, Vyas and Ogihara, Mitsunori and Xu, Jun and Zhang, Hui},
title = {Data Streaming Algorithms for Estimating Entropy of Network Traffic},
year = {2006},
isbn = {1595933190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1140277.1140295},
doi = {10.1145/1140277.1140295},
abstract = {Using entropy of traffic distributions has been shown to aid a wide variety of network monitoring applications such as anomaly detection, clustering to reveal interesting patterns, and traffic classification. However, realizing this potential benefit in practice requires accurate algorithms that can operate on high-speed links, with low CPU and memory requirements. In this paper, we investigate the problem of estimating the entropy in a streaming computation model. We give lower bounds for this problem, showing that neither approximation nor randomization alone will let us compute the entropy efficiently. We present two algorithms for randomly approximating the entropy in a time and space efficient manner, applicable for use on very high speed (greater than OC-48) links. The first algorithm for entropy estimation is inspired by the structural similarity with the seminal work of Alon et al. for estimating frequency moments, and we provide strong theoretical guarantees on the error and resource usage. Our second algorithm utilizes the observation that the performance of the streaming algorithm can be enhanced by separating the high-frequency items (or elephants) from the low-frequency items (or mice). We evaluate our algorithms on traffic traces from different deployment scenarios.},
booktitle = {Proceedings of the Joint International Conference on Measurement and Modeling of Computer Systems},
pages = {145–156},
numpages = {12},
keywords = {data streaming, traffic analysis},
location = {Saint Malo, France},
series = {SIGMETRICS '06/Performance '06}
}

@article{10.1145/1140103.1140328,
author = {Broberg, James A. and Liu, Zhen and Xia, Cathy H. and Zhang, Li},
title = {A Multicommodity Flow Model for Distributed Stream Processing},
year = {2006},
issue_date = {June 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/1140103.1140328},
doi = {10.1145/1140103.1140328},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jun},
pages = {377–378},
numpages = {2},
keywords = {stream processing, potential function, distributed algorithms, multicommodity flow}
}

@inproceedings{10.1145/1140277.1140328,
author = {Broberg, James A. and Liu, Zhen and Xia, Cathy H. and Zhang, Li},
title = {A Multicommodity Flow Model for Distributed Stream Processing},
year = {2006},
isbn = {1595933190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1140277.1140328},
doi = {10.1145/1140277.1140328},
booktitle = {Proceedings of the Joint International Conference on Measurement and Modeling of Computer Systems},
pages = {377–378},
numpages = {2},
keywords = {distributed algorithms, stream processing, potential function, multicommodity flow},
location = {Saint Malo, France},
series = {SIGMETRICS '06/Performance '06}
}

@article{10.1145/2796314.2745882,
author = {Ghaderi, Javad and Shakkottai, Sanjay and Srikant, Rayadurgam},
title = {Scheduling Storms and Streams in the Cloud},
year = {2015},
issue_date = {June 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/2796314.2745882},
doi = {10.1145/2796314.2745882},
abstract = {Motivated by emerging big streaming data processing paradigms (e.g., Twitter Storm, Streaming MapReduce), we investigate the problem of scheduling graphs over a large cluster of servers. Each graph is a job, where nodes represent compute tasks and edges indicate data-flows between these compute tasks. Jobs (graphs) arrive randomly over time, and upon completion, leave the system. When a job arrives, the scheduler needs to partition the graph and distribute it over the servers to satisfy load balancing and cost considerations. Specifically, neighboring compute tasks in the graph that are mapped to different servers incur load on the network; thus a mapping of the jobs among the servers incurs a cost that is proportional to the number of "broken edges''. We propose a low complexity randomized scheduling algorithm that, without service preemptions, stabilizes the system with graph arrivals/departures; more importantly, it allows a smooth trade-off between minimizing average partitioning cost and average queue lengths. Interestingly, to avoid service preemptions, our approach does not rely on a Gibbs sampler; instead, we show that the corresponding limiting invariant measure has an interpretation stemming from a loss system.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jun},
pages = {439–440},
numpages = {2},
keywords = {graph partitioning, dynamic resource allocation}
}

@inproceedings{10.1145/2745844.2745882,
author = {Ghaderi, Javad and Shakkottai, Sanjay and Srikant, Rayadurgam},
title = {Scheduling Storms and Streams in the Cloud},
year = {2015},
isbn = {9781450334860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2745844.2745882},
doi = {10.1145/2745844.2745882},
abstract = {Motivated by emerging big streaming data processing paradigms (e.g., Twitter Storm, Streaming MapReduce), we investigate the problem of scheduling graphs over a large cluster of servers. Each graph is a job, where nodes represent compute tasks and edges indicate data-flows between these compute tasks. Jobs (graphs) arrive randomly over time, and upon completion, leave the system. When a job arrives, the scheduler needs to partition the graph and distribute it over the servers to satisfy load balancing and cost considerations. Specifically, neighboring compute tasks in the graph that are mapped to different servers incur load on the network; thus a mapping of the jobs among the servers incurs a cost that is proportional to the number of "broken edges''. We propose a low complexity randomized scheduling algorithm that, without service preemptions, stabilizes the system with graph arrivals/departures; more importantly, it allows a smooth trade-off between minimizing average partitioning cost and average queue lengths. Interestingly, to avoid service preemptions, our approach does not rely on a Gibbs sampler; instead, we show that the corresponding limiting invariant measure has an interpretation stemming from a loss system.},
booktitle = {Proceedings of the 2015 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {439–440},
numpages = {2},
keywords = {dynamic resource allocation, graph partitioning},
location = {Portland, Oregon, USA},
series = {SIGMETRICS '15}
}

@inproceedings{10.1145/1379272.1379282,
author = {Golab, Lukasz and Johnson, Theodore and Koudas, Nick and Srivastava, Divesh and Toman, David},
title = {Optimizing Away Joins on Data Streams},
year = {2008},
isbn = {9781595939630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1379272.1379282},
doi = {10.1145/1379272.1379282},
abstract = {Monitoring aggregates on network traffic streams is a compelling application of data stream management systems. Often, streaming aggregation queries involve joining multiple inputs (e.g., client requests and server responses) using temporal join conditions (e.g., within 5 seconds), followed by computation of aggregates (e.g., COUNT) over temporal windows (e.g., every 5 minutes). These types of queries help identify malfunctioning servers (missing responses), malicious clients (bursts of requests during a denial-of-service attack), or improperly configured protocols (short timeout intervals causing many retransmissions). However, while such query expression is natural, its evaluation over massive data streams is inefficient.In this paper, we develop rewriting techniques for streaming aggregation queries that join multiple inputs. Our techniques identify conditions under which expensive joins can be optimized away, while providing error bounds for the results of the rewritten queries. The basis of the optimization is a powerful but decidable theory in which constraints over data streams can be formulated. We show the efficiency and accuracy of our solutions via experimental evaluation on real-life IP network data using the Gigascope stream processing engine.},
booktitle = {Proceedings of the 2nd International Workshop on Scalable Stream Processing System},
pages = {48–57},
numpages = {10},
keywords = {data stream joins, data stream integrity constraints, data stream query rewriting},
location = {Nantes, France},
series = {SSPS '08}
}

@inproceedings{10.1145/3332186.3332256,
author = {Katragadda, Satya and Gottumukkala, Raju and Venna, Siva and Lipari, Nicholas and Gaikwad, Shailendra and Pusala, Murali and Chen, Jian and Borst, Christoph W. and Raghavan, Vijay and Bayoumi, Magdy},
title = {VAStream: A Visual Analytics System for Fast Data Streams},
year = {2019},
isbn = {9781450372275},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3332186.3332256},
doi = {10.1145/3332186.3332256},
abstract = {Processing high-volume, high-velocity data streams is an important big data problem in many sciences, engineering, and technology domains. There are many open-source distributed stream processing and cloud platforms that offer low-latency stream processing at scale, but the visualization and user-interaction components of these systems are limited to visualizing the outcome of stream processing results. Visual analysis represents a new form of analysis where the user has more control and interactive capabilities either to dynamically change the visualization, analytics or data management processes. VAStream provides an environment for big data stream processing along with interactive visualization capabilities. The system environment consists of hardware and software modules to optimize streaming data workflow (that includes data ingest, pre-processing, analytics, visualization, and collaboration components). The system environment is evaluated for two real-time streaming applications. The real-time event detection using social media streams uses text data arriving from sources such as Twitter to detect emerging events of interest. The real-time river sensor network analysis project uses unsupervised classification methods to classify sensor network streams arriving from the US river network to detect water quality problems. We discuss implementation details and provide performance comparison results of various individual stream processing operations for both stream processing applications.},
booktitle = {Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (Learning)},
articleno = {76},
numpages = {8},
keywords = {machine learning, Visual analytics, stream computing, visualization, big data infrastructure},
location = {Chicago, IL, USA},
series = {PEARC '19}
}

@inproceedings{10.1109/UCC.2014.15,
author = {Lu, Ruirui and Wu, Gang and Xie, Bin and Hu, Jingtong},
title = {Stream Bench: Towards Benchmarking Modern Distributed Stream Computing Frameworks},
year = {2014},
isbn = {9781479978816},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UCC.2014.15},
doi = {10.1109/UCC.2014.15},
abstract = {While big data is becoming ubiquitous, interest in handling data stream at scale is also gaining popularity, which leads to the sprout of many distributed stream computing systems. However, complexity of stream computing and diversity of workloads expose great challenges to benchmark these systems. Due to lack of standard criteria, evaluations and comparisons of these systems tend to be difficult. This paper takes an early step towards benchmarking modern distributed stream computing frameworks. After identifying the challenges and requirements in the field, we raise our benchmark definition Stream Bench regarding the requirements. Stream Bench proposes a message system functioning as a mediator between stream data generation and consumption. It also covers 7 benchmark programs that intend to address typical stream computing scenarios and core operations. Not only does it care about performance of systems under different data scales, but also takes fault tolerance ability and durability into account, which drives to incorporate four workload suites targeting at these various aspects of systems. Finally, we illustrate the feasibility of Stream Bench by applying it to two popular frameworks, Apache Storm and Apache Spark Streaming. We draw comparisons from various perspectives between the two platforms with workload suites of Stream Bench. In addition, we also demonstrate performance improvement of Storm's latest version with the benchmark.},
booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
pages = {69–78},
numpages = {10},
keywords = {big data, benchmark, distributed stream computing},
series = {UCC '14}
}

@inproceedings{10.1145/2096123.2096134,
author = {Hazra, Jagabondhu and Das, Kaushik and Seetharam, Deva P. and Singhee, Amith},
title = {Stream Computing Based Synchrophasor Application for Power Grids},
year = {2011},
isbn = {9781450310611},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2096123.2096134},
doi = {10.1145/2096123.2096134},
abstract = {This paper proposes an application of stream computing analytics framework to high speed synchrophasor data for real time monitoring and control of electric grid. High volume streaming synchrophasor data from geographically distributed grid sensors (namely, Phasor Measurement Units) are collected, synchronized, aggregated when required and analyzed using a stream computing platform to estimate the grid stability in real time. This real time stability monitoring scheme will help the grid operators to take preventive or corrective measures ahead of time to mitigate any disturbance before they develop into wide-spread. A protptype of the scheme is demonstrated on a benchmark 3 machines 9 bus system and the IEEE 14 bus test system.},
booktitle = {Proceedings of the First International Workshop on High Performance Computing, Networking and Analytics for the Power Grid},
pages = {43–50},
numpages = {8},
keywords = {power grid, voltage stability, stream computing, synchrophasor},
location = {Seattle, Washington, USA},
series = {HiPCNA-PG '11}
}

@inproceedings{10.1145/3236367.3236380,
author = {Mu\~{n}oz, Javier Fern\'{a}ndez and Dolz, Manuel F. and del Rio Astorga, David and Cepeda, Javier Prieto and Garc\'{\i}a, J. Daniel},
title = {Supporting MPI-Distributed Stream Parallel Patterns in GrPPI},
year = {2018},
isbn = {9781450364928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236367.3236380},
doi = {10.1145/3236367.3236380},
abstract = {In the recent years, the large volumes of stream data and the near real-time requirements of data streaming applications have exacerbated the need for new scalable algorithms and programming interfaces for distributed and shared-memory platforms. To contribute in this direction, this paper presents a new distributed MPI back end for GrPPI, a C++ high-level generic interface of data-intensive and stream processing parallel patterns. This back end, as a new execution policy, supports the distributed and hybrid (distributed and shared-memory) parallel execution of the Pipeline and Farm patterns, where the hybrid mode combines the MPI policy with a GrPPI shared-memory one. A detailed analysis of the GrPPI MPI execution policy reports considerable benefits from the programmability, flexibility and readability points of view. The experimental evaluation on a streaming application with different distributed and shared-memory scenarios reports considerable performance gains with respect to the sequential versions at the expense of negligible GrPPI overheads.},
booktitle = {Proceedings of the 25th European MPI Users' Group Meeting},
articleno = {17},
numpages = {10},
keywords = {Distributed Patterns, Stream Processing, C++ Programming, Generic Programming, Parallel Patterns},
location = {Barcelona, Spain},
series = {EuroMPI'18}
}

@inproceedings{10.1145/3401025.3401734,
author = {Presser, Daniel and Siqueira, Frank and Rodrigues, Lu\'{\i}s and Romano, Paolo},
title = {EdgeScaler: Effective Elastic Scaling for Graph Stream Processing Systems},
year = {2020},
isbn = {9781450380287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3401025.3401734},
doi = {10.1145/3401025.3401734},
abstract = {Existing solutions for elastic scaling perform poorly with graph stream processing for two key reasons. First, when the system is scaled, the graph must be dynamically re-partitioned among workers. This requires a partitioning algorithm that is fast and offers good locality, a task that is far from being trivial. Second, existing modelling techniques for distributed graph processing systems only consider hash partitioning, and do not leverage the semantic knowledge used by more efficient partitioners. In this paper we propose EdgeScaler, an elastic scaler for graph stream processing systems that tackles these challenges by employing, in a synergistic way, two innovative techniques: MicroMacroSplitter and AccuLocal. MicroMacroSplitter is a new edge-based graph partitioning strategy that is as fast as simple hash partinioners, while achieving quality comparable to the best state-of-the-art solutions. AccuLocal is a novel performance model that takes the partitioner features into account while avoiding expensive off-line training phases. An extensive experimental evaluation offers insights on the effectiveness of the proposed mechanisms and shows that EdgeScaler is able to significantly outperform existing solutions designed for generic stream processing systems.},
booktitle = {Proceedings of the 14th ACM International Conference on Distributed and Event-Based Systems},
pages = {39–50},
numpages = {12},
keywords = {elastic scaling, stream processing, graph processing},
location = {Montreal, Quebec, Canada},
series = {DEBS '20}
}

@inproceedings{10.1145/1142473.1142522,
author = {Jain, Navendu and Amini, Lisa and Andrade, Henrique and King, Richard and Park, Yoonho and Selo, Philippe and Venkatramani, Chitra},
title = {Design, Implementation, and Evaluation of the Linear Road Bnchmark on the Stream Processing Core},
year = {2006},
isbn = {1595934340},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1142473.1142522},
doi = {10.1145/1142473.1142522},
abstract = {Stream processing applications have recently gained significant attention in the networking and database community. At the core of these applications is a stream processing engine that performs resource allocation and management to support continuous tracking of queries over collections of physically-distributed and rapidly-updating data streams. While numerous stream processing systems exist, there has been little work on understanding the performance characteristics of these applications in a distributed setup. In this paper, we examine the performance bottlenecks of streaming data applications, in particular the Linear Road stream data management benchmark, in achieving good performance in large-scale distributed environments, using the Stream Processing Core (SPC), a stream processing middleware we have developed. First, we present the design and implementation of the Linear Road benchmark on the SPC middleware. SPC has been designed to scale to tens of thousands of processing nodes, while supporting concurrent applications and multiple simultaneous queries. Second, we identify the main performance bottlenecks in the Linear Road application in achieving scalability and low query response latency. Our results show that data locality, buffer capacity, physical allocation of processing elements to infrastructure nodes, and packaging for transporting streamed data are important factors in achieving good application performance. Though we evaluate our system primarily for the Linear Road application, we believe it also provides useful insights into the overall system behavior for supporting other distributed and large-scale continuous streaming data applications. Finally, we examine how SPC can be used and tuned to enable a very efficient implementation of the Linear Road application in a distributed environment.},
booktitle = {Proceedings of the 2006 ACM SIGMOD International Conference on Management of Data},
pages = {431–442},
numpages = {12},
keywords = {linear road, distributed stream processing systems, performance evaluation, bottleneck analysis},
location = {Chicago, IL, USA},
series = {SIGMOD '06}
}

@article{10.1145/1012888.1005709,
author = {Kumar, Abhishek and Sung, Minho and Xu, Jun (Jim) and Wang, Jia},
title = {Data Streaming Algorithms for Efficient and Accurate Estimation of Flow Size Distribution},
year = {2004},
issue_date = {June 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/1012888.1005709},
doi = {10.1145/1012888.1005709},
abstract = {Knowing the distribution of the sizes of traffic flows passing through a network link helps a network operator to characterize network resource usage, infer traffic demands, detect traffic anomalies, and accommodate new traffic demands through better traffic engineering. Previous work on estimating the flow size distribution has been focused on making inferences from sampled network traffic. Its accuracy is limited by the (typically) low sampling rate required to make the sampling operation affordable. In this paper we present a novel data streaming algorithm to provide much more accurate estimates of flow distribution, using a "lossy data structure" which consists of an array of counters fitted well into SRAM. For each incoming packet, our algorithm only needs to increment one underlying counter, making the algorithm fast enough even for 40 Gbps (OC-768) links. The data structure is lossy in the sense that sizes of multiple flows may collide into the same counter. Our algorithm uses Bayesian statistical methods such as Expectation Maximization to infer the most likely flow size distribution that results in the observed counter values after collision. Evaluations of this algorithm on large Internet traces obtained from several sources (including a tier-1 ISP) demonstrate that it has very high measurement accuracy (within 2%). Our algorithm not only dramatically improves the accuracy of flow distribution measurement, but also contributes to the field of data streaming by formalizing an existing methodology and applying it to the context of estimating the flow-distribution.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jun},
pages = {177–188},
numpages = {12},
keywords = {traffic analysis, statistical inference, network measurement, data streaming}
}

@inproceedings{10.1145/1005686.1005709,
author = {Kumar, Abhishek and Sung, Minho and Xu, Jun (Jim) and Wang, Jia},
title = {Data Streaming Algorithms for Efficient and Accurate Estimation of Flow Size Distribution},
year = {2004},
isbn = {1581138733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1005686.1005709},
doi = {10.1145/1005686.1005709},
abstract = {Knowing the distribution of the sizes of traffic flows passing through a network link helps a network operator to characterize network resource usage, infer traffic demands, detect traffic anomalies, and accommodate new traffic demands through better traffic engineering. Previous work on estimating the flow size distribution has been focused on making inferences from sampled network traffic. Its accuracy is limited by the (typically) low sampling rate required to make the sampling operation affordable. In this paper we present a novel data streaming algorithm to provide much more accurate estimates of flow distribution, using a "lossy data structure" which consists of an array of counters fitted well into SRAM. For each incoming packet, our algorithm only needs to increment one underlying counter, making the algorithm fast enough even for 40 Gbps (OC-768) links. The data structure is lossy in the sense that sizes of multiple flows may collide into the same counter. Our algorithm uses Bayesian statistical methods such as Expectation Maximization to infer the most likely flow size distribution that results in the observed counter values after collision. Evaluations of this algorithm on large Internet traces obtained from several sources (including a tier-1 ISP) demonstrate that it has very high measurement accuracy (within 2%). Our algorithm not only dramatically improves the accuracy of flow distribution measurement, but also contributes to the field of data streaming by formalizing an existing methodology and applying it to the context of estimating the flow-distribution.},
booktitle = {Proceedings of the Joint International Conference on Measurement and Modeling of Computer Systems},
pages = {177–188},
numpages = {12},
keywords = {network measurement, traffic analysis, statistical inference, data streaming},
location = {New York, NY, USA},
series = {SIGMETRICS '04/Performance '04}
}

@inproceedings{10.1145/3093742.3093902,
author = {Hesse, Guenter and Matthies, Christoph and Reissaus, Benjamin and Uflacker, Matthias},
title = {A New Application Benchmark for Data Stream Processing Architectures in an Enterprise Context: Doctoral Symposium},
year = {2017},
isbn = {9781450350655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3093742.3093902},
doi = {10.1145/3093742.3093902},
abstract = {Against the backdrop of ever-growing data volumes and trends like the Internet of Things (IoT) or Industry 4.0, Data Stream Processing Systems (DSPSs) or data stream processing architectures in general receive a greater interest. Continuously analyzing streams of data allows immediate responses to environmental changes. A challenging task in that context is assessing and comparing data stream processing architectures in order to identify the most suitable one for certain settings.The present paper provides an overview about performance benchmarks that can be used for analyzing data stream processing applications. By describing shortcomings of these benchmarks, the need for a new application benchmark in this area, especially for a benchmark covering enterprise architectures, is highlighted. A key role in such an enterprise context is the combination of streaming data and business data, which is barely covered in current data stream processing benchmarks. Furthermore, first ideas towards the development of a solution, i.e., a new application benchmark that is able to fill the existing gap, are depicted.},
booktitle = {Proceedings of the 11th ACM International Conference on Distributed and Event-Based Systems},
pages = {359–362},
numpages = {4},
keywords = {Internet of Things, Performance Benchmarking, Benchmark Development, Data Stream Processing, Stream Processing},
location = {Barcelona, Spain},
series = {DEBS '17}
}

@inproceedings{10.1145/2675743.2776763,
author = {Saleh, Omran and Sattler, Kai-Uwe},
title = {The PipeFlow Approach},
year = {2015},
isbn = {9781450332866},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2675743.2776763},
doi = {10.1145/2675743.2776763},
abstract = {In this paper, we present a description of our solution for solving the DEBS Grand Challenge 2015 that targets the analysis of taxi trips. Our implementation of this challenge is based on a general-purpose stream processing system called PipeFlow, which is designed and implemented to efficiently process continuous queries over high volume/speed data streams with low latency. Moreover, we present an experimental evaluation to show the effectiveness of the proposed solution with respect to query throughput and latency.},
booktitle = {Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems},
pages = {326–327},
numpages = {2},
keywords = {stream processing, DEBS grand challenge, PipeFlow},
location = {Oslo, Norway},
series = {DEBS '15}
}

@inproceedings{10.1109/CCGRID.2017.147,
author = {Runsewe, Olubisi and Samaan, Nancy},
title = {Cloud Resource Scaling for Big Data Streaming Applications Using A Layered Multi-Dimensional Hidden Markov Model},
year = {2017},
isbn = {9781509066100},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGRID.2017.147},
doi = {10.1109/CCGRID.2017.147},
abstract = {Recent advancements in technology have led to a deluge of data that require real-time analysis with strict latency constraints. A major challenge, however, is determining the amount of resources required by big data stream processing applications in response to heterogeneous data sources, streaming events, unpredictable data volume and velocity changes. Over-provisioning of resources for peak loads can be wasteful while under-provisioning can have a huge impact on the performance of the streaming applications. The majority of research efforts on resource scaling in the cloud are investigated from the cloud provider's perspective, they focus on web applications and do not consider multiple resource bottlenecks. We aim at analyzing the resource scaling problem from a big data streaming application provider's point of view such that efficient scaling decisions can be made for future resource utilization. This paper proposes a Layered Multi-dimensional Hidden Markov Model (LMD-HMM) for facilitating the management of resource auto-scaling for big data streaming applications in the cloud. Our detailed experimental evaluation shows that LMD-HMM performs best with an accuracy of 98%, outperforming the single-layer hidden markov model.},
booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
pages = {848–857},
numpages = {10},
keywords = {Resource Scaling, Layered Hidden Markov Model, Big Data, Stream Processing, Resource Prediction, Cloud Computing},
location = {Madrid, Spain},
series = {CCGrid '17}
}

@inproceedings{10.1145/3093742.3093921,
author = {Zacheilas, Nikos and Kalogeraki, Vana and Nikolakopoulos, Yiannis and Gulisano, Vincenzo and Papatriantafilou, Marina and Tsigas, Philippas},
title = {Maximizing Determinism in Stream Processing Under Latency Constraints},
year = {2017},
isbn = {9781450350655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3093742.3093921},
doi = {10.1145/3093742.3093921},
abstract = {The problem of coping with the demands of determinism and meeting latency constraints is challenging in distributed data stream processing systems that have to process high volume data streams that arrive from different unsynchronized input sources. In order to deterministically process the streaming data, they need mechanisms that synchronize the order in which tuples are processed by the operators. On the other hand, achieving real-time response in such a system requires careful tradeoff between determinism and low latency performance. We build on a recently proposed approach to handle data exchange and synchronization in stream processing, namely ScaleGate, which comes with guarantees for determinism and an efficient lock-free implementation, enabling high scalability. Considering the challenge and trade-offs implied by real-time constraints, we propose a system which comprises (a) a novel data structure called Slack-ScaleGate (SSG), along with its algorithmic implementation; SSG enables us to guarantee the deterministic processing of tuples as long as they are able to meet their latency constraints, and (b) a method to dynamically tune the maximum amount of time that a tuple can wait in the SSG data-structure, relaxing the determinism guarantees when needed, in order to satisfy the latency constraints. Our detailed experimental evaluation using a traffic monitoring application deployed in the city of Dublin, illustrates the working and benefits of our approach.},
booktitle = {Proceedings of the 11th ACM International Conference on Distributed and Event-Based Systems},
pages = {112–123},
numpages = {12},
keywords = {Stream Processing, Complex Event Processing, Deterministic Processing},
location = {Barcelona, Spain},
series = {DEBS '17}
}

@inproceedings{10.1145/3465480.3467844,
author = {Tommasini, Riccardo and Bonte, Pieter},
title = {Web Stream Processing with RSP4J},
year = {2021},
isbn = {9781450385558},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465480.3467844},
doi = {10.1145/3465480.3467844},
abstract = {Social Media Analysis, Internet of Things, and Fake News detection have unveiled the relevance of real-time analytics on the Web. As a consequence, the Web infrastructure is evolving to enable continuous and reactive data access. Since data streams available on the Web originate from a variety of sources, they are highly heterogeneous. Indeed, addressing data variety and velocity simultaneously is inevitable. Stream Reasoning is the research field that studies how to combine data integration techniques with stream processing technologies. In particular, solutions for RDF Stream Processing (RSP) combine stream processing notions with data integration standards. This tutorial paper presents RSP4J, a innovative API that aims at fostering the adoption of RSP by simplifying the usage, benchmarking, and fast prototyping of Web Stream Processing applications.},
booktitle = {Proceedings of the 15th ACM International Conference on Distributed and Event-Based Systems},
pages = {164–167},
numpages = {4},
keywords = {web stream processing, stream reasoning, RDF stream processing},
location = {Virtual Event, Italy},
series = {DEBS '21}
}

@inproceedings{10.1145/2488222.2488255,
author = {Soul\'{e}, Robert and Gordon, Michael I. and Amarasinghe, Saman and Grimm, Robert and Hirzel, Martin},
title = {Dynamic Expressivity with Static Optimization for Streaming Languages},
year = {2013},
isbn = {9781450317580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488222.2488255},
doi = {10.1145/2488222.2488255},
abstract = {Developers increasingly use streaming languages to write applications that process large volumes of data with high throughput. Unfortunately, when picking which streaming language to use, they face a difficult choice. On the one hand, dynamically scheduled languages allow developers to write a wider range of applications, but cannot take advantage of many crucial optimizations. On the other hand, statically scheduled languages are extremely performant, but have difficulty expressing many important streaming applications.This paper presents the design of a hybrid scheduler for stream processing languages. The compiler partitions the streaming application into coarse-grained subgraphs separated by dynamic rate boundaries. It then applies static optimizations to those subgraphs. We have implemented this scheduler as an extension to the StreamIt compiler. To evaluate its performance, we compare it to three scheduling techniques used by dynamic systems (OS thread, demand, and no-op) on a combination of micro-benchmarks and real-world inspired synthetic benchmarks. Our scheduler not only allows the previously static version of StreamIt to run dynamic rate applications, but it outperforms the three dynamic alternatives. This demonstrates that our scheduler strikes the right balance between expressivity and performance for stream processing languages.},
booktitle = {Proceedings of the 7th ACM International Conference on Distributed Event-Based Systems},
pages = {159–170},
numpages = {12},
keywords = {streamit, stream processing},
location = {Arlington, Texas, USA},
series = {DEBS '13}
}

@article{10.1145/3460013,
author = {Daghistani, Anas and Aref, Walid G. and Ghafoor, Arif and Mahmood, Ahmed R.},
title = {SWARM: Adaptive Load Balancing in Distributed Streaming Systems for Big Spatial Data},
year = {2021},
issue_date = {September 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
issn = {2374-0353},
url = {https://doi.org/10.1145/3460013},
doi = {10.1145/3460013},
abstract = {The proliferation of GPS-enabled devices has led to the development of numerous location-based services. These services need to process massive amounts of streamed spatial data in real-time. The current scale of spatial data cannot be handled using centralized systems. This has led to the development of distributed spatial streaming systems. Existing systems are using static spatial partitioning to distribute the workload. In contrast, the real-time streamed spatial data follows non-uniform spatial distributions that are continuously changing over time. Distributed spatial streaming systems need to react to the changes in the distribution of spatial data and queries. This article introduces SWARM, a lightweight adaptivity protocol that continuously monitors the data and query workloads across the distributed processes of the spatial data streaming system and redistributes and rebalances the workloads as soon as performance bottlenecks get detected. SWARM is able to handle multiple query-execution and data-persistence models. A distributed streaming system can directly use SWARM to adaptively rebalance the system’s workload among its machines with minimal changes to the original code of the underlying spatial application. Extensive experimental evaluation using real and synthetic datasets illustrate that, on average, SWARM achieves 2 improvement in throughput over a static grid partitioning that is determined based on observing a limited history of the data and query workloads. Moreover, SWARM reduces execution latency on average 4 compared with the other technique.},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = {jun},
articleno = {14},
numpages = {43},
keywords = {distributed streaming systems, cluster utilization, spatial continuous queries, Load balancing, spatial stream processing}
}

@inproceedings{10.1145/3447545.3451190,
author = {Henning, S\"{o}ren and Hasselbring, Wilhelm},
title = {How to Measure Scalability of Distributed Stream Processing Engines?},
year = {2021},
isbn = {9781450383318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447545.3451190},
doi = {10.1145/3447545.3451190},
abstract = {Scalability is promoted as a key quality feature of modern big data stream processing engines. However, even though research made huge efforts to provide precise definitions and corresponding metrics for the term scalability, experimental scalability evaluations or benchmarks of stream processing engines apply different and inconsistent metrics. With this paper, we aim to establish general metrics for scalability of stream processing engines. Derived from common definitions of scalability in cloud computing, we propose two metrics: a load capacity function and a resource demand function. Both metrics relate provisioned resources and load intensities, while requiring specific service level objectives to be fulfilled. We show how these metrics can be employed for scalability benchmarking and discuss their advantages in comparison to other metrics, used for stream processing engines and other software systems.},
booktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},
pages = {85–88},
numpages = {4},
keywords = {scalability, stream processing, cloud computing, metrics},
location = {Virtual Event, France},
series = {ICPE '21}
}

@inproceedings{10.1145/2843043.2843056,
author = {Eskandari, Leila and Huang, Zhiyi and Eyers, David},
title = {P-Scheduler: Adaptive Hierarchical Scheduling in Apache Storm},
year = {2016},
isbn = {9781450340427},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2843043.2843056},
doi = {10.1145/2843043.2843056},
abstract = {With ever-accelerating data creation rates in Big Data applications, there is a need for efficient stream processing engines. Apache Storm has been of interest in both academia and industry because of its real-time, distributed, scalable and reliable framework for stream processing. In this paper, we propose an adaptive hierarchical scheduler for the Storm framework, to allocate the resources more efficiently and improve performance. In our method, we consider the data transfer rate and traffic pattern between Storm's tasks and assign highly-communicating task pairs to the same computing node by dynamically employing two phases of graph partitioning. We also calculate the number of required computing nodes in the cluster based on the overall load of the application and use this information to reduce inter-node traffic. Our performance evaluation shows a significant improvement compared to the default scheduler provided by Storm, which evenly distributes the tasks across the cluster, ignoring the communication patterns between them.},
booktitle = {Proceedings of the Australasian Computer Science Week Multiconference},
articleno = {26},
numpages = {10},
keywords = {graph partitioning, stream processing, apache storm, scheduling, big data},
location = {Canberra, Australia},
series = {ACSW '16}
}

@article{10.1145/3441299,
author = {Stefani, Lorenzo De and Terolli, Erisa and Upfal, Eli},
title = {Tiered Sampling: An Efficient Method for Counting Sparse Motifs in Massive Graph Streams},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {5},
issn = {1556-4681},
url = {https://doi.org/10.1145/3441299},
doi = {10.1145/3441299},
abstract = {We introduce Tiered Sampling, a novel technique for estimating the count of sparse motifs in massive graphs whose edges are observed in a stream. Our technique requires only a single pass on the data and uses a memory of fixed size M, which can be magnitudes smaller than the number of edges.Our methods address the challenging task of counting sparse motifs—sub-graph patterns—that have a low probability of appearing in a sample of M edges in the graph, which is the maximum amount of data available to the algorithms in each step. To obtain an unbiased and low variance estimate of the count, we partition the available memory into tiers (layers) of reservoir samples. While the base layer is a standard reservoir sample of edges, other layers are reservoir samples of sub-structures of the desired motif. By storing more frequent sub-structures of the motif, we increase the probability of detecting an occurrence of the sparse motif we are counting, thus decreasing the variance and error of the estimate.While we focus on the designing and analysis of algorithms for counting 4-cliques, we present a method which allows generalizing Tiered Sampling to obtain high-quality estimates for the number of occurrence of any sub-graph of interest, while reducing the analysis effort due to specific properties of the pattern of interest.We present a complete analytical analysis and extensive experimental evaluation of our proposed method using both synthetic and real-world data. Our results demonstrate the advantage of our method in obtaining high-quality approximations for the number of 4 and 5-cliques for large graphs using a very limited amount of memory, significantly outperforming the single edge sample approach for counting sparse motifs in large scale graphs.},
journal = {ACM Trans. Knowl. Discov. Data},
month = {may},
articleno = {79},
numpages = {52},
keywords = {Graph motif mining, stream computing, reservoir sampling}
}

@inproceedings{10.1145/3210284.3210286,
author = {Bilal, Muhammad and Alsibyani, Hassan and Canini, Marco},
title = {Mitigating Network Side Channel Leakage for Stream Processing Systems in Trusted Execution Environments},
year = {2018},
isbn = {9781450357821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210284.3210286},
doi = {10.1145/3210284.3210286},
abstract = {A crucial concern regarding cloud computing is the confidentiality of sensitive data being processed in the cloud. Trusted Execution Environments (TEEs), such as Intel Software Guard extensions (SGX), allow applications to run securely on an untrusted platform. However, using TEEs alone for stream processing is not enough to ensure privacy as network communication patterns may leak information about the data.This paper introduces two techniques -- anycast and multicast --for mitigating leakage at inter-stage communications in streaming applications according to a user-selected mitigation level. These techniques aim to achieve network data obliviousness, i.e., communication patterns should not depend on the data. We implement these techniques in an SGX-based stream processing system. We evaluate the latency and throughput overheads, and the data obliviousness using three benchmark applications. The results show that anycast scales better with input load and mitigation level, and provides better data obliviousness than multicast.},
booktitle = {Proceedings of the 12th ACM International Conference on Distributed and Event-Based Systems},
pages = {16–27},
numpages = {12},
keywords = {Intel SGX, Stream processing, network data obliviousness},
location = {Hamilton, New Zealand},
series = {DEBS '18}
}

@inproceedings{10.1145/2872427.2883075,
author = {Rokicki, Markus and Zerr, Sergej and Siersdorfer, Stefan},
title = {Just in Time: Controlling Temporal Performance in Crowdsourcing Competitions},
year = {2016},
isbn = {9781450341431},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872427.2883075},
doi = {10.1145/2872427.2883075},
abstract = {Many modern data analytics applications in areas such as crisis management, stock trading, and healthcare, rely on components capable of nearly real-time processing of streaming data produced at varying rates. In addition to automatic processing methods, many tasks involved in those applications require further human assessment and analysis. However, current crowdsourcing platforms and systems do not support stream processing with variable loads. In this paper, we investigate how incentive mechanisms in competition based crowdsourcing can be employed in such scenarios. More specifically, we explore techniques for stimulating workers to dynamically adapt to both anticipated and sudden changes in data volume and processing demand, and we analyze effects such as data processing throughput, peak-to-average ratios, and saturation effects. To this end, we study a wide range of incentive schemes and utility functions inspired by real world applications. Our large-scale experimental evaluation with more than 900 participants and more than 6200 hours of work spent by crowd workers demonstrates that our competition based mechanisms are capable of adjusting the throughput of online workers and lead to substantial on-demand performance boosts.},
booktitle = {Proceedings of the 25th International Conference on World Wide Web},
pages = {817–827},
numpages = {11},
keywords = {stream processing, competitions, crowdsourcing},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16}
}

@inproceedings{10.1145/3328905.3332511,
author = {Grulich, Philipp M. and Traub, Jonas and Bre\ss{}, Sebastian and Katsifodimos, Asterios and Markl, Volker and Rabl, Tilmann},
title = {Generating Reproducible Out-of-Order Data Streams},
year = {2019},
isbn = {9781450367943},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328905.3332511},
doi = {10.1145/3328905.3332511},
abstract = {Evaluating modern stream processing systems in a reproducible manner requires data streams with different data distributions, data rates, and real-world characteristics such as delayed and out-of-order tuples. In this paper, we present an open source stream generator which generates reproducible and deterministic out-of-order streams based on real data files, simulating arbitrary fractions of out-of-order tuples and their respective delays.},
booktitle = {Proceedings of the 13th ACM International Conference on Distributed and Event-Based Systems},
pages = {256–257},
numpages = {2},
keywords = {Out-of-Order, Benchmarking, Data Generation, Stream Processing},
location = {Darmstadt, Germany},
series = {DEBS '19}
}

@article{10.1145/3184120,
author = {\c{S}ahin, Semih and Gedik, Bu\u{g}ra},
title = {C-Stream: A Co-Routine-Based Elastic Stream Processing Engine},
year = {2018},
issue_date = {September 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
issn = {2329-4949},
url = {https://doi.org/10.1145/3184120},
doi = {10.1145/3184120},
abstract = {Stream processing is a computational paradigm for on-the-fly processing of live data. This paradigm lends itself to implementations that can provide high throughput and low latency by taking advantage of various forms of parallelism that are naturally captured by the stream processing model of computation, such as pipeline, task, and data parallelism. In this article, we describe the design and implementation of C-Stream, which is an elastic stream processing engine. C-Stream encompasses three unique properties. First, in contrast to the widely adopted event-based interface for developing streaming operators, C-Stream provides an interface wherein each operator has its own driver loop and relies on data availability application programming interfaces (APIs) to decide when to perform its computations. This self-control-based model significantly simplifies the development of operators that require multiport synchronization. Second, C-Stream contains a dynamic scheduler that manages the multithreaded execution of the operators. The scheduler, which is customizable via plug-ins, enables the execution of the operators as co-routines, using any number of threads. The base scheduler implements back-pressure, provides data availability APIs, and manages preemption and termination handling. Last, C-Stream varies the degree of parallelism to resolve bottlenecks by both dynamically changing the number of threads used to execute an application and adjusting the number of replicas of data-parallel operators. We provide an experimental evaluation of C-Stream. The results show that C-Stream is scalable, highly customizable, and can resolve bottlenecks by dynamically adjusting the level of data parallelism used.},
journal = {ACM Trans. Parallel Comput.},
month = {apr},
articleno = {15},
numpages = {27},
keywords = {elastic stream processing engine, C-Stream}
}

@inproceedings{10.1145/3314221.3314580,
author = {Mamouras, Konstantinos and Stanford, Caleb and Alur, Rajeev and Ives, Zachary G. and Tannen, Val},
title = {Data-Trace Types for Distributed Stream Processing Systems},
year = {2019},
isbn = {9781450367127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314221.3314580},
doi = {10.1145/3314221.3314580},
abstract = {Distributed architectures for efficient processing of streaming data are increasingly critical to modern information processing systems. The goal of this paper is to develop type-based programming abstractions that facilitate correct and efficient deployment of a logical specification of the desired computation on such architectures. In the proposed model, each communication link has an associated type specifying tagged data items along with a dependency relation over tags that captures the logical partial ordering constraints over data items. The semantics of a (distributed) stream processing system is then a function from input data traces to output data traces, where a data trace is an equivalence class of sequences of data items induced by the dependency relation. This data-trace transduction model generalizes both acyclic synchronous data-flow and relational query processors, and can specify computations over data streams with a rich variety of partial ordering and synchronization characteristics. We then describe a set of programming templates for data-trace transductions: abstractions corresponding to common stream processing tasks. Our system automatically maps these high-level programs to a given topology on the distributed implementation platform Apache Storm while preserving the semantics. Our experimental evaluation shows that (1) while automatic parallelization deployed by existing systems may not preserve semantics, particularly when the computation is sensitive to the ordering of data items, our programming abstractions allow a natural specification of the query that contains a mix of ordering constraints while guaranteeing correct deployment, and (2) the throughput of the automatically compiled distributed code is comparable to that of hand-crafted distributed implementations.},
booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {670–685},
numpages = {16},
keywords = {types, distributed data stream processing},
location = {Phoenix, AZ, USA},
series = {PLDI 2019}
}

@inproceedings{10.1145/2933267.2933514,
author = {Martin, Andr\'{e} and Brito, Andrey and Fetzer, Christof},
title = {Real-Time Social Network Graph Analysis Using StreamMine3G},
year = {2016},
isbn = {9781450340212},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2933267.2933514},
doi = {10.1145/2933267.2933514},
abstract = {In this paper, we present our approach for solving the DEBS Grand Challenge 2016 using StreamMine3G, a distributed, highly scalable, elastic and fault tolerant event stream processing (ESP) system. We first provide an overview about StreamMine3G with regards to its programming model and architecture, followed by thorough description of the implementation for the two queries that provide up-to-date information about (i) the top-3 active posts and (ii) the top-k comments with the largest maximum cliques. Novel aspects of our implementation include (i) highly optimized data structures that lower the amount of lookups and traversals, and a (ii) deterministic data partitioning and processing scheme that allows the system to scale without bounds in an elastic fashion while still guaranteeing semantic transparency. In order to better utilize nowadays many-core machines, we furthermore propose a pipelining scheme in addition to data partitioning. Finally, we present a brief performance evaluation of our system.},
booktitle = {Proceedings of the 10th ACM International Conference on Distributed and Event-Based Systems},
pages = {322–329},
numpages = {8},
keywords = {CEP, scalability, state management, migration, fault tolerance, complex event processing, ESP, event stream processing},
location = {Irvine, California},
series = {DEBS '16}
}

@inproceedings{10.1145/3437378.3444365,
author = {Qi, Tianyu and Rodriguez, Maria},
title = {A Traffic and Resource Aware Online Storm Scheduler},
year = {2021},
isbn = {9781450389563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437378.3444365},
doi = {10.1145/3437378.3444365},
abstract = {Streaming applications have become widespread with the advent of big data and IoT. They are latency-sensitive applications that aim to process vast amounts of data in near real time. They are usually modelled as directed graphs and their deployment and orchestration in a cluster of nodes are managed by distributed stream processing systems. These systems are responsible for placing the graph components within the cluster nodes, which determines the application’s communication overhead and ultimately affects performance metrics such as latency and throughput. This work presents an adaptive, heuristic-based, scheduling algorithm for distributed stream processing systems that aims to minimize the latency and maximize the throughput of streaming applications deployed in heterogeneous clusters, while considering the resource constraints of the available nodes. The proposed approach uses a graph partitioning algorithm and real time traffic data monitored from a deployed application to derive a near-optimal operator placement plan that minimizes inter-node communication and balances the overall communication load distribution. We evaluated our approach using three micro-benchmark and two practical applications, and the results demonstrate that our scheduler outperforms the default scheduler of a popular stream processing system and a state-of-the-art algorithm, improving throughput by up to 106% and reducing complete latency by up to 58% for most applications.},
booktitle = {2021 Australasian Computer Science Week Multiconference},
articleno = {8},
numpages = {10},
keywords = {Scheduling, Stream Processing, Graph partitioning, Storm},
location = {Dunedin, New Zealand},
series = {ACSW '21}
}

@inproceedings{10.1145/2814576.2814808,
author = {Peng, Boyang and Hosseini, Mohammad and Hong, Zhihao and Farivar, Reza and Campbell, Roy},
title = {R-Storm: Resource-Aware Scheduling in Storm},
year = {2015},
isbn = {9781450336185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814576.2814808},
doi = {10.1145/2814576.2814808},
abstract = {The era of big data has led to the emergence of new systems for real-time distributed stream processing, e.g., Apache Storm is one of the most popular stream processing systems in industry today. However, Storm, like many other stream processing systems lacks an intelligent scheduling mechanism. The default round-robin scheduling currently deployed in Storm disregards resource demands and availability, and can therefore be inefficient at times. We present R-Storm (Resource-Aware Storm), a system that implements resource-aware scheduling within Storm. R-Storm is designed to increase overall throughput by maximizing resource utilization while minimizing network latency. When scheduling tasks, R-Storm can satisfy both soft and hard resource constraints as well as minimizing network distance between components that communicate with each other. We evaluate R-Storm on set of micro-benchmark Storm applications as well as Storm applications used in production at Yahoo! Inc. From our experimental results we conclude that R-Storm achieves 30-47% higher throughput and 69-350% better CPU utilization than default Storm for the micro-benchmarks. For the Yahoo! Storm applications, R-Storm outperforms default Storm by around 50% based on overall throughput. We also demonstrate that R-Storm performs much better when scheduling multiple Storm applications than default Storm.},
booktitle = {Proceedings of the 16th Annual Middleware Conference},
pages = {149–161},
numpages = {13},
keywords = {Stream Processing, Resource-Aware Scheduling, Storm},
location = {Vancouver, BC, Canada},
series = {Middleware '15}
}

@inproceedings{10.1145/3524860.3539639,
author = {Heinrich, Roman and Luthra, Manisha and Kornmayer, Harald and Binnig, Carsten},
title = {Zero-Shot Cost Models for Distributed Stream Processing},
year = {2022},
isbn = {9781450393089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524860.3539639},
doi = {10.1145/3524860.3539639},
abstract = {This paper proposes a learned cost estimation model for Distributed Stream Processing Systems (DSPS) with an aim to provide accurate cost predictions of executing queries. A major premise of this work is that the proposed learned model can generalize to the dynamics of streaming workloads out-of-the-box. This means a model once trained can accurately predict performance metrics such as latency and throughput even if the characteristics of the data and workload or the deployment of operators to hardware changes at runtime. That way the model can be used to solve tasks such as optimizing the placement of operators to minimize the end-to-end latency of a streaming query or maximize its throughput even under varying conditions. Our evaluation on a well-known DSPS, Apache Storm, shows that the model can predict accurately for unseen workloads and queries while generalizing across real-world benchmarks.},
booktitle = {Proceedings of the 16th ACM International Conference on Distributed and Event-Based Systems},
pages = {85–90},
numpages = {6},
keywords = {stream processing, zero-shot learning, cost models},
location = {Copenhagen, Denmark},
series = {DEBS '22}
}

@inproceedings{10.1145/3341105.3374111,
author = {Mebrek, Wafaa and Bouzeghoub, Amel},
title = {A Stream Reasoning Framework Based on a Multi-Agents Model},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3374111},
doi = {10.1145/3341105.3374111},
abstract = {Processing on-the-fly high volume of data streams is increasingly needed. To cope with the heterogeneity of this data, RDF model is more and more being adopted leading to plethora of RDF Stream Processing (RSP) systems and languages dealing with issues such as continuous querying, incremental reasoning and complex event processing (CEP). However, most of them has implemented centralized approaches and therefore suffer from some limitations as collaboration, sharing, expressiveness and scalability. Multi-agents systems have widely proven their worth and efficiency in particular their intrinsic decentralized property along with their cooperation and communication mechanism. In this paper we propose a new framework MAS4MEAN (Multi-Agent System for streaM rEAsoNing) based on a multi-agents model to embrace their benefits and tackle the challenges of increasing the scalability and ease of deployment in highly dynamic environments. A preliminary experimental evaluation with a real-world dataset show promising results when compared to an existing work.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {509–512},
numpages = {4},
keywords = {multi-agents systems, stream processing, stream reasoning, RDF streams},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@inproceedings{10.1145/3401025.3401732,
author = {Farhat, Omar and Bindra, Harsh and Daudjee, Khuzaima},
title = {Leaving Stragglers at the Window: Low-Latency Stream Sampling with Accuracy Guarantees},
year = {2020},
isbn = {9781450380287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3401025.3401732},
doi = {10.1145/3401025.3401732},
abstract = {Stream Processing Engines (SPEs) are used to process large volumes of application data to emit high velocity output. Under high load, SPEs aim to minimize output latency by leveraging sample processing for many applications that can tolerate approximate results. Sample processing limits input to only a subset of events such that the sample is statistically representative of the input while ensuring output accuracy guarantees. For queries containing window operators, sample processing continuously samples events until all events relevant to the window operator have been ingested. However, events can suffer from large ingestion delays due to long or bursty network latencies. This leads to stragglers that are events generated within the window's timeline but are delayed beyond the window's deadline. Window computations that account for stragglers can add significant latency while providing inconsequential accuracy improvement. We propose Aion, an algorithm that utilizes sampling to provide approximate answers with low latency by minimizing the effect of stragglers. Aion quickly processes the window to minimize output latency while still achieving high accuracy guarantees. We implement Aion in Apache Flink and show using benchmark workloads that Aion reduces stream output latency by up to 85% while providing 95% accuracy guarantees.},
booktitle = {Proceedings of the 14th ACM International Conference on Distributed and Event-Based Systems},
pages = {15–26},
numpages = {12},
keywords = {sampling, windows, watermark, stream processing},
location = {Montreal, Quebec, Canada},
series = {DEBS '20}
}

@inproceedings{10.1145/3533028.3533308,
author = {Horchidan, Sonia and Kritharakis, Emmanouil and Kalavri, Vasiliki and Carbone, Paris},
title = {Evaluating Model Serving Strategies over Streaming Data},
year = {2022},
isbn = {9781450393751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3533028.3533308},
doi = {10.1145/3533028.3533308},
abstract = {We present the first performance evaluation study of model serving integration tools in stream processing frameworks. Using Apache Flink as a representative stream processing system, we evaluate alternative Deep Learning serving pipelines for image classification. Our performance evaluation considers both the case of embedded use of Machine Learning libraries within stream tasks and that of external serving via Remote Procedure Calls. The results indicate superior throughput and scalability for pipelines that make use of embedded libraries to serve pre-trained models. Whereas, latency can vary across strategies, with external serving even achieving lower latency when network conditions are optimal due to better specialized use of underlying hardware. We discuss our findings and provide further motivating arguments towards research in the area of ML-native data streaming engines in the future.},
booktitle = {Proceedings of the Sixth Workshop on Data Management for End-To-End Machine Learning},
articleno = {4},
numpages = {5},
keywords = {data streams, machine learning inference},
location = {Philadelphia, Pennsylvania},
series = {DEEM '22}
}

@inproceedings{10.1145/3448016.3452794,
author = {Farhat, Omar and Daudjee, Khuzaima and Querzoni, Leonardo},
title = {Klink: Progress-Aware Scheduling for Streaming Data Systems},
year = {2021},
isbn = {9781450383431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448016.3452794},
doi = {10.1145/3448016.3452794},
abstract = {Modern stream processing engines (SPEs) process large volumes of events propagated at high velocity through multiple queries. To improve performance, existing SPEs generally aim to minimize query output latency by minimizing, in turn, the propagation delay of events in query pipelines. However, for queries containing commonly used blocking operators such as windows, this scheduling approach can be inefficient. Watermarks are events popularly utilized by SPEs to correctly process window operators. Watermarks are injected into the stream to signify that no events preceding their timestamp should be further expected. Through the design and development of Klink, we leverage these watermarks to robustly infer stream progress based on window deadlines and network delay, and to schedule query pipeline execution that reflects stream progress. Klink aims to unblock window operators and to rapidly propagate events to output operators while performing judicious memory management. We integrate Klink into the popular open source SPE Apache Flink and demonstrate that Klink delivers significant performance gains over existing scheduling policies on benchmark workloads for both scale-up and scale-out deployments.},
booktitle = {Proceedings of the 2021 International Conference on Management of Data},
pages = {485–498},
numpages = {14},
keywords = {scheduling, watermarks, stream processing, windows},
location = {Virtual Event, China},
series = {SIGMOD '21}
}

@inproceedings{10.1109/UCC.2014.46,
author = {Bellavista, Paolo and Corradi, Antonio and Reale, Andrea and Ticca, Nicola},
title = {Priority-Based Resource Scheduling in Distributed Stream Processing Systems for Big Data Applications},
year = {2014},
isbn = {9781479978816},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UCC.2014.46},
doi = {10.1109/UCC.2014.46},
abstract = {Distributed Stream Processing Systems (DSPSs) are attracting increasing industrial and academic interest as flexible tools to implement scalable and cost-effective on-line analytics applications over Big Data streams. Often hosted in private/public cloud deployment environments, DSPSs offer data stream processing services that transparently exploit the distributed computing resources made available to them at runtime. Given the volume of data of interest, possible (hard/soft) real-time processing requirements, and the time-variable characteristics of input data streams, it is very important for DSPSs to use smart and innovative scheduling techniques that allocate computing resources properly and avoid static over-provisioning. In this paper, we originally investigate the suitability of exploiting application-level indications about differentiated priorities of different stream processing tasks to enable application-specific DSPS resource scheduling, e.g., Capable of re-shaping processing resources in order to dynamically follow input data peaks of prioritized tasks, with no static over-provisioning. We originally propose a general and simple technique to design and implement priority-based resource scheduling in flow-graph-based DSPSs, by allowing application developers to augment DSPS graphs with priority metadata and by introducing an extensible set of priority schemas to be automatically handled by the extended DSPS. In addition, we show the effectiveness of our approach via its implementation and integration in our Quasit DSPS and through experimental evaluation of this prototype on a real-world stream processing application of Big Data vehicular traffic analysis.},
booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
pages = {363–370},
numpages = {8},
keywords = {Priority-based Resource Scheduling, Cloud Computing Optimization, Distributed Stream Processing, Big Data, Vehicular Traffic Analysis, Application-level and Application-specific Scheduling},
series = {UCC '14}
}

@inproceedings{10.1145/1385989.1386014,
author = {White, Seth and Alves, Alexandre and Rorke, David},
title = {WebLogic Event Server: A Lightweight, Modular Application Server for Event Processing},
year = {2008},
isbn = {9781605580906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1385989.1386014},
doi = {10.1145/1385989.1386014},
abstract = {This paper describes WebLogic Event Server (WL EvS), an application server designed for hosting event-driven applications that require low latency and deterministic behavior. WL EvS is based on a modular architecture in which both server components and applications are represented as modules. The application programming model supports applications that are a mixture of reusable Java components and EPL (Event Processing Language), a query language that extends SQL with stream processing capabilities. WL EvS applications are meta-data driven, in that application behavior can be changed without recompilation or redeploying an application. The paper also presents the results of a benchmark performance study. The results show that the approach used by WL EvS can handle extremely high volumes of events while providing deterministic latency.},
booktitle = {Proceedings of the Second International Conference on Distributed Event-Based Systems},
pages = {193–200},
numpages = {8},
keywords = {complex event processing, Java, application server, Spring, stream processing, OSGi},
location = {Rome, Italy},
series = {DEBS '08}
}

@article{10.1145/3571158,
author = {Mostafaei, Habib and Afridi, Shafi},
title = {SDN-Enabled Resource Provisioning Framework for Geo-Distributed Streaming Analytics},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1533-5399},
url = {https://doi.org/10.1145/3571158},
doi = {10.1145/3571158},
abstract = {Geographically distributed (geo-distributed) datacenters for stream data processing typically comprise multiple edges and core datacenters connected through Wide-Area Network (WAN) with a master node responsible for allocating tasks to worker nodes. Since WAN links significantly impact the performance of distributed task execution, the existing task assignment approach is unsuitable for distributed stream data processing with low latency and high throughput demand. In this paper, we propose a resource provisioning framework using the Software-Defined Networking (SDN) concept with an SDN controller responsible for monitoring the WAN, selecting an appropriate subset of worker nodes, and assigning tasks to the designated worker nodes. We implemented the data plane of the framework in P4 and the control plane components in Python. We tested the performance of the proposed system on Apache Spark, Apache Storm, and Apache Flink using the Yahoo! streaming benchmark on a set of custom topologies. The results of the experiments validate that the proposed approach is viable for distributed stream processing and confirm that it can improve at least 1.64x the processing time of incoming events of the current stream processing systems.},
note = {Just Accepted},
journal = {ACM Trans. Internet Technol.},
month = {nov},
keywords = {Cluster manager, Geo-distributed Stream analytics, Stream processing, Software-Defined Networking (SDN)}
}

@inproceedings{10.1145/2955193.2955206,
author = {Du, Guangxiang and Gupta, Indranil},
title = {New Techniques to Curtail the Tail Latency in Stream Processing Systems},
year = {2016},
isbn = {9781450342209},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2955193.2955206},
doi = {10.1145/2955193.2955206},
abstract = {This paper presents a series of novel techniques for reducing the tail latency in stream processing systems like Apache Storm. Concretely, we present three mechanisms: (1) adaptive timeout coupled with selective replay to catch straggler tuples; (2) shared queues among different tasks of the same operator to reduce overall queueing delay; (3) latency feedback-based load balancing, intended to mitigate heterogenous scenarios. We have implemented these techniques in Apache Storm, and present experimental results using sets of micro-benchmarks as well as two topologies from Yahoo! Inc. Our results show improvement in tail latency up to 72.9%.},
booktitle = {Proceedings of the 4th Workshop on Distributed Cloud Computing},
articleno = {7},
numpages = {6},
keywords = {apache storm, tail latency, stream processing systems},
location = {Chicago, Illinois},
series = {DCC '16}
}

@article{10.1145/3428221,
author = {Kallas, Konstantinos and Niksic, Filip and Stanford, Caleb and Alur, Rajeev},
title = {DiffStream: Differential Output Testing for Stream Processing Programs},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {OOPSLA},
url = {https://doi.org/10.1145/3428221},
doi = {10.1145/3428221},
abstract = {High performance architectures for processing distributed data streams, such as Flink, Spark Streaming, and Storm, are increasingly deployed in emerging data-driven computing systems. Exploiting the parallelism afforded by such platforms, while preserving the semantics of the desired computation, is prone to errors, and motivates the development of tools for specification, testing, and verification. We focus on the problem of differential output testing for distributed stream processing systems, that is, checking whether two implementations produce equivalent output streams in response to a given input stream. The notion of equivalence allows reordering of logically independent data items, and the main technical contribution of the paper is an optimal online algorithm for checking this equivalence. Our testing framework is implemented as a library called DiffStream in Flink. We present four case studies to illustrate how our framework can be used to (1) correctly identify bugs in a set of benchmark MapReduce programs, (2) facilitate the development of difficult-to-parallelize high performance applications, and (3) monitor an application for a long period of time with minimal performance overhead.},
journal = {Proc. ACM Program. Lang.},
month = {nov},
articleno = {153},
numpages = {29},
keywords = {stream processing, differential testing, runtime verification}
}

@article{10.1145/1269899.1254898,
author = {Xia, Cathy H. and Liu, Zhen and Towsley, Don and Lelarge, Marc},
title = {Scalability of Fork/Join Queueing Networks with Blocking},
year = {2007},
issue_date = {June 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/1269899.1254898},
doi = {10.1145/1269899.1254898},
abstract = {This paper investigates how the through put of a general fork-join queueing network with blocking behaves as the number of nodes increases to infinity while the processing speed and buffer space of each node stay unchanged. The problem is motivated by applications arising from distributed systems and computer networks. One example is large-scale distributed stream processing systems where TCP is used as the transport protocol for data transfer in between processing components. Other examples include reliable multicast in overlay networks, and reliable data transfer in ad hoc networks. Using an analytical approach, the paper establishes bounds on the asymptotic throughput of such a network. For a subclass of networks which are balanced, we obtain sufficient conditions under which the network stays scalable in the sense that the throughput is lower bounded by a positive constant as the network size increases. Necessary conditions of throughput scalability are derived for general networks. The special class of series-parallel networks is then studied in greater detail, where the asymptotic behavior of the throughput is characterized.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jun},
pages = {133–144},
numpages = {12},
keywords = {fork and join, scalability, queueing networks, throughput, asymptotic analysis, blocking}
}

@inproceedings{10.1145/1254882.1254898,
author = {Xia, Cathy H. and Liu, Zhen and Towsley, Don and Lelarge, Marc},
title = {Scalability of Fork/Join Queueing Networks with Blocking},
year = {2007},
isbn = {9781595936394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1254882.1254898},
doi = {10.1145/1254882.1254898},
abstract = {This paper investigates how the through put of a general fork-join queueing network with blocking behaves as the number of nodes increases to infinity while the processing speed and buffer space of each node stay unchanged. The problem is motivated by applications arising from distributed systems and computer networks. One example is large-scale distributed stream processing systems where TCP is used as the transport protocol for data transfer in between processing components. Other examples include reliable multicast in overlay networks, and reliable data transfer in ad hoc networks. Using an analytical approach, the paper establishes bounds on the asymptotic throughput of such a network. For a subclass of networks which are balanced, we obtain sufficient conditions under which the network stays scalable in the sense that the throughput is lower bounded by a positive constant as the network size increases. Necessary conditions of throughput scalability are derived for general networks. The special class of series-parallel networks is then studied in greater detail, where the asymptotic behavior of the throughput is characterized.},
booktitle = {Proceedings of the 2007 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {133–144},
numpages = {12},
keywords = {scalability, asymptotic analysis, queueing networks, fork and join, throughput, blocking},
location = {San Diego, California, USA},
series = {SIGMETRICS '07}
}

@article{10.1145/3410048.3410060,
author = {Aral, Atakan and Erol-Kantarci, Melike and Brandi\'{c}, Ivona},
title = {Staleness Control for Edge Data Analytics},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/3410048.3410060},
doi = {10.1145/3410048.3410060},
abstract = {A new generation of cyber-physical systems has emerged with a large number of devices that continuously generate and consume massive amounts of data in a distributed and mobile manner. Accurate and near real-time decisions based on such streaming data are in high demand in many areas of optimization for such systems. Edge data analytics bring processing power in the proximity of data sources, reduce the network delay for data transmission, allowlargescale distributed training, and consequently help meeting real-time requirements. Nevertheless, the multiplicity of data sources leads to multiple distributed machine learning models that may suffer from sub-optimal performance due to the inconsistency in their states. In this work, we tackle the insularity, concept drift, and connectivity issues in edge data analytics to minimize its accuracy handicap without losing its timeliness benefits. Thus, we propose an efficient model synchronization mechanism for distributed and stateful data analytics. Staleness Control for Edge Data Analytics (SCEDA) ensures the high adaptability of synchronization frequency in the face of an unpredictable environment by addressing the trade-off between the generality and timeliness of the model.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jul},
pages = {19–20},
numpages = {2},
keywords = {edge computing, concept drift, reinforcement learning., non-stationarity, staleness control, data stream processing}
}

@inproceedings{10.1145/3337821.3337870,
author = {Wang, Yidan and Tari, Zahir and Huang, Xiaoran and Zomaya, Albert Y.},
title = {A Network-Aware and Partition-Based Resource Management Scheme for Data Stream Processing},
year = {2019},
isbn = {9781450362955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3337821.3337870},
doi = {10.1145/3337821.3337870},
abstract = {With the increasing demand for data-driven decision making, there is an urgent need for processing geographically distributed data streams in real-time. The existing scheduling and resource management schemes efficiently optimize stream processing performance with the awareness of resource, quality-of-service, and network traffic. However, the correlation between network delay and inter-operator communication pattern is not well-understood. In this study, we propose a network-aware and partition-based resource management scheme to deal with the ever-changing network condition and data communication in stream processing. The proposed approach applies operator fusion by considering the computational demand of individual operators and the inter-operator communication patterns. It maps the fused operators to the clustered hosts with the weighted shortest processing time heuristic. Meanwhile, we established a 3-dimensional coordinate system for prompt reflection of the network condition, real-time traffic, and resource availability. We evaluated the proposed approach against two benchmarks, and the results demonstrate the efficiency in throughput and resource utilization. We also conducted a case study and implemented a prototype system supported by the proposed approach that aims to utilize the stream processing paradigm for pedestrian behavior analysis. The prototype application estimates walking time for a given path according to the real crowd traffic. The promising evaluation results of processing performance further illustrate the efficiency of the proposed approach.},
booktitle = {Proceedings of the 48th International Conference on Parallel Processing},
articleno = {20},
numpages = {10},
keywords = {Apache Storm, Pedestrian Behavior, Data Stream Processing},
location = {Kyoto, Japan},
series = {ICPP 2019}
}

@inproceedings{10.1145/3448016.3457320,
author = {Silvestre, Pedro F. and Fragkoulis, Marios and Spinellis, Diomidis and Katsifodimos, Asterios},
title = {Clonos: Consistent Causal Recovery for Highly-Available Streaming Dataflows},
year = {2021},
isbn = {9781450383431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448016.3457320},
doi = {10.1145/3448016.3457320},
abstract = {Stream processing lies in the backbone of modern businesses, being employed for mission critical applications such as real-time fraud detection, car-trip fare calculations, traffic management, and stock trading. Large-scale applications are executed by scale-out stream processing systems on thousands of long-lived operators, which are subject to failures. Recovering from failures fast and consistently are both top priorities, yet they are only partly satisfied by existing fault tolerance methods due to the strong assumptions these make. In particular, prior solutions fail to address consistency in the presence of nondeterminism, such as calls to external services, asynchronous timers and processing-time windows. This paper describes Clonos, a fault tolerance approach that achieves fast, local operator recovery with exactly-once guarantees and high availability by instantly switching to passive standby operators. Clonos enforces causally consistent recovery, including output deduplication, by tracking nondeterminism within the system through causal logging. To implement Clonos we re-engineered many of the internal subsystems of a state of the art stream processor. We evaluate Clonos' overhead and recovery on the Nexmark benchmark against Apache Flink. Clonos achieves instant recovery with negligible overhead and, unlike previous work, does not make assumptions on the deterministic nature of operators.},
booktitle = {Proceedings of the 2021 International Conference on Management of Data},
pages = {1637–1650},
numpages = {14},
keywords = {high-availability, consistency, stream processing, exactly-once, cloud computing, fault-tolerance},
location = {Virtual Event, China},
series = {SIGMOD '21}
}

@inproceedings{10.1145/1807128.1807139,
author = {He, Bingsheng and Yang, Mao and Guo, Zhenyu and Chen, Rishan and Su, Bing and Lin, Wei and Zhou, Lidong},
title = {Comet: Batched Stream Processing for Data Intensive Distributed Computing},
year = {2010},
isbn = {9781450300360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807128.1807139},
doi = {10.1145/1807128.1807139},
abstract = {Batched stream processing is a new distributed data processing paradigm that models recurring batch computations on incrementally bulk-appended data streams. The model is inspired by our empirical study on a trace from a large-scale production data-processing cluster; it allows a set of effective query optimizations that are not possible in a traditional batch processing model.We have developed a query processing system called Comet that embraces batched stream processing and integrates with DryadLINQ. We used two complementary methods to evaluate the effectiveness of optimizations that Comet enables. First, a prototype system deployed on a 40-node cluster shows an I/O reduction of over 40% using our benchmark. Second, when applied to a real production trace covering over 19 million machine-hours, our simulator shows an estimated I/O saving of over 50%.},
booktitle = {Proceedings of the 1st ACM Symposium on Cloud Computing},
pages = {63–74},
numpages = {12},
keywords = {data-intensive scalable computing, query series, batched stream processing, resource management},
location = {Indianapolis, Indiana, USA},
series = {SoCC '10}
}

@article{10.1145/3092819.3092823,
author = {Cardellini, Valeria and Grassi, Vincenzo and Lo Presti, Francesco and Nardelli, Matteo},
title = {Optimal Operator Replication and Placement for Distributed Stream Processing Systems},
year = {2017},
issue_date = {March 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {4},
issn = {0163-5999},
url = {https://doi.org/10.1145/3092819.3092823},
doi = {10.1145/3092819.3092823},
abstract = {Exploiting on-the-fly computation, Data Stream Processing (DSP) applications are widely used to process unbounded streams of data and extract valuable information in a near real-time fashion. As such, they enable the development of new intelligent and pervasive services that can improve our everyday life. To keep up with the high volume of daily produced data, the operators that compose a DSP application can be replicated and placed on multiple, possibly distributed, computing nodes, so to process the incoming data flow in parallel. Moreover, to better exploit the abundance of diffused computational resources (e.g., Fog computing), recent trends investigate the possibility of decentralizing the DSP application placement.In this paper, we present and evaluate a general formulation of the optimal DSP replication and placement (ODRP) as an integer linear programming problem, which takes into account the heterogeneity of application requirements and infrastructural resources. We integrate ODRP as prototype scheduler in the Apache Storm DSP framework. By leveraging on the DEBS 2015 Grand Challenge as benchmark application, we show the benefits of a joint optimization of operator replication and placement and how ODRP can optimize different QoS metrics, namely response time, internode traffic, cost, availability, and a combination thereof.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {may},
pages = {11–22},
numpages = {12}
}

@article{10.1145/1384529.1375493,
author = {Liu, Shao and Zhang-Shen, Rui and Jiang, Wenjie and Rexford, Jennifer and Chiang, Mung},
title = {Performance Bounds for Peer-Assisted Live Streaming},
year = {2008},
issue_date = {June 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/1384529.1375493},
doi = {10.1145/1384529.1375493},
abstract = {Peer-assisted streaming is a promising way for service providers to offer high-quality IPTV to consumers at reasonable cost. In peer-assisted streaming, the peers exchange video chunks with one another, and receive additional data from the central server as needed. In this paper, we analyze how to provision resources for the streaming system, in terms of the server capacity, the video quality, and the depth of the distribution trees that deliver the content. We derive the performance bounds for minimum server load, maximum streaming rate, and minimum tree depth under different peer selection constraints. Furthermore, we show that our performance bounds are actually tight, by presenting algorithms for constructing trees that achieve our bounds.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jun},
pages = {313–324},
numpages = {12},
keywords = {tree construction, video, streaming, IPTV, peer-to-peer}
}

@inproceedings{10.1145/1375457.1375493,
author = {Liu, Shao and Zhang-Shen, Rui and Jiang, Wenjie and Rexford, Jennifer and Chiang, Mung},
title = {Performance Bounds for Peer-Assisted Live Streaming},
year = {2008},
isbn = {9781605580050},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1375457.1375493},
doi = {10.1145/1375457.1375493},
abstract = {Peer-assisted streaming is a promising way for service providers to offer high-quality IPTV to consumers at reasonable cost. In peer-assisted streaming, the peers exchange video chunks with one another, and receive additional data from the central server as needed. In this paper, we analyze how to provision resources for the streaming system, in terms of the server capacity, the video quality, and the depth of the distribution trees that deliver the content. We derive the performance bounds for minimum server load, maximum streaming rate, and minimum tree depth under different peer selection constraints. Furthermore, we show that our performance bounds are actually tight, by presenting algorithms for constructing trees that achieve our bounds.},
booktitle = {Proceedings of the 2008 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {313–324},
numpages = {12},
keywords = {streaming, video, tree construction, IPTV, peer-to-peer},
location = {Annapolis, MD, USA},
series = {SIGMETRICS '08}
}

@article{10.1145/1639562.1639596,
author = {Liu, Yang and Zhang, Linfeng and Guan, Yong},
title = {A Distributed Data Streaming Algorithm for Network-Wide Traffic Anomaly Detection},
year = {2009},
issue_date = {September 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {2},
issn = {0163-5999},
url = {https://doi.org/10.1145/1639562.1639596},
doi = {10.1145/1639562.1639596},
abstract = {Nowadays, Internet has serious security problems and network failures that are hard to resolve, for example, botnet attacks, polymorphic worm/virus spreading, DDoS, and flash crowds. To address many of these problems, we need to have a network-wide view of the traffic dynamics, and more importantly, be able to detect traffic anomaly in a timely manner. To our knowledge, Principle Component Analysis (PCA)is the best-known spatial detection method for the network-wide traffic anomaly. However, existing PCA-based solutions have scalability problems in that they require O(m2 n)running time and O(mn)space to analyze traffic measurements from m aggregated traffic flows within a sliding window of the length n. We propose a novel data streaming algorithm for PCA-based network-wide traffic anomaly detection in a distributed fashion. Our algorithm can archive O(wn log n)running time and O(wn)space at local monitors,and O(m2 log n)running time and O(m log n) space at Network Operation Center (NOC), where w denotes the maximum number of traffic flows at a local monitor.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {oct},
pages = {81–82},
numpages = {2}
}

@inproceedings{10.1145/2933267.2933300,
author = {Rinne, Mikko and Solanki, Monika and Nuutila, Esko},
title = {RFID-Based Logistics Monitoring with Semantics-Driven Event Processing},
year = {2016},
isbn = {9781450340212},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2933267.2933300},
doi = {10.1145/2933267.2933300},
abstract = {In this paper a real-life counterfeit and theft detection scenario from pharmaceutical manufacturing is modelled using events encoded as XML and RDF. With Esper and Instans event processing platforms, the second one from the semantic web domain, the same task is configured and an experimental performance evaluation is carried out. Our results show that even though the starting points are very different, the same core task can be accomplished on both platforms. We provide quantitative performance comparisons that corroborate our analysis. For an understanding of what can be expected from each framework outside the core task, the differences between the two tools and their respective domains are qualitatively analysed.},
booktitle = {Proceedings of the 10th ACM International Conference on Distributed and Event-Based Systems},
pages = {238–245},
numpages = {8},
keywords = {EPCIS, stream processing, RFID, complex event processing, IoT, supply chain logistics, SPARQL},
location = {Irvine, California},
series = {DEBS '16}
}

@article{10.1145/2479957.2479962,
author = {Simoncelli, Davide and Dusi, Maurizio and Gringoli, Francesco and Niccolini, Saverio},
title = {Stream-Monitoring with Blockmon: Convergence of Network Measurements and Data Analytics Platforms},
year = {2013},
issue_date = {April 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {2},
issn = {0146-4833},
url = {https://doi.org/10.1145/2479957.2479962},
doi = {10.1145/2479957.2479962},
abstract = {Recent work in network measurements focuses on scaling the performance of monitoring platforms to 10Gb/s and beyond. Concurrently, IT community focuses on scaling the analysis of big-data over a cluster of nodes. So far, combinations of these approaches have targeted flexibility and usability over real-timeliness of results and efficient allocation of resources. In this paper we show how to meet both objectives with BlockMon, a network monitoring platform originally designed to work on a single node, which we extended to run distributed stream-data analytics tasks. We compare its performance against Storm and Apache S4, the state-of-the-art open-source stream-processing platforms, by implementing a phone call anomaly detection system and a Twitter trending algorithm: our enhanced BlockMon has a gain in performance of over 2.5x and 23x, respectively. Given the different nature of those applications and the performance of BlockMon as single-node network monitor [1], we expect our results to hold for a broad range of applications, making distributed BlockMon a good candidate for the convergence of network-measurement and IT-analysis platforms.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = {apr},
pages = {29–36},
numpages = {8},
keywords = {performance analysis, data analysis, distributed computing}
}

