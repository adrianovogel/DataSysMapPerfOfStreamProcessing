@INPROCEEDINGS{7027482,
author={Lu, Ruirui and Wu, Gang and Xie, Bin and Hu, Jingtong},
booktitle={2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
title={Stream Bench: Towards Benchmarking Modern Distributed Stream Computing Frameworks},
year={2014},
volume={},
number={},
pages={69-78},
abstract={While big data is becoming ubiquitous, interest in handling data stream at scale is also gaining popularity, which leads to the sprout of many distributed stream computing systems. However, complexity of stream computing and diversity of workloads expose great challenges to benchmark these systems. Due to lack of standard criteria, evaluations and comparisons of these systems tend to be difficult. This paper takes an early step towards benchmarking modern distributed stream computing frameworks. After identifying the challenges and requirements in the field, we raise our benchmark definition Stream Bench regarding the requirements. Stream Bench proposes a message system functioning as a mediator between stream data generation and consumption. It also covers 7 benchmark programs that intend to address typical stream computing scenarios and core operations. Not only does it care about performance of systems under different data scales, but also takes fault tolerance ability and durability into account, which drives to incorporate four workload suites targeting at these various aspects of systems. Finally, we illustrate the feasibility of Stream Bench by applying it to two popular frameworks, Apache Storm and Apache Spark Streaming. We draw comparisons from various perspectives between the two platforms with workload suites of Stream Bench. In addition, we also demonstrate performance improvement of Storm's latest version with the benchmark.},
keywords={Benchmark testing;Measurement;Message systems;Throughput;Fault tolerance;Fault tolerant systems;Storms;distributed stream computing;benchmark;big data},
doi={10.1109/UCC.2014.15},
ISSN={},
month={Dec},}
@INPROCEEDINGS{4014007,
author={Dana, Chris and Li, Danjue and Harrison, David and Chuah, Chen-nee},
booktitle={2005 IEEE 7th Workshop on Multimedia Signal Processing},
title={BASS: BitTorrent Assisted Streaming System for Video-on-Demand},
year={2005},
volume={},
number={},
pages={1-4},
abstract={This paper introduces a hybrid server/P2P streaming system called bittorrent-assisted streaming system (BASS) for large-scale video-on-demand (VoD) services. By distributing the load among P2P connections as well as maintaining active server connections, BASS can increase the system scalability while decreasing media playout wait times. To analyze the benefits of BASS, we examine torrent trace data collected in the first week of distribution for Fedora Core 3 and develop an empirical model of bittorrent client performance. Based on this, we run trace-based simulations to evaluate BASS and show that it is more scalable than current unicast solutions and can greatly decrease the average waiting time before playback},
keywords={Streaming media;Scalability;Performance analysis;Analytical models;Large-scale systems;Unicast;Multimedia systems;System performance;Network servers;Peer to peer computing},
doi={10.1109/MMSP.2005.248586},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6005385,
author={Ajwani, Deepak and Ali, Shoukat and Katrinis, Kostas and Li, Cheng-Hong and Park, Alfred J. and Morrison, John P. and Schenfeld, Eugen},
booktitle={2011 IEEE 19th Annual International Symposium on Modelling, Analysis, and Simulation of Computer and Telecommunication Systems},
title={A Flexible Workload Generator for Simulating Stream Computing Systems},
year={2011},
volume={},
number={},
pages={409-417},
abstract={Stream computing is an emerging computational model for performing complex operations on and across multi-source, high volume data flows. Given that the deployment of the model has only started, the pool of mature applications employing this model is fairly small, and therefore the availability of workloads for various types of applications is scarce. Thus, there is a need for synthetic generation of large-scale workloads for evaluation of stream computing applications at scale. This paper presents a framework for producing synthetic workloads for stream computing systems. Our framework extends known random graph generation concepts with stream computing specific features, providing researchers with realistic input stream graphs and allowing them to focus on system development, optimization and analysis. Serving the goal of covering a disparity of potential applications, the presented framework exhibits high user-controlled configurability. The produced workloads could be used to drive simulations for performance evaluation and for proof-of-concept prototyping of processing, networking and operating system hardware and software.},
keywords={Generators;Kernel;Computational modeling;Data models;Solid modeling;Real time systems;Monitoring},
doi={10.1109/MASCOTS.2011.54},
ISSN={2375-0227},
month={July},}
@INPROCEEDINGS{8035150,
author={Cole, Stephen V. and Buhler, Jeremy},
booktitle={2017 International Conference on High Performance Computing & Simulation (HPCS)},
title={MERCATOR: A GPGPU Framework for Irregular Streaming Applications},
year={2017},
volume={},
number={},
pages={727-736},
abstract={GPUs have a natural affinity for streaming applications exhibiting consistent, predictable dataflow. However, many high-impact irregular streaming applications, including sequence pattern matching, decision-tree and decision-cascade evaluation, and large-scale graph processing, exhibit unpredictable dataflow due to data-dependent filtering or expansion of the data stream. Existing GPU frameworks do not support arbitrary irregular streaming dataflow tasks, and developing application-specific optimized implementations for such tasks requires expert GPU knowledge. We introduce MERCATOR, a lightweight framework supporting modular CUDA streaming application development for irregular applications. A developer can use MERCATOR to decompose an irregular application for the GPU without explicitly remapping work to threads at runtime. MERCATOR applications are efficiently parallelized on the GPU through a combination of replication across blocks and queueing between nodes to accommodate irregularity. We quantify the performance impact of MERCATOR's support for irregularity and illustrate its utility by implementing a biological sequence comparison pipeline similar to the well-known NCBI BLASTN algorithm. MERCATOR code is available by request to the first author.},
keywords={Graphics processing units;Computational modeling;Topology;Pipelines;Instruction sets;Parallel processing;System recovery;streaming dataflow;parallel computing;SIMD;GPU;irregular computation},
doi={10.1109/HPCS.2017.111},
ISSN={},
month={July},}
@INPROCEEDINGS{8588230,
author={Memeti, Suejb and Pllana, Sabri},
booktitle={2018 IEEE International Conference on Computational Science and Engineering (CSE)},
title={HSTREAM: A Directive-Based Language Extension for Heterogeneous Stream Computing},
year={2018},
volume={},
number={},
pages={138-145},
abstract={Big data streaming applications require utilization of heterogeneous parallel computing systems, which may comprise multiple multi-core CPUs and many-core accelerating devices such as NVIDIA GPUs and Intel Xeon Phis. Programming such systems require advanced knowledge of several hardware architectures and device-specific programming models, including OpenMP and CUDA. In this paper, we present HSTREAM, a compiler directive-based language extension to support programming stream computing applications for heterogeneous parallel computing systems. HSTREAM source-to-source compiler aims to increase the programming productivity by enabling programmers to annotate the parallel regions for heterogeneous execution and generate target specific code. The HSTREAM runtime automatically distributes the workload across CPUs and accelerating devices. We demonstrate the usefulness of HSTREAM language extension with various applications from the STREAM benchmark. Experimental evaluation results show that HSTREAM can keep the same programming simplicity as OpenMP, and the generated code can deliver performance beyond what CPUs-only and GPUs-only executions can deliver.},
keywords={Programming;Acceleration;Instruction sets;Syntactics;Parallel processing;Graphics processing units;Runtime;stream computing, heterogeneous parallel computing systems, source-to-source compilation},
doi={10.1109/CSE.2018.00026},
ISSN={},
month={Oct},}
@INPROCEEDINGS{4740992,
author={Lu, Yifeng and Ren, Hao and Wang, Jinlin},
booktitle={2008 International Conference on Computer and Electrical Engineering},
title={Real-Time Performance vs. Server Bandwidth Cost in Peer-to-Peer Streaming System},
year={2008},
volume={},
number={},
pages={286-290},
abstract={In P2P streaming system, real-time performance is very important for evaluating quality of service, which directly determines the user experience. However, real-time performance is restricted by server bandwidth cost. Based on the proposed data transmitting model, this paper investigates the recursiveness of real-time performance through theoretical analysis, and computes its relationship with server bandwidth cost. The impact of system scale and service capacity of peer is also discussed. Especially, we consider both overlay diameter and the one hop delay in the investigation, hence can obtain more exact results. Our findings are of great importance for the design and deployment of P2P streaming system.},
keywords={Bandwidth;Costs;Peer to peer computing;Processor scheduling;Streaming media;Real time systems;Quality of service;Performance analysis;Delay;Scalability;Peer-to-Peer;Streaming;Real-time Performance},
doi={10.1109/ICCEE.2008.31},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9562644,
author={Liu, Tao and Yang, Zhihong and Sun, Yuzhong},
booktitle={2021 22nd Asia-Pacific Network Operations and Management Symposium (APNOMS)},
title={Docker Container Networking Based Apache Storm and Flink Benchmark Test},
year={2021},
volume={},
number={},
pages={49-52},
abstract={Many distributed stream computing engines have emerged to handle big data, and they can be deployed in cloud environments consisting of native networks or container networks. Most of the benchmark research on stream computing engines are carried out under the native network, and the research on the impact on container network on stream computing engines is currently inadequate. However, the use of container network will inevitably lead to performance degradation, which is the disadvantage of all virtual networks. In this work, we build Apache Storm and Apache Flink, which are Streaming Computation Engines in container network and native network environments and conduct performance measurements through experiments processing textual data to verify how much performance decreases in container network. Experiments show that the throughput in a container network environment is 1%-5% lower and CPU utilization is 11%-18% lower than in a local network environment.},
keywords={Measurement;Degradation;Cloud computing;Storms;Containers;Benchmark testing;Big Data;Container Network;Apache Storm;Apache Flink;Streaming Computation Engines;Benchmark Test},
doi={10.23919/APNOMS52696.2021.9562644},
ISSN={2576-8565},
month={Sep.},}
@INPROCEEDINGS{8718106,
author={Hanif, Muhammad and Yoon, Hyeongdeok and Lee, Choonhwa},
booktitle={2019 International Conference on Information Networking (ICOIN)},
title={Benchmarking Tool for Modern Distributed Stream Processing Engines},
year={2019},
volume={},
number={},
pages={393-395},
abstract={There is an upsurge in the usage and adaptation of streaming applications in the recent years by both industry and academia. At the core of these applications is streaming data processing engines that perform resource management and allocation in order to support continuous track of queries over distributed data streams. Several stream processing engines exists to handle these distributed streaming applications. In this paper, we present different challenges of the stream processing systems, in particular to stateful operators and implement Linear Road benchmark to examine the characteristic and performance metrics of the streaming system, in particular Apache Flink. Furthermore, we examine that Apache Flink can be used as a core for an efficient Linear Road application implementation for distributed environments without breaching the SLA requirements of the application.},
keywords={Benchmark testing;Roads;Engines;Real-time systems;Time factors;Distributed databases;Tools;Streaming;Benchmarking;SLA;Distributed Computing;Cloud Computing},
doi={10.1109/ICOIN.2019.8718106},
ISSN={1976-7684},
month={Jan},}
@INPROCEEDINGS{6121348,
author={Keong, Chee Yik and Hoong, Poo Kuan and Ting, Choo-Yee},
booktitle={2011 IEEE 17th International Conference on Parallel and Distributed Systems},
title={Efficient Hybrid Push-Pull Based P2P Media Streaming System},
year={2011},
volume={},
number={},
pages={735-740},
abstract={Peer-to-Peer (P2P) communication is a popular protocol that has significant impacted and also changed the way for files being distributed over the large networks. Variants of P2P protocols are also applied for other media distribution such as audio and video streaming. The P2P protocol is widely adapted by researchers as a method to handle larger group of users. Cool streaming, the first large scale P2P streaming experiment till today, applied a mesh-based streaming system which has slowly evolved from a pure pull system to a hybrid push-pull system. In this paper, we present our proposed push-pull scheduling for P2P streaming that can heuristically select the most optimal frame to be pushed based on the rules that we designed. Our proposed solution incorporates the fast content distribution characteristic of both Push and Pull approaches. For performance evaluation, we compare our scheduling algorithm with the pure pull Cool streaming scheduling and Random push-pull scheduling where both scheduling serve as a benchmark in three main criteria - end-to-end delay, frame miss-ratio and frame redundancy. Simulation results showed that our proposed heuristic push-pull overall outperformed the other scheduling schemes, where our proposed scheduling algorithm demonstrates as a better solution towards reducing mesh delay in P2P streaming.},
keywords={Peer to peer computing;Delay;Redundancy;Streaming media;Scheduling;Scheduling algorithm;Protocols;P2P Streaming;CoolStreaming;Mesh-based Pull;Push-Pull Scheduling},
doi={10.1109/ICPADS.2011.55},
ISSN={1521-9097},
month={Dec},}
@INPROCEEDINGS{5676652,
author={Giacomazzi, Paolo and Poli, Alessandro},
booktitle={International Congress on Ultra Modern Telecommunications and Control Systems},
title={Performance analysis of optimization techniques in peer-to-peer video streaming systems with tree/forest topology},
year={2010},
volume={},
number={},
pages={96-102},
abstract={Peer-to-peer video streaming systems are overlay networks used to distribute, among other types of content, live video content to large sets of users by relying on network and computing resources directly provided by users that are receiving the video stream. In this paper, we analyze the impact of two optimization techniques that can be adopted in peer-to-peer video streaming systems, with tree or forest topology, to cope with the negative effects of user's leaves. We carry out a performance analysis of these systems, analyzing their sensitivity to the most critical system parameters, when nearly-permanent nodes, i.e., peers with a smaller-than-average leave rate, are used to optimize the overlay topology.},
keywords={Peer to peer computing;Streaming media;Bandwidth;Encoding;Optimization;Performance analysis;Topology;Peer-to-peer;video streaming;tree;optimization techniques;permanent nodes;performance analysis},
doi={10.1109/ICUMT.2010.5676652},
ISSN={2157-023X},
month={Oct},}
@INPROCEEDINGS{7401437,
author={Rattanaopas, Kritwara and Tandayya, Pichaya},
booktitle={2015 International Computer Science and Engineering Conference (ICSEC)},
title={Performance analysis of a multi-tier video on demand service on virtualization platforms},
year={2015},
volume={},
number={},
pages={1-6},
abstract={Cloud computing technology, especially virtualization is employed in many data centers nowadays. The key concept of virtualization concerns elastic or scalable infrastructure. This concept can be implemented by exploiting multi-tier web applications and hypervisors which are virtual machine management software. Xen hypervisor has presented its Version 4.4 in 2014. In this paper, we present the performance analysis comparison between Xen para-virtualization and KVM full virtualization on the case study of open source video streaming called Cumulusclips, a YouTube-like system. This investigation involves real workload mp4 video streaming on 200 clients' browser, running 3 experiments, including large video files (~3 GB), small video files (~120 MB) and random-size video files (the ratio of large and small video files is 25%/75%). The requests size results show that Xen para-virtualization can serve all requests better than KVM full virtualization and use less resource. Xen's performance is dropped when CPU usage is 100% in Experiment 1 (large files). In Experiments 2 (small files) and 3 (random-size files), Xen's CPU usage is under 10%, but KVM's CPU usage is over 50%. The requests size results of Xen and KVM are equal in Experiment 2, but Xen has the maximum throughput about a half (51%) of KVM's. Therefore, we can conclude that Xen para-virtualization has better performance than KVM full virtualization on multi-tier video streaming system.},
keywords={Virtualization;Streaming media;Servers;Virtual machine monitors;Cloud computing;Computer architecture;Cloud computing;virtualization;performance comparison;Multi-tier applications;Video Streaming;Xen;KVM},
doi={10.1109/ICSEC.2015.7401437},
ISSN={},
month={Nov},}
@INPROCEEDINGS{5931331,
author={Zotos, Nikolaos and Xilouris, Georgios and Kourtis, Anastasios and Renzi, Daniele and Shao, Beilu},
booktitle={2011 IEEE Nineteenth IEEE International Workshop on Quality of Service},
title={Performance evaluation of H264/SVC streaming system featuring real-time in-network adaptation},
year={2011},
volume={},
number={},
pages={1-3},
abstract={In the recent years one of the most active research topics in multimedia networking is the exploitation of the Scalable Video Coding (SVC) as a scalable solution for efficient network resources utilization. SVC introduces scalability by exploiting a layered encoding of the video stream, thus enabling real-time in-network adaptation by selectively allowing the transmission of appropriate layers. This paper presents an architecture that exploits SVC capabilities in order to provide end-to-end QoS assurance via in-network video adaptation. The adaptation system management is based on MPEG-21 framework while the network QoS mechanisms are based on DiffServ standard. The performance evaluation of the proposed architecture is performed over a real test-bed infrastructure.},
keywords={Streaming media;Static VAr compensators;Quality of service;Real time systems;Media;Video coding;Transform coding;in-network adaptation;SVC;QoS;DiffServ;end-to-end;streaming;H264},
doi={10.1109/IWQOS.2011.5931331},
ISSN={1548-615X},
month={June},}
@INPROCEEDINGS{7017111,
author={Lee, Suk Kyu and Kim, Hyunsoon and Lee, Woonghee and Kim, Hwantae and Jung, Jongtack and Kim, Hwangnam},
booktitle={2014 IEEE 33rd International Performance Computing and Communications Conference (IPCCC)},
title={ReMA: Real-time 3D video streaming system for mobile devices},
year={2014},
volume={},
number={},
pages={1-8},
abstract={User's multimedia interaction is facing a paradigm shift from 2D to 3D videos. Nonetheless, it is still difficult to watch 3D videos with a mobile device. With current technological barrier in wireless networking, it is hardly imagined that the timely transmission for a 3D video streaming could be feasible with the mobile device. In this paper, we propose ReMA, a novel 3D video distribution system based on a lightweight compression, a linkadaptive transmission scheme, and a network-side assistance for processing capability. ReMA consists of a 3D data transmitter, a receiver, and an infrastructure for generating and distributing 3D videos. We implemented the proposed system in a real testbed and conducted a thorough empirical evaluation study. Based on the empirical results, the proposed system presents a great promise in streaming 3D video in real-time to the mobile device.},
keywords={Three-dimensional displays;Streaming media;Mobile handsets;Delays;Vectors;Decoding;Cameras;Mobile multimedia system;3D Video streaming system;Experimental evaluation},
doi={10.1109/PCCC.2014.7017111},
ISSN={2374-9628},
month={Dec},}
@ARTICLE{9097462,
author={Su, Guoxin and Liu, Li and Zhang, Minjie and Rosenblum, David S.},
journal={IEEE Transactions on Software Engineering},
title={Quantitative Verification for Monitoring Event-Streaming Systems},
year={2022},
volume={48},
number={2},
pages={538-550},
abstract={High-performance data streaming technologies are increasingly adopted in IT companies to support the integration of heterogeneous and possibly distributed applications. Compared with the traditional message queuing middleware, a streaming platform enables the implementation of event-streaming systems (ESS) which include not only complex queues but also pipelines that transform and react to the streams of data. By analysing the centralised data streams, one can evaluate the Quality-of-Service for other systems and components that produce or consume those streams. We consider the exploitation of probabilistic model checking as a performance monitoring technique for ESS systems. Probabilistic model checking is a mature, powerful verification technique with successful application in performance analysis. However, an ESS system may contain quantitative parameters that are determined by event streams observed in a certain period of time. In this paper, we present a novel theoretical framework called QV4M (meaning “quantitative verification for monitoring”) for monitoring ESS systems, which is based on two recent methods of probabilistic model checking. QV4M assumes the parameters in a probabilistic system model as random variables and infers the statistical significance for the probabilistic model checking output. We also present an empirical evaluation of computational time and data cost for QV4M.},
keywords={Task analysis;Probabilistic logic;Model checking;Measurement;Monitoring;Pipelines;Computational modeling;Discrete-time markov chain;event stream;parametric model checking;performance monitoring;probabilistic model checking;statistical inference},
doi={10.1109/TSE.2020.2996033},
ISSN={1939-3520},
month={Feb},}
@INPROCEEDINGS{8617019,
author={Saddam Hussain Shah, Syed and Said, Naina and Nayab, Aysha and Khan, Waleed and Shinwari, Zaryab Ali and Jawwad, Muhammad and Minallah, Nasru},
booktitle={2018 International Conference on Frontiers of Information Technology (FIT)},
title={Performance Comparison of Chunk and Peer Scheduling Algorithms of Peer-to-Peer Streaming Systems},
year={2018},
volume={},
number={},
pages={361-366},
abstract={With increasing popularity of Peer to Peer systems for video streaming, it is important that the expectations of the users regarding the quality of such systems are being met. In a P2P system, the media stream is divided into small data units known as chunks. Each peer in a Peer to Peer (P2P) system has to take two important decisions at a given time. First, which chunks are to be shared and second with which peer. This paper compares the performance of different combinations of chunk/peer schedulers in terms of chunk diffusion delay, average chunk distribution delay and max chunk distribution delay. By doing so, the best possible combination of the two schedulers for the given experimental setup is explored. The results obtained under the specified experimental setup show that when chunk scheduling algorithm Deadline Based Chunk Scheduler (DLc) is combined with different peer scheduling algorithms, the best results are obtained by its combination with Chunk Earliest Free Pair Scheduler (CEFp). For a constant peer scheduler CEFp combined with different chunk schedulers, the best results are obtained by combining it with Latest Blind Chunk Scheduler (LBc). Finally, with varying neighborhood size, the best results are obtained by the combination of DLC and Chunk Almost Free Peer Scheduler (CAFp)},
keywords={Peer-to-peer computing;Streaming media;Delays;Scheduling;Scheduling algorithms;Bandwidth;Media;Peer to Peer systems;Chunk Scheduler;Peer Scheduler;flexibility;scalability;performance;SSSim},
doi={10.1109/FIT.2018.00070},
ISSN={2334-3141},
month={Dec},}
@INPROCEEDINGS{8457759,
author={van Dongen, Giselle and Steurtewagen, Bram and Van den Poel, Dirk},
booktitle={2018 IEEE International Congress on Big Data (BigData Congress)},
title={Latency Measurement of Fine-Grained Operations in Benchmarking Distributed Stream Processing Frameworks},
year={2018},
volume={},
number={},
pages={247-250},
abstract={This paper describes a benchmark for stream processing frameworks allowing accurate latency benchmarking of fine-grained individual stages of a processing pipeline. By determining the latency of distinct common operations in the processing flow instead of the end-to-end latency, we can form guidelines for efficient processing pipeline design. Additionally, we address the issue of defining time in distributed systems by capturing time on one machine and defining the baseline latency. We validate our benchmark for Apache Flink using a processing pipeline comprising common stream processing operations. Our results show that joins are the most time consuming operation in our processing pipeline. The latency incurred by adding a join operation is 4.5 times higher than for a parsing operation, and the latency gradually becomes more dispersed after adding additional stages.},
keywords={Benchmark testing;Pipelines;Task analysis;Time measurement;Message systems;Storms;big data applications;distributed stream computing;benchmark;Flink;Kafka},
doi={10.1109/BigDataCongress.2018.00043},
ISSN={},
month={July},}
@INPROCEEDINGS{7474816,
author={Qian, Shilei and Wu, Gang and Huang, Jie and Das, Tathagata},
booktitle={2016 IEEE International Conference on Industrial Technology (ICIT)},
title={Benchmarking modern distributed streaming platforms},
year={2016},
volume={},
number={},
pages={592-598},
abstract={The prevalence of big data technology has generated increasing demands in large-scale streaming data processing. However, for certain tasks it is still challenging to appropriately select a platform due to the diversity of choices and the complexity of configurations. This paper focuses on benchmarking some principal streaming platforms. We achieve our goals on StreamBench, a streaming benchmark tool based on which we introduce proper modifications and extensions. We then accomplish performance comparisons among different big data platforms, including Apache Spark, Apache Storm and Apache Samza. In terms of performance criteria, we consider both computational capability and fault-tolerance ability. Finally, we give a summary on some key knobs for performance tuning as well as on hardware utilization.},
keywords={Benchmark testing;Sparks;Storms;Hardware;Fault tolerance;Fault tolerant systems;Throughput;distributed streaming computing;benchmark;big data;spark streaming;storm},
doi={10.1109/ICIT.2016.7474816},
ISSN={},
month={March},}
@INPROCEEDINGS{7530084,
author={Chintapalli, Sanket and Dagit, Derek and Evans, Bobby and Farivar, Reza and Graves, Thomas and Holderbaugh, Mark and Liu, Zhuo and Nusbaum, Kyle and Patil, Kishorkumar and Peng, Boyang Jerry and Poulosky, Paul},
booktitle={2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
title={Benchmarking Streaming Computation Engines: Storm, Flink and Spark Streaming},
year={2016},
volume={},
number={},
pages={1789-1792},
abstract={Streaming data processing has been gaining attention due to its application into a wide range of scenarios. To serve the booming demands of streaming data processing, many computation engines have been developed. However, there is still a lack of real-world benchmarks that would be helpful when choosing the most appropriate platform for serving real-time streaming needs. In order to address this problem, we developed a streaming benchmark for three representative computation engines: Flink, Storm and Spark Streaming. Instead of testing speed-of-light event processing, we construct a full data pipeline using Kafka and Redis in order to more closely mimic the real-world production scenarios. Based on our experiments, we provide a performance comparison of the three data engines in terms of 99th percentile latency and throughput for various configurations.},
keywords={Storms;Benchmark testing;Sparks;Throughput;Engines;Data processing;Pipelines;Streaming processing;Benchmark;Storm;Spark;Flink;Low Latency},
doi={10.1109/IPDPSW.2016.138},
ISSN={},
month={May},}
@INPROCEEDINGS{7307040,
author={Mao, Hanzi and Tian, Chen and Sun, Jingdong and Yan, Junhua and Wu, Weimin and Huang, Benxiong},
booktitle={2014 IEEE 11th Intl Conf on Ubiquitous Intelligence and Computing and 2014 IEEE 11th Intl Conf on Autonomic and Trusted Computing and 2014 IEEE 14th Intl Conf on Scalable Computing and Communications and Its Associated Workshops},
title={Shadow VoD: Performance Evaluation as a Capability in Production P2P-CDN Hybrid VoD Networks},
year={2014},
volume={},
number={},
pages={771-776},
abstract={Video-on-Demand (VoD) services have achieved great success recently. Most such streaming systems are P2P-CDNhybrid systems. To ensure reliable performance, the most efficient way is to subject those VoD streaming networks to large-scale, realistic performance evaluations. Our previous Shadow Stream system is a production Internet live streaming network with performance evaluation as a built-in capability. In this paper, we extend the same idea into the VoD services. There exists significant difference between live and VoD, hence Shadow Stream cannot be directly used in VoD context. Firstly, clients in P2PVoD service are not synchronized in viewing progress, secondly, in VoD there exists interactive operations (e.g., Pause and drag), thirdly, the different play points of users also bring difficulty to replacing departed real clients. In this paper, we solve all above mentioned challenges. We implement Shadow VoD and demonstrate its benefits through extensive evaluations.},
keywords={Testing;Production;Virtual machine monitors;Emulation;Performance evaluation;Streaming media;Conferences},
doi={10.1109/UIC-ATC-ScalCom.2014.77},
ISSN={},
month={Dec},}
@ARTICLE{7192704,
author={Satyanarayan, Arvind and Russell, Ryan and Hoffswell, Jane and Heer, Jeffrey},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization},
year={2016},
volume={22},
number={1},
pages={659-668},
abstract={We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.},
keywords={Data visualization;Visualization;Data models;Encoding;Indexes;Runtime;Computer architecture;Information visualization;systems;toolkits;declarative specification;optimization;interaction;streaming data;Information visualization;systems;toolkits;declarative specification;optimization;interaction;streaming data},
doi={10.1109/TVCG.2015.2467091},
ISSN={1941-0506},
month={Jan},}
@ARTICLE{7163643,
author={Saleh, Bassel and Qiu, Dongyu},
journal={IEEE/ACM Transactions on Networking},
title={Performance Analysis of Network-Coding-Based P2P Live Streaming Systems},
year={2016},
volume={24},
number={4},
pages={2140-2153},
abstract={Peer-to-peer (P2P) video streaming is a scalable and cost-effective technology to stream video content to a large population of users and has attracted a lot of research for over a decade now. Recently, network coding has been introduced to improve the efficiency of these systems and to simplify the protocol design. There are already some successful commercial applications that utilize network coding. However, previous analytical studies of network-coding-based P2P streaming systems mainly focused on fundamental properties of the system and ignored the influence of the protocol details. In this study, a unique stochastic model is developed to reveal how segments of the video stream evolve over their lifetime in the buffer before they go into playback. Different strategies for segment selection have been studied with the model, and their performance has been compared. A new approximation of the probability of linear independence of coded blocks has been proposed to study the redundancy of network coding. Finally, extensive numerical results and simulations have been provided to validate our model. From these results, in-depth insights into how system parameters and segment selection strategies affect the performance of the system have been obtained.},
keywords={Servers;Streaming media;Bandwidth;Topology;Delays;Protocols;Analytical models;Network coding;peer-to-peer;performance analysis;video streaming},
doi={10.1109/TNET.2015.2448597},
ISSN={1558-2566},
month={Aug},}
@INPROCEEDINGS{6413677,
author={Preud'Homme, Thomas and Sopena, Julien and Thomas, Gaël and Folliot, Bertil},
booktitle={2012 IEEE 18th International Conference on Parallel and Distributed Systems},
title={An Improvement of OpenMP Pipeline Parallelism with the BatchQueue Algorithm},
year={2012},
volume={},
number={},
pages={348-355},
abstract={In the context of multicore programming, pipeline parallelism is a solution to easily transform a sequential program into a parallel one without requiring a whole rewriting of the code. The OpenMP stream-computing extension presented by Pop and Cohen proposes an extension of OpenMP to handle pipeline parallelism. However, their communication algorithm relies on Multiple-producer-Multiple-Consumer queues, while pipelined applications mostly deal with linear chains of communication, i.e., with only a single producer and a single consumer. To improve the performance of the OpenMP stream-extension, we propose to add a more specialized Single-Producer-Single-Consumer communication algorithm called Batch Queue and to select it for one-to-one communication. Our evaluation shows that Batch Queue is then able to improve the throughput up to a factor 2 on an 8-core machine both for example application and real applications. Our study shows therefore that using specialized and efficient communication algorithms can have a significant impact on the overall performance of pipelined applications.},
keywords={Parallel processing;Pipelines;Throughput;Benchmark testing;Synchronization;Multicore processing;Scalability;Pipeline parallelism;inter-core communication;multi-core systems;cache coherency;OpenMP},
doi={10.1109/ICPADS.2012.55},
ISSN={1521-9097},
month={Dec},}
@INPROCEEDINGS{5364699,
author={Liang, Chao and Liu, Yong and Ross, Keith W.},
booktitle={2009 21st IEEE International Conference on Tools with Artificial Intelligence},
title={Topology Optimization in Multi-tree Based P2P Streaming System},
year={2009},
volume={},
number={},
pages={806-813},
abstract={In recent years, peer-to-peer (P2P) technology has been demonstrated tremendously effective in delivering large-scale video streaming services. Although P2P streaming is scalable and robust, the network-oblivious peering and scheduling in the current designs impede the further improvement in streaming quality and the efficient usage of network resources. New P2P streaming systems exploit network information provided by Internet service providers (ISPs) to achieve a higher level of application performance and generate lower traffic stress. In this paper, utilizing information from ISPs, we investigate the strategies on the topology construction and maintenance of multi-tree based P2P streaming systems. We study topology optimization to minimize the average height of sub-stream trees and the average propagation latency in each tree. We first present the optimization formulations, and then propose a set of heuristic algorithms for the construction and dynamic management of the multiple sub-stream trees for practical implementation. Through numerical comparison study, we show that our algorithms can significantly improve the delay performance of existing P2P streaming systems.},
keywords={Streaming media;Network topology;Delay;Peer to peer computing;Large-scale systems;Robustness;Impedance;Web and internet services;Telecommunication traffic;Stress},
doi={10.1109/ICTAI.2009.17},
ISSN={2375-0197},
month={Nov},}
@INPROCEEDINGS{9912882,
author={Georgiou, Joanna and Symeonides, Moysis and Kasioulis, Michalis and Trihinas, Demetris and Pallis, George and Dikaiakos, Marios D.},
booktitle={2022 IEEE Symposium on Computers and Communications (ISCC)},
title={BenchPilot: Repeatable & Reproducible Benchmarking for Edge Micro-DCs},
year={2022},
volume={},
number={},
pages={1-6},
abstract={Micro-Datacenters (DCs) are emerging as key en-ablers for Edge computing and 5G mobile networks by pro-viding processing power closer to IoT devices to extract timely analytic insights. However, the performance evaluation of data stream processing on micro-DCs is a daunting task due to difficulties raised by the time-consuming setup, configuration and heterogeneity of the underlying environment. To address these challenges, we introduce BenchPilot, a modular and highly customizable benchmarking framework for edge micro-DCs. BenchPilot provides a high-level declarative model for describing experiment testbeds and scenarios that automates the bench-marking process on Streaming Distributed Processing Engines (SDPEs). The latter enables users to focus on performance analysis instead of dealing with the complex and time-consuming setup. BenchPilot instantiates the underlying cluster, performs repeatable experimentation, and provides a unified monitoring stack in heterogeneous Micro-DCs. To highlight the usability of BenchPilot, we conduct experiments on two popular streaming engines, namely Apache Storm and Flink. Our experiments compare the engines based on performance, CPU utilization, energy consumption, temperature, and network I/O.},
keywords={Energy consumption;Storms;Telecommunication traffic;Benchmark testing;Central Processing Unit;Servers;Usability;Edge Computing;Internet of Things},
doi={10.1109/ISCC55528.2022.9912882},
ISSN={2642-7389},
month={June},}
@INPROCEEDINGS{5962881,
author={Chen, Yishuai and Zhang, Baoxian and Chen, Changjia},
booktitle={2011 IEEE International Conference on Communications (ICC)},
title={Modeling and Performance Analysis of P2P Live Streaming Systems under Flash Crowds},
year={2011},
volume={},
number={},
pages={1-5},
abstract={A fundamental problem that a peer-to-peer (P2P) live streaming system faces is how to support flash crowds effectively. A flash crowd occurs when a burst of join requests arrive at a system. When a flash crowd occurs, the sudden arrival of numerous peers may starve the upload capacity of a P2P system, and degrade the quality of service. By theoretical analysis and simulations, we find that a system has limited capacity to handle a flash crowd: It can recover to a new stable state when the size of flash crowd is small or moderate, but collapse when the flash crowd is excessively large. The capacity of a system is independent of initial state of the system while relevant to stable peers' departure rate, which suggests this capacity is an essential property of a P2P live streaming system. In addition, we prove that a P2P live streaming system with admission control has excellent capacity to handle flash crowds: It can recover from flash crowds of excessively large size and a startup peer's waiting time scales logarithmically with the size of flash crowds. Our theoretical model and simulation results provide a promising framework to understand the capacity of a P2P live streaming system for handling flash crowds.},
keywords={Peer to peer computing;Admission control;Bandwidth;Electric shock;Analytical models;Simulation;Media},
doi={10.1109/icc.2011.5962881},
ISSN={1938-1883},
month={June},}
@INPROCEEDINGS{8509390,
author={Karimov, Jeyhun and Rabl, Tilmann and Katsifodimos, Asterios and Samarev, Roman and Heiskanen, Henri and Markl, Volker},
booktitle={2018 IEEE 34th International Conference on Data Engineering (ICDE)},
title={Benchmarking Distributed Stream Data Processing Systems},
year={2018},
volume={},
number={},
pages={1507-1518},
abstract={The need for scalable and efficient stream analysis has led to the development of many open-source streaming data processing systems (SDPSs) with highly diverging capabilities and performance characteristics. While first initiatives try to compare the systems for simple workloads, there is a clear gap of detailed analyses of the systems' performance characteristics. In this paper, we propose a framework for benchmarking distributed stream processing engines. We use our suite to evaluate the performance of three widely used SDPSs in detail, namely Apache Storm, Apache Spark, and Apache Flink. Our evaluation focuses in particular on measuring the throughput and latency of windowed operations, which are the basic type of operations in stream analytics. For this benchmark, we design workloads based on real-life, industrial use-cases inspired by the online gaming industry. The contribution of our work is threefold. First, we give a definition of latency and throughput for stateful operators. Second, we carefully separate the system under test and driver, in order to correctly represent the open world model of typical stream processing deployments and can, therefore, measure system performance under realistic conditions. Third, we build the first benchmarking framework to define and test the sustainable performance of streaming systems. Our detailed evaluation highlights the individual characteristics and use-cases of each system.},
keywords={Benchmark testing;Throughput;Measurement;Generators;Storms;Engines;Stream data processing;Stream benchmark;Apache Flink;Apache Spark;Apache Storm},
doi={10.1109/ICDE.2018.00169},
ISSN={2375-026X},
month={April},}
@INPROCEEDINGS{5696853,
author={Changjun Gao and Yusong Huo and Yujie Su and Jun Wu and Yan Ma},
booktitle={2010 International Conference on Advanced Intelligence and Awarenss Internet (AIAI 2010)},
title={Su-peercast: A P2P live streaming system with super-node based on PeerCast},
year={2010},
volume={},
number={},
pages={23-27},
abstract={The amount of client a live streaming system can serve by unicast is limited by the bandwidth requirement. Theoretically, IP-multicast is an efficient solution for that situation, but it suffers from poor deployment. Therefore, another solution, called Application Layer Multicast (ALM), is being increasingly recognized as a available alternative. However, this solution also has certain shortcomings. In this paper, we firstly introduce a live streaming system—PeerCast based on application layer multicast, and besides that we indicate its existing problems under practical deployment in the large-scale network. Secondly, in order to improve the PeerCast system performance, we append a Super-Node layer, which can divide the live system into different domains, and re-design the play process and heartbeat detection mechanism for our new live system. Finally, the re-designed system performance evaluation is presented.},
keywords={Super-Node;Tracker;P2P;Streaming;Large-scale},
doi={10.1049/cp.2010.0713},
ISSN={},
month={Oct},}
@ARTICLE{9507502,
author={Van Dongen, Giselle and Van Den Poel, Dirk},
journal={IEEE Access},
title={Influencing Factors in the Scalability of Distributed Stream Processing Jobs},
year={2021},
volume={9},
number={},
pages={109413-109431},
abstract={More and more use cases require fast, accurate, and reliable processing of large volumes of data. To do this, a distributed stream processing framework is needed which can distribute the load over several machines. In this work, we study and benchmark the scalability of stream processing jobs in four popular frameworks: Flink, Kafka Streams, Spark Streaming, and Structured Streaming. Besides that, we determine the factors that influence the performance and efficiency of scaling processing jobs with distinct characteristics. We evaluate horizontal, as well as vertical scalability. Our results show how the scaling efficiency is impacted by many factors including the initial cluster layout and direction of scaling, the pipeline design, the framework design, resource allocation, and data characteristics. Finally, we give some recommendations on how practitioners should undertake to scale their clusters.},
keywords={Scalability;Throughput;Pipelines;Benchmark testing;Sparks;Measurement;Storms;Apache spark;structured streaming;apache flink;apache kafka;kafka streams;distributed computing;stream processing frameworks;scalability;benchmarking;big data},
doi={10.1109/ACCESS.2021.3102645},
ISSN={2169-3536},
month={},}
@ARTICLE{9591429,
author={Daghistani, Anas and Khayat, Mosab and Felemban, Muhamad and Aref, Walid G. and Ghafoor, Arif},
journal={IEEE Transactions on Dependable and Secure Computing},
title={Guard: Attack-Resilient Adaptive Load Balancing in Distributed Streaming Systems},
year={2022},
volume={19},
number={6},
pages={4172-4186},
abstract={The performance of distributed streaming systems relies on how even the workload is distributed among their machines. However, data and query workloads are skewed and change rapidly. Therefore, multiple adaptive load-balancing mechanisms have been proposed in the literature to rebalance distributed streaming systems according to the changes in their workloads. This paper introduces a novel attack model that targets adaptive load-balancing mechanisms of distributed streaming systems. The attack reduces the throughput and the availability of the system by making it stay in a continuous state of rebalancing. This paper proposes Guard, a component that detects and blocks attacks that target the adaptive load balancing of distributed streaming systems. Guard uses an unsupervised machine-learning technique to detect malicious users that are involved in the attack. Guard does not block any user unless it detects that the user is malicious. Guard does not depend on a specific application. Experimental evaluation for a high-intensity attack illustrates that Guard improves the throughput and the availability of the system by 85% and 86%, respectively. Moreover, Guard improves the minimum availability that the attacker achieves by 325%.},
keywords={Adaptive systems;Throughput;Load modeling;Adaptation models;Social networking (online);Real-time systems;Load management;Attack-resilient;malicious activity;adaptive load balancing;distributed streaming systems},
doi={10.1109/TDSC.2021.3123071},
ISSN={1941-0018},
month={Nov},}
@INPROCEEDINGS{7923779,
author={Havet, Aurelien and Schiavoni, Valerio and Felber, Pascal and Rouvoy, Romain},
booktitle={2017 IEEE International Conference on Cloud Engineering (IC2E)},
title={Introducing SECURESTREAMS: Scalable Middleware for Reactive and Secure Data Stream Processing},
year={2017},
volume={},
number={},
pages={1-4},
abstract={We introduce SECURESTREAMS, a middleware framework for secure stream processing. Its design builds on Intel's Secure Guard Extensions (SGX) to guarantee the privacy and the integrity of the data being processed. Our initial experimental results of SECURESTREAMS are promising: the framework is easy to use, and delivers high throughput, enabling developers to implement complex processing pipelines in a few lines of scripting code.},
keywords={Pipelines;Throughput;Middleware;Scalability;Containers;Programming;Benchmark testing;streaming;reactive programming;Lua;SGX},
doi={10.1109/IC2E.2017.50},
ISSN={},
month={April},}
@INPROCEEDINGS{9216979,
author={Wang, Lening and Zhang, Yutong and Chen, Xiaoyu and Jin, Ran},
booktitle={2020 IEEE 16th International Conference on Automation Science and Engineering (CASE)},
title={Online Computation Performance Analysis for Distributed Machine Learning Pipelines in Fog Manufacturing},
year={2020},
volume={},
number={},
pages={1628-1633},
abstract={Smart manufacturing enables real-time data streaming from interconnected manufacturing processes to improve manufacturing quality, throughput, flexibility, and cost reduction via computation services. In these computation services, machine learning pipelines integrate various types of computation method options to match the contextualized, on-demand computation needs for the maximum prediction accuracy or the best model structure interpretation. On the other hand, there is a pressing need to integrate Fog computing in manufacturing, which will reduce communication time latency and dependency on connections, improve responsiveness and reliability of the computation services, and maintain data privacy. However, there is a knowledge gap in using machine learning pipelines in Fog manufacturing. Existing offloading strategies are not effective, due to the lack of accurate prediction model for the performance of computation services before the execution of those heterogeneous computation tasks. In this paper, machine learning pipelines are implemented in Fog manufacturing. The computation performance of each sub-step of pipelines is predicted and analyzed via linear regression models and random forest regression models. A Fog manufacturing testbed is adopted to validate the performance of the employed models. The results show that the models can adequately predict the performance of computation services, which can be further integrated into Fog manufacturing to better support offloading strategies for machine learning pipelines.},
keywords={Pipelines;Computational modeling;Manufacturing;Machine learning;Predictive models;Bandwidth;Task analysis;Computation Services;Fog Computing;Fog Manufacturing;Machine Learning Pipeline},
doi={10.1109/CASE48305.2020.9216979},
ISSN={2161-8089},
month={Aug},}
@INPROCEEDINGS{6063011,
author={Gu, Yi and Wu, Qishi and Liu, Xin and Yu, Dantong},
booktitle={2011 IEEE International Conference on High Performance Computing and Communications},
title={Improving Throughput and Reliability of Distributed Scientific Workflows for Streaming Data Processing},
year={2011},
volume={},
number={},
pages={347-354},
abstract={With the advent of next-generation scientific applications, the workflow-based computing technology has become an indispensable research method for managing and streamlining large-scale distributed data processing. This paper investigates a problem of mapping distributed workflows for streaming data processing in faulty networks where nodes and links are subject to probabilistic failures. We formulate this problem as a bi-objective optimization problem in terms of both throughput and reliability, and propose a decentralized layer-oriented method to achieve high throughput for smooth data flow while satisfying a prespecified overall failure rate bound for a guaranteed level of reliability. The superiority of the proposed mapping solution is illustrated by both extensive simulation-based performance comparisons with existing algorithms and experimental results from a real-life scientific workflow deployed in wide-area networks.},
keywords={Reliability;Throughput;Computer network reliability;Optimization;Approximation methods;Complexity theory;Computational modeling;Reliability;fault tolerance;workflow mapping;frame rate;distributed computing},
doi={10.1109/HPCC.2011.52},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{5695643,
author={Lin, Yunyue and Wu, Qishi and Lu, Xukang and Gu, Yi},
booktitle={2010 IEEE 16th International Conference on Parallel and Distributed Systems},
title={Bandwidth Constrained Tree Construction for Live Streaming Systems in P2P Networks},
year={2010},
volume={},
number={},
pages={516-523},
abstract={The traditional client-server architecture widely adopted on the Internet is not adequate to meet the increasing user loads and bandwidth demands in live streaming systems especially for multimedia content delivery. Peer-to-peer P2P) overlay networks provide excellent system scalability and high resource utilization, which make it an attractive solution to this problem. This paper considers a hybrid hierarchical P2P overlay network structure that consists of both super and normal peers. The media streaming architecture is built upon a tree structured network of super peers and the tree construction process has a significant impact on the overall system performance. We construct network cost models and formulate a Bandwidth Constrained Tree (BCT) construction problem, which aims at maximizing the number of peers that satisfy a specified bandwidth constraint. We prove that BCT is NP-complete and propose optimal algorithms in two special cases and a heuristic approach in a general case. The performance superiority of the proposed method is illustrated by an extensive set of experiments on simulated networks of various sizes in comparison with existing greedy and degree constrained algorithms.},
keywords={Bandwidth;Peer to peer computing;Throughput;Network topology;Algorithm design and analysis;Topology;Heuristic algorithms;P2P;overlay networks;live streaming;spanning tree},
doi={10.1109/ICPADS.2010.39},
ISSN={1521-9097},
month={Dec},}
@ARTICLE{6381402,
author={Tang, Yuzhe and Gedik, Bugra},
journal={IEEE Transactions on Parallel and Distributed Systems},
title={Autopipelining for Data Stream Processing},
year={2013},
volume={24},
number={12},
pages={2344-2354},
abstract={Stream processing applications use online analytics to ingest high-rate data sources, process them on-the-fly, and generate live results in a timely manner. The data flow graph representation of these applications facilitates the specification of stream computing tasks with ease, and also lends itself to possible runtime exploitation of parallelization on multicore processors. While the data flow graphs naturally contain a rich set of parallelization opportunities, exploiting them is challenging due to the combinatorial number of possible configurations. Furthermore, the best configuration is dynamic in nature; it can differ across multiple runs of the application, and even during different phases of the same run. In this paper, we propose an autopipelining solution that can take advantage of multicore processors to improve throughput of streaming applications, in an effective and transparent way. The solution is effective in the sense that it provides good utilization of resources by dynamically finding and exploiting sources of pipeline parallelism in streaming applications. It is transparent in the sense that it does not require any hints from the application developers. As a part of our solution, we describe a light-weight runtime profiling scheme to learn resource usage of operators comprising the application, an optimization algorithm to locate best places in the data flow graph to explore additional parallelism, and an adaptive control scheme to find the right level of parallelism. We have implemented our solution in an industrial-strength stream processing system. Our experimental evaluation based on microbenchmarks, synthetic workloads, as well as real-world applications confirms that our design is effective in optimizing the throughput of stream processing applications without requiring any changes to the application code.},
keywords={Runtime;Throughput;Instruction sets;Parallel processing;Streaming media;Multicore processing;Stream processing;parallelization;autopipelining},
doi={10.1109/TPDS.2012.333},
ISSN={1558-2183},
month={Dec},}
@ARTICLE{6025323,
author={Ullah, Ihsan and Doyen, Guillaume and Bonnet, Gregory and Gaiti, Dominique},
journal={IEEE Communications Surveys & Tutorials},
title={A Survey and Synthesis of User Behavior Measurements in P2P Streaming Systems},
year={2012},
volume={14},
number={3},
pages={734-749},
abstract={In terms of scalability, cost and ease of deployment, the Peer-to-Peer (P2P) approach has emerged as a promising solution for video streaming applications. Its architecture enables end-hosts, called peers, to relay the video stream to each other. P2P systems are in fact networks of users who control peers. Thus, user behavior is crucial to the performance of these systems because it directly impacts the streaming flow. To understand user behavior, several measurement studies have been carried out over different video streaming systems. Each measurement analyzes a particular system focusing on specific metrics and presents insights. However, a single study based on a particular system and specific metrics is not sufficient to provide a complete model of user behavior considering all of its components and the impact of external factors on them. In this paper, we propose a comparison and a synthesis of these measurements. First of all, we review video streaming architectures, followed by a survey on the user behavior measurements in these architectures. Then, we gather insights revealed in these measurements and compare them for consensual and contrasting points. Finally, we extract components of user behavior, their external impacting factors and relationships among them. We also point out those aspects of user behavior which require further investigations.},
keywords={Peer to peer computing;Streaming media;IP networks;Protocols;Servers;Internet;IPTV;Measurements;user behavior;Peer-to-Peer;video streaming},
doi={10.1109/SURV.2011.082611.00134},
ISSN={1553-877X},
month={Third},}
@INPROCEEDINGS{5970484,
author={Paniga, Stefano and Borsani, Luca and Redondi, Alessandro and Tagliasacchi, Marco and Cesana, Matteo},
booktitle={2011 The 10th IFIP Annual Mediterranean Ad Hoc Networking Workshop},
title={Experimental evaluation of a video streaming system for Wireless Multimedia Sensor Networks},
year={2011},
volume={},
number={},
pages={165-170},
abstract={Wireless Multimedia Sensor Networks (WMSNs) are recently emerging as an extension to traditional scalar wireless sensor networks, with the distinctive feature of supporting the acquisition and delivery of multimedia content such as audio, images and video. In this paper, a complete framework is proposed and developed for streaming video flows in WMSNs. Such framework is designed in a cross-layer fashion with three main building blocks: (i) a hybrid DPCM/DCT encoder; (ii) a congestion control mechanism and (iii) a selective priority automatic request mechanism at the MAC layer. The system has been implemented on the IntelMote2 platform operated by TinyOS and thoroughly evaluated through testbed experiments on multi-hop WMSNs. The source code of the whole system is publicly available to enable reproducible research.},
keywords={Streaming media;Multimedia communication;Wireless sensor networks;Cameras;Delay;Transform coding;Wireless communication},
doi={10.1109/Med-Hoc-Net.2011.5970484},
ISSN={},
month={June},}
@INPROCEEDINGS{5676653,
author={Giacomazzi, Paolo and Poli, Alessandro},
booktitle={International Congress on Ultra Modern Telecommunications and Control Systems},
title={Push-pull techniques in peer-to-peer video streaming systems with tree/forest topology},
year={2010},
volume={},
number={},
pages={89-95},
abstract={Peer-to-peer video streaming systems are overlay networks used to distribute, among other types of content, live video content to large sets of users by relying on computing and network resources directly provided by users that are receiving video streaming services. Peer-to-peer video streaming systems with tree or forest topology are typically push-based, since the video content is provided by parent peers with no need for periodical requests. In this paper we analyze the impact of two complementing pull-based mechanisms aiming at improving the overall performance of the overlay network. Results show that the proposed hybrid push-pull approaches can be beneficial when the stability of the system is low, i.e., the average permanence time of peers is short.},
keywords={Streaming media;Peer to peer computing;Bandwidth;Encoding;Topology;Delay;Analytical models;Peer-to-peer;video streaming;tree;retransmission;backup parents;performance analysis},
doi={10.1109/ICUMT.2010.5676653},
ISSN={2157-023X},
month={Oct},}
@INPROCEEDINGS{9237049,
author={Bang, Jiwon and Choi, Mi-Jung},
booktitle={2020 21st Asia-Pacific Network Operations and Management Symposium (APNOMS)},
title={Docker environment based Apache Storm and Spark Benchmark Test},
year={2020},
volume={},
number={},
pages={322-325},
abstract={With the development of various technologies such as high-speed Internet and SNS dissemination, there have been many fields that require processing of big data generated in real time. Accordingly, real-time streaming data processing technology has been developed, and representative platforms include Apache Storm, Apache Spark, and Hadoop. These processing technologies provide scalability to configure distributed systems using multiple servers because they vary in performance, such as throughput and processing speed, depending on the server environment, but the more the number of servers, the more difficult it is to manage. To solve this problem, a problem can be solved by using a docker, a kind of virtualization system that provides ease of expansion. However, there is a place to maintain a native environment without using Docker due to the problem that performance may be reduced, which is a disadvantage of all virtualization systems. In this paper, we build Apache Storm and Apache Spark, which are real-time data processing systems in Docker and Native environments and conduct performance measurements through experiments processing JSON-format data to verify how much performance decreases in Docker environments.},
keywords={Servers;Storms;Sparks;Real-time systems;Throughput;Measurement;Distributed databases;Docker;Apache Storm;Apache Spark;Distributed Stream Processing Platform;Benchmark Test},
doi={10.23919/APNOMS50412.2020.9237049},
ISSN={2576-8565},
month={Sep.},}
@INPROCEEDINGS{4459148,
author={Gorton, Ian and Wynne, Adam and Almquist, Justin and Chatterton, Jack},
booktitle={Seventh Working IEEE/IFIP Conference on Software Architecture (WICSA 2008)},
title={The MeDICi Integration Framework: A Platform for High Performance Data Streaming Applications},
year={2008},
volume={},
number={},
pages={95-104},
abstract={Building high performance analytical applications for data streams generated from sensors is a challenging software engineering problem. Such applications typically comprise a complex pipeline of processing components that capture, transform and analyze the incoming data stream. In addition, applications must provide high throughput, be scalable and easily modifiable so that new analytical components can be added with minimum effort. In this paper we describe the MeDICi integration framework (MIF), which is a middleware platform we have created to address these challenges. The MIF extends an open source messaging platform with a component-based API for integrating components into analytical pipelines. We describe the features and capabilities of the MIF, and show how it has been used to build a production analytical application for detecting cyber security attacks. The application was composed from multiple independently developed components using several different programming languages. The resulting application was able to process network sensor traffic in real time and provide insightful feedback to network analysts as soon as potential attacks were recognized.},
keywords={Application software;Independent component analysis;Data analysis;Pipelines;Performance analysis;Software engineering;Throughput;Middleware;Production;Computer security;integration;component model;pipelines},
doi={10.1109/WICSA.2008.21},
ISSN={},
month={Feb},}
@INPROCEEDINGS{9860334,
author={Rajput, Kaustubh Rajendra and Kulkarni, Chinmay Dilip and Cho, Byungjin and Wang, Wei and Kim, In Kee},
booktitle={2022 IEEE International Conference on Edge Computing and Communications (EDGE)},
title={EdgeFaaSBench: Benchmarking Edge Devices Using Serverless Computing},
year={2022},
volume={},
number={},
pages={93-103},
abstract={Due to the development of small-size, energy-efficient, and powerful CPUs and GPUs for single board computers, various edge devices are widely adopted for hosting real-world applications, including real-time object detection, autonomous driving, and sensor stream processing. At the same time, serverless computing receives increasing attention as a new application deployment model because of its simplicity, scalability, event-driven processing, and short-lived computation. Therefore, there is a growing demand for applying serverless computing to edge computing environments. However, due to the lack of characterization of serverless edge computing (e.g., application performance and impact from resource heterogeneity), researchers and practitioners have to conduct tedious measurements to understand the performance of serverless applications on edge devices in non-systematic ways.We create EdgeFaaSBench, a novel benchmark suite for serverless computing on edge devices, to bridge this gap. EdgeFaaSBench is developed on top of Apache OpenFaaS with Docker Swarm and can run various serverless benchmark workloads on edge devices with different hardware specifications (e.g., GPUs). EdgeFaaSBench contains 14 different benchmark workloads running on heterogeneous edge devices and captures various system-level, application-level, and serverless-specific metrics, including system utilization, response time, cold/warm start times, and impact of concurrent function executions. Experimental studies are conducted on two widely used edge devices, Raspberry Pi 4B and Jetson Nano, to show EdgeFaaSBench’s capabilities to benchmark serverless computing on edge devices.},
keywords={Performance evaluation;Sentiment analysis;Scalability;Serverless computing;Object detection;Benchmark testing;Real-time systems;Benchmarking and Performance Evaluation;Edge Computing;Serverless Computing},
doi={10.1109/EDGE55608.2022.00024},
ISSN={2767-9918},
month={July},}
@INPROCEEDINGS{1015491,
author={Petkov, D. and Harr, R. and Amarasinghe, S.},
booktitle={Proceedings 16th International Parallel and Distributed Processing Symposium},
title={Efficient pipelining of nested loops: unroll-and-squash},
year={2002},
volume={},
number={},
pages={6 pp-},
abstract={The size and complexity of current custom VLSI have forced the use of high-level programming languages to describe hardware, and compiler and synthesis technology to map abstract designs into silicon. Since streaming data processing in DSP applications is typically described by loop constructs in a high-level language, loops are the most critical portions of the hardware description and special techniques are developed to optimally synthesize them. We introduce a new method for mapping and pipelining nested loops efficiently into hardware. It achieves fine-grain parallelism even on strong intra- and inter-iteration data-dependent inner loops and, by sharing resources economically, improves performance at the expense of a small amount of additional area. We implemented the transformation within the Nimble Compiler environment and evaluated its performance on several signal processing benchmarks. The method achieves up to 2× improvement in the area efficiency compared to the best known optimization techniques.},
keywords={Pipeline processing;Hardware;Very large scale integration;Computer languages;Program processors;Silicon;Data processing;Digital signal processing;High level languages;Environmental economics},
doi={10.1109/IPDPS.2002.1015491},
ISSN={},
month={April},}
@INPROCEEDINGS{4482757,
author={Liu, Xuening and Yin, Hao and Lin, Chuang and Liu, Yu and Chen, Zhijia and Xiao, Xin},
booktitle={22nd International Conference on Advanced Information Networking and Applications (aina 2008)},
title={Performance Analysis and Industrial Practice of Peer-Assisted Content Distribution Network for Large-Scale Live Video Streaming},
year={2008},
volume={},
number={},
pages={568-574},
abstract={Recently efficient and scalable live video streaming system over the Internet has become a hot topic. In order to improve the system performance metrics, such as startup delay, source-to-end delay, playback continuity and scalability, many previous works developed two successful cases of content distribution network (CDN) and peer-to-peer (P2P) Network for the design of large-scale live video streaming systems, but no single one has yet delivered both the scale and service quality. To combine the advantages of CDN and P2P network has been considered as a feasible orientation for large-scale video stream delivering. In this paper, we propose a peer-assisted content distribution network, i.e. PACDN, which borrows the mesh-based P2P ideas into the traditional CDN to enhance the performance and scalability. The basic features of PACDN include: 1) To meet the real time requirement of live video stream service, i.e. to ensure that the video stream could be continuously and stably delivered from the source to each edge server for offering good QoS to different regions clients, the placement edge servers and source streaming server(s) build a hierarchical multi-tree based and in-hierarchy peer-assisted overlay, which is optimized according to the knowledge of underlying physical topology. This scheme in the design is called "server side peer-assisted". 2) To enhance the system scalability and reduce the deployment cost, clients and edge servers construct a Client/Server based and P2P network assisted overlay with the increasing of viewers, which is called "client side peer-assisted" in this design. We compare the inner performance of PACDN with existing approaches based on comprehensive simulations and analysis. The results show that our proposed design outperforms previous systems in the service quality and scalability. PACDN has been implemented as an Internet live video streaming service and it was successfully deployed for broadcasting many important live programs in China in 2007. The industrial experiences prove that this design is scalable and reliable. We believe that the wide deployment of PACDN and its further development will soon benefit many more Internet users.},
keywords={Performance analysis;Large-scale systems;Streaming media;Scalability;Network servers;Internet;System performance;Peer to peer computing;Quality of service;Network topology;Content Distribution Network;Peer-to-Peer;Live Video Streaming;QoS;Scalability},
doi={10.1109/AINA.2008.132},
ISSN={2332-5658},
month={March},}
@INPROCEEDINGS{8596544,
author={Bouslama, Abdelilah and Laaziz, Yassin and Tali, Abdelhak},
booktitle={2018 IEEE 5th International Congress on Information Science and Technology (CiSt)},
title={Scalable and Real-Time Time Series Analytics: Telemedicine as Use Case},
year={2018},
volume={},
number={},
pages={70-73},
abstract={Real-time processing and data analytics of big data has become a main operation in different business, such as extracting manufacturing, healthcare, smart Cities, social and media network data, ... etc. Also another concept has been appear that significant interest in building new system refers to high-speed real-time and near real-time data streams. Big data workloads in the wild show a strong temporal variability that not only poses the risk of slow responsiveness in data analysis, but also leads to a high risk of service outage. The recent development of batch streaming systems based on the MapReduce framework is shown effective on non-overloaded systems. However, little is known on how to enhance the performance of the batch streaming systems for bursty workloads. In this paper, we propose a latency-driven data controller, which aims to process as much data as possible, while processing these as fast as the application target latency and system capacity allow. In particular by implementing Spark Streaming as emerging and complex batch streaming system which include features that allow placing data in an augmented distributed memory, shedding out-of-date data, (improving the processing locality of Map tasks, and delaying data processing in transient overloads.},
keywords={Distributed databases;Real-time systems;Deep learning;Sparks;Time series analysis;Benchmark testing;Prediction algorithms;Real time;Spark;Kafka;Cassandra;IOT;Tensorflow;Deep Learning;Times Series},
doi={10.1109/CIST.2018.8596544},
ISSN={2327-1884},
month={Oct},}
@INPROCEEDINGS{7851536,
author={Tournavitis, Georgios and Franke, Björn},
booktitle={2010 19th International Conference on Parallel Architectures and Compilation Techniques (PACT)},
title={Semi-automatic extraction and exploitation of hierarchical pipeline parallelism using profiling information},
year={2010},
volume={},
number={},
pages={377-388},
abstract={In recent years multi-core computer systems have left the realm of high-performance computing and virtually all of today's desktop computers and embedded computing systems are equipped with several processing cores. Still, no single parallel programming model has found widespread support and parallel programming remains an art for the majority of application programmers. In addition, there exists a plethora of sequential legacy applications for which automatic parallelization is the only hope to benefit from the increased processing power of modern multi-core systems. In the past automatic parallelization largely focused on data parallelism. In this paper we present a novel approach to extracting and exploiting pipeline parallelism from sequential applications. We use profiling to overcome the limitations of static data and control flow analysis enabling more aggressive parallelization. Our approach is orthogonal to existing automatic parallelization approaches and additional data parallelism may be exploited in the individual pipeline stages. The key contribution of this paper is a whole-program representation that supports profiling, parallelism extraction and exploitation. We demonstrate how this enhances conventional pipeline parallelization by incorporating support for multi-level loops and pipeline stage replication in a uniform and automatic way. We have evaluated our methodology on a set of multimedia and stream processing benchmarks and demonstrate speedups of up to 4.7 on a eight-core Intel Xeon machine.},
keywords={Pipelines;Pipeline processing;Multimedia communication;Streaming media;Programming;Decoding;Parallelization;Pipeline Parallelism;Streaming Applications;Program Dependence Graph},
doi={},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6552430,
author={Hassan, Md. Mahedi and Neng, Choong Khong and Suan, Lee Cheng},
booktitle={IET International Conference on Wireless Communications and Applications (ICWCA 2012)},
title={Performance analysis of video streaming on different hybrid CDN & P2P infrastructure},
year={2012},
volume={},
number={},
pages={1-6},
abstract={With the rapid expansion of network application over the Internet, the deployment of live streaming systems become more and more popular, significantly enhancing the user experience. As the numbers of users are expanding significantly, the traditional Client-Server architecture can't afford the number of growing users. Therefore the video quality of service and network scalability is become so deprived. Based on the demand of users and drawbacks of client-server architecture, institutes and researchers have provided effective solutions to contrive new application systems called Content Delivery Network (CDN) and Peerto-Peer (P2P) network. Recently, researchers have proposed a hybrid approach that amalgamates both CDN and P2P was proposed in the literature. The goal of this paper is to simulate and investigate the performance of hybrid CDN and P2P on live-casting video distribution, and contrast it against our propounded hybrid CDN and P2P with hierarchical arrangement called Dynamic Mobile Server (DMS), in terms of average frame loss ratio, packet loss ratio and peak signal noise ratio.},
keywords={content delivery network;peer-to-peer network;dynamic mobile server;proxy server;peak signal noise ratio},
doi={10.1049/cp.2012.2087},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7973790,
author={Runsewe, Olubisi and Samaan, Nancy},
booktitle={2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)},
title={Cloud Resource Scaling for Big Data Streaming Applications Using a Layered Multi-dimensional Hidden Markov Model},
year={2017},
volume={},
number={},
pages={848-857},
abstract={Recent advancements in technology have led to a deluge of data that require real-time analysis with strict latency constraints. A major challenge, however, is determining the amount of resources required by big data stream processing applications in response to heterogeneous data sources, streaming events, unpredictable data volume and velocity changes. Over-provisioning of resources for peak loads can be wasteful while under-provisioning can have a huge impact on the performance of the streaming applications. The majority of research efforts on resource scaling in the cloud are investigated from the cloud provider's perspective, they focus on web applications and do not consider multiple resource bottlenecks. We aim at analyzing the resource scaling problem from a big data streaming application provider's point of view such that efficient scaling decisions can be made for future resource utilization. This paper proposes a Layered Multi-dimensional Hidden Markov Model (LMD-HMM) for facilitating the management of resource auto-scaling for big data streaming applications in the cloud. Our detailed experimental evaluation shows that LMD-HMM performs best with an accuracy of 98%, outperforming the single-layer hidden markov model.},
keywords={Cloud computing;Hidden Markov models;Big Data;Real-time systems;Storms;Sparks;Data models;Big Data;Cloud Computing;Stream Processing;Resource Prediction;Resource Scaling;Layered Hidden Markov Model},
doi={10.1109/CCGRID.2017.147},
ISSN={},
month={May},}
@ARTICLE{8493343,
author={Runsewe, Olubisi and Samaan, Nancy},
journal={IEEE Transactions on Cloud Computing},
title={Cloud Resource Scaling for Time-Bounded and Unbounded Big Data Streaming Applications},
year={2021},
volume={9},
number={2},
pages={504-517},
abstract={Recent advancements in technology have led to a deluge of big data streams that require real-time analysis with strict latency constraints. A major challenge, however, is determining the amount of resources required by applications processing these streams given their high volume, velocity and variety. The majority of research efforts on resource scaling in the cloud are investigated from the cloud provider's perspective with little consideration for multiple resource bottlenecks. We aim at analyzing the resource scaling problem from an application provider's point of view such that efficient scaling decisions can be made. This paper provides two contributions to the study of resource scaling for big data streaming applications in the cloud. First, we present a Layered Multi-dimensional Hidden Markov Model (LMD-HMM) for managing time-bounded streaming applications. Second, to cater to unbounded streaming applications, we propose a framework based on a Layered Multi-dimensional Hidden Semi-Markov Model (LMD-HSMM). The parameters in our models are evaluated using modified Forward and Backward algorithms. Our detailed experimental evaluation results show that LMD-HMM is very effective with respect to cloud resource prediction for bounded streaming applications running for shorter periods while the LMD-HSMM accurately predicts the resource usage for streaming applications running for longer periods.},
keywords={Hidden Markov models;Cloud computing;Big Data;Task analysis;Real-time systems;Predictive models;Storms;Big data;cloud computing;stream processing;resource prediction;resource scaling;layered hidden Markov model;layered hidden semi-Markov model},
doi={10.1109/TCC.2018.2876242},
ISSN={2168-7161},
month={April},}
@INPROCEEDINGS{5235330,
author={Boggia, G. and Camarda, P. and Fortuna, R. and Grieco, L. A.},
booktitle={2009 Proceedings of 18th International Conference on Computer Communications and Networks},
title={A Scheduling Strategy to Avoid Playout Interruptions in Video Streaming Systems},
year={2009},
volume={},
number={},
pages={1-6},
abstract={In Internet multimedia streaming, a raw quality base layer is adaptively enriched with one or more enhancement layers to fully use the available bandwidth. In this work, using a control theoretic approach, we design and implement an innovative scheduling strategy for properly distributing the network available bandwidth among base and enhancement layers, in order to avoid playout interruptions due to base layer underflows at the decoder side. The proposed solution has been casted in a H.264/AVC SVC video streaming architecture. Experimental results, collected using a single bottleneck testbed and three different benchmarking video sequences, have demonstrated that the proposed scheduling strategy is able to avoid or strongly limit the number of playout interruptions under moderate or high traffic conditions, respectively.},
keywords={Streaming media;Bandwidth;MPEG 4 Standard;Algorithm design and analysis;Testing;Adaptive systems;Performance evaluation;Internet;Throughput;Decoding},
doi={10.1109/ICCCN.2009.5235330},
ISSN={1095-2055},
month={Aug},}
@INPROCEEDINGS{9671679,
author={Zhao, Yifan and Yang, Xian and Vatsavai, Ranga Raju},
booktitle={2021 IEEE International Conference on Big Data (Big Data)},
title={A Scalable System for Searching Large-scale Multi-sensor Remote Sensing Image Collections},
year={2021},
volume={},
number={},
pages={3780-3783},
abstract={Huge amounts of remote sensing data collected from hundreds of operational satellites in conjunction with on-demand UAV based imaging products are offering unprecedented capabilities towards monitoring dynamic earth resources. However, searching for the right combination of imagery products that satisfy an application requirement is a daunting task. Earlier efforts at streamlining remote sensing data discovery include NASA’s Earth Observing System (EOS) Data and Information System (EOSDIS), USGS Global Visualization Viewer (GloVis), and several other research systems like Minnesota MapServer. These systems were built on top of metadata harvesting, indexing, keyword searching modules which were not scalable and interoperable. To address these challenges, recently the SpatioTemporal Asset Catalog (STAC) specification was developed to provide a common language to describe a range of geospatial information, so that data products can be more easily indexed and discovered. In this paper we present an highly scalable STAC API based system with spatiotemporal indexing support. Experimental evaluation shows that our spatiotemporal indexing based queries are 1000x faster than standard STAC API server.},
keywords={Earth Observing System;Urban areas;Metadata;Big Data;Streaming media;Spatiotemporal phenomena;Task analysis;SpatioTemporal Asset Catalog (STAC);Spa-tiotemporal Indexing;Remote Sensing Data Discovery},
doi={10.1109/BigData52589.2021.9671679},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6725057,
author={Walczak, M. and Lewandowski, M. and Żołek, N.},
booktitle={2013 IEEE International Ultrasonics Symposium (IUS)},
title={Optimization of real-time ultrasound PCIe data streaming and OpenCL processing for SAFT imaging},
year={2013},
volume={},
number={},
pages={2064-2067},
abstract={Our goal is to develop a complete ultrasound platform based on real-time SAFT (Synthetic Aperture Focusing Technique) GPU processing. We are planning to integrate all the ultrasound modules and processing resources (GPU) in a single rack enclosure with the PCIe switch fabric backplane. The first developed module (RX64) provides acquisition and streaming of 64 ultrasound channels. We implemented and benchmarked data streaming from the RX64 to the GPU memory and the SAFT image reconstruction on the GPU. A high system performance was achieved using hardware assisted direct memory transfers and pipelined processing workflow. The complete system throughput, including 128 channel data transfer at 16kS per line and low-resolution 256×256 pixel image SAFT reconstruction on a single Nvidia K5000 GPU, reached 450 fps. The obtained results proved the feasibility of the ultrasound real-time imaging system with GPU SAFT processing.},
keywords={Graphics processing units;Ultrasonic imaging;Imaging;Kernel;Real-time systems;Apertures;Data transfer;ultrasonic imaging;synthetic aperture;GPGPU;FPGA},
doi={10.1109/ULTSYM.2013.0527},
ISSN={1051-0117},
month={July},}
@INPROCEEDINGS{4488121,
author={Bracciale, L. and Lo Piccolo, F. and Luzzi, D. and Salsano, S. and Bianchi, G. and Blefari-Melazzi, N.},
booktitle={2008 4th International Telecommunication Networking Workshop on QoS in Multiservice IP Networks},
title={A push-based scheduling algorithm for large scale P2P live streaming},
year={2008},
volume={},
number={},
pages={1-7},
abstract={In this paper, we present a chunk scheduling algorithm for a mesh-based peer-to-peer live streaming system and we evaluate it by simulations over large-scale networks. Literature papers typically design chunk scheduling algorithms by considering the chunk delivery ratio as performance metric. We propose a push-based algorithm, which not only tries to maximize the chunk delivery ratio but it also takes into account and tries to minimize the delivery delay of chunks at the peer nodes. This is an important requirement, when dealing with real-time multimedia flows. Another important contribution of this paper is the design and implementation of a simulator able to evaluate the performance of large scale P2P networks (tens of thousands peers). The importance of this contribution lies in the fact that existing simulators and performance studies handle at most hundreds or few thousands of peers, while real-life P2P streaming systems aim at distributing contents to several hundreds of thousands, if not millions, of users. The performance evaluation study aims at providing a comprehensive view of what performance can be expected for mesh-based peer-to-peer streaming systems, both in terms of chunk delivery ratio and delay, for a large range of the number of users. The individual effect of a variety of system parameters, and especially number of partner nodes in the mesh, constrained link bandwidth, node heterogeneity, and network size, has been analyzed. Our results show that performances of the proposed push-based solution are already quite effective even with severely bandwidth constrained large scale networks.},
keywords={Scheduling algorithm;Large-scale systems;Peer to peer computing;Delay;Measurement;Bandwidth;Algorithm design and analysis;Scalability;Streaming media;Proposals},
doi={10.1109/ITNEWS.2008.4488121},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8457872,
author={Truong, Tri Minh and Harwood, Aaron and Sinnott, Richard O. and Chen, Shiping},
booktitle={2018 IEEE 11th International Conference on Cloud Computing (CLOUD)},
title={Performance Analysis of Large-Scale Distributed Stream Processing Systems on the Cloud},
year={2018},
volume={},
number={},
pages={754-761},
abstract={Real-time data processing is often a necessity as it can provide insights that have less value if discovered off-line or after the fact. However, large-scale stream processing systems are non-trivial to build and deploy. While there are many frameworks that allow users to create large-scale distributed systems, there remains many challenges in understanding the performance, cost of deployment and considerations and impact of potential (partial) outages on real-time systems performance. Our work considers the performance of Cloud-based stream processing systems in terms of back-pressure and expected utilization. The performance of an exemplar stream application is explored using different Cloud-based virtual machine resources and where the scale of deployment and cost benefits are taken into consideration in relation to the overall performance. To achieve this, we develop an algorithm based on queueing theory to predict the throughput and latency of stream data processing while supporting system stability. Our methodology for making fundamental measurements is applicable to mainstream stream processing frameworks such as Apache Storm and Heron. The method is especially suitable for large-scale distributed stream processing where jobs can run for extended time periods. We benchmark the performance of the system on the national research cloud of Australia (Nectar), and present a performance analysis based on estimating the overall effective utilization.},
keywords={Queueing analysis;Real-time systems;Topology;Throughput;Storms;Cloud computing;Steady-state;performance analysis;stream processing;Cloud},
doi={10.1109/CLOUD.2018.00103},
ISSN={2159-6190},
month={July},}
@INPROCEEDINGS{5433193,
author={Narang, Ankur and Agarwal, Vikas and Kedia, Monu and Garg, Vijay K},
booktitle={2009 International Conference on High Performance Computing (HiPC)},
title={Highly scalable algorithm for distributed real-time text indexing},
year={2009},
volume={},
number={},
pages={332-341},
abstract={Stream computing research is moving from terascale to petascale levels. It aims to rapidly analyze data as it streams in from many sources and make decisions with high speed and accuracy in fields as diverse as security surveillance and financial services including stock trading. We specifically consider real-time text indexing and search with high input data rates (10 GB/s or more) along with small index age-off (expiry) time. This makes it necessary to have maximal indexing rates for large volumes of data as well as minimal latency for indexing (time between start of indexing for a document and its availability for search) while maintaining very-low search response time. In addition, future massively parallel architectures with storage class memories will enable high speed in-memory real-time indexing, where index can be completely stored in a high capacity storage class memory. In this paper, we present the design of distributed data-structures and distributed real-time text indexing algorithm for parallel systems having large (thousands to hundred thousand) number of cores/processors, while simultaneously providing acceptable search performance [1]. The inherent trade-offs involved in index space, indexing throughput and search response time make this problem particularly challenging. Our algorithm uses group-based index construction and leverages novel index data structures that reduce load imbalance and make text indexing and merge process more scalable and efficient. We show analytically that the asymptotic parallel time complexity of our distributed indexing algorithm, is at least ?(log(P)) factor better than typical indexing approaches, where P is the number of indexing nodes in a group. We further demonstrate the performance and scalability of our distributed indexing algorithm, on an MPP architecture (Blue Gene/L) using actual IBM intranet data. We achieved high indexing throughput of around 312 GB/min on an 8 K node Blue Gene/L machine. In comparison with parallel indexing implemented using typical approaches like CLucene, this is 3?-7? better. To the best of our knowledge, this is the first published result on indexing throughput at such a large scale, with sustained search performance. We further show that our approach is scalable to 128 K nodes, giving an estimated indexing throughput of 5 T B/min. We also achieved indexing latency that is around 10? better than typical indexing approaches.},
keywords={Indexing;Delay;Throughput;Algorithm design and analysis;Petascale computing;Data analysis;Data security;Surveillance;Parallel architectures;Real time systems},
doi={10.1109/HIPC.2009.5433193},
ISSN={1094-7256},
month={Dec},}
@INPROCEEDINGS{5395356,
author={Xu, Jialing and Yang, Guang-Hua and Li, Victor O.K.},
booktitle={2009 15th International Conference on Parallel and Distributed Systems},
title={A Population Dynamics Model for Data Streaming over P2P Networks},
year={2009},
volume={},
number={},
pages={602-608},
abstract={Data streaming (DS) over peer-to-peer (P2P) networks has been intensively studied in recent years and there have been various schemes proposed already. To evaluate these schemes, either measurement in experimental implementations, or simulation and theoretical analysis have been used. The former is inadequate as data are collected from different experiments, while the latter lacks a proper theoretical dynamics model. Our research aims at providing a general theoretical model to evaluate DS over P2P systems and analyze their dynamic behaviors. In this paper, with the analysis and abstraction of the characteristics of peers and their organization in DS over P2P, we propose a general population dynamics model for DS over P2P with fixed population. The model depicts the dynamic distribution of peers as a closed Markov queuing network. In particular, the model is scheme-independent and can be used with various schemes. Through theoretical analysis, we prove the model has equilibrium and only one closed-form solution. Besides, we verify the model through simulations, and show that it is a helpful analytical tool with a case study.},
keywords={Peer to peer computing;Analytical models;Streaming media;Scalability;Costs;Closed-form solution;IP networks;Performance analysis;Multimedia communication;Stock markets;peer-to-peer;data streaming;Markov queuing network;system dynamics},
doi={10.1109/ICPADS.2009.56},
ISSN={1521-9097},
month={Dec},}
@INPROCEEDINGS{8514883,
author={Javed, M. Haseeb and Lu, Xiaoyi and Panda, Dhabaleswar K.},
booktitle={2018 IEEE International Conference on Cluster Computing (CLUSTER)},
title={Cutting the Tail: Designing High Performance Message Brokers to Reduce Tail Latencies in Stream Processing},
year={2018},
volume={},
number={},
pages={223-233},
abstract={Over the last decade, organizations have become heavily reliant on providing near-instantaneous insights to the end user based on vast amounts of data collected from various sources in real-time. In order to accomplish this task, a stream processing pipeline is constructed, which in its most basic form, consists of a Stream Processing Engine (SPE) and a Message Broker (MB). The SPE is responsible for performing actual computations on the data and providing insights from it. MB, on the other hand, acts as an intermediate queue to which data is written by ephemeral sources and then fetched by the SPE to perform computations on. Due to the inherent real-time nature of such a pipeline, low latency is a highly desirable feature for them. Thus, several existing research works in the community focus on improving latency and throughput of the streaming pipeline. However, there is a dearth of studies optimizing the tail latencies of such pipelines. Moreover, the root cause of this high tail latency is still vague. In this paper, we propose a model-based approach to analyze in-depth the reasons behind high tail latency in streaming systems such as Apache Kafka. Having found the MB to be a major contributor of messages with high tail latencies in a streaming pipeline, we design and implement an RDMA-enhanced high-performance MB, called Frieda, with the higher goal of accelerating any arbitrary stream processing pipeline regardless of the SPE used. Our experiments show a reduction of up to 98% in 99.9th percentile latency for microbenchmarks and up to 31% for full-fledged stream processing pipeline constructed using Yahoo! Streaming Benchmark.},
keywords={Pipelines;Real-time systems;Message systems;Benchmark testing;Engines;Throughput;Analytical models;Stream Processing, Message Broker, Tail Latency, Kafka, RDMA},
doi={10.1109/CLUSTER.2018.00040},
ISSN={2168-9253},
month={Sep.},}
@INPROCEEDINGS{9378241,
author={Stein, Oliver and Blamey, Ben and Karlsson, Johan and Sabirsh, Alan and Spjuth, Ola and Hellander, Andreas and Toor, Salman},
booktitle={2020 IEEE International Conference on Big Data (Big Data)},
title={Smart Resource Management for Data Streaming using an Online Bin-packing Strategy},
year={2020},
volume={},
number={},
pages={2207-2216},
abstract={Data stream processing frameworks provide reliable and efficient mechanisms for executing complex workflows over large datasets. A common challenge for the majority of currently available streaming frameworks is efficient utilization of resources. Most frameworks use static or semi-static settings for resource utilization that work well for established use cases but lead to marginal improvements for unseen scenarios. Another pressing issue is the efficient processing of large individual objects such as images and matrices typical for scientific datasets. HarmonicIO has proven to be a good solution for streams of relatively large individual objects, as demonstrated in a benchmark comparison with the Apache Spark and Kafka streaming frameworks. We here present an extension of the HarmonicIO framework based on the online bin-packing algorithm. The main focus is to compare different strategies adapted in streaming frameworks for efficient resource utilization. Based on a real world use case from large-scale microscopy pipelines, we compare two different strategies of auto-scaling implemented in the HarmonicIO and Spark Streaming frameworks.},
keywords={Pipelines;Pressing;Streaming media;Big Data;Resource management;Sparks;Reliability;Data Streaming;Resource Management;Cloud Infrastructures;Scheduling;Big Data;Scientific Data analysis;Online Bin-packing;Profiling},
doi={10.1109/BigData50022.2020.9378241},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9835692,
author={Verheijde, Jim and Karakoidas, Vassilios and Fragkoulis, Marios and Katsifodimos, Asterios},
booktitle={2022 IEEE 38th International Conference on Data Engineering (ICDE)},
title={S-QUERY: Opening the Black Box of Internal Stream Processor State},
year={2022},
volume={},
number={},
pages={1314-1327},
abstract={Distributed streaming dataflow systems have evolved into scalable and fault-tolerant production-grade systems. Their applicability has departed from the mere analysis of streaming windows and complex-event processing, and now includes cloud applications and machine learning inference. Although the advancements in the state management of streaming systems have contributed significantly to their maturity, the internal state of streaming operators has been so far hidden from external applications. However, that internal state can be seen as a materialized view that can be used for analytics, monitoring, and debugging. In this paper we argue that exposing the internal state of streaming systems to outside applications by making it queryable, opens the road for novel use cases. To this end, we introduce S-QUERY: an approach and reference architecture where the state of stream processors can be queried - either live or through snapshots, achieving different isolation levels. We show how this new capability can be implemented in an existing open-source stream processor, and how queryable state can affect the performance of such a system. Our experimental evaluation suggests that the snapshot configuration adds only up to 8ms latency in the 99.99thpercentile and negligible increase in 0-90thpercentiles.},
keywords={Fault tolerance;Program processors;Databases;Roads;Fault tolerant systems;Machine learning;Debugging},
doi={10.1109/ICDE53745.2022.00103},
ISSN={2375-026X},
month={May},}
@INPROCEEDINGS{7484160,
author={Xu, Le and Peng, Boyang and Gupta, Indranil},
booktitle={2016 IEEE International Conference on Cloud Engineering (IC2E)},
title={Stela: Enabling Stream Processing Systems to Scale-in and Scale-out On-demand},
year={2016},
volume={},
number={},
pages={22-31},
abstract={The era of big data has led to the emergence of new real-time distributed stream processing engines like Apache Storm. We present Stela (STream processing ELAsticity), a stream processing system that supports scale-out and scale-in operations in an on-demand manner, i.e., when the user requests such a scaling operation. Stela meets two goals: 1) it optimizes post-scaling throughput, and 2) it minimizes interruption to the ongoing computation while the scaling operation is being carried out. We have integrated Stela into Apache Storm. We present experimental results using micro-benchmark Storm applications, as well as production applications from industry (Yahoo! Inc. and IBM). Our experiments show that compared to Apache Storm's default scheduler, Stela's scale-out operation achieves throughput that is 21-120% higher, and interruption time that is significantly smaller. Stela's scale-in operation chooses the right set of servers to remove and achieves 2X-5X higher throughput than Storm's default strategy.},
keywords={Throughput;Storms;Measurement;Servers;Elasticity;Parallel processing;Engines;Distributed Systems;Stream Processing;Elasticity;Scalability},
doi={10.1109/IC2E.2016.38},
ISSN={},
month={April},}
@INPROCEEDINGS{6038734,
author={Ding, Yan and Liu, Jiangchuan},
booktitle={2011 IEEE International Conference on Peer-to-Peer Computing},
title={Efficient stereo segment scheduling in peer-to-peer 3D/multi-view video streaming},
year={2011},
volume={},
number={},
pages={182-191},
abstract={3D (or stereo) video has been a visually appealing and costly affordable technology. More sophisticated multi-view videos have also been demonstrated. Yet their remarkably increased data volume poses greater challenges to the conventional client/server streaming systems, which has already suffered from supporting 2D videos. The stringent multi-stream synchronization further complicate the system design. In this paper, we present an initial attempt toward efficient streaming of stereo/multi-view videos over a peer-to-peer network. We show that the inherent multi-stream nature of stereo video makes segment scheduling more difficult, which is particularly acute with the existence of multiple senders in a peer-to-peer overlay. We formulate the stereo segment scheduling problem as a Binary Quadratic Programming problem and optimally solve it using an MIQP solver. However, given the high peer dynamics and the stringent playback deadline in real-time streaming, the optimal solution is too costly to be obtained. Thus, we develop two efficient algorithms to allow peers frequently compute the scheduling. We show that one of the proposed algorithms can achieve an analytical guarantee in the worst case performance, in particular, the approximation factor is at most 3 comparing with the optimal solution. We implement the proposed algorithms and the optimal in a peer-to-peer simulating system, and show that the proposed algorithms can achieve near-optimal performance efficiently. We further implement two other scheduling algorithms that are used in popular peer-to-peer streaming systems for comparison, and extend our design to support multi-view video with view diversity and dynamics. Under different end-system and network configurations with both stereo and multi-view streaming, the simulation results demonstrate that our algorithms outperform others in terms of streaming quality, stream synchronization/smoothness and scalability.},
keywords={Streaming media;Three dimensional displays;Bandwidth;Peer to peer computing;Heuristic algorithms;Synchronization;Algorithm design and analysis},
doi={10.1109/P2P.2011.6038734},
ISSN={2161-3567},
month={Aug},}
@ARTICLE{6587820,
author={Chen, Yishuai and Zhang, Baoxian and Liu, Yong and Zhu, Wei},
journal={IEEE Transactions on Multimedia},
title={Measurement and Modeling of Video Watching Time in a Large-Scale Internet Video-on-Demand System},
year={2013},
volume={15},
number={8},
pages={2087-2098},
abstract={Video watching time is a crucial measure for studying user watching behavior in online Internet video-on-demand (VoD) systems. It is important for system planning, user engagement understanding, and system quality evaluation. However, due to the limited access of user data in large-scale streaming systems, a systematic measurement, analysis, and modeling of video watching time is still missing. In this paper, we measure PPLive, one of the most popular commercial Internet VoD systems in China, over a three week period. We collect accurate user watching data of more than 100 million streaming sessions of more than 100 thousand distinct videos. Based on the measurement data, we characterize the distribution of watching time of different types of videos and reveal a number of interesting characteristics regarding the relation between video watching time and various video-related features (including video type, duration, and popularity). We further build a suite of mathematical models for characterizing these relationships. Extensive performance evaluation shows the high accuracy of these models as compared with commonly used data-mining based models. Our measurement and modeling results bring forth important insights for simulation, design, deployment, and evaluation of Internet VoD systems.},
keywords={Streaming media;Internet;Mathematical model;Watches;IPTV;Measurement;modeling;streaming media;videos;consumer behavior},
doi={10.1109/TMM.2013.2280123},
ISSN={1941-0077},
month={Dec},}
@INPROCEEDINGS{4211027,
author={Ferdman, Michael and Falsafi, Babak},
booktitle={2007 IEEE International Symposium on Performance Analysis of Systems & Software},
title={Last-Touch Correlated Data Streaming},
year={2007},
volume={},
number={},
pages={105-115},
abstract={Recent research advocates address-correlating predictors to identify cache block addresses for prefetch. Unfortunately, address-correlating predictors require correlation data storage proportional in size to a program's active memory footprint. As a result, current proposals for this class of predictor are either limited in coverage due to constrained on-chip storage requirements or limited in prediction lookahead due to long off-chip correlation data lookup. In this paper, we propose last-touch correlated data streaming (LT-cords), a practical address-correlating predictor. The key idea of LT-cords is to record correlation data off chip in the order they will be used and stream them into a practically-sized on-chip table shortly before they are needed, thereby obviating the need for scalable on-chip tables and enabling low-latency lookup. We use cycle-accurate simulation of an 8-way out-of-order superscalar processor to show that: (1) LT-cords with 214KB of on-chip storage can achieve the same coverage as a last-touch predictor with unlimited storage, without sacrificing predictor lookahead, and (2) LT-cords improves performance by 60% on average and 385% at best in the benchmarks studied},
keywords={Prefetching;Proposals;Delay;Memory;Data structures;Microarchitecture;Computer architecture;Laboratories;Predictive models;History},
doi={10.1109/ISPASS.2007.363741},
ISSN={},
month={April},}
@INPROCEEDINGS{7161530,
author={Kreutzer, Moritz and Pieper, Andreas and Hager, Georg and Wellein, Gerhard and Alvermann, Andreas and Fehske, Holger},
booktitle={2015 IEEE International Parallel and Distributed Processing Symposium},
title={Performance Engineering of the Kernel Polynomal Method on Large-Scale CPU-GPU Systems},
year={2015},
volume={},
number={},
pages={417-426},
abstract={The Kernel Polynomial Method (KPM) is a well-established scheme in quantum physics and quantum chemistry to determine the Eigen value density and spectral properties of large sparse matrices. In this work we demonstrate the high optimization potential and feasibility of peta-scale heterogeneous CPU-GPU implementations of the KPM. At the node level we show that it is possible to decouple the sparse matrix problem posed by KPM from main memory bandwidth both on CPU and GPU. To alleviate the effects of scattered data access we combine loosely coupled outer iterations with tightly coupled block sparse matrix multiple vector operations, which enables pure data streaming. All optimizations are guided by a performance analysis and modelling process that indicates how the computational bottlenecks change with each optimization step. Finally we use the optimized node-level KPM with a hybrid-parallel framework to perform large-scale heterogeneous electronic structure calculations for novel topological materials on a pet scale-class Cray XC30 system.},
keywords={Sparse matrices;Optimization;Kernel;Graphics processing units;Computer architecture;Eigenvalues and eigenfunctions;Frequency modulation;Parallel programming;Quantum mechanics;Performance analysis;Sparse matrices},
doi={10.1109/IPDPS.2015.76},
ISSN={1530-2075},
month={May},}
@INPROCEEDINGS{6176388,
author={Sbirlea, Dragos and Shirako, Jun and Newton, Ryan and Sarkar, Vivek},
booktitle={2011 First Workshop on Data-Flow Execution Models for Extreme Scale Computing},
title={SCnC: Efficient Unification of Streaming with Dynamic Task Parallelism},
year={2011},
volume={},
number={},
pages={58-65},
abstract={Stream processing is a special form of the dataflow execution model that offers extensive opportunities for optimization and automatic parallelization. To take full advantage of the paradigm, however, typically requires programmers to learn a new language and re-implement their applications. This work shows that it is possible to exploit streaming as a safe and automatic optimization of a more general dataflow-based modelâ€"one in which computation kernels are written in standard, general-purpose languages and organizedas a coordination graph.We propose Streaming Concurrent Collections (SCnC), a streaming system that can efficiently run a subset of programs supported by Concurrent Collections (CnC). CnC is a general purpose parallel programming paradigm with a task-parallel look and feel but based on dataflow graph principles. Its expressiveness extends to any arbitrary task graph. Integration of these models would allow application developers to benefit from the performance and tight memory footprint of stream parallelism for eligible subgraphs of their application.In this paper we formally define the requirements (streaming access patterns) needed for using SCnC, and outline a static decision procedure for identifying and processing eligible SCnC subgraphs.We present initial results on an prototype implementation that show that transitioning from general CnC to SCnC leads to a throughput increase of up to 40x for certain benchmarks, and also enable programs with large data sizes to execute in available memory for cases where CnC execution may run out of memory.},
keywords={System recovery;Runtime;Synchronization;Programming;Computational modeling;Shape;Prototypes;streaming;dataflow;dynamic task parallelism},
doi={10.1109/DFM.2011.13},
ISSN={},
month={Oct},}
@ARTICLE{8013748,
author={Al-Zubaidy, Hussein and Fodor, Viktoria and Dán, György and Flierl, Markus},
journal={IEEE Transactions on Multimedia},
title={Reliable Video Streaming With Strict Playout Deadline in Multihop Wireless Networks},
year={2017},
volume={19},
number={10},
pages={2238-2251},
abstract={Motivated by emerging vision-based intelligent services, we consider the problem of rate adaptation for high-quality and low-delay visual information delivery over wireless networks using scalable video coding. Rate adaptation in this setting is inherently challenging due to the interplay between the variability of the wireless channels, the queuing at the network nodes, and the frame-based decoding and playback of the video content at the receiver at very short time scales. To address the problem, we propose a low-complexity model-based rate adaptation algorithm for scalable video streaming systems, building on a novel performance model based on stochastic network calculus. We validate the analytic model using extensive simulations. We show that it allows fast near-optimal rate adaptation for fixed transmission paths, as well as cross-layer optimized routing and video rate adaptation in mesh networks, with less than 10% quality degradation compared to the best achievable performance.},
keywords={Streaming media;Adaptation models;Calculus;Delays;Video coding;Wireless networks;Multihop fading channels;network calculus;performance analysis;scalable video coding;wireless multimedia},
doi={10.1109/TMM.2017.2742399},
ISSN={1941-0077},
month={Oct},}
@INPROCEEDINGS{4110188,
author={Gill, Gennette and Hansen, John and Singh, Montek},
booktitle={2006 IEEE/ACM International Conference on Computer Aided Design},
title={Loop Pipelining for High-Throughput Stream Computation Using Self-Timed Rings},
year={2006},
volume={},
number={},
pages={289-296},
abstract={We present a technique for increasing the throughput of stream processing architectures by removing the bottlenecks caused by loop structures. We implement loops as self-timed pipelined rings that can operate on multiple data sets concurrently. Our contribution includes a transformation algorithm which takes as input a high-level program and gives as output the structure of an optimized pipeline ring. Our technique handles nested loops and is further enhanced by loop unrolling. Simulations run on benchmark examples show a 1.3 to 4.9times speedup without unrolling and a 2.6 to 9.7times speedup with twofold loop unrolling},
keywords={Pipeline processing;Streaming media;Throughput;Iterative algorithms;Hardware;Computer architecture;Concurrent computing;Cryptography;Iterative methods;Delay},
doi={10.1109/ICCAD.2006.320135},
ISSN={1558-2434},
month={Nov},}
@INPROCEEDINGS{9215262,
author={Harini, S and Ravikumar, Aswathy},
booktitle={2020 International Conference on Smart Electronics and Communication (ICOSEC)},
title={Effect of Parallel Workload on Dynamic Voltage Frequency Scaling for Dark Silicon Ameliorating},
year={2020},
volume={},
number={},
pages={1012-1017},
abstract={Dynamic Voltage and Frequency Scaling (DVFS) approach is proposed to control the power consumption in devices of different types like from a small mobile device to a huge server. This paper aims to study the effect of parallel execution of two benchmark applications, one the Stanford Single Source benchmarks (lightweight parallel code) and, Stanford Parallel Applications for Shared Memory (SPLASH-2) programs (heavy real-time data streaming parallel applications that run on multi -core clusters) on DVFS for dark silicon ameliorating. Both these benchmarks executed on a gem5 Full System simulator, booting a linaro based linux kernel. To get a holistic big picture of the power and thermal properties of systems that run on DVFS, in addition to the control feature present in gem 5, a power-estimation framework used for the evaluation of the efficiency of various DVFS policies, the MCPAT and Hotspot is also employed. Based on the execution of Stanford workloads DVFS model is analyzed in terms of memory footprint and on other critical processor performance metrics, like running time per core, bus latency, number of read, writes, access time, cache hit or miss. The gem5 is extended with full DVFS support by the addition of a framework in which easy power-model integration can be done.},
keywords={Benchmark testing;Timing;Power demand;Kernel;Transistors;Voltage control;Multicore processing;Shared Memory;Power consumption;Gem5;Dynamic Voltage and Frequency Scaling;Voltage Regulator;Stanford Parallel Applications for Shared-Memory;McPAT (Multicore Power;Area and Timing},
doi={10.1109/ICOSEC49089.2020.9215262},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{5158431,
author={Meng, Shicong and Kashyap, Srinivas R. and Venkatramani, Chitra and Liu, Ling},
booktitle={2009 29th IEEE International Conference on Distributed Computing Systems},
title={REMO: Resource-Aware Application State Monitoring for Large-Scale Distributed Systems},
year={2009},
volume={},
number={},
pages={248-255},
abstract={To observe, analyze and control large scale distributed systems and the applications hosted on them, there is an increasing need to continuously monitor performance attributes of distributed system and application states. This results in application state monitoring tasks that require fine-grained attribute information to be collected from relevant nodes efficiently. Existing approaches either treat multiple application state monitoring tasks independently and build ad-hoc monitoring trees for each task, or construct a single static monitoring tree for multiple tasks. We argue that a careful planning of multiple application state monitoring tasks by jointly considering multi-task optimization and node level resource constraints can provide significant gains in performance and scalability. In this paper, we present REMO, a REsource-aware application state MOnitoring system. REMO produces a forest of optimized monitoring trees through iterations of two phases, one phase exploring cost sharing opportunities via estimation and the other refining the monitoring plan through resource-sensitive tree construction. Our experimental results include those gathered by deploying REMO on a BlueGene/P rack running IBM's large-scale distributed streaming system - System S. Using REMO running over 200 monitoring tasks for an application deployed across 200 nodes results in a 35%-45% decrease in the percentage error of collected attributes compared to existing schemes.},
keywords={Monitoring;Large-scale systems;Control system analysis;Performance analysis;Distributed control;Control systems;Constraint optimization;Performance gain;Scalability;Cost function;State monitoring;Resource-Aware;Distributed Systems;Data Stream;Overlay;Continuous Query},
doi={10.1109/ICDCS.2009.15},
ISSN={1063-6927},
month={June},}
@INPROCEEDINGS{5729398,
author={Boudko, Svetlana and Leister, Wolfgang and Griwodz, Carsten and Halvorsen, Pål},
booktitle={2010 IEEE 4th International Conference on Internet Multimedia Services Architecture and Application},
title={Maximizing video quality for several unicast streams in a multipath overlay network},
year={2010},
volume={},
number={},
pages={1-5},
abstract={A streaming system that uses an overlay network for multipath streaming needs to make decisions concerning the distribution of the available bandwidth among all of its clients. This decision making should aim at delivering the best possible quality to all clients while providing an optimal utilization of the network resources. We consider a scenario where videos are hierarchically layered-encoded and most requests are negligibly overlapped in time. It implies that using multicast is not efficient, and instead, the streams are striped and allocated to multiple paths from the server to the client. To evaluate how well the rate-allocation algorithms approach optimality, we have earlier built a benchmarking system that provides the optimal solution for assigning available bandwidth to delivery paths. However, as video quality is not linearly related to bitrate, the trivial maximization of the total consumed bandwidth does not necessarily maximize the video quality. To address this problem, we define a metric that assesses video quality for a group of clients that we use as a utility function in the revised benchmarking system. Due to its concavity, this utility function distributes the bandwidth resources proportionally fair between the clients of the system.},
keywords={Benchmark testing;Continuous wavelet transforms;Silicon},
doi={10.1109/IMSAA.2010.5729398},
ISSN={},
month={Dec},}
@INPROCEEDINGS{5425308,
author={Merani, M. L. and Leonardi, G. P. and Saladino, D.},
booktitle={GLOBECOM 2009 - 2009 IEEE Global Telecommunications Conference},
title={Scalability and Peer Churning in IP-TV: An Analytical Insight},
year={2009},
volume={},
number={},
pages={1-6},
abstract={Abstract-Peer-to-peer (P2P) technology for TV broadcasting over the Internet is becoming more and more popular in the very last years. This paper introduces a network-wide metric to assess the efficiency of P2P streaming systems and develops a mathematical model to explain: (i) the scalability of such architectures with the number of peers, as evidenced by recent measurements; (ii) the initial decrement of efficiency (hence, quality) when a sharp increase in the number of peers in system occurs, as reported by experimental data. As for the second point, the proposed model builds upon the fundamental remark that when a peer first joins the system, it has no video content to share with others: its upload contribution is null for an initial time interval and the new peer behaves as a free rider. Three situations concerning the system reaction to the requests of the new entering peers are examined: full compensation; partial compensation; no reaction at all. Depending on the system answer and on its extent, system efficiency is shown to exhibit different time trends.},
keywords={Scalability;Streaming media;Monitoring;TV broadcasting;Performance analysis;Delay;Peer to peer computing;Mathematics;Electronic mail;Internet},
doi={10.1109/GLOCOM.2009.5425308},
ISSN={1930-529X},
month={Nov},}
@ARTICLE{8113470,
author={Xu, Jian and Li, Fuxiang and Chen, Ke and Zhou, Fucai and Choi, Junho and Shin, Juhyun},
journal={IEEE Access},
title={Dynamic Chameleon Authentication Tree for Verifiable Data Streaming in 5G Networks},
year={2017},
volume={5},
number={},
pages={26448-26459},
abstract={Chameleon authentication tree (CAT) is an important authenticated data structure for verifiable data streaming in 5G networks. But the typical CAT cannot support the dynamic scenario very well because it cannot expend freely since its height is fixed. Therefore, we proposed a dynamic CAT (DCAT) with the feature of adaptive expansion. We divided the algorithms of the DCAT with the following phases: setup, append, query, and verification. The DCAT removes the drawbacks of the static CAT. In the setup phase, it is not required for the scale of the tree to be determined, and the scale of the tree can be adaptively expanded during the data-appending phase. Therefore, the DCAT can suit the data stream environment better. During the data querying phase, the average authentication path length has been reduced, which leads to less space requirement and better verification efficiency. Finally, we performed theoretical analysis and drew a comparison between the static CAT and the DCAT in terms of performance. The result indicates that the DCAT provides improvements in the performance of the data-appending, data-querying, and data verification processes.},
keywords={Authentication;Cats;Vegetation;Heuristic algorithms;Servers;Algorithm design and analysis;Verifiable data streaming;chameleon authentication tree;authenticated data structures;integrity},
doi={10.1109/ACCESS.2017.2771281},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{4671772,
author={Cao Liang and Xinming Huang},
booktitle={2008 IEEE Workshop on Signal Processing Systems},
title={SmartCell: A power-efficient reconfigurable architecture for data streaming applications},
year={2008},
volume={},
number={},
pages={257-262},
abstract={This paper presents SmartCell as a novel power efficient reconfigurable architecture targeted for data streaming applications. We describe the design details of the SmartCell architecture, including processing element, reconfigurable interconnection fabrics, instruction and control process and dynamic configuration scheme. The performance in terms of power efficiency and system throughput is evaluated through a set of benchmark applications, and is compared with ASIC, FPGA and RaPiD reconfigurable architecture. The results show that the SmartCell consumes about 52% and 75% less power than RaPiD and FPGA, respectively. It is demonstrated that SmartCell is a promising reconfigurable, power efficient and scalable computing architecture that can potentially bridge the gap between logic specific ASIC and configurable FPGA for data streaming applications.},
keywords={Reconfigurable architectures;Field programmable gate arrays;Application specific integrated circuits;Power system interconnection;Fabrics;Process control;Throughput;Computer architecture;Bridges;Reconfigurable logic;DSP;ASIC;FPGA;CGRA;power efficiency;reconfigurability;data streaming application},
doi={10.1109/SIPS.2008.4671772},
ISSN={2162-3570},
month={Oct},}
@INPROCEEDINGS{7502294,
author={Algemili, Usamah},
booktitle={2016 IEEE 2nd International Conference on Big Data Security on Cloud (BigDataSecurity), IEEE International Conference on High Performance and Smart Computing (HPSC), and IEEE International Conference on Intelligent Data and Security (IDS)},
title={Investigation of Reconfigurable FPGA Design for Processing Big Data Streams},
year={2016},
volume={},
number={},
pages={226-233},
abstract={Big Data situation has placed a tremendous pressure on the existing computational models. The challenges of Big Data call for a new approach to solve both software and hardware problems. Streaming applications is a form of on-demand software distribution. In streaming scenarios, only essential portions of an application's code need to be installed on the system, while the receiver performs the main operations. The necessary code and files are delivered over the network as, and when, they are required. The hardware architecture plays an important role in improving the efficiency of a streaming system. The variance of hardware performance on different HW architectures is quite interesting. Previous work confirms that the CPUs, GPUs, and FPGAs are performing differently on specific applications. The previous efforts of hardware benchmarking show that GPUs outperformed the other platforms in terms of execution time. CPUs outperformed in overall execution combined with transfer time. FPGAs outperformed for fixed algorithms using streaming [1]. Hence, this paper evaluates the performance of streaming applications on a pipelined FPGA design. In the context of real-time processing, it elects one of the Big Data streaming problems that gets a candidate for majority element on-the-fly, that is Moore's Voting Algorithm. The performance analysis of Moore's algorithm on FPGA highlights a noticeable improvement by using a pipelining architecture.},
keywords={Field programmable gate arrays;Big data;Computer architecture;Hardware;Pipeline processing;Software;Central Processing Unit;Big Data Processing;Streaming Processing;Reconfigurable Computing;FPGA Design;Pipeline Design;On-the-fly processing},
doi={10.1109/BigDataSecurity-HPSC-IDS.2016.75},
ISSN={},
month={April},}
@INPROCEEDINGS{9148636,
author={Carpio, Francisco and Delgado, Marta and Jukan, Admela},
booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)},
title={Engineering and Experimentally Benchmarking a Container-based Edge Computing System},
year={2020},
volume={},
number={},
pages={1-6},
abstract={While edge computing is envisioned to superbly serve latency sensitive applications, the implementation-based studies benchmarking its performance are few and far between. To address this gap, we engineer a modular edge cloud computing system architecture that is built on latest advances in containerization techniques, including Kafka, for data streaming, Docker, as application platform, and Firebase Cloud, as realtime database system. We benchmark the performance of the system in terms of scalability, resource utilization and latency by comparing three scenarios: cloud-only, edge-only and combined edge-cloud. The measurements show that edge-only solution outperforms other scenarios only when deployed with data located at one edge only, i.e., without edge computing wide data synchronization. In case of applications requiring data synchronization through the cloud, edge-cloud scales around a factor 10 times better than cloudonly, until certain number of concurrent users in the system, and above this point, cloud-only scales better. In terms of resource utilization, we observe that whereas the mean utilization increases linearly with the number of user requests, the maximum values for the memory and the network I/O heavily increase when with an increasing amount of data.},
keywords={Cloud computing;Edge computing;Benchmark testing;Containers;Scalability;Database systems;edge computing;cloud;IoT;networking},
doi={10.1109/ICC40277.2020.9148636},
ISSN={1938-1883},
month={June},}
@INPROCEEDINGS{5363755,
author={Kowalski, Greg and Hefeeda, Mohamed},
booktitle={2009 11th IEEE International Symposium on Multimedia},
title={Empirical Analysis of Multi-sender Segment Transmission Algorithms in Peer-to-Peer Streaming},
year={2009},
volume={},
number={},
pages={243-250},
abstract={We study and analyze segment transmission scheduling algorithms in swarm-based peer-to-peer (P2P) streaming systems. These scheduling algorithms are responsible for coordinating the streaming of video data from multiple senders to a receiver in each streaming session. Although scheduling algorithms directly impact the user-perceived visual quality in streaming sessions, they have not been rigorously analyzed in the literature. In this paper, we first conduct an extensive experimental study to evaluate various scheduling algorithms on many PlanetLab nodes distributed all over the world. We study three important performance metrics: (i) continuity index which captures the smoothness of the video playback, (ii) load balancing index which indicates how the load is spread across sending peers, and (iii) buffering delay required to ensure continuous playback. Our experimental analysis reveals the strengths and weaknesses of each scheduling algorithm, and provides insights for developing better ones in order to improve the overall performance of P2P streaming systems. Then, we propose a new scheduling algorithm called on-time delivery of VBR streams (ODV). Our experiments show that the proposed scheduling algorithm improves the playback quality by increasing the continuity index, requires smaller buffering delays, and achieves more balanced load distribution across peers.},
keywords={Algorithm design and analysis;Peer to peer computing;Scheduling algorithm;Streaming media;Video compression;Delay;Bit rate;Processor scheduling;Measurement;Load management;peer-to-peer streaming;segment scheduling;multisender transmission},
doi={10.1109/ISM.2009.55},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6465752,
author={Hazra, J. and Reddi, Ravi Kiran and Das, Kaushik and Seetharam, Deva P. and Sinha, A. K.},
booktitle={2012 3rd IEEE PES Innovative Smart Grid Technologies Europe (ISGT Europe)},
title={Power grid transient stability prediction using wide area synchrophasor measurements},
year={2012},
volume={},
number={},
pages={1-8},
abstract={Electric power systems are prone to various kinds of transient disturbances which exist only for a fraction of second and often trigger cascading failures. Hence it is important to detect and prevent them from spreading in time. Conventionally these events are prevented by deploying costly special protection systems (SPS). Unfortunately, in many cases SPSs mis-operate as they could not predict the stability well ahead and are designed to operate based on past experiences and extensive off-line simulations. This paper proposes an online transient stability prediction scheme based on live synchrophasor data. The novelty of the proposed method is that it accurately predicts the transient stability based on only few (10 to 12) sample fault data without solving computationally extensive electromechanical dynamics. Synchrophasor data from geographically distributed Phasor Measurement Units (PMUs) are collected, synchronized, aggregated (if required) and analyzed on a stream computing platform to predict the trajectories of the generators which are then used to predict the transient stability of the grid. Performance of the proposed scheme is evaluated on the benchmark systems and evaluation results are presented in this paper.},
keywords={Power system stability;Generators;Stability analysis;Transient analysis;Trajectory;Rotors;PMU;Synchrophasors;Transient Stability;Stream computing},
doi={10.1109/ISGTEurope.2012.6465752},
ISSN={2165-4824},
month={Oct},}
@INPROCEEDINGS{9751185,
author={Alhussain, Azzam and Lin, Mingjie},
booktitle={2022 56th Annual Conference on Information Sciences and Systems (CISS)},
title={Hardware-Efficient Deconvolution-Based GAN for Edge Computing},
year={2022},
volume={},
number={},
pages={172-176},
abstract={Generative Adversarial Networks (GAN) are cutting-edge algorithms for generating new data samples based on the learned data distribution. However, its performance comes at a significant cost in terms of computation and memory requirements. In this paper, we proposed an HW/SW co-design approach for training quantized deconvolution GAN (QDCGAN) implemented on FPGA using a scalable streaming dataflow architecture capable of achieving higher throughput versus resource utilization trade-off. The developed accelerator is based on an efficient deconvolution engine that offers high parallelism with respect to scaling factors for GAN-based edge computing. Furthermore, various precisions, datasets, and network scalability were analyzed for low-power inference on resource-constrained platforms. Lastly, an end-to-end open-source framework is provided for training, implementation, state-space exploration, and scaling the inference using Vivado high-level synthesis for Xilinx SoC-FPGAs, and a comparison testbed with Jetson Nano.},
keywords={Training;Deconvolution;Scalability;Memory management;Parallel processing;Generative adversarial networks;Throughput;GAN;FPGA;Deep Learning;Neural Network},
doi={10.1109/CISS53076.2022.9751185},
ISSN={},
month={March},}
@ARTICLE{9025240,
author={van Dongen, Giselle and Van den Poel, Dirk},
journal={IEEE Transactions on Parallel and Distributed Systems},
title={Evaluation of Stream Processing Frameworks},
year={2020},
volume={31},
number={8},
pages={1845-1858},
abstract={The increasing need for real-time insights in data sparked the development of multiple stream processing frameworks. Several benchmarking studies were conducted in an effort to form guidelines for identifying the most appropriate framework for a use case. In this article, we extend this research and present the results gathered. In addition to Spark Streaming and Flink, we also include the emerging frameworks Structured Streaming and Kafka Streams. We define four workloads with custom parameter tuning. Each of these is optimized for a certain metric or for measuring performance under specific scenarios such as bursty workloads. We analyze the relationship between latency, throughput, and resource consumption and we measure the performance impact of adding different common operations to the pipeline. To ensure correct latency measurements, we use a single Kafka broker. Our results show that the latency disadvantages of using a micro-batch system are most apparent for stateless operations. With more complex pipelines, customized implementations can give event-driven frameworks a large latency advantage. Due to its micro-batch architecture, Structured Streaming can handle very high throughput at the cost of high latency. Under tight latency SLAs, Flink sustains the highest throughput. Additionally, Flink shows the least performance degradation when confronted with periodic bursts of data. When a burst of data needs to be processed right after startup, however, micro-batch systems catch up faster while event-driven systems output the first events sooner.},
keywords={Benchmark testing;Sparks;Pipelines;Throughput;Storms;Microsoft Windows;Measurement;Apache spark;structured streaming;apache flink;apache kafka;kafka streams;distributed computing;stream processing frameworks;benchmarking;big data},
doi={10.1109/TPDS.2020.2978480},
ISSN={1558-2183},
month={Aug},}
@INPROCEEDINGS{7818662,
author={Wang, Guyue and Wada, Koichi and Yamagiwa, Shinichi},
booktitle={2016 Fourth International Symposium on Computing and Networking (CANDAR)},
title={Performance Evaluation of Parallelizing Algorithm Using Spanning Tree for Stream-Based Computing},
year={2016},
volume={},
number={},
pages={497-503},
abstract={This paper proposes a detailed performance evaluation of an algorithm using spanning tree that automatically exploits the parallelism and determines an execution order of multiple kernel programs in distributed environment. In stream-based computing, efficient parallel execution requires careful scheduling of the invocation of the kernel programs. By mapping a kernel to a node and an I/O stream between kernels to an edge, the entire stream process can be treated as a spanning tree. The spanning tree, which allows feedback and feedforward edges, is effective for expressing dependencies that exist among kernels. In spanning tree, the nodes at the same depth do not have edges between them, and thus can be executed in parallel in the case parent nodes have been already executed. The series of the nodes can be executed in a pipelined manner. Thus, the proposed algorithm can extract both spatial and temporal parallelism. To evaluate the effectiveness of the proposed algorithm, two applications have been developed and parallelized based on the proposed algorithm. The results show that the parallel execution using four nodes of a GPU cluster obtained 3.5 times speedup in 2D-FFT and 3.0 times speedup in LU decomposition, compared to the sequential execution.},
keywords={Parallel processing;Kernel;Pipelines;Graphics processing units;Performance evaluation;Clustering algorithms;Central Processing Unit;High Performance Computing;Stream Computing;Parallelizing Algorithm;Multiple GPUs;Spanning Tree},
doi={10.1109/CANDAR.2016.0092},
ISSN={2379-1896},
month={Nov},}
@INPROCEEDINGS{6009018,
author={Zhang, Yongpeng},
booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum},
title={Data Parallel Programming Model for Many-Core Architectures},
year={2011},
volume={},
number={},
pages={2065-2068},
abstract={Emerging accelerating architectures, such as GPUs, have proved successful in providing significant performance gains to various application domains. This is done by exploiting data parallelism in existing algorithms. However, programming in a data-parallel fashion imposes extra burdens to programmers, who are used to writing sequential programs. New programming models and frameworks are needed to reach a balance between programmability, portability and performance. We start from stream processing domain and propose GStream, a general-purpose, scalable data streaming framework on GPUs. The contributions of GStream are as follows: (1) We provide powerful, yet concise language abstractions suitable to describe conventional algorithms as streaming problems. (2) We project these abstractions onto GPUs to fully exploit their inherent massive data-parallelism. (3) We demonstrate the viability of streaming on accelerators. Experiments show that the proposed framework provides flexibility, programmability and performance gains for various benchmarks from a collection of domains, including but not limited to data streaming, data parallel problems, numerical codes and text search. This work lays a foundation to our future work to develop more general data parallel programming models for many-core architectures.},
keywords={Graphics processing unit;Parallel processing;Benchmark testing;Libraries;Kernel;Computer architecture},
doi={10.1109/IPDPS.2011.378},
ISSN={1530-2075},
month={May},}
@ARTICLE{9290133,
author={Bordin, Maycon Viana and Griebler, Dalvan and Mencagli, Gabriele and Geyer, Cláudio F. R. and Fernandes, Luiz Gustavo L.},
journal={IEEE Access},
title={DSPBench: A Suite of Benchmark Applications for Distributed Data Stream Processing Systems},
year={2020},
volume={8},
number={},
pages={222900-222917},
abstract={Systems enabling the continuous processing of large data streams have recently attracted the attention of the scientific community and industrial stakeholders. Data Stream Processing Systems (DSPSs) are complex and powerful frameworks able to ease the development of streaming applications in distributed computing environments like clusters and clouds. Several systems of this kind have been released and currently maintained as open source projects, like Apache Storm and Spark Streaming. Some benchmark applications have often been used by the scientific community to test and evaluate new techniques to improve the performance and usability of DSPSs. However, the existing benchmark suites lack of representative workloads coming from the wide set of application domains that can leverage the benefits offered by the stream processing paradigm in terms of near real-time performance. The goal of this article is to present a new benchmark suite composed of 15 applications coming from areas like Finance, Telecommunications, Sensor Networks, Social Networks and others. This article describes in detail the nature of these applications, their full workload characterization in terms of selectivity, processing cost, input size and overall memory occupation. In addition, it exemplifies the usefulness of our benchmark suite to compare real DSPSs by selecting Apache Storm and Spark Streaming for this analysis.},
keywords={Benchmark testing;Storms;Sparks;Task analysis;Throughput;Distributed databases;Tools;Data stream processing;big data;benchmarking;apache storm;spark streaming},
doi={10.1109/ACCESS.2020.3043948},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{5462030,
author={Liu, Zimu and Wu, Chuan and Li, Baochun and Zhao, Shuqiao},
booktitle={2010 Proceedings IEEE INFOCOM},
title={UUSee: Large-Scale Operational On-Demand Streaming with Random Network Coding},
year={2010},
volume={},
number={},
pages={1-9},
abstract={Since the inception of network coding in information theory, we have witnessed a sharp increase of research interest in its applications in communications and networking, where the focus has been on more practical aspects. However, thus far, network coding has not been deployed in real-world commercial systems in operation at a large scale, and in a production setting. In this paper, we present the objectives, rationale, and design in the first production deployment of random network coding, where it has been used in the past year as the cornerstone of a large-scale production on-demand streaming system, operated by UUSee Inc., delivering thousands of on-demand video channels to millions of unique visitors each month. To achieve a thorough understanding of the performance of network coding, we have collected 200 Gigabytes worth of real-world traces throughout the 17-day Summer Olympic Games in August 2008, and present our lessons learned after an in-depth trace-driven analysis.},
keywords={Large-scale systems;Network coding;Streaming media;Production systems;Peer to peer computing;Performance analysis;Network servers;Bandwidth;Protocols;Information theory},
doi={10.1109/INFCOM.2010.5462030},
ISSN={0743-166X},
month={March},}
@INPROCEEDINGS{9139645,
author={HoseinyFarahabady, M. Reza and Jannesari, Ali and Taheri, Javid and Bao, Wei and Zomaya, Albert Y. and Tari, Zahir},
booktitle={2020 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGRID)},
title={Q-Flink: A QoS-Aware Controller for Apache Flink},
year={2020},
volume={},
number={},
pages={629-638},
abstract={Modern stream-data processing platforms are required to execute processing pipelines over high-volume, yet high-velocity, datasets under tight latency constraints. Apache Flink has emerged as an important new technology of large-scale platform that can distribute processing over a large number of computing nodes in a cluster (i.e., scale-out processing). Flink allows application developers to design and execute queries over continuous raw-inputs to analyze a large amount of streaming data in a parallel and distributed fashion. To increase the throughput of computing resources in stream processing platforms, a service provider might be tempted to use a consolidation strategy to pack as many processing applications as possible on the working nodes, with the hope of increasing the total revenue by improving the overall resource utilization. However, there is a hidden trap for achieving such a higher throughput solely by relying on an interference-oblivious consolidation strategy. In practice, collocated applications in a shared platform can fiercely compete with each others for obtaining the capacity of shared resources (e.g., cache and memory bandwidth) which in turn can lead to a severe performance degradation for all consolidated workloads.This paper addresses the shared resource contention problem associated with the auto-resource controlling mechanism of Apache Flink engine running across a distributed cluster. A controlling strategy is proposed to handle scenarios in which stream processing applications may have different quality of service (QoS) requirements while the resource interference is considered as the key performance-limiting parameter. The performance evaluation is carried out by comparing the proposed controller with the default Flink resource allocation strategy in a testbed cluster with total 32 Intel Xeon cores under different workload traffic with up to 4000 streaming applications chosen from various benchmarking tools. Experimental results demonstrate that the proposed controller can successfully decrease the average latency of high priority applications by 223% during the burst traffic while maintaining the requested QoS enforcement levels.},
keywords={Quality of service;Resource management;Time factors;Engines;Data processing;Interference;Process control;Massive Data Stream Processing;Apache Flink;Meta-Scheduling;Resource Allocation;Computer System Modeling and Profiling;Model Predictive Controller},
doi={10.1109/CCGrid49817.2020.00-30},
ISSN={},
month={May},}
@INPROCEEDINGS{5684743,
author={Li, Maodong and Chen, Zhenzhong and Tan, Yap-Peng},
booktitle={2010 5th International ICST Conference on Communications and Networking in China},
title={Scalable video transmission over multiuser MIMO-OFDM systems},
year={2010},
volume={},
number={},
pages={1-8},
abstract={With the proliferation of wireless services, multimedia interactivities are quickly becoming ubiquitous. As multimedia traffics generally have large packets volume, high data rate requirements in wireless transmission are critical. Next generation wireless systems, e.g., multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM), provide high throughput and support flexible resource management strategies for multimedia services. By fully exploiting spatial, temporal, and frequency diversities of MIMO-OFDM systems, intelligent resource allocation schemes can increase the overall performance of the multimedia streaming system significantly. In this paper, we describe a general framework of cross-layer resource allocation design for scalable video transmission over multiuser MIMO-OFDM systems. Scalable video coding provides an efficient solution for video adaptation to satisfy diverse requirements from heterogeneous mobile clients according to their system specifications and channel conditions. Generally, the base layer of a scalable video bitstream is more important than the enhancement layer as the enhancement layer can only be used for decoding if the base layer is available. Scalable video packets are entitled with different priorities in video reconstructions. Adaptation can be achieved by discarding some enhancement layer packets when network is congested. Based on the characteristics of scalable video, our objective is to optimize the overall system performance for multiple scalable video downlink over the Space Division Multiple Access (SDMA)-OFDM system from a multiple-antenna base station. Our cross-layer optimization is achieved by jointly linking packet prioritization from application layer and radio resource allocation at the physical layer. Based on packet priority of scalable video, time-frequency resource, power and modulation schemes are adaptively selected based on a prioritized water filling algorithm to maximize the overall system performance and to ensure fairness among different users. The performance of the proposed strategy is demonstrated by experimental comparisons with conventional radio resource allocation schemes.},
keywords={Media;Scalable Video;Packet Prioritization;MIMO;SDMA;OFDM;Resource Allocation},
doi={},
ISSN={},
month={Aug},}
@INPROCEEDINGS{5062193,
author={Wu, J. and Li, B.},
booktitle={IEEE INFOCOM 2009},
title={Keep Cache Replacement Simple in Peer-Assisted VoD Systems},
year={2009},
volume={},
number={},
pages={2591-2595},
abstract={Peer-assisted Video-on-Demand (VoD) systems have not only received substantial recent research attention, but also been implemented and deployed with success in large-scale real- world streaming systems, such as PPLive. Peer-assisted Video- on-Demand systems are designed to take full advantage of peer upload bandwidth contributions with a cache on each peer. Since the size of such a cache on each peer is limited, it is imperative that an appropriate cache replacement algorithm is designed. There exists a tremendous level of flexibility in the design space of such cache replacement algorithms, including the simplest alternatives such as Least Recently Used (LRU). Which algorithm is the best to minimize server bandwidth costs, so that when peers need a media segment, it is most likely available from caches of other peers? Such a question, however, is arguably non-trivial to answer, as both the demand and supply of media segments are stochastic in nature. In this paper, we seek to construct an analytical framework based on optimal control theory and dynamic programming, to help us form an in-depth understanding of optimal strategies to design cache replacement algorithms. With such analytical insights, we have shown with extensive simulations that, the performance margin enjoyed by optimal strategies over the simplest algorithms is not substantial, when it comes to reducing server bandwidth costs. In most cases, the simplest choices are good enough as cache replacement algorithms in peer-assisted VoD systems.},
keywords={Algorithm design and analysis;Bandwidth;Large-scale systems;Streaming media;Costs;Stochastic processes;Optimal control;Dynamic programming;Performance analysis;Analytical models},
doi={10.1109/INFCOM.2009.5062193},
ISSN={0743-166X},
month={April},}
@INPROCEEDINGS{7727557,
author={Loginov, Alexander and Heywood, Malcolm I. and Wilson, Garnett},
booktitle={2016 International Joint Conference on Neural Networks (IJCNN)},
title={Benchmarking a coevolutionary streaming classifier under the individual household electric power consumption dataset},
year={2016},
volume={},
number={},
pages={2834-2841},
abstract={The application of genetic programming (GP) to streaming data analysis appears, on the face of it, to be a less than obvious choice. If nothing else, the (perceived) computational cost of model building under GP would preclude its application to tasks with non-stationary properties. Conversely, there is a rich history of applying GP to various tasks associated with trading agent design for currency and stock markets. In this work, we investigate the utility of a coevolutionary framework originally proposed for trading agent design to the related streaming data task of predicting individual household electric power consumption. In addition, we address several benchmarking issues, such as effective preprocessing of stream data using a candlestick representation originally developed for financial market analysis, and quantification of performance using a novel `area under the curve' style metric for streaming data. The computational cost of evolving GP solutions is demonstrated to be suitable for real-time operation under this task and shown to provide classification performance competitive with current established methods for streaming data classification. Finally, we note that the individual household electric power consumption dataset is more flexible than the more widely used electricity utility prediction dataset, because it supports benchmarking at multiple temporal time scales.},
keywords={Sociology;Statistics;Benchmark testing;Registers;Training;Labeling;Firewire},
doi={10.1109/IJCNN.2016.7727557},
ISSN={2161-4407},
month={July},}
@ARTICLE{4668501,
author={Mansour, Hassan and Krishnamurthy, Vikram and Nasiopoulos, Panos},
journal={IEEE Transactions on Multimedia},
title={Channel Aware Multiuser Scalable Video Streaming Over Lossy Under-Provisioned Channels: Modeling and Analysis},
year={2008},
volume={10},
number={7},
pages={1366-1381},
abstract={In this paper, we analyze the performance of media-aware multiuser video streaming strategies in capacity limited wireless channels suffering from latency problems and packet losses. Wireless video streaming applications are characterized by their bandwidth-intensity, delay-sensitivity, and loss-tolerance. Our main contributions include (i) a rate-minimized unequal erasure protection (UXP) scheme, (ii) an analytical expression for packet delay and play-out deadline of UXP protected scalable video, (iii) a loss-distortion model for hierarchical predictive video coders with picture copy concealment, (iv) an analysis of the performance and complexity of delay-aware, capacity-aware, and optimized UXP streaming scenarios, and (v) we show that the use of unequal error protection causes a rate-constrained optimization problem to be nonconvex. Performance evaluations using a 3GPP network simulator show that, for different channel capacities and packet loss rates, delay-aware nonstationary rate-allocation streaming policies deliver significant gains which range between 1.65 dB to 2 dB in average Y-PSNR of the received video streams over delay-unaware strategies. These gains come at a cost of increased offline computation which is performed prior to the start of the streaming session or in batches during transmission and therefore, do not affect the run-time performance of the streaming system.},
keywords={Streaming media;Delay;Performance analysis;Performance loss;Error correction codes;Channel capacity;Performance gain;Predictive models;Costs;Runtime;Loss-distortion modeling;scalable video coding (SVC);streaming delay analysis;unequal erasure protection (UXP);wireless video streaming},
doi={10.1109/TMM.2008.2004915},
ISSN={1941-0077},
month={Nov},}
@INPROCEEDINGS{4215644,
author={Liang, J. and Gu, X. and Nahrstedt, K.},
booktitle={IEEE INFOCOM 2007 - 26th IEEE International Conference on Computer Communications},
title={Self-Configuring Information Management for Large-Scale Service Overlays},
year={2007},
volume={},
number={},
pages={472-480},
abstract={Service overlay networks (SON) provide important infrastructure support for many emerging distributed applications such as web service composition, distributed stream processing, and workflow management. Quality-sensitive distributed applications such as multimedia services and on-line data analysis often desire the SON to provide up-to-date dynamic information about different overlay nodes and overlay links. However, it is a challenging task to provide scalable and efficient information management for large-scale SONs, where both system conditions and application requirements can change over time. In this paper, we present InfoEye, a model-based self-configuring distributed information management system that consists of a set of monitoring sensors deployed on different overlay nodes. InfoEye can dynamically configure the operations of different sensors based on current statistical application query patterns and system attribute distributions. Thus, InfoEye can greatly improve the scalability of SON by answering information queries with minimum monitoring overhead. We have implemented a prototype of InfoEye and evaluated its performance using both extensive simulations and micro-benchmark experiments on PlanetLab. The experimental results show that InfoEye can significantly reduce the information management overhead compared with existing approaches. In addition, InfoEye can quickly reconfigure itself in response to application requirement and system information pattern changes.},
keywords={Information management;Large-scale systems;Streaming media;Sensor phenomena and characterization;Web services;Data analysis;Sensor systems;Sensor systems and applications;Scalability;Monitoring},
doi={10.1109/INFCOM.2007.62},
ISSN={0743-166X},
month={May},}
@ARTICLE{9466838,
author={van Dongen, Giselle and Poel, Dirk Van Den},
journal={IEEE Access},
title={A Performance Analysis of Fault Recovery in Stream Processing Frameworks},
year={2021},
volume={9},
number={},
pages={93745-93763},
abstract={Distributed stream processing frameworks have gained widespread adoption in the last decade because they abstract away the complexity of parallel processing. One of their key features is built-in fault tolerance. In this work, we dive deeper into the implementation, performance, and efficiency of this critical feature for four state-of-the-art frameworks. We include the established Spark Streaming and Flink frameworks and the more novel Spark Structured Streaming and Kafka Streams frameworks. We test the behavior under different types of faults and settings: master failure with and without high-availability setups, driver failures for Spark frameworks, worker failure with or without exactly-once semantics, application and task failures. We highlight differences in behavior during these failures on several aspects, e.g., whether there is an outage, downtime, recovery time, data loss, duplicate processing, accuracy, and the cost and behavior of different message delivery guarantees. Our results highlight the impact of framework design on the speed of fault recovery and explain how different use cases may benefit from different approaches. Due to their task-based scheduling approach, the Spark frameworks can recover within 30 seconds and in most cases without necessitating an application restart. Kafka Streams has only a few seconds of downtime, but is slower at catching up on delays. Finally, Flink can offer end-to-end exactly-once semantics at a low cost but requires job restarts for most failures leading to high recovery times of around 50 seconds.},
keywords={Sparks;Task analysis;Semantics;Fault tolerant systems;Fault tolerance;Storms;Benchmark testing;Apache spark;structured streaming;apache flink;apache kafka;kafka streams;distributed computing;stream processing frameworks;fault tolerance;benchmarking;big data},
doi={10.1109/ACCESS.2021.3093208},
ISSN={2169-3536},
month={},}
@ARTICLE{9044374,
author={Zhang, Yuan and Yan, Jinyao and Pu, Lingjun and Chen, Shiyu},
journal={IEEE Internet of Things Journal},
title={Dynamic Component Placement and Request Scheduling for IoT Big Data Streaming},
year={2020},
volume={7},
number={8},
pages={7156-7170},
abstract={Internet-of-Things (IoT) big data streaming applications, such as video surveillance and automatic driving, tend to use mobile-edge computing (MEC) infrastructure to enhance their performance and augment their functionalities. Although extensive previous studies have worked on offloading requests to MEC servers, none of them has comprehensively and thoroughly considered the important features of IoT data streaming applications (i.e., component dependency and dynamic arrival) and the infrastructure provisioning (i.e., capacity constraint and colocation interference). In this article, we consider the offloading problem for dynamically arrived IoT data streaming requests on MEC servers in real time. We model it as a delay-sensitive multiuser multiresource online offloading problem respecting component dependency and capacity constraint. The problem is NP-hard with offloading decisions coupling together. To solve it, we decouple the problem into component placement problem and request scheduling problem and propose a two-stage DPGPD algorithm with polynomial time complexity. We show the first stage dynamic programming (DP) algorithm is the optimal solution and the second-stage greedy primal–dual (GPD) algorithm is asymptotic optimal. The simulation results show that our solution is effective yet efficient compared to benchmark solutions. (DP provides the optimal placement layout with $12 \times $ less decision time of Gurobi; and GPD provides the asymptotic optimal scheduling with $5 \times $ less average waiting time compared to least work left (LWL) in heavy workload.) We implement a dedicated prototype and exploit several representative big data streaming applications to evaluate it. Lab-scale experiment shows that our solution can provide over $3 \times $ less total completion time compared to local execution.},
keywords={Servers;Big Data;Internet of Things;Heuristic algorithms;Layout;Dynamic scheduling;Big data applications;dynamic scheduling;edge computing;Internet-of-Things (IoT)},
doi={10.1109/JIOT.2020.2982458},
ISSN={2327-4662},
month={Aug},}
@INPROCEEDINGS{7841533,
author={Lopez, Martin Andreoni and Lobato, Antonio Gonzalez Pastana and Duarte, Otto Carlos M. B.},
booktitle={2016 IEEE Global Communications Conference (GLOBECOM)},
title={A Performance Comparison of Open-Source Stream Processing Platforms},
year={2016},
volume={},
number={},
pages={1-6},
abstract={Distributed stream processing platforms is a new class of real-time monitoring systems that analyze and extracts knowledge from large continuous streams of data. This type of systems is crucial for providing high throughput and low latency required by Big Data or Internet of Things monitoring applications. This paper describes and analyzes three main open-source distributed stream- processing platforms: Storm Flink, and Spark Streaming. We analyze the system architectures and we compare their main features. We carry out two experiments concerning anomaly detection on network traffic to evaluate the throughput efficiency and the resilience to node failures. Results show that the performance of native stream processing systems, Storm and Flink, is up to 15 times higher than the micro-batch processing system, Spark Streaming. On the other hand, Spark Streaming is more robust to node failures and provides recovery without losses.},
keywords={Real-time systems;Storms;Fasteners;Topology;Sparks;Monitoring;Batch production systems},
doi={10.1109/GLOCOM.2016.7841533},
ISSN={},
month={Dec},}
@INPROCEEDINGS{1630867,
author={Vijayakumar, N.N. and Ying Liu and Plale, B.},
booktitle={Sixth IEEE International Symposium on Cluster Computing and the Grid (CCGRID'06)},
title={Calder query grid service: insights and experimental evaluation},
year={2006},
volume={1},
number={},
pages={5 pp.-543},
abstract={We have architected and evaluated a new kind of data resource, one that is composed of a logical collection of ephemeral data streams that could be viewed as a collection of publish-subscribe "channels" over which rich data-access and semantic operations can be performed. This paper contributes new insight to stream processing under the highly asynchronous stream workloads often found in data-driven scientific applications, and presents insights gained through porting a distributed stream processing system to a grid services framework. Experimental results reveal limits on stream processing rates that are directly tied to differences in stream rates.},
keywords={Databases;Data flow computing;Time measurement;Computer science;Publish-subscribe;Performance evaluation;Distributed computing;Hardware;Flow graphs;Pipelines},
doi={10.1109/CCGRID.2006.25},
ISSN={},
month={May},}
@INPROCEEDINGS{7502926,
author={Čermák, Milan and Tovarňák, Daniel and Laštovička, Martin and Čeleda, Pavel},
booktitle={NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium},
title={A performance benchmark for NetFlow data analysis on distributed stream processing systems},
year={2016},
volume={},
number={},
pages={919-924},
abstract={Modern distributed stream processing systems can potentially be applied to real time network flow processing. However, differences in performance make some systems more suitable than others for being applied to this domain. We propose a novel performance benchmark, which is based on common security analysis algorithms of NetFlow data to determine the suitability of distributed stream processing systems. Three of the most used distributed stream processing systems are bench-marked and the results are compared with NetFlow data processing challenges and requirements. The benchmark results show that each system reached a sufficient data processing speed using a basic deployment scenario with little to no configuration tuning. Our benchmark, unlike any other, enables the performance of small structured messages to be processed on any stream processing system.},
keywords={Benchmark testing;Data processing;Distributed databases;Sparks;Storms;Real-time systems;Fasteners},
doi={10.1109/NOMS.2016.7502926},
ISSN={2374-9709},
month={April},}
@INPROCEEDINGS{8750955,
author={Shahverdi, Elkhan and Awad, Ahmed and Sakr, Sherif},
booktitle={2019 IEEE 35th International Conference on Data Engineering Workshops (ICDEW)},
title={Big Stream Processing Systems: An Experimental Evaluation},
year={2019},
volume={},
number={},
pages={53-60},
abstract={As the world gets more instrumented and connected, we are witnessing a flood of digital data generated from various hardware (e.g., sensors) or software in the format of flowing streams of data. Real-time processing for such massive amounts of streaming data is a crucial requirement in several application domains including financial markets, surveillance systems, manufacturing, smart cities, and scalable monitoring infrastructure. In the last few years, several big stream processing engines have been introduced to tackle this challenge. In this article, we present an extensive experimental study of five popular systems in this domain, namely, Apache Storm, Apache Flink, Apache Spark, Kafka Streams and Hazelcast Jet. We report and analyze the performance characteristics of these systems. In addition, we report a set of insights and important lessons that we have learned from conducting our experiments.},
keywords={Storms;Sparks;Task analysis;Yarn;Real-time systems;Java;Benchmark testing;Big Stream Processing;Benchmarking},
doi={10.1109/ICDEW.2019.00-35},
ISSN={2473-3490},
month={April},}
@INPROCEEDINGS{1207018,
author={Suh, J. and Kim, E.-G. and Crago, S.P. and Lakshmi Srinivasan and French, M.C.},
booktitle={30th Annual International Symposium on Computer Architecture, 2003. Proceedings.},
title={A performance analysis of PIM, stream processing, and tiled processing on memory-intensive signal processing kernels},
year={2003},
volume={},
number={},
pages={410-419},
abstract={Trends in microprocessors of increasing die size and clock speed and decreasing feature sizes have fueled rapidly increasing performance. However, the limited improvements in DRAM latency and bandwidth and diminishing returns of increasing superscalar ILP and cache sizes have led to the proposal of new microprocessor architectures that implement processor-in-memory, stream processing, and tiled processing. Each architecture is typically evaluated separately and compared to a baseline architecture. We evaluate the performance of processors that implement these architectures on a common set of signal processing kernels. The implementation results are compared with the measured performance of a conventional system based on the PowerPC with Altivec. The results show that these new processors show significant improvements over conventional systems and that each architecture has its own strengths and weaknesses.},
keywords={Performance analysis;Signal processing;Kernel;Delay;Microprocessors;Bandwidth;Clocks;Random access memory;Pipeline processing;Beam steering},
doi={10.1109/ISCA.2003.1207018},
ISSN={1063-6897},
month={June},}
@INPROCEEDINGS{7428510,
author={Zhao, Yong and Zhang, Ying and Yao, Yiting and Li, Youfu and Liu, Peng},
booktitle={2015 IEEE Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)},
title={Cocktail: A hybrid system combining Hadoop and Storm},
year={2015},
volume={},
number={},
pages={20-25},
abstract={Hadoop and Storm are playing a significant role in Cloud Computing and either of them has its own applicable area. Cocktail is a new hybrid system that combines Hadoop and Storm into one single system, leveraging the functions of two computing frameworks. The design and implementation of Cocktail includes a SQL-like query language making the implementation of details transparent for users, an intelligent framework selector based on cost model to choose appropriate framework automatically, and an efficient resource scheduling and task execution framework. Cocktail has a wide range of application scenarios from batch processing to stream computing, using Storm to process real-time data and Hadoop to process large-scale data. We compare the performance, throughput and scalability of Cocktail with SummingBird to demonstrate the practicability and capability. According to benchmark, for small-scale data, the performance of Cocktail is close to Summingbird based on Storm and 20%~40% faster than Summingbird based on Hadoop. And for large-scale data, Cocktail's throughput is 40% higher than Summingbird's throughout based on Storm.},
keywords={Storms;Computational modeling;Computer architecture;Yarn;Processor scheduling;Real-time systems;Throughput;Hadoop;Storm;Hybrid System},
doi={10.1109/IAEAC.2015.7428510},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9708969,
author={Jung, Kumseok and Gascon-Samson, Julien and Pattabiraman, Karthik},
booktitle={2021 IEEE/ACM Symposium on Edge Computing (SEC)},
title={OneOS: Middleware for Running Edge Computing Applications as Distributed POSIX Pipelines},
year={2021},
volume={},
number={},
pages={242-256},
abstract={Edge computing application developers often need to employ a combination of software tools in order to deal with the challenges of heterogeneity and network dynamism. As a result, developers write extra code irrelevant to the core application logic, to provide interoperability between interacting tools. Existing software frameworks offer programming models and cloud-hosted services to ease the overall development process. However, the framework-specific APIs exacerbate the technology fragmentation problem, requiring developers to write more glue code between competing frameworks. In this paper, we present a middleware called OneOS, which provides a distributed computing environment through the standard POSIX API. OneOS maintains a global view of the computer network, presenting the same file system and process space to any user application running in the network. OneOS intercepts POSIX API calls and transparently handles the interaction with the corresponding I/O resource in the network. Using the OneOS Domain-Specific Language (DSL), users can distribute a legacy POSIX pipeline over the network. We evaluate the performance of OneOS against an open-source IoT Platform, ThingsJS, using an IoT stream processing benchmark suite, and a distributed video processing application. OneOS executes the programs about 3x faster than ThingsJS, and reduces the code size by about 25%.},
keywords={Codes;Pipelines;Streaming media;Programming;Middleware;Software tools;Standards;edge computing;internet of things;distribution transparency},
doi={10.1145/3453142.3493505},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6666449,
author={Dilawari, A. and Tahir, Muhammad},
booktitle={2013 IEEE 24th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)},
title={Optimal flow splitting for multi-path multi-interface wireless data streaming networks},
year={2013},
volume={},
number={},
pages={1878-1882},
abstract={We propose optimal flow splitting for wireless data streaming networks consisting of nodes that are equipped with more than one wireless communication interface. The objective is to efficiently distribute data traffic among multiple wireless interfaces, leveraging an additional axis of freedom capable of providing improved performance. For that purpose a distributed framework based on convex optimization is developed that achieves optimal resource utilization for multi-interface multi-path network configuration. Although flow splitting can be performed using single wireless interface, our performance evaluation results show an improved performance when employing multiple wireless interfaces. Performance evaluation results reveal that 50% energy saving can be achieved when using optimal flow splitting for dual interface compared to single interface node architecture. In addition, the proposed solution is inherently robust to link outages due to the availability of multiple wireless interfaces. The proposed framework is quite flexible and can be easily extended to integrate any other performance parameters of interest.},
keywords={Wireless communication;Routing;Resource management;Radio frequency;Signal to noise ratio;Peer-to-peer computing;Performance evaluation},
doi={10.1109/PIMRC.2013.6666449},
ISSN={2166-9589},
month={Sep.},}
@INPROCEEDINGS{6607498,
author={Mueller, Christopher and Lederer, Stefan and Timmerer, Christian and Hellwagner, Hermann},
booktitle={2013 IEEE International Conference on Multimedia and Expo (ICME)},
title={Dynamic Adaptive Streaming over HTTP/2.0},
year={2013},
volume={},
number={},
pages={1-6},
abstract={MPEG Dynamic Adaptive Streaming over HTTP (DASH) is a new streaming standard that has been recently ratified as an international standard (IS). In comparison to other streaming systems, e.g., HTTP progressive download, DASH is able to handle varying bandwidth conditions providing smooth streaming. Furthermore, it enables NAT and Firewall traversal, flexible and scalable deployment as well as reduced infrastructure costs due to the reuse of existing Internet infrastructure components, e.g., proxies, caches, and Content Distribution Networks (CDN). Recently, the Hypertext Transfer Protocol Bis (httpbis) working group of the IETF has officially started the development of HTTP 2.0. Initially three major proposals have been submitted to the IETF i.e., Googles' SPDY, Microsofts' HTTP Speed+Mobility and Network-Friendly HTTP Upgrade, but SPDY has been chosen as working draft for HTTP 2.0. In this paper we implemented MPEG-DASH over HTTP 2.0 (i.e., SPDY), demonstrating its potential benefits and drawbacks. Moreover, several experimental evaluations have been performed that compare HTTP 2.0 with HTTP 1.1 and HTTP 1.0 in the context of DASH. In particular, the protocol overhead, the performance for different round trip times, and DASH with HTTP 2.0 in a lab test scenario has been evaluated in detail.},
keywords={Servers;Bandwidth;Transform coding;Abstracts;Multiplexing;Multimedia communication;Focusing;MPEG-DASH;HTTP 2.0;SPDY;Dynamic Adaptive Streaming over HTTP;Evaluation},
doi={10.1109/ICME.2013.6607498},
ISSN={1945-788X},
month={July},}
@INPROCEEDINGS{6047193,
author={Zhang, Yongpeng and Mueller, Frank},
booktitle={2011 International Conference on Parallel Processing},
title={GStream: A General-Purpose Data Streaming Framework on GPU Clusters},
year={2011},
volume={},
number={},
pages={245-254},
abstract={Emerging accelerating architectures, such as GPUs, have proved successful in providing significant performance gains to various application domains. However, their viability to operate on general streaming data is still ambiguous. In this paper, we propose GStream, a general-purpose, scalable data streaming framework on GPUs. The contributions of GStream are as follows: (1) We provide powerful, yet concise language abstractions suitable to describe conventional algorithms as streaming problems. (2)We project these abstractions onto GPUs to fully exploit their inherent massive data parallelism.(3) We demonstrate the viability of streaming on accelerators. Experiments show that the proposed framework provides flexibility, programmability and performance gains for various benchmarks from a collection of domains, including but not limited to data streaming, data parallel problems and numerical codes.},
keywords={Graphics processing unit;Libraries;Finite impulse response filter;Parallel processing;Kernel;Computer architecture;Programming},
doi={10.1109/ICPP.2011.22},
ISSN={2332-5690},
month={Sep.},}
@INPROCEEDINGS{9671517,
author={Stephen, Colin},
booktitle={2021 IEEE International Conference on Big Data (Big Data)},
title={A Scalable Linear-Time Algorithm for Horizontal Visibility Graph Construction Over Long Sequences},
year={2021},
volume={},
number={},
pages={40-50},
abstract={The horizontal visibility graph (HVG) representation of a time series is a structured graph whose connectivity properties have been used to study the dynamics of a wide range of nonlinear systems. Applications range from the brain (EEG), the heart (ECG) and the financial markets (bid prices), to the sun (solar intensity readings) and river flows. HVGs have also been extended to image-based pattern recognition. Efficient and scalable online HVG construction is vital to extending HVG-based time series analysis to long, streaming, and distributed real-world time series data.The fastest scalable method for constructing HVGs today is the binary search tree (BST) encoding–decoding algorithm, which is O(n log n) in time series length for balanced data such as noise. However, in practice BST is highly sensitive to the geometric structure of a time series and its performance degrades significantly towards O(n2) when data possess long term dependencies or when the sample frequency is high, which occur regularly in practice. To avoid these problems we leverage an O(n) ordered rooted tree representation of time series that is (graph) dual to the HVG. We demonstrate that this representation leads to an algorithm for HVG construction that is agnostic with respect to the geometry and auto-correlations of the underlying data. Moreover, it possesses an efficient branch fusion operation for tree merging, leading to the idea of a bipartite HVG introduced in this paper, which allows HVGs for very large time series to be constructed efficiently in parallel.After introducing our method and algorithms for parallel construction of HVGs we report on experimental benchmarks comparing their real-world performance to existing approaches on long time series. On data sampled from fractional Brownian motions, deterministic chaotic systems, brain EEG recordings, and the financial markets, our dual tree algorithms significantly outperform previous methods.},
keywords={Geometry;Time-frequency analysis;Runtime;Time series analysis;Merging;Big Data;Streaming media;time series analysis;graph algorithms},
doi={10.1109/BigData52589.2021.9671517},
ISSN={},
month={Dec},}