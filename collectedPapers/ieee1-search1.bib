@INPROCEEDINGS{4756433,
author={Buford, John and Wu, Xiaotao and Bajpai, Ratan and Karthikeyan, S. and Krishnaswamy, Venkatesh},
booktitle={2008 The Second International Conference on Next Generation Mobile Applications, Services, and Technologies},
title={Enterprise Communications Platform Support for Integrated Location-Based Applications},
year={2008},
volume={},
number={},
pages={190-195},
abstract={Location-based services can be used by enterprises to enhance the customer experience and improve workforce operational efficiency. The focus of our work is to provide a scalable architecture for location-based services which integrates into the enterprise communications platform to support new types of converged communications services involving real-time location processing. Unlike prior work in location servers and middleware, we separate application-level processing and raw location event stream processing into two separate components. We show analytically that this leads to performance advantage. By leveraging existing event driven architecture technologies, our approach integrates with the enterprise event bus, is highly scalable, and permits other real-time event streams to be used by location-based applications. We have implemented a prototype to demonstrate the generality and validity of this approach.},
keywords={Mobile communication;Middleware;Prototypes;Subscriptions;Geographic Information Systems;Context;Performance analysis;Network servers;Next generation networking;Communications technology;Location-Based Services;Event Processor;Enterprise Communications;Middleware},
doi={10.1109/NGMAST.2008.86},
ISSN={2161-2897},
month={Sep.},}
@INPROCEEDINGS{5560099,
author={Lu, Xukang and Wu, Qishi and Li, Runzhi and Lin, Yunyue},
booktitle={2010 Proceedings of 19th International Conference on Computer Communications and Networks},
title={On Tree Construction of Super Peers for Hybrid P2P Live Media Streaming},
year={2010},
volume={},
number={},
pages={1-6},
abstract={This paper considers a hybrid hierarchical P2P overlay network structure that consists of both super and normal peers. The media streaming architecture is built upon a tree-structured network of super peers and the tree construction process has a significant impact on the overall system performance. We build network cost models and formulate a specific type of problem to maximize the minimum node throughput in Tree Construction (max-minTC), which aims at optimizing the system's stream rate by constructing an efficient spanning tree among super peers. We consider two scenarios: (i) When the overlay network has an arbitrary topology, we prove max-minTC to be NP-complete by reducing from the Degree Constrained Spanning Tree problem and propose an efficient heuristic algorithm. The performance superiority of the proposed algorithm is justified by experimental results collected by a live media streaming system deployed in real networks and is also illustrated by extensive simulations performed on a large set of simulated networks of various sizes from small to large scales in comparison with other methods, (ii) When the topology of the overlay network is complete, we rigorously prove that the same heuristic algorithm yields an optimal solution.},
keywords={Peer to peer computing;Bandwidth;Throughput;Pediatrics;Network topology;Construction industry;Heuristic algorithms},
doi={10.1109/ICCCN.2010.5560099},
ISSN={1095-2055},
month={Aug},}
@INPROCEEDINGS{5504759,
author={Powell Jr., Harry C. and Brandt-Pearce, Maïté and Barth, Adam T. and Lach, John},
booktitle={2010 International Conference on Body Sensor Networks},
title={A Methodology for the Systematic Evaluation of ANN Classifiers for BSN Applications},
year={2010},
volume={},
number={},
pages={240-245},
abstract={While many BSN applications require that sensor nodes be able to operate for extended periods of time, they also often require the wireless transmission of copious amounts of sensor data to a data aggregator or base station, where the raw data is processed into application-relevant information. The energy requirements of such streaming can be prohibitive, given the competing considerations of form factor and battery life requirements. Making intelligent decisions on the node about which data to store or transmit, and which to ignore, is a promising method of reducing energy consumption. Artificial neural network (ANN) classifiers are among several competitive techniques for such data selection. However, no systematic metrics exist for determining if an ANN classifier is suited for a particular resource constrained computing environment of a typical BSN node. An especially difficult task is assessing, at the design stage, which classifier architectures are feasible on a given resource-constrained node, what computational resources are required to execute a given classifier, and what classification performance might be achieved by a particular classifier on a given set of resources. This paper describes techniques for quantifying and predicting the performance of ANN classifiers on wearable sensor nodes using scalable synthetic test data. Additionally, the paper shows a comparison of synthetic data with gait data collected using an inertial BSN node, and classification results of the gait data using a cerebellar model arithmetic computer (CMAC) architecture show excellent agreement with theoretical predictions.},
keywords={Artificial neural networks;Body sensor networks;Intelligent sensors;Computer architecture;Wireless sensor networks;Base stations;Batteries;Artificial intelligence;Energy consumption;Wearable sensors},
doi={10.1109/BSN.2010.48},
ISSN={2376-8894},
month={June},}
@INPROCEEDINGS{9781127,
author={Chen, Mingkang and Sun, Jingtao and Aida, Kento and Figueiredo, Renato J. and Ku, Yun-Jung and Subratie, Kensworth},
booktitle={2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)},
title={Intelligent Live Video Streaming for Object Detection},
year={2021},
volume={},
number={},
pages={1427-1434},
abstract={These days, sensors and cameras are being deployed on an increasingly large scale. Furthermore, the rapid development of machine learning models for computer vision now presents novel opportunities for the use of artificial intelligence (AI) and Internet of Things (IoT) combinations in various application scenarios. However, challenges remain in supporting low-latency video streaming from distributed mobile IoT devices under dynamic network environments, and overcoming video data quality degradation that results from weather “noise”, which reduces the accuracy of AI-based data analyses such as object detection. In this paper, we propose a live video stream processing system for supporting intelligent services that integrates the following features. First, to cope with dynamic networks and achieve low latency, our approach employs a peer-to-peer (P2P)-based virtual network at the edge and a multi-tiered architecture composed of IoT cameras, edge, and cloud servers. Second, we construct a flexible messaging system for video analysis built upon SINETStream, which is a messaging system that adopts a topic-based pub/sub model. Third, we implement a framework that can remove weather-related (rain, snow, and fog) noise by applying weather classification and adaptive noise removal models that improve the accuracy of video analysis from data collected outdoors. The latency, throughput, and image quality benchmark experiments conducted to validate the feasibility of our proposed system showed that the process resulted in image quality improvements of approximately 30% (on average).},
keywords={Image quality;Adaptation models;Image edge detection;Object detection;Streaming media;Throughput;Internet of Things;IoT;Edge Computing;P2P;Video Stream;Object Detection},
doi={10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00214},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9833963,
author={Sezer, Ahmet Dundar and Madhow, Upamanyu},
booktitle={2022 IEEE 23rd International Workshop on Signal Processing Advances in Wireless Communication (SPAWC)},
title={Spatially redundant, precision-constrained transmit precoding for mmWave LoS MIMO},
year={2022},
volume={},
number={},
pages={1-5},
abstract={Line of sight (LoS) multi-input multi-output (MIMO) systems have attractive scaling properties with increase in carrier frequency, with the potential for 100+Gbps links over 10s to 100s of meters with the reasonable form using the millimeter wave (mmWave) and terahertz (THz) bands. We propose and investigate an approach to all-digital LoS MIMO which addresses the difficulty of limited available precision for digital-to-analog converters (DACs) and analog-to-digital converters (ADCs). In order to reduce dynamic range requirements at the receiver, we consider spatially redundant transmit precoding (more transmit antennas than number of spatially multiplexed data streams) with 1-bit DACs. We introduce a novel approach for attaining the higher dynamic range required for precoding over the air (OTA), which we term OTA-DAC: the 1-bit DACs for clusters of transmit elements synthesize approximations to zero-forcing precoding across clusters. We illustrate our ideas for 64×4 and 16×4 LoS MIMO systems, comparing with a benchmark approach of 1-bit quantized ZF precoding for transmit elements evenly spaced across the aperture. Our OTA-DAC approach substantially outperforms the benchmark, and does not exhibit the error floors incurred by the latter.},
keywords={Wireless communication;Technological innovation;Precoding;Transmitting antennas;Termination of employment;Receiving antennas;Dynamic range;Millimeter wave;LoS;MIMO;ADC;DAC},
doi={10.1109/SPAWC51304.2022.9833963},
ISSN={1948-3252},
month={July},}
@ARTICLE{7015569,
author={Kumbhare, Alok Gautam and Simmhan, Yogesh and Frincu, Marc and Prasanna, Viktor K.},
journal={IEEE Transactions on Cloud Computing},
title={Reactive Resource Provisioning Heuristics for Dynamic Dataflows on Cloud Infrastructure},
year={2015},
volume={3},
number={2},
pages={105-118},
abstract={The need for low latency analysis over high-velocity data streams motivates the need for distributed continuous dataflow systems. Contemporary stream processing systems use simple techniques to scale on elastic cloud resources to handle variable data rates. However, application QoS is also impacted by variability in resource performance exhibited by clouds and hence necessitates autonomic methods of provisioning elastic resources to support such applications on cloud infrastructure. We develop the concept of “dynamic dataflows” which utilize alternate tasks as additional control over the dataflow's cost and QoS. Further, we formalize an optimization problem to represent deployment and runtime resource provisioning that allows us to balance the application's QoS, value, and the resource cost. We propose two greedy heuristics, centralized and sharded, based on the variable-sized bin packing algorithm and compare against a Genetic Algorithm (GA) based heuristic that gives a near-optimal solution. A large-scale simulation study, using the linear road benchmark and VM performance traces from the AWS public cloud, shows that while GA-based heuristic provides a better quality schedule, the greedy heuristics are more practical, and can intelligently utilize cloud elasticity to mitigate the effect of variability, both in input data rates and cloud resource performance, to meet the QoS of fast data applications.},
keywords={Cloud computing;Throughput;Quality of service;Optimization;Runtime;Ports (Computers);Bandwidth;Dataflows;stream processing, cloud;resource management;scheduling;high velocity data;runtime adaptation;Dataflows;stream processing;cloud;resource management;scheduling;high velocity data;runtime adaptation},
doi={10.1109/TCC.2015.2394316},
ISSN={2168-7161},
month={April},}
@INPROCEEDINGS{5210817,
author={Gupta, Chetan and Wang, Song and Ari, Ismail and Hao, Ming and Dayal, Umeshwar and Mehta, Abhay and Marwah, Manish and Sharma, Ratnesh},
booktitle={2009 IEEE Conference on Commerce and Enterprise Computing},
title={CHAOS: A Data Stream Analysis Architecture for Enterprise Applications},
year={2009},
volume={},
number={},
pages={33-40},
abstract={In this paper, we describe the design of our architecture for continuous, heterogeneous analysis over streams, aka CHAOS that combines stream processing, approximation techniques, mining, complex event processing and visualization. CHAOS, with the novel concept of computational stream analysis Cube, provides an effective, scalable platform for near real time processing of business and enterprise streams. We describe our approach with a real data center temperature analysis application.},
keywords={Chaos;Data analysis;Business;Data visualization;Engines;Information analysis;Computer architecture;Performance analysis;Information management;Ecosystems;Stream Analysis Architecture;Data Center},
doi={10.1109/CEC.2009.74},
ISSN={2378-1971},
month={July},}
@ARTICLE{4378429,
author={Purandare, Darshan and Guha, Ratan},
journal={IEEE Transactions on Multimedia},
title={An Alliance Based Peering Scheme for P2P Live Media Streaming},
year={2007},
volume={9},
number={8},
pages={1633-1644},
abstract={While recent measurement studies have shown the effectiveness of P2P network in media streaming, there have been questions raised about the quality of service (QoS), reliability of streaming services and sub optimal uplink utilization in particular. P2P streaming systems are inherently less reliable because of churn, internet dynamics, node heterogeneity and randomness in the swarm. We present a new model for P2P media streaming based on clustering of peers, called alliances. We show that alliance formation is a loosely coupled and an effective way to organize the peers. We show that our model maps to a ldquosmall-worldrdquo network, which form efficient overlay structures and are robust to network perturbations such as churn. We present a comparative simulation based study of our model with CoolStreaming/DONet and present a quantitative performance evaluation. Simulation results are promising and show that our model scales well under varying workloads and conditions, delivers near optimal levels of QoS, and for most cases, performs at par or even better than CoolStreaming/DONet.},
keywords={Streaming media;Peer to peer computing;Quality of service;TV;Bandwidth;Particle measurements;Internet;Robustness;Video on demand;Surges;Media streaming;peer-to-peer;quality of service;small world network;video on demand},
doi={10.1109/TMM.2007.907453},
ISSN={1941-0077},
month={Dec},}
@INPROCEEDINGS{8567672,
author={Chao, Mengyuan and Yang, Chen and Zeng, Yukun and Stoleru, Radu},
booktitle={2018 IEEE/ACM Symposium on Edge Computing (SEC)},
title={F-MStorm: Feedback-Based Online Distributed Mobile Stream Processing},
year={2018},
volume={},
number={},
pages={273-285},
abstract={A distributed mobile stream processing system allows mobile devices to process stream data that exceeds any single device's computation capability without the help of infrastructure. It is paramount to have such a system in many critical application scenarios, such as military operations and disaster response, yet an efficient online mobile stream processing system is still missing. In this paper, we make the key observation that the unique characteristics of mobile stream processing call for a feedback-based system design, which is in sharp contrast with the static configuration and scheduling of the current mobile stream processing system, "MStorm". At first, we demonstrate the inefficiencies of MStorm through several real-world experiments. Then, we propose F-MStorm, a feedback-based online distributed mobile stream processing system, which adopts the feedback-based approach in the configuration, scheduling and execution levels of system design. We implement F-MStorm on Android phones and evaluate its performance through benchmark applications. We show that it achieves up to 3x lower response time, 10% higher throughput and consumes 23% less communication energy than the state-of-the-art systems.},
keywords={Task analysis;Mobile handsets;Throughput;Optimal scheduling;Delays;Cloud computing;Round robin;stream processing;edge computing;scheduling},
doi={10.1109/SEC.2018.00027},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8750932,
author={Al-Sayeh, Hani and Sattler, Kai-Uwe},
booktitle={2019 IEEE 35th International Conference on Data Engineering Workshops (ICDEW)},
title={Gray Box Modeling Methodology for Runtime Prediction of Apache Spark Jobs},
year={2019},
volume={},
number={},
pages={117-124},
abstract={Nowadays, many data centers facilitate data processing and acquisition by developing multiple Apache Spark jobs which can be executed in private clouds with various parameters. Each job might take various application parameters which influence its execution time. Some examples of application parameters can be a selected area of interest in spatiotemporal data processing application or a time range of events in a complex event stream processing application. To predict its runtime accurately, these application parameters shall be considered during constructing its runtime model. Runtime prediction of Spark jobs allows us to schedule them efficiently in order to utilize cloud resources, increase system throughput, reduce job latency and meet customers requirements, e.g. deadlines and QoS. Also, the prediction is considered as important advantage when using a pay-as-you-go pricing model. In this paper, we present a gray box modeling methodology for runtime prediction of each individual Apache Spark job in two steps. The first one is building a white box model for predicting the input RDD size of each stage relying on prior knowledge about its behaviour and taking the application parameters into consideration. The second one is extracting a black box runtime model of each task by observing its runtime metrics according to various allocated resources and variant input RDD sizes. The modeling methodology is validated with experimental evaluation on a real-world application, and the results show a high matching accuracy which reached 83-94% of the actual runtime of the tested application.},
keywords={Runtime;Sparks;Predictive models;Data models;Task analysis;Computational modeling;Cluster computing;Runtime Prediction;Large scale data processing;Modelling},
doi={10.1109/ICDEW.2019.00-23},
ISSN={2473-3490},
month={April},}
@ARTICLE{8055438,
author={Schaffner, Michael and Scheidegger, Florian and Cavigelli, Lukas and Kaeslin, Hubert and Benini, Luca and Smolic, Aljosa},
journal={IEEE Transactions on Image Processing},
title={Towards Edge-Aware Spatio-Temporal Filtering in Real-Time},
year={2018},
volume={27},
number={1},
pages={265-280},
abstract={Spatio-temporal edge-aware (STEA) filtering methods have recently received increased attention due to their ability to efficiently solve or approximate important image-domain problems in a temporally consistent manner - which is a crucial property for video-processing applications. However, existing STEA methods are currently unsuited for real-time, embedded stream-processing settings due to their high processing latency, large memory, and bandwidth requirements, and the need for accurate optical flow to enable filtering along motion paths. To this end, we propose an efficient STEA filtering pipeline based on the recently proposed permeability filter (PF), which offers high quality and halo reduction capabilities. Using mathematical properties of the PF, we reformulate its temporal extension as a causal, non-linear infinite impulse response filter, which can be efficiently evaluated due to its incremental nature. We bootstrap our own accurate flow using the PF and its temporal extension by interpolating a quasi-dense nearest neighbour field obtained with an improved PatchMatch algorithm, which employs binarized octal orientation maps (BOOM) descriptors to find correspondences among subsequent frames. Our method is able to create temporally consistent results for a variety of applications such as optical flow estimation, sparse data upsampling, visual saliency computation and disparity estimation. We benchmark our optical flow estimation on the MPI Sintel dataset, where we currently achieve a Pareto optimal quality-efficiency tradeoff with an average endpoint error of 7.68 at 0.59 s single-core execution time on a recent desktop machine.},
keywords={Optical imaging;Adaptive optics;Estimation;Image edge detection;Data structures;Boolean functions;Standards;Edge-aware filter;spatio-temporal filter;patch-match;binary descriptor;optical flow},
doi={10.1109/TIP.2017.2757259},
ISSN={1941-0042},
month={Jan},}
@INPROCEEDINGS{8831217,
author={Trotter, Michael and Wood, Timothy and Hwang, Jinho},
booktitle={2019 IEEE International Conference on Autonomic Computing (ICAC)},
title={Forecasting a Storm: Divining Optimal Configurations using Genetic Algorithms and Supervised Learning},
year={2019},
volume={},
number={},
pages={136-146},
abstract={With the advent of Big Data platforms like Apache Storm, computations once deemed infeasible locally become possible at scale. However, doing so entails orchestrating powerful yet expensive clusters. With its focus on stream processing, Storm optimizes for low-latency and high throughput. However, to realize this goal and thereby maximize the utility of these clusters' resources, operators must execute these tasks under their optimal configurations. Yet, the search space for finding such configurations is so vast and time-consuming to explore so as to be effectively intractable due to issues like the temporal overhead of testing new candidate configurations, the sheer number of permutations of parameters within each configuration and their interdependence among each other. In order to efficiently cover the search space, we automate the process with genetic algorithms. Moreover, we fuse this technique not only with additional cluster information gleaned from JMX profiling and Storm performance data but also with classifiers constructed from training data from past executions of a plethora of Storm topologies. Utilizing a diverse set of Storm benchmark topologies as evaluation data, we show that the fully enhanced genetic algorithms can efficiently find configurations that perform on average 4.67× better than "rules of thumb"-derived manual baselines. Moreover, we demonstrate that our fully refined classifiers enhance the GA throughput on average across the topologies by 22% while reducing search time by a factor of 6.47×.},
keywords={Topology;Storms;Fasteners;Genetic algorithms;Task analysis;Instruction sets;Optimization;Apache Storm;Genetic Algorithm;Supervised Learning;Automatic Performance Tuning},
doi={10.1109/ICAC.2019.00025},
ISSN={2474-0756},
month={June},}
@INPROCEEDINGS{6818327,
author={Viel, Emeric and Ueda, Haruyasu},
booktitle={2014 IEEE 30th International Conference on Data Engineering Workshops},
title={Data stream partitioning re-optimization based on runtime dependency mining},
year={2014},
volume={},
number={},
pages={199-206},
abstract={In distributed data stream processing, a program made of multiple queries can be parallelized by partitioning input streams according to the values of specific attributes, or partitioning keys. Applying different partitioning keys to different queries requires re-partitioning intermediary streams, causing extra communication and reduced throughput. Re-partitionings can be avoided by detecting dependencies between the partitioning keys applicable to each query. Existing partitioning optimization methods analyze query syntax at compile-time to detect inter-key dependencies and avoid re-partitionings. This paper extends those compile-time methods by adding a runtime re-optimization step based on the mining of temporal approximate dependencies (TADs) between partitioning keys. A TAD is defined in this paper as a type of dependency that can be approximately valid over a moving time window. Our evaluation, based on a simulation of the Linear Road Benchmark, showed a 94.5% reduction of the extra communication cost.},
keywords={Accuracy;Optimization;Runtime;Data mining;Monitoring;Roads;Routing;data-stream processing;DSMS;distributed processing;partitioning optimization;temporal approximate dependencies;dependency mining},
doi={10.1109/ICDEW.2014.6818327},
ISSN={},
month={March},}
@ARTICLE{9770381,
author={Cornel, Daniel and Zechmeister, Silvana and Groeller, Eduard and Waser, Jurgen},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Watertight Incremental Heightfield Tessellation},
year={2022},
volume={},
number={},
pages={1-1},
abstract={In this paper, we propose a method for the interactive visualization of medium-scale dynamic heightfields without visual artifacts. Our data fall into a category too large to be rendered directly at full resolution, but small enough to fit into GPU memory without pre-filtering and data streaming. We present the real-world use case of unfiltered flood simulation data of such medium scale that need to be visualized in real time for scientific purposes. Our solution facilitates compute shaders to maintain a guaranteed watertight triangulation in GPU memory that approximates the interpolated heightfields with view-dependent, continuous levels of detail. In each frame, the triangulation is updated incrementally by iteratively refining the cached result of the previous frame to minimize the computational effort. In particular, we minimize the number of heightfield sampling operations to make adaptive and higher-order interpolations viable options. We impose no restriction on the number of subdivisions and the achievable level of detail to allow for extreme zoom ranges required in geospatial visualization. Our method provides a stable runtime performance and can be executed with a limited time budget. We present a comparison of our method to three state-of-the-art methods, in which our method is competitive to previous non-watertight methods in terms of runtime, while outperforming them in terms of accuracy.},
keywords={Surface reconstruction;Merging;Data visualization;Real-time systems;Rendering (computer graphics);Interpolation;Graphics processing units;Visualization techniques and methodologies;heightfield rendering;terrain rendering;level of detail;tessellation},
doi={10.1109/TVCG.2022.3173081},
ISSN={1941-0506},
month={},}
@INPROCEEDINGS{5466996,
author={Mazzola Paluska, Justin and Pham, Hubert},
booktitle={2010 IEEE International Conference on Pervasive Computing and Communications (PerCom)},
title={Interactive streaming of structured data},
year={2010},
volume={},
number={},
pages={11-19},
abstract={We present ChunkStream, a system for efficient streaming and interactive editing of online video. Rather than using a specialized protocol and stream format, ChunkStream makes use of a generic mechanism employing chunks. Chunks are fixed-size arrays that contain a mixture of scalar data and references to other chunks. Chunks allow programmers to expose large, but fine-grained, data structures over the network. ChunkStream represents video clips using simple data types like linked lists and search trees, allowing a client to retrieve and work with only the portions of the clips that it needs. ChunkStream supports resource-adaptive playback and “live” streaming of real-time video as well as fast, frame-accurate seeking; bandwidth-efficient high-speed playback; and compilation of editing decisions from a set of clips. Benchmarks indicate that ChunkStream uses less bandwidth than HTTP Live Streaming while providing better support for editing primitives.},
keywords={Streaming media;Video sharing;Protocols;Data structures;Mobile computing;Internet;Pervasive computing;Smart phones;Clouds;Mashups},
doi={10.1109/PERCOM.2010.5466996},
ISSN={},
month={March},}
@ARTICLE{9552915,
author={Alsurdeh, Raed and Calheiros, Rodrigo N. and Matawie, Kenan M. and Javadi, Bahman},
journal={IEEE Access},
title={Hybrid Workflow Scheduling on Edge Cloud Computing Systems},
year={2021},
volume={9},
number={},
pages={134783-134799},
abstract={Internet of Things applications can be represented as workflows in which stream and batch processing are combined to accomplish data analytics objectives in many application domains such as smart home, health care, bioinformatics, astronomy, and education. The main challenge of this combination is the differentiation of service quality constraints between batch and stream computations. Stream processing is highly latency-sensitive while batch processing is more likely resource-intensive. In this work, we propose an end-to-end hybrid workflow scheduling on an edge cloud system as a two-stage framework. In the first stage, we propose a resource estimation algorithm based on a linear optimization approach, gradient descent search (GDS), and in the second stage, we propose a cluster-based provisioning and scheduling technique for hybrid workflows on heterogeneous edge cloud resources. We provide a multi-objective optimization model for execution time and monetary cost under constraints of deadline and throughput. Results demonstrate the framework performance in controlling the execution of hybrid workflows by efficiently tuning several parameters including stream arrival rate, processing throughput, and workflow complexity. In comparison to a meta-heuristics technique using Particle Swarm Optimization (PSO), the proposed scheduler provides significant improvement for large-scale hybrid workflows in terms of execution time and cost with an average of 8% and 35%, respectively.},
keywords={Task analysis;Cloud computing;Costs;Computational modeling;Data models;Resource management;Real-time systems;Hybrid workflow scheduling;streaming scheduling;gradient search optimization;resource estimation and provisioning},
doi={10.1109/ACCESS.2021.3116716},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{6999665,
author={Seyfabad, Mehdi Seydali and Akbari, Behzad},
booktitle={2014 22nd Iranian Conference on Electrical Engineering (ICEE)},
title={CAC-live: Centralized assisted cloud P2P live streaming},
year={2014},
volume={},
number={},
pages={908-913},
abstract={Peer-to-Peer (P2P) live video streaming over the Internet is a developing technology that recently has gained more attention. The use of P2P network with leveraging of local resources of peers, increases scalability and reduces costs. One of the limitations of P2P live video streaming systems is the lack of adequate resources such as available upload bandwidth, both at video source and inside P2P overlay network that lead to reduce the quality of service (QoS) experienced by the users. One solution for this problem is to employ additional on-demand resources such as virtual machines (VM) that are rented from a cloud provider to increase the amount of total available bandwidth. In this paper, we propose an architecture for improving the QoS of the peers by using virtual machines (VMs) dynamically are rented from cloud providers. Estimation of required VMs is performed through a central-based method and the number of VMs is calculated periodically. Our simulation based performance evaluation shows the efficiency of the proposed method.},
keywords={Quality of service;Bandwidth;Virtual machining;Overlay networks;Delays;Streaming media;Monitoring;live video;overlay network;p2p streaming;cloud computing},
doi={10.1109/IranianCEE.2014.6999665},
ISSN={2164-7054},
month={May},}
@INPROCEEDINGS{7363758,
author={Zacheilas, Nikos and Kalogeraki, Vana and Zygouras, Nikolas and Panagiotou, Nikolaos and Gunopulos, Dimitrios},
booktitle={2015 IEEE International Conference on Big Data (Big Data)},
title={Elastic complex event processing exploiting prediction},
year={2015},
volume={},
number={},
pages={213-222},
abstract={Supporting real-time, cost-effective execution of Complex Event processing applications in the cloud has been an important goal for many scientists in recent years. Distributed Stream Processing Systems (DSPS) have been widely adopted by major computing companies as a powerful approach for large-scale Complex Event processing (CEP). However, determining the appropriate degree of parallelism of the DSPS' components can be particularly challenging as the volume of data streams is becoming increasingly large, the rule set is becoming continuously complex, and the system must be able to handle such large data stream volumes in real-time, taking into consideration changes in the burstiness levels and data characteristics. In this paper we describe our solution to building elastic complex event processing systems on top of our distributed CEP system which combines two commonly used frameworks, Storm and Esper, in order to provide both ease of usage and scalability. Our approach makes the following contributions: (i) we provide a mechanism for predicting the load and latency of the Esper engines in upcoming time windows, and (ii) we propose a novel algorithm for automatically adjusting the number of engines to use in the upcoming windows, taking into account the cost and the performance gains of possible changes. Our detailed experimental evaluation with a real traffic monitoring application that analyzes bus traces from the city of Dublin indicates the benefits in the working of our approach. Our proposal outperforms the current state of the art technique in regards to the amount of tuples that it can process by four orders of magnitude.},
keywords={Engines;Storms;Mathematical model;Monitoring;Computational modeling;Topology;Measurement},
doi={10.1109/BigData.2015.7363758},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9101830,
author={Katsipoulakis, Nikos R. and Labrinidis, Alexandros and Chrysanthis, Panos K.},
booktitle={2020 IEEE 36th International Conference on Data Engineering (ICDE)},
title={SPEAr: Expediting Stream Processing with Accuracy Guarantees},
year={2020},
volume={},
number={},
pages={1105-1116},
abstract={Stream Processing Engines (SPEs) are used for realtime and continuous processing with stateful operations. This type of processing poses numerous challenges due to its associated complexity, unpredictable input, and need for timely results. As a result, users tend to overprovision resources, and online scaling is required in order to overcome overloaded situations. Current attempts for expediting stateful processing are impractical, due to their inability to uphold the quality of results, maintain performance, and reduce memory requirements. In this paper, we present the SPEAr system, which can expedite processing of stateful operations automatically by trading accuracy for performance. SPEAr detects when it can accelerate processing by employing online sampling and accuracy estimation at no additional cost. We built SPEAr on top of Storm and our experiments indicate that it can reduce processing times by more than an order of magnitude, use more than an order of magnitude less memory, and offer accuracy guarantees in real-world benchmarks.},
keywords={Watermarking;Buffer storage;Storms;Real-time systems;Memory management;Manuals;Silicon},
doi={10.1109/ICDE48307.2020.00100},
ISSN={2375-026X},
month={April},}
@INPROCEEDINGS{8996300,
author={Zhang, Wenyu and Lu, Yanfeng and Li, Yi and Qiao, Hong},
booktitle={2019 Chinese Automation Congress (CAC)},
title={Convolutional Neural Networks on Apache Storm},
year={2019},
volume={},
number={},
pages={2399-2404},
abstract={the performance of deep learning largely depends on the size of data. One data source is real-time streaming data, produced from mobile devices, sensors or social media, etc. Streaming data is high-speed and large-scale, which needs real-time processing. However, current mainstream frameworks are mainly designed for off-line data. To suit this, we first propose a deep learning framework based on Apache Storm, which is a distributed stream processing frame, fast and fault-tolerant. Our framework implements the distributed training of CNNs. which is different from MMLSpark or TensorFlowOnSpark that is a pure Java implementation. The design of message passing and synchronization is also suitable to other MapReduce-family distributed computing platforms. To validate our work, MNIST and Cifar -10 datasets are used for evaluation and comparison with similar architectures. The results show our framework, in resource-limited environment, realizes about 10 times speedup.},
keywords={Fasteners;Storms;Topology;Parallel processing;Training;Neural networks;Machine learning;Computer Vision;Distributed Systems;Neural Networks;Speed up;Streaming Datoe},
doi={10.1109/CAC48633.2019.8996300},
ISSN={2688-0938},
month={Nov},}
@INPROCEEDINGS{9179188,
author={Hai, Tran Hoang and Khiem, Nguyen Trong},
booktitle={2020 International Conference on Electrical, Communication, and Computer Engineering (ICECCE)},
title={Architecture for IDS Log Processing using Spark Streaming},
year={2020},
volume={},
number={},
pages={1-5},
abstract={In a large network enterprise system, the use network intrusion detection system (N-IDS) become popular since it has very important role and a challenging task to the network manager in term of security management. Existing network systems develop and expand both in terms of network size, load, and application traffic so the processing of a single IDS is not enough and imposed a high overload on the system. Therefore, there is a need for upgrading a novel IDS system to adapt to the new challenges. To improve the performance of the entire N-IDS system, the traditional way is to replace it with a higher performance server to meet the requirements of processing and storage or using several N-IDS systems. However, in those types of systems, the cost is often expensive but the processing and representation data real-time is still very limited and it does not meet the urgent requirements of security manager. In this paper, we propose novel architecture of distributed log processing and storage tools to improve N-IDS data processing. Our goal is to improve overall system performance and cost-efficient. In this paper, we recommend the use of distributed processing and storage tools to improve N-IDS data processing by Apache Spark and make a comparison with previous works using Hadoop Cluster. Our proposed model introduces a real-time data streaming tool, e.g., Apache Spark Streaming, for near real-time analysis of log processing.},
keywords={Sparks;Tools;Computer architecture;Servers;Real-time systems;Data models},
doi={10.1109/ICECCE49384.2020.9179188},
ISSN={},
month={June},}
@INPROCEEDINGS{9006320,
author={Twaty, Muaz and Ghrab, Amine and Skhiri, Sabri},
booktitle={2019 IEEE International Conference on Big Data (Big Data)},
title={GraphOpt: a Framework for Automatic Parameters Tuning of Graph Processing Frameworks},
year={2019},
volume={},
number={},
pages={3744-3753},
abstract={Finding the optimal configuration of a black-box system is a difficult problem that requires a lot of time and human labor. Big data processing frameworks are among the increasingly popular systems whose tuning is a complex and time consuming. The challenge of automatically finding the optimal parameters of big data frameworks attracted a lot of research in recent years. Some of the studies focused on optimizing specific frameworks such as distributed stream processing [1], [2], or finding the best cloud configurations [3], while others proposed general services for optimizing any black-box system [4]. In this paper, we introduce a new use case in the domain of automatic parameter tuning: optimizing the parameters of distributed graph processing frameworks. This task is notably difficult given the particular challenges of distributed graph processing that include the graph partitioning and the iterative nature of graph algorithms. To address this challenge, we designed and implemented GraphOpt: an efficient and scalable black-box optimization framework that automatically tunes distributed graph processing frameworks. GraphOpt implements state-of-the-art optimization algorithms and introduces a new hill-climbing-based search algorithm. These algorithms are used to optimize the performance of two major graph processing frameworks: Giraph and GraphX. Extensive experiments were run on GraphOpt using multiple graph benchmarks to evaluate its performance and show that it provides up to 47.8% improvement compared to random search and an average improvement of up to 5.7%.},
keywords={Optimization;Tuning;Sparks;Partitioning algorithms;Predictive models;Message systems;Big Data;Distributed Graph Processing;Parameters Tuning;Black-box Optimization},
doi={10.1109/BigData47090.2019.9006320},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6846746,
author={Lai, Farley and Hasan, Syed Shabih and Laugesen, Austin and Chipara, Octav},
booktitle={IPSN-14 Proceedings of the 13th International Symposium on Information Processing in Sensor Networks},
title={CSense: A stream-processing toolkit for robust and high-rate mobile sensing applications},
year={2014},
volume={},
number={},
pages={119-129},
abstract={This paper presents CSense - a stream-processing toolkit for developing robust and high-rate mobile sensing application in Java. CSense addresses the needs of these systems by providing a new programming model that supports flexible application configuration, a high-level concurrency model, memory management, and compiler analyses and optimizations. Our compiler includes a novel flow analysis that optimizes the exchange of data across components from an application-wide perspective. A mobile sensing application benchmark indicates that flow analysis may reduce CPU utilization by as much as 45%. Static analysis is used to detect a range of programming errors including application composition errors, improper use of memory management, and data races. We identify that memory management and concurrency limit the scalability of stream processing systems. We incorporate memory pools, frame conversion optimizations, and custom synchronization primitives to develop a scalable run-time. CSense is evaluated on Galaxy Nexus phones running Android. Empirical results indicate that our run-time achieves 19 times higher steam processing rate compared to a realistic baseline implementation. We demonstrate the versatility of CSense by developing three mobile sensing applications.},
keywords={Ports (Computers);Concurrent computing;Java;Optimization;Sensors;Programming;Memory management;Dataflow computing;runtime environment;embedded software},
doi={10.1109/IPSN.2014.6846746},
ISSN={},
month={April},}
@INPROCEEDINGS{5767851,
author={Kalyvianaki, Evangelia and Wiesemann, Wolfram and Vu, Quang Hieu and Kuhn, Daniel and Pietzuch, Peter},
booktitle={2011 IEEE 27th International Conference on Data Engineering},
title={SQPR: Stream query planning with reuse},
year={2011},
volume={},
number={},
pages={840-851},
abstract={When users submit new queries to a distributed stream processing system (DSPS), a query planner must allocate physical resources, such as CPU cores, memory and network bandwidth, from a set of hosts to queries. Allocation decisions must provide the correct mix of resources required by queries, while achieving an efficient overall allocation to scale in the number of admitted queries. By exploiting overlap between queries and reusing partial results, a query planner can conserve resources but has to carry out more complex planning decisions. In this paper, we describe SQPR, a query planner that targets DSPSs in data centre environments with heterogeneous resources. SQPR models query admission, allocation and reuse as a single constrained optimisation problem and solves an approximate version to achieve scalability. It prevents individual resources from becoming bottlenecks by re-planning past allocation decisions and supports different allocation objectives. As our experimental evaluation in comparison with a state-of-the-art planner shows SQPR makes efficient resource allocation decisions, even with a high utilisation of resources, with acceptable overheads.},
keywords={Planning;Digital signal processing;Resource management;Optimization;Bandwidth;Load modeling;Relays},
doi={10.1109/ICDE.2011.5767851},
ISSN={2375-026X},
month={April},}
@INPROCEEDINGS{1623943,
author={Zeitler, E. and Risch, T.},
booktitle={22nd International Conference on Data Engineering Workshops (ICDEW'06)},
title={Processing High-Volume Stream Queries on a Supercomputer},
year={2006},
volume={},
number={},
pages={x147-x147},
abstract={Scientific instruments, such as radio telescopes, colliders, sensor networks, and simulators generate very high volumes of data streams that scientists analyze to detect and understand physical phenomena. The high data volume and the need for advanced computations on the streams require substantial hardware resources and scalable stream processing. We address these challenges by developing data stream management technology to support high-volume stream queries utilizing massively parallel computer hardware. We have developed a data stream management system prototype for state-of-the-art parallel hardware. The performance evaluation uses real measurement data from LOFAR, a radio telescope antenna array being developed in the Netherlands.},
keywords={Supercomputers;Hardware;Radio astronomy;Instruments;Sensor phenomena and characterization;Computational modeling;Analytical models;Technology management;Space technology;Concurrent computing},
doi={10.1109/ICDEW.2006.118},
ISSN={},
month={April},}
@INPROCEEDINGS{9029068,
author={Li, Kejian and Liu, Gang and Lu, Minhua},
booktitle={2019 20th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT)},
title={A Holistic Stream Partitioning Algorithm for Distributed Stream Processing Systems},
year={2019},
volume={},
number={},
pages={202-207},
abstract={The performances of modern distributed stream processing systems are critically affected by the distribution of the load across workers. Skewed data streams in real world are very common and pose a great challenge to these systems, especially for stateful applications. Key splitting, which allows a single key to be routed to multiple workers, is a great idea to achieve good balance of load in the cluster. However, it comes with the cost of increased memory consumption and computation overhead as well as network communication. In this paper, we present a new definition of metric to model the cost of key splitting for intra-operator parallelism in stream processing systems and provide a novel perspective to reduce replication factor while keeping both overall load imbalance and processing latency low. Similar to previous work, our approach treats the head and the tail of the distribution differently in order to reduce memory requirements. For the head, it uses our proposed notion of regional load imbalance to decide dynamically whether to make one more worker responsible for the heavy hitter or not. For the tail, it simply uses hash partitioning to keep the size of the routing table for the head as small as possible. Extensive experimental evaluation demonstrates that our approach provides superior performance compared to the state-of-the-art partitioning algorithms in terms of load imbalance, replication factor and latency over different levels of skewed stream distributions.},
keywords={Partitioning algorithms;Memory management;Measurement;Parallel processing;Microsoft Windows;Load modeling;Throughput;stream processing;stream partitioning;load imbalance;key splitting},
doi={10.1109/PDCAT46702.2019.00046},
ISSN={2640-6721},
month={Dec},}
@INPROCEEDINGS{5703506,
author={Cazalas, Jonathan and Guha, Ratan},
booktitle={2010 IEEE/IFIP International Conference on Embedded and Ubiquitous Computing},
title={GEDS: GPU Execution of Continuous Queries on Spatio-Temporal Data Streams},
year={2010},
volume={},
number={},
pages={112-119},
abstract={Much research exists for the efficient processing of spatio-temporal data streams. However, all methods ultimately rely on an ill-equipped processor, namely a CPU, to evaluate concurrent, continuous spatio-temporal queries over these data streams. This paper presents GEDS, a scalable, Graphics Processing Unit (GPU)-based framework for the evaluation of continuous spatio-temporal queries over spatio-temporal data streams. GEDS employs the computation sharing and parallel processing paradigms to deliver scalability in the evaluation of continuous spatio-temporal queries. The GEDS framework utilizes the parallel processing capability of the GPU, a stream processor by trade, to handle the computation required in this application. Experimental evaluation shows promising performance and shows the scalability and efficacy of GEDS in spatio-temporal data streaming environments.},
keywords={Graphics processing unit;Mobile communication;Data models;Central Processing Unit;Computational modeling;Arrays;Databases;spatio-temporal data streams;computation sharing;parallel processing;location-based services;mobile database systems;continuous query;graphical processing unit;GPU},
doi={10.1109/EUC.2010.26},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8025307,
author={HoseinyFarahabady, MohammadReza and Taheri, Javid and Tari, Zahir and Zomaya, Albert Y.},
booktitle={2017 46th International Conference on Parallel Processing (ICPP)},
title={A Dynamic Resource Controller for a Lambda Architecture},
year={2017},
volume={},
number={},
pages={332-341},
abstract={Lambda architecture is a novel event-driven serverless paradigm that allows companies to build scalable and reliable enterprise applications. As an attractive alternative to traditional service oriented architecture (SOA), Lambda architecture can be used in many use cases including BI tools, in-memory graph databases, OLAP, and streaming data processing. In practice, an important aim of Lambda's service providers is devising an efficient way to co-locate multiple Lambda functions with different attributes into a set of available computing resources. However, previous studies showed that consolidated workloads can compete fiercely for shared resources, resulting in severe performance variability/degradation. This paper proposes a resource allocation mechanism for a Lambda platform based on the model predictive control framework. Performance evaluation is carried out by comparing the proposed solution with multiple resource allocation heuristics, namely enhanced versions of spread and binpack, and best-effort approaches. Results confirm that the proposed controller increases the overall resource utilization by 37% on average and achieves a significant improvement in preventing QoS violation incidents compared to others.},
keywords={Quality of service;Resource management;Sensitivity;Memory management;Interference;Servers;Dynamic Resource Allocation;Performance degradation;Lambda Platform Processing;Shared Resource Interference},
doi={10.1109/ICPP.2017.42},
ISSN={2332-5690},
month={Aug},}
@INPROCEEDINGS{8944449,
author={Yadav, Shekhar Kumar and Patel, Jigisha N.},
booktitle={2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)},
title={Application of Compressed Sensing using a Reed Solomon (RS) code based Deterministic Measurement Matrix},
year={2019},
volume={},
number={},
pages={1-5},
abstract={Compressed Sensing (CS) is an emerging technique in the field of acquiring and compressing signals as this technique allows for sampling a signal which is sparse in some domain with a rate well below the limit prescribed by the conventional Shannon-Nyquist sampling theorem. As a result, this new sensing paradigm is applicable to many fields like medical imaging, Data streaming, UWB-based communication systems, wireless sensor networks etc. A sensing matrix is one of the principal components in the architecture of compressed sensing. Traditionally, random sensing matrices have been used for CS but these matrices prove difficult for practical implementation and hence the development of deterministic sensing matrix have gathered recent momentum. In this paper, CS is applied to gray scale images using the deterministic sensing matrix based on Reed-Solomon (RS) code with asymptotically optimal coherence. The performance is compared with random measurement matrix for different reconstruction algorithms like Orthogonal Matching Pursuit (OMP) and Basis Pursuit (BP). The performance metrics considered for comparison of the original and reconstructed images are Structural Similarity Index (SSIM), PSNR, SNR and run time. Also, the role of the level of signal sparsity in CS is analyzed using simulation results.},
keywords={Sparse matrices;Sensors;Image reconstruction;Compressed sensing;Discrete wavelet transforms;Coherence;Compressed Sensing;Measurement matrix;Reed-Solomon code;Discrete Wavelet Transform;BP;OMP},
doi={10.1109/ICCCNT45670.2019.8944449},
ISSN={},
month={July},}
@INPROCEEDINGS{9006139,
author={Silva, Pedro and Costan, Alexandru and Antoniu, Gabriel},
booktitle={2019 IEEE International Conference on Big Data (Big Data)},
title={Investigating Edge vs. Cloud Computing Trade-offs for Stream Processing},
year={2019},
volume={},
number={},
pages={469-474},
abstract={The recent spectacular rise of the Internet of Things and the associated augmentation of the data deluge motivated the emergence of Edge computing as a means to distribute processing from centralized Clouds towards decentralized processing units close to the data sources. This led to new challenges in ways to distribute processing across Cloud-based, Edge-based or hybrid Cloud/Edge-based infrastructures. In particular, a major question is: how much can one improve (or degrade) the performance of an application by performing computation closer to the data sources rather than in the Cloud? This paper proposes a methodology to understand such performance trade-offs and illustrates it through experimental evaluation with two real-life stream processing use-cases executed on fully-Cloud and hybrid Cloud-Edge testbeds using state-of-the-art processing engines for each environment. We derive a set of take-aways for the community, highlighting the limitations of each environment, the scenarios that could benefit from hybrid Edge-Cloud deployments, what relevant parameters impact performance and how.},
keywords={Cloud computing;Edge computing;Data processing;Sensors;Performance evaluation;Logic gates;Edge Computing;Edge Analytics;Fog Computing;Cloud Computing;Stream Processing;Flink;Edgent},
doi={10.1109/BigData47090.2019.9006139},
ISSN={},
month={Dec},}
@ARTICLE{8735782,
author={Maroulis, Stathis and Zacheilas, Nikos and Kalogeraki, Vana},
journal={IEEE Transactions on Parallel and Distributed Systems},
title={A Holistic Energy-Efficient Real-Time Scheduler for Mixed Stream and Batch Processing Workloads},
year={2019},
volume={30},
number={12},
pages={2624-2635},
abstract={In recent years we have experienced a wide adoption of novel distributed processing frameworks such as Apache Spark for handling batch and stream processing big data applications. An important aspect that has not been examined in these systems yet, is the energy consumption during the applications' execution. Reducing the energy consumption of modern datacenters is a necessity, as datacenters contribute over 2 percent of the total US electric usage. However, efficiently scheduling applications in distributed processing systems can be challenging as there is a trade-off between minimizing the datacenter's energy usage and satisfying the application performance requirements. In this work we propose, ExpREsS, a scheduler for orchestrating the execution of Spark applications in a way that enables us to minimize the energy consumption while ensuring that the applications' performance requirements are met. Our approach exploits time-series segmentation for capturing the applications' energy usage and execution times, and then applies a novel DVFS technique to minimize the energy consumption. In order to tackle the limited number of application's profiling runs, we exploit regression techniques to predict the applications' execution times and power consumption. Our detailed experimental evaluation using realistic workloads on our local cluster illustrates the working and benefits of our approach.},
keywords={Power demand;Energy consumption;Cluster computing;Central Processing Unit;Time-frequency analysis;Distributed processing;Distributed systems;scheduling;green computing;apache spark;cluster management},
doi={10.1109/TPDS.2019.2922606},
ISSN={1558-2183},
month={Dec},}
@ARTICLE{7908950,
author={Antaris, Stefanos and Rafailidis, Dimitrios},
journal={IEEE Transactions on Big Data},
title={In-Memory Stream Indexing of Massive and Fast Incoming Multimedia Content},
year={2018},
volume={4},
number={1},
pages={40-54},
abstract={In this article, a media storm indexing mechanism is presented, where media storms are defined as fast incoming batches. We propose an approximate media storm indexing mechanism to index/store massive image collections with varying incoming image rate. To evaluate the proposed indexing mechanism, two architectures are used: i) a baseline architecture, which utilizes a disk-based processing strategy and ii) an in-memory architecture, which uses the Flink distributed stream processing framework. This study is the first in the literature to utilize an in-memory processing strategy to provide a media storm indexing mechanism. In the experimental evaluation conducted on two image datasets, among the largest publicly available with 80 M and 1 B images, a media storm generator is implemented to evaluate the proposed media storm indexing mechanism on different indexing workloads, that is, images that come with high volume and different velocity at the scale of 105 and 106 incoming images per second. Using the approximate media storm indexing mechanism a significant speedup factor, equal to 26.32 on average, is achieved compared with conventional indexing techniques, while maintaining high search accuracy, after having indexed the media storms. Finally, the implementations of both architectures and media storm indexing mechanisms are made publicly available.},
keywords={Multimedia communication;Distributed databases;Streaming media;Search problems;In-memory processing;multimedia storage and search;stream processing},
doi={10.1109/TBDATA.2017.2697441},
ISSN={2332-7790},
month={March},}
@INPROCEEDINGS{8845079,
author={Gokalgandhi, Bhargav and Seskar, Ivan},
booktitle={IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)},
title={Distributed Processing for Encoding and Decoding of Binary LDPC codes using MPI},
year={2019},
volume={},
number={},
pages={596-601},
abstract={Low Density Parity Check (LDPC) codes are linear error correcting codes used in communication systems for Forward Error Correction (FEC). But, intensive computation is required for encoding and decoding of LDPC codes, making it difficult for practical usage in general purpose software based signal processing systems. In order to accelerate the encoding and decoding of LDPC codes, distributed processing over multiple multi-core CPUs using Message Passing Interface (MPI) is performed. Implementation is done using Stream Processing and Batch Processing mechanisms and the execution time for both implementations is compared w.r.t variation in number of CPUs and number of cores per CPU. Performance evaluation of distributed processing is shown by variation in execution time w.r.t. increase in number of processors (CPU cores).},
keywords={Parity check codes;Program processors;Decoding;Encoding;Generators;Acceleration;Message passing},
doi={10.1109/INFCOMW.2019.8845079},
ISSN={},
month={April},}
@INPROCEEDINGS{7363874,
author={Luckow, Andre and Kennedy, Ken and Manhardt, Fabian and Djerekarov, Emil and Vorster, Bennie and Apon, Amy},
booktitle={2015 IEEE International Conference on Big Data (Big Data)},
title={Automotive big data: Applications, workloads and infrastructures},
year={2015},
volume={},
number={},
pages={1201-1210},
abstract={Data is increasingly affecting the automotive industry, from vehicle development, to manufacturing and service processes, to online services centered around the connected vehicle. Connected, mobile and Internet of Things devices and machines generate immense amounts of sensor data. The ability to process and analyze this data to extract insights and knowledge that enable intelligent services, new ways to understand business problems, improvements of processes and decisions, is a critical capability. Hadoop is a scalable platform for compute and storage and emerged as de-facto standard for Big Data processing at Internet companies and in the scientific community. However, there is a lack of understanding of how and for what use cases these new Hadoop capabilities can be efficiently used to augment automotive applications and systems. This paper surveys use cases and applications for deploying Hadoop in the automotive industry. Over the years a rich ecosystem emerged around Hadoop comprising tools for parallel, in-memory and stream processing (most notable MapReduce and Spark), SQL and NOSQL engines (Hive, HBase), and machine learning (Mahout, MLlib). It is critical to develop an understanding of automotive applications and their characteristics and requirements for data discovery, integration, exploration and analytics. We then map these requirements to a confined technical architecture consisting of core Hadoop services and libraries for data ingest, processing and analytics. The objective of this paper is to address questions, such as: What applications and datasets are suitable for Hadoop? How can a diverse set of frameworks and tools be managed on multi-tenant Hadoop cluster? How do these tools integrate with existing relational data management systems? How can enterprise security requirements be addressed? What are the performance characteristics of these tools for real-world automotive applications? To address the last question, we utilize a standard benchmark (TPCx-HS), and two application benchmarks (SQL and machine learning) that operate on a dataset of multiple Terabytes and billions of rows.},
keywords={Vehicles;Big data;Automotive applications;Industries;Lakes;Business},
doi={10.1109/BigData.2015.7363874},
ISSN={},
month={Oct},}
@ARTICLE{8630099,
author={Nardelli, Matteo and Cardellini, Valeria and Grassi, Vincenzo and Presti, Francesco Lo},
journal={IEEE Transactions on Parallel and Distributed Systems},
title={Efficient Operator Placement for Distributed Data Stream Processing Applications},
year={2019},
volume={30},
number={8},
pages={1753-1767},
abstract={In the last few years, a large number of real-time analytics applications rely on the Data Stream Processing (DSP) so to extract, in a timely manner, valuable information from distributed sources. Moreover, to efficiently handle the increasing amount of data, recent trends exploit the emerging presence of edge/Fog computing resources so to decentralize the execution of DSP applications. Since determining the Optimal DSP Placement (for short, ODP) is an NP-hard problem, we need efficient heuristics that can identify a good application placement on the computing infrastructure in a feasible amount of time, even for large problem instances. In this paper, we present several DSP placement heuristics that consider the heterogeneity of computing and network resources; we divide them in two main groups: model-based and model-free. The former employ different strategies for efficiently solving the ODP model. The latter implement, for the problem at hand, some of the well-known meta-heuristics, namely greedy first-fit, local search, and tabu search. By leveraging on ODP, we conduct a thorough experimental evaluation, aimed to assess the heuristics' efficiency and efficacy under different configurations of infrastructure size, application topology, and optimization objectives.},
keywords={Computational modeling;Quality of service;Search problems;Delays;Optimization;Storms;Distributed data stream processing;geo-distributed systems;heuristics;operator placement;quality of service},
doi={10.1109/TPDS.2019.2896115},
ISSN={1558-2183},
month={Aug},}
@INPROCEEDINGS{5283513,
author={Brito, Andrey and Fetzer, Christof and Felber, Pascal},
booktitle={2009 28th IEEE International Symposium on Reliable Distributed Systems},
title={Multithreading-Enabled Active Replication for Event Stream Processing Operators},
year={2009},
volume={},
number={},
pages={22-31},
abstract={Event stream processing (ESP) systems are very popular in monitoring applications. Algorithmic trading, network monitoring and sensor networks are good examples of applications that rely upon ESP systems. As these systems become larger and more widely deployed, they have to answer increasingly stronger requirements that are often difficult to satisfy. Fault-tolerance is a good example of such a non-trivial requirement. Making ESP operators fault-tolerant can add considerable performance overhead to the application. In this paper, we focus on active replication as an approach to provide fault-tolerance to ESP operators. More precisely, we address the performance costs of active replication for operators in distributed ESP applications.We use a speculation mechanism based on software transactional memory (STM) to achieve the following goals: (i) enable replicas to make progress using optimistic delivery; (ii) enable early forwarding of speculative computation results; (iii) enable active replication of multi-threaded operators using transactional executions. Experimental evaluation shows that, using this combination of mechanisms, one can implement highly efficient fault-tolerant ESP operators.},
keywords={Electrostatic precipitators;Fault tolerance;Monitoring;Delay;Application software;Costs;Broadcasting;Reliability engineering;Systems engineering and theory;Sensor systems and applications;active replication;event processing;fault-tolerance;distributed systems;speculation;parallel computing},
doi={10.1109/SRDS.2009.37},
ISSN={1060-9857},
month={Sep.},}
@INPROCEEDINGS{8005324,
author={Maroulis, Stathis and Zacheilas, Nikos and Kalogeraki, Vana},
booktitle={2017 IEEE International Conference on Autonomic Computing (ICAC)},
title={ExpREsS: EneRgy Efficient Scheduling of Mixed Stream and Batch Processing Workloads},
year={2017},
volume={},
number={},
pages={27-32},
abstract={Nowadays we see the wide adoption of novel distributed processing frameworks such as Apache Spark for handling batch and stream processing big data applications. An important aspect that has not been examined in these systems is their energy consumption during the application execution. Reducing the power consumption of modern datacenters is a necessity as datacenters contribute over 2% of the total US electric usage. One way of addressing this energy issue is by scheduling the applications in an energy-efficient way. However, efficiently scheduling applications can be challenging as we need to consider the trade-off between the datacenter's energy usage and per application performance requirements. In this work we propose, ExpREsS, a scheduler for orchestrating the execution of Spark applications so that it both minimizes the energy consumption and satisfies the applications' performance requirements. Our approach exploits time-series prediction models for capturing the applications' energy usage and execution times, and then applies a novel DVFS technique to minimize the energy consumption. Our detailed experimental evaluation using realistic workloads on our local cluster illustrates the working and benefits of our approach.},
keywords={Energy consumption;Sparks;Power demand;Time-frequency analysis;Batch production systems;Radio spectrum management;Distributed Systems;Scheduling;Green Computing},
doi={10.1109/ICAC.2017.43},
ISSN={2474-0756},
month={July},}
@INPROCEEDINGS{6912528,
author={Coluccio, Roberto and Ghidini, Giacomo and Reale, Andrea and Levine, David and Bellavista, Paolo and Emmons, Stephen P. and Smith, Jeffrey O.},
booktitle={2014 IEEE Symposium on Computers and Communications (ISCC)},
title={Online stream processing of machine-to-machine communications traffic: A platform comparison},
year={2014},
volume={},
number={},
pages={1-7},
abstract={In a machine-to-machine (M2M) communications system, the deployed devices relay data from on-board sensors to a back-end application over a wireless network. Since the cellular network provides very good coverage (especially in inhabited areas) and is relatively inexpensive, commercial M2M applications often prefer it to other technologies such as WiFi or satellite links. Unfortunately, having been originally designed with human users in mind, the cellular network provides little support to monitor millions of unattended devices. For this reason, it is extremely important to monitor the underlying signalling traffic to detect misbehaving devices or network problems. In the cellular network used by M2M communications systems, the network elements communicate using the Signalling System #7 (SS7), and a real-life system can generate tens of millions of SS7 messages per hour. This paper reports the results of our practical investigation on the possibility to use distributed stream processing systems (DSPSs) to perform real-time analysis of SS7 traffic in a commercial M2M communications system consisting of hundreds of thousands of devices. Through a thorough experimental evaluation based on the analysis of real-world SS7 traces, we present and compare the implementations of a DSPS-based data analysis application on top of either the well-known Storm DSPS or the Quasit middleware. The results show that, by using DSPS services, we are able to largely meet the real-time processing requirements of our use-case scenario.},
keywords={Storms;GSM;Digital signal processing;Monitoring;Data models;Data analysis;Databases;distributed stream processing;M2M communications;SS7;Quasit;Storm},
doi={10.1109/ISCC.2014.6912528},
ISSN={1530-1346},
month={June},}
@INPROCEEDINGS{1557051,
author={Munshi, A. and Wong, A. and Clinton, A. and Braganza, S. and Bishop, W. and McCool, M.},
booktitle={Canadian Conference on Electrical and Computer Engineering, 2005.},
title={A parameterizable SIMD stream processor},
year={2005},
volume={},
number={},
pages={806-811},
abstract={Stream processing is a data processing paradigm in which long sequences of homogeneous data records are passed through one or more computational kernels to produce sequences of processed output data. Applications that fit this model include polygon rendering (computer graphics), matrix multiplication (scientific computing), 2D convolution (media processing), and data encryption (security). Computers that exploit stream computations process data faster than conventional microcomputers because they utilize a memory system and an execution model that increases on-chip bandwidth and delivers high throughput. We have designed a general-purpose, parameterizable, SIMD stream processor that operates on IEEE single-precision floating point data. The system is implemented in VHDL, and consists of a configurable FPU, execution unit array, and memory interface. The FPU supports pipelined operations for multiplication, addition, division, and square root. The data width is configurable. The execution array operates in lock-step with an instruction controller, which issues 32-bit instructions to the execution array. To exploit stream parallelism, the number of execution units as well as the number of interleaved threads is specified as a parameter at compilation time. The memory system allows all execution units to access one element of data from memory in every clock cycle. All memory accesses also pass through a routing network to support conditional reads and writes of stream data. Functional and timing simulations have been performed using a variety of benchmark programs. The system has also been synthesized into an Altera FPGA to verify resource utilization.},
keywords={Data processing;Kernel;Application software;Rendering (computer graphics);Computer graphics;Scientific computing;Convolution;Cryptography;Computer security;Data security},
doi={10.1109/CCECE.2005.1557051},
ISSN={0840-7789},
month={May},}
@INPROCEEDINGS{7570513,
author={Chakraborty, Rudraneel and Majumdar, Shikharesh},
booktitle={2016 International Symposium on Performance Evaluation of Computer and Telecommunication Systems (SPECTS)},
title={A priority based resource scheduling technique for multitenant storm clusters},
year={2016},
volume={},
number={},
pages={1-6},
abstract={In this work in progress paper, we present our ongoing effort towards devising a priority based resource scheduling technique and framework for apache storm. Apache Storm is a popular distributed real time stream processing engine which has been widely adopted by key players in the industry including YAHOO and Twitter. An application running in storm is called a topology that is characterized by a Directed Acyclic Graph (DAG). To run multiple of such topologies in a storm cluster, storm provides with default, out of the box scheduler called Isolation Scheduler. Isolation Scheduler assigns resources to topologies based on static resource configuration and does not provide any means to prioritize topologies based on their varying business priority. As a result, performance degradation, even complete starvation of topologies with high business priority is possible when available cluster resources are insufficient. A priority based resource scheduling strategy is proposed in this paper to overcome this problem. A preliminary performance evaluation is performed to demonstrate effectiveness of the proposed scheduler over the default storm Isolation Scheduler.},
keywords={Topology;Storms;Real-time systems;Fasteners;Big data;Dynamic scheduling;Distributed Computing;Distributed Stream Processing (DSP);Big Data;Apache Storm;Event Processing;Resource Management;Priority Scheduling},
doi={10.1109/SPECTS.2016.7570513},
ISSN={},
month={July},}
@INPROCEEDINGS{5686260,
author={Asif, Muhammad Salman and Omer, Mohammad and Luna, Amjad and Sheikh, Noor. M.},
booktitle={2006 IEEE GCC Conference (GCC)},
title={A multiprocessor framework for rapid-prototyping and evaluation of soft transceivers},
year={2006},
volume={},
number={},
pages={1-5},
abstract={Recent years have seen rapid evolution in the architectures being explored for realizing high-speed software-defined radios. There is, however, a distinct need for a low-cost programmable platform where algorithms for base-band transceivers can be rapidly prototyped and tested with real-world data, streaming in from diverse sources of telecommunication traffic. This paper explores an analytical method for laying out such a generic platform. It investigates the constraints involved in realizing such a platform, and the minimum functionality needed within the solution so as to provide adequate scalability to allow the implementation of a wide variety of communication algorithms. The paper concludes with a case study of a multi-channel communication system that has been successfully implemented on the proposed platform, highlighting the performance benchmarks it had to meet in order to prove suitable for the task of communication system evaluation.},
keywords={Receivers;Computer architecture;Digital signal processing;Transceivers;Clocks;Field programmable gate arrays;Communication systems;MIPS;DSP;Analog Front End (AFE);Buffers;Data Converters;PAM (pulse amplitude modulation)},
doi={10.1109/IEEEGCC.2006.5686260},
ISSN={},
month={March},}
@INPROCEEDINGS{8048925,
author={Farahabady, Mohammad Reza Hoseiny and Zomaya, Albert Y. and Tari, Zahir},
booktitle={2017 IEEE International Conference on Cluster Computing (CLUSTER)},
title={QoS- and Contention- Aware Resource Provisioning in a Stream Processing Engine},
year={2017},
volume={},
number={},
pages={137-146},
abstract={This paper addresses the shared resource contention problem associated with the auto-parallelization of running queries in distributed stream processing engines. In such platforms, analyzing a large amount of data often requires to execute user-defined queries over continues raw-inputs in a parallel fashion at each single host. However, previous studies showed that the collocated applications can fiercely compete for shared resources, resulting in a severe performance degradation among applications. This paper presents an advanced resource allocation strategy for handling scenarios in which the target applications have different quality of service (QoS) requirements while shared-resource interference is considered as a key performance-limiting parameter. To properly allocate the best possible resource to each query, the proposed controller predicts the performance degradation of the running pane-level as well as the window-level queries when co-running with other queries. This is addressed as an optimization problem where a set of cost functions is defined to achieve the following goals: a) reduce the sum of QoS violation incidents over all machines; b) keep the CPU utilization level within an accepted range; and c) avoid fierce shared resource interference among collocated applications. Particle swarm optimization is used to find an acceptable solution at each round of the controlling period. The performance of the proposed solution is benchmarked with Round-Robin and best-effort strategies, and the experimental results clearly demonstrate that the proposed controller has the following advantages over its opponents: it increases the overall resource utilization by 15% on average while can reduce the average tuple latencies by 14%. It also achieves an average 123% improvement in preventing QoS violation incidents.},
keywords={Quality of service;Resource management;Engines;Interference;Predictive models;Monitoring;Process control;Stream Processing;Parallelization Factor;Shared Resource Interference;Workload Consolidation},
doi={10.1109/CLUSTER.2017.21},
ISSN={2168-9253},
month={Sep.},}
@ARTICLE{8868214,
author={Fang, Junhua and Zhang, Rong and Zhao, Yan and Zheng, Kai and Zhou, Xiaofang and Zhou, Aoying},
journal={IEEE Transactions on Knowledge and Data Engineering},
title={A-DSP: An Adaptive Join Algorithm for Dynamic Data Stream on Cloud System},
year={2021},
volume={33},
number={5},
pages={1861-1876},
abstract={The join operations, including both equi and non-equi joins, are essential to the complex data analytics in the big data era. However, they are not inherently supported by existing DSPEs (Distributed Stream Processing Engines). The state-of-the-art join solutions on DSPEs rely on either complicated routing strategies or resource-inefficient processing structures, which are susceptible to dynamic workload, especially when the DSPEs face various join predicate operations and skewed data distribution. In this paper, we propose a new cost-effective stream join framework, named A-DSP (Adaptive Dimensional Space Processing), which enhances the adaptability of real-time join model and minimizes the resource used over the dynamic workloads. Our proposal includes: 1) a join model generation algorithm devised to adaptively switch between different join schemes so as to minimize the number of processing task required; 2) a load-balancing mechanism which maximizes the processing throughput; and 3) a lightweight algorithm designed for cutting down unnecessary migration cost. Extensive experiments are conducted to compare our proposal against state-of-the-art solutions on both benchmark and real-world workloads. The experimental results verify the effectiveness of our method, especially on reducing the operational cost under pay-as-you-go pricing scheme.},
keywords={Task analysis;Routing;Data models;Heuristic algorithms;Adaptation models;Parallel processing;Computational modeling;Distributed stream join;theta-join;cost effective},
doi={10.1109/TKDE.2019.2947055},
ISSN={1558-2191},
month={May},}
@INPROCEEDINGS{8171365,
author={Wang, Yidan and Tari, Zahir and HoseinyFarahabady, M. Reza and Zomaya, Albert Y.},
booktitle={2017 IEEE 16th International Symposium on Network Computing and Applications (NCA)},
title={QoS-aware resource allocation for stream processing engines using priority channels},
year={2017},
volume={},
number={},
pages={1-9},
abstract={This paper addresses the challenging problem of guaranteeing quality-of-service (QoS) requirements associated with parallel running queries in distributed stream processing engines. In such platforms, the real-time processing of streaming data often requires executing a set of user-defined queries over continues data flows. However, previous studies showed that guaranteeing QoS enforcement (such as end-to-end response time) for a collection of applications is a complex problem. This paper presents an advanced resource allocation strategy to tackle such a problem by considering the traffic pattern of individual data streams. To properly allocate resource for streaming queries execution, we define a certain number of priority channels to categorize the streaming data across the system. The resource allocation is addressed as an optimization problem where a set of cost functions is defined to achieve the following goals: a) reduce the sum of QoS violation incidents across all applications; b) increase the CPU utilization level, and (c) avoid the additional costs caused by frequent reconfigurations. The proposed solution does not depend on any assumption about the incoming data rate or the query processing time. The performance of the proposed solution is benchmarked, and the experimental results reveal that the proposed scheme increases the overall resource utilization by 23% on average and reduces the QoS violations by 29% against round-robin strategy. It could also prevent QoS violation incidents at different levels by tuning the cost function.},
keywords={Quality of service;Resource management;Delays;Time factors;Real-time systems;Engines;Dynamic scheduling;Stream Processing Engine;Dynamic Resource Allocation;End-to-End Response Time;Quality of Service Enforcements;Apache Storm},
doi={10.1109/NCA.2017.8171365},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9355671,
author={Harwood, Aaron and Read, Maria Rodriguez and Niroshana Amarasinghe, Gayashan},
booktitle={2020 IEEE 40th International Conference on Distributed Computing Systems (ICDCS)},
title={Dragon: A Lightweight, High Performance Distributed Stream Processing Engine},
year={2020},
volume={},
number={},
pages={1344-1351},
abstract={The performance of a distributed stream processing engine is traditionally considered in terms of fundamental measurements of latency and throughput. Recently, Apache Storm has demonstrated sub-millisecond latencies for inter-component tuple transmission, though it does so through aggressive throttling that leads to strict throughput limitations in order to keep tuple queues near empty. On the other hand, Apache Heron has excellent throughput characteristics, especially when operating near unstable conditions, but its inter-component latencies typically start around 10 milliseconds. Both of these systems require roughly 650MB of installation space. We have developed Dragon, loosely based on the same API as Storm and Heron, that is both lightweight, requiring just 7.5MB of installation space, and competitive in performance to Storm and Heron. In this paper we show experiments with all three systems using the Word Count benchmark. Dragon achieves throughput characteristics near to that of Heron and inter-component latencies less than 10ms under high load. In particular, Dragon's maximum latency is significantly less that Storm's maximum latency under high load. Finally Dragon managed to remain stable at higher effective throughput than Heron. We believe Dragon is a good "allrounder" solution and is particularly suitable for Edge computing applications, given its small installation footprint.},
keywords={Fault tolerance;Storms;Fault tolerant systems;Throughput;Sparks;Engines;Edge computing;stream processing engine;latency;throughput},
doi={10.1109/ICDCS47774.2020.00177},
ISSN={2575-8411},
month={Nov},}
@INPROCEEDINGS{6623627,
author={},
booktitle={2013 IEEE 12th International Symposium on Network Computing and Applications},
title={Table of contents},
year={2013},
volume={},
number={},
pages={v-viii},
abstract={The following topics are dealt with: data streaming; content management; cloud computing; distributed data processing; performance evaluation; SLA-aware resource management; energy-aware resource management; recommendation-aware trust evaluation; network configuration; network customization; and wireless sensor networks.},
keywords={},
doi={10.1109/NCA.2013.8},
ISSN={},
month={Aug},}